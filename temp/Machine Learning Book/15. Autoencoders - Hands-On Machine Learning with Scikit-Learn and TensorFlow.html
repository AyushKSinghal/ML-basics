<!--[if IE]><![endif]-->
<!DOCTYPE html>
<!--[if IE 8]><html class="no-js ie8 oldie" lang="en" prefix="og: http://ogp.me/ns/# og:book: http://ogp.me/ns/book# og:video: http://ogp.me/ns/video#"

    
        itemscope itemtype="http://schema.org/Book http://schema.org/ItemPage"" data-login-url="/accounts/login/"
data-offline-url="/"
data-url="/library/view/hands-on-machine-learning/9781491962282/ch10.html"
data-csrf-cookie="csrfsafari"
data-highlight-privacy="private"


  data-user-id="2309833"
  data-user-uuid="2d2acfb7-1cff-4dc7-9037-8ffbac19b02e"
  data-username="ayushksinghal"
  data-account-type="Trial"
  
  data-activated-trial-date="12/02/2017"


  data-archive="9781491962282"
  data-publishers="O&#39;Reilly Media, Inc."



  data-htmlfile-name="ch10.html"
  data-epub-title="Hands-On Machine Learning with Scikit-Learn and TensorFlow" data-debug=0 data-testing=0><![endif]-->
<!--[if gt IE 8]><!-->
<html class="js flexbox flexboxlegacy no-touch no-websqldatabase indexeddb history csscolumns csstransforms localstorage sessionstorage applicationcache svg inlinesvg no-zoom gr__safaribooksonline_com" prefix="og: http://ogp.me/ns/# og:book: http://ogp.me/ns/book# og:video: http://ogp.me/ns/video#" itemscope="" itemtype="http://schema.org/Book http://schema.org/ItemPage" "="" data-login-url="/accounts/login/" data-offline-url="/" data-url="/library/view/hands-on-machine-learning/9781491962282/ch10.html" data-csrf-cookie="csrfsafari" data-highlight-privacy="private" data-user-id="2309833" data-user-uuid="2d2acfb7-1cff-4dc7-9037-8ffbac19b02e" data-username="ayushksinghal" data-account-type="Trial" data-activated-trial-date="12/02/2017" data-archive="9781491962282" data-publishers="O'Reilly Media, Inc." data-htmlfile-name="ch10.html" data-epub-title="Hands-On Machine Learning with Scikit-Learn and TensorFlow" data-debug="0" data-testing="0" style="" data-ember-extension="1" lang="en"><!--<![endif]--><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="author" content="Safari Books Online"><meta name="format-detection" content="telephone=no"><meta http-equiv="cleartype" content="on"><meta name="HandheldFriendly" content="True"><meta name="MobileOptimized" content="320"><meta name="apple-itunes-app" content="app-id=881697395, app-argument=safaridetail://9781491962282"><meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, maximum-scale=1.0"><meta property="twitter:account_id" content="4503599627559754"><script type="text/javascript" src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/510f1a6865.js"></script><script src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/nr-spa-1044.js"></script><script type="text/javascript" async="" src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/linkid.js"></script><script src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/1732687426968531.js" async=""></script><script async="" src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/fbevents.js"></script><script type="text/javascript" async="" src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/bat.js"></script><script type="text/javascript" async="" src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/conversion_async.js"></script><script type="text/javascript" async="" src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/insight.js"></script><script type="text/javascript" async="" src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/conversion_async.js"></script><script async="" src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/gtm.js"></script><script async="" src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/analytics.js"></script><script type="text/javascript">(window.NREUM||(NREUM={})).loader_config={xpid:"VQQDUVVVGwACU1RUAQA="};window.NREUM||(NREUM={}),__nr_require=function(t,e,n){function r(n){if(!e[n]){var o=e[n]={exports:{}};t[n][0].call(o.exports,function(e){var o=t[n][1][e];return r(o||e)},o,o.exports)}return e[n].exports}if("function"==typeof __nr_require)return __nr_require;for(var o=0;o<n.length;o++)r(n[o]);return r}({1:[function(t,e,n){function r(t){try{c.console&&console.log(t)}catch(e){}}var o,i=t("ee"),a=t(19),c={};try{o=localStorage.getItem("__nr_flags").split(","),console&&"function"==typeof console.log&&(c.console=!0,o.indexOf("dev")!==-1&&(c.dev=!0),o.indexOf("nr_dev")!==-1&&(c.nrDev=!0))}catch(s){}c.nrDev&&i.on("internal-error",function(t){r(t.stack)}),c.dev&&i.on("fn-err",function(t,e,n){r(n.stack)}),c.dev&&(r("NR AGENT IN DEVELOPMENT MODE"),r("flags: "+a(c,function(t,e){return t}).join(", ")))},{}],2:[function(t,e,n){function r(t,e,n,r,o){try{d?d-=1:i("err",[o||new UncaughtException(t,e,n)])}catch(c){try{i("ierr",[c,s.now(),!0])}catch(u){}}return"function"==typeof f&&f.apply(this,a(arguments))}function UncaughtException(t,e,n){this.message=t||"Uncaught error with no additional information",this.sourceURL=e,this.line=n}function o(t){i("err",[t,s.now()])}var i=t("handle"),a=t(20),c=t("ee"),s=t("loader"),f=window.onerror,u=!1,d=0;s.features.err=!0,t(1),window.onerror=r;try{throw new Error}catch(p){"stack"in p&&(t(12),t(11),"addEventListener"in window&&t(6),s.xhrWrappable&&t(13),u=!0)}c.on("fn-start",function(t,e,n){u&&(d+=1)}),c.on("fn-err",function(t,e,n){u&&(this.thrown=!0,o(n))}),c.on("fn-end",function(){u&&!this.thrown&&d>0&&(d-=1)}),c.on("internal-error",function(t){i("ierr",[t,s.now(),!0])})},{}],3:[function(t,e,n){t("loader").features.ins=!0},{}],4:[function(t,e,n){function r(){C++,M=y.hash,this[u]=b.now()}function o(){C--,y.hash!==M&&i(0,!0);var t=b.now();this[l]=~~this[l]+t-this[u],this[d]=t}function i(t,e){E.emit("newURL",[""+y,e])}function a(t,e){t.on(e,function(){this[e]=b.now()})}var c="-start",s="-end",f="-body",u="fn"+c,d="fn"+s,p="cb"+c,h="cb"+s,l="jsTime",m="fetch",v="addEventListener",w=window,y=w.location,b=t("loader");if(w[v]&&b.xhrWrappable){var g=t(9),x=t(10),E=t(8),O=t(6),R=t(12),P=t(7),T=t(13),S=t("ee"),N=S.get("tracer");t(14),b.features.spa=!0;var M,j=w[v],C=0;S.on(u,r),S.on(p,r),S.on(d,o),S.on(h,o),S.buffer([u,d,"xhr-done","xhr-resolved"]),O.buffer([u]),R.buffer(["setTimeout"+s,"clearTimeout"+c,u]),T.buffer([u,"new-xhr","send-xhr"+c]),P.buffer([m+c,m+"-done",m+f+c,m+f+s]),E.buffer(["newURL"]),g.buffer([u]),x.buffer(["propagate",p,h,"executor-err","resolve"+c]),N.buffer([u,"no-"+u]),a(T,"send-xhr"+c),a(S,"xhr-resolved"),a(S,"xhr-done"),a(P,m+c),a(P,m+"-done"),E.on("pushState-end",i),E.on("replaceState-end",i),j("hashchange",i,!0),j("load",i,!0),j("popstate",function(){i(0,C>1)},!0)}},{}],5:[function(t,e,n){function r(t){}if(window.performance&&window.performance.timing&&window.performance.getEntriesByType){var o=t("ee"),i=t("handle"),a=t(12),c=t(11),s="learResourceTimings",f="addEventListener",u="resourcetimingbufferfull",d="bstResource",p="resource",h="-start",l="-end",m="fn"+h,v="fn"+l,w="bstTimer",y="pushState",b=t("loader");b.features.stn=!0,t(8);var g=NREUM.o.EV;o.on(m,function(t,e){var n=t[0];n instanceof g&&(this.bstStart=b.now())}),o.on(v,function(t,e){var n=t[0];n instanceof g&&i("bst",[n,e,this.bstStart,b.now()])}),a.on(m,function(t,e,n){this.bstStart=b.now(),this.bstType=n}),a.on(v,function(t,e){i(w,[e,this.bstStart,b.now(),this.bstType])}),c.on(m,function(){this.bstStart=b.now()}),c.on(v,function(t,e){i(w,[e,this.bstStart,b.now(),"requestAnimationFrame"])}),o.on(y+h,function(t){this.time=b.now(),this.startPath=location.pathname+location.hash}),o.on(y+l,function(t){i("bstHist",[location.pathname+location.hash,this.startPath,this.time])}),f in window.performance&&(window.performance["c"+s]?window.performance[f](u,function(t){i(d,[window.performance.getEntriesByType(p)]),window.performance["c"+s]()},!1):window.performance[f]("webkit"+u,function(t){i(d,[window.performance.getEntriesByType(p)]),window.performance["webkitC"+s]()},!1)),document[f]("scroll",r,{passive:!0}),document[f]("keypress",r,!1),document[f]("click",r,!1)}},{}],6:[function(t,e,n){function r(t){for(var e=t;e&&!e.hasOwnProperty(u);)e=Object.getPrototypeOf(e);e&&o(e)}function o(t){c.inPlace(t,[u,d],"-",i)}function i(t,e){return t[1]}var a=t("ee").get("events"),c=t(22)(a,!0),s=t("gos"),f=XMLHttpRequest,u="addEventListener",d="removeEventListener";e.exports=a,"getPrototypeOf"in Object?(r(document),r(window),r(f.prototype)):f.prototype.hasOwnProperty(u)&&(o(window),o(f.prototype)),a.on(u+"-start",function(t,e){var n=t[1],r=s(n,"nr@wrapped",function(){function t(){if("function"==typeof n.handleEvent)return n.handleEvent.apply(n,arguments)}var e={object:t,"function":n}[typeof n];return e?c(e,"fn-",null,e.name||"anonymous"):n});this.wrapped=t[1]=r}),a.on(d+"-start",function(t){t[1]=this.wrapped||t[1]})},{}],7:[function(t,e,n){function r(t,e,n){var r=t[e];"function"==typeof r&&(t[e]=function(){var t=r.apply(this,arguments);return o.emit(n+"start",arguments,t),t.then(function(e){return o.emit(n+"end",[null,e],t),e},function(e){throw o.emit(n+"end",[e],t),e})})}var o=t("ee").get("fetch"),i=t(19);e.exports=o;var a=window,c="fetch-",s=c+"body-",f=["arrayBuffer","blob","json","text","formData"],u=a.Request,d=a.Response,p=a.fetch,h="prototype";u&&d&&p&&(i(f,function(t,e){r(u[h],e,s),r(d[h],e,s)}),r(a,"fetch",c),o.on(c+"end",function(t,e){var n=this;e?e.clone().arrayBuffer().then(function(t){n.rxSize=t.byteLength,o.emit(c+"done",[null,e],n)}):o.emit(c+"done",[t],n)}))},{}],8:[function(t,e,n){var r=t("ee").get("history"),o=t(22)(r);e.exports=r,o.inPlace(window.history,["pushState","replaceState"],"-")},{}],9:[function(t,e,n){var r=t("ee").get("mutation"),o=t(22)(r),i=NREUM.o.MO;e.exports=r,i&&(window.MutationObserver=function(t){return this instanceof i?new i(o(t,"fn-")):i.apply(this,arguments)},MutationObserver.prototype=i.prototype)},{}],10:[function(t,e,n){function r(t){var e=a.context(),n=c(t,"executor-",e),r=new f(n);return a.context(r).getCtx=function(){return e},a.emit("new-promise",[r,e],e),r}function o(t,e){return e}var i=t(22),a=t("ee").get("promise"),c=i(a),s=t(19),f=NREUM.o.PR;e.exports=a,f&&(window.Promise=r,["all","race"].forEach(function(t){var e=f[t];f[t]=function(n){function r(t){return function(){a.emit("propagate",[null,!o],i),o=o||!t}}var o=!1;s(n,function(e,n){Promise.resolve(n).then(r("all"===t),r(!1))});var i=e.apply(f,arguments),c=f.resolve(i);return c}}),["resolve","reject"].forEach(function(t){var e=f[t];f[t]=function(t){var n=e.apply(f,arguments);return t!==n&&a.emit("propagate",[t,!0],n),n}}),f.prototype["catch"]=function(t){return this.then(null,t)},f.prototype=Object.create(f.prototype,{constructor:{value:r}}),s(Object.getOwnPropertyNames(f),function(t,e){try{r[e]=f[e]}catch(n){}}),a.on("executor-start",function(t){t[0]=c(t[0],"resolve-",this),t[1]=c(t[1],"resolve-",this)}),a.on("executor-err",function(t,e,n){t[1](n)}),c.inPlace(f.prototype,["then"],"then-",o),a.on("then-start",function(t,e){this.promise=e,t[0]=c(t[0],"cb-",this),t[1]=c(t[1],"cb-",this)}),a.on("then-end",function(t,e,n){this.nextPromise=n;var r=this.promise;a.emit("propagate",[r,!0],n)}),a.on("cb-end",function(t,e,n){a.emit("propagate",[n,!0],this.nextPromise)}),a.on("propagate",function(t,e,n){this.getCtx&&!e||(this.getCtx=function(){if(t instanceof Promise)var e=a.context(t);return e&&e.getCtx?e.getCtx():this})}),r.toString=function(){return""+f})},{}],11:[function(t,e,n){var r=t("ee").get("raf"),o=t(22)(r),i="equestAnimationFrame";e.exports=r,o.inPlace(window,["r"+i,"mozR"+i,"webkitR"+i,"msR"+i],"raf-"),r.on("raf-start",function(t){t[0]=o(t[0],"fn-")})},{}],12:[function(t,e,n){function r(t,e,n){t[0]=a(t[0],"fn-",null,n)}function o(t,e,n){this.method=n,this.timerDuration=isNaN(t[1])?0:+t[1],t[0]=a(t[0],"fn-",this,n)}var i=t("ee").get("timer"),a=t(22)(i),c="setTimeout",s="setInterval",f="clearTimeout",u="-start",d="-";e.exports=i,a.inPlace(window,[c,"setImmediate"],c+d),a.inPlace(window,[s],s+d),a.inPlace(window,[f,"clearImmediate"],f+d),i.on(s+u,r),i.on(c+u,o)},{}],13:[function(t,e,n){function r(t,e){d.inPlace(e,["onreadystatechange"],"fn-",c)}function o(){var t=this,e=u.context(t);t.readyState>3&&!e.resolved&&(e.resolved=!0,u.emit("xhr-resolved",[],t)),d.inPlace(t,y,"fn-",c)}function i(t){b.push(t),l&&(x?x.then(a):v?v(a):(E=-E,O.data=E))}function a(){for(var t=0;t<b.length;t++)r([],b[t]);b.length&&(b=[])}function c(t,e){return e}function s(t,e){for(var n in t)e[n]=t[n];return e}t(6);var f=t("ee"),u=f.get("xhr"),d=t(22)(u),p=NREUM.o,h=p.XHR,l=p.MO,m=p.PR,v=p.SI,w="readystatechange",y=["onload","onerror","onabort","onloadstart","onloadend","onprogress","ontimeout"],b=[];e.exports=u;var g=window.XMLHttpRequest=function(t){var e=new h(t);try{u.emit("new-xhr",[e],e),e.addEventListener(w,o,!1)}catch(n){try{u.emit("internal-error",[n])}catch(r){}}return e};if(s(h,g),g.prototype=h.prototype,d.inPlace(g.prototype,["open","send"],"-xhr-",c),u.on("send-xhr-start",function(t,e){r(t,e),i(e)}),u.on("open-xhr-start",r),l){var x=m&&m.resolve();if(!v&&!m){var E=1,O=document.createTextNode(E);new l(a).observe(O,{characterData:!0})}}else f.on("fn-end",function(t){t[0]&&t[0].type===w||a()})},{}],14:[function(t,e,n){function r(t){var e=this.params,n=this.metrics;if(!this.ended){this.ended=!0;for(var r=0;r<d;r++)t.removeEventListener(u[r],this.listener,!1);if(!e.aborted){if(n.duration=a.now()-this.startTime,4===t.readyState){e.status=t.status;var i=o(t,this.lastSize);if(i&&(n.rxSize=i),this.sameOrigin){var s=t.getResponseHeader("X-NewRelic-App-Data");s&&(e.cat=s.split(", ").pop())}}else e.status=0;n.cbTime=this.cbTime,f.emit("xhr-done",[t],t),c("xhr",[e,n,this.startTime])}}}function o(t,e){var n=t.responseType;if("json"===n&&null!==e)return e;var r="arraybuffer"===n||"blob"===n||"json"===n?t.response:t.responseText;return l(r)}function i(t,e){var n=s(e),r=t.params;r.host=n.hostname+":"+n.port,r.pathname=n.pathname,t.sameOrigin=n.sameOrigin}var a=t("loader");if(a.xhrWrappable){var c=t("handle"),s=t(15),f=t("ee"),u=["load","error","abort","timeout"],d=u.length,p=t("id"),h=t(18),l=t(17),m=window.XMLHttpRequest;a.features.xhr=!0,t(13),f.on("new-xhr",function(t){var e=this;e.totalCbs=0,e.called=0,e.cbTime=0,e.end=r,e.ended=!1,e.xhrGuids={},e.lastSize=null,h&&(h>34||h<10)||window.opera||t.addEventListener("progress",function(t){e.lastSize=t.loaded},!1)}),f.on("open-xhr-start",function(t){this.params={method:t[0]},i(this,t[1]),this.metrics={}}),f.on("open-xhr-end",function(t,e){"loader_config"in NREUM&&"xpid"in NREUM.loader_config&&this.sameOrigin&&e.setRequestHeader("X-NewRelic-ID",NREUM.loader_config.xpid)}),f.on("send-xhr-start",function(t,e){var n=this.metrics,r=t[0],o=this;if(n&&r){var i=l(r);i&&(n.txSize=i)}this.startTime=a.now(),this.listener=function(t){try{"abort"===t.type&&(o.params.aborted=!0),("load"!==t.type||o.called===o.totalCbs&&(o.onloadCalled||"function"!=typeof e.onload))&&o.end(e)}catch(n){try{f.emit("internal-error",[n])}catch(r){}}};for(var c=0;c<d;c++)e.addEventListener(u[c],this.listener,!1)}),f.on("xhr-cb-time",function(t,e,n){this.cbTime+=t,e?this.onloadCalled=!0:this.called+=1,this.called!==this.totalCbs||!this.onloadCalled&&"function"==typeof n.onload||this.end(n)}),f.on("xhr-load-added",function(t,e){var n=""+p(t)+!!e;this.xhrGuids&&!this.xhrGuids[n]&&(this.xhrGuids[n]=!0,this.totalCbs+=1)}),f.on("xhr-load-removed",function(t,e){var n=""+p(t)+!!e;this.xhrGuids&&this.xhrGuids[n]&&(delete this.xhrGuids[n],this.totalCbs-=1)}),f.on("addEventListener-end",function(t,e){e instanceof m&&"load"===t[0]&&f.emit("xhr-load-added",[t[1],t[2]],e)}),f.on("removeEventListener-end",function(t,e){e instanceof m&&"load"===t[0]&&f.emit("xhr-load-removed",[t[1],t[2]],e)}),f.on("fn-start",function(t,e,n){e instanceof m&&("onload"===n&&(this.onload=!0),("load"===(t[0]&&t[0].type)||this.onload)&&(this.xhrCbStart=a.now()))}),f.on("fn-end",function(t,e){this.xhrCbStart&&f.emit("xhr-cb-time",[a.now()-this.xhrCbStart,this.onload,e],e)})}},{}],15:[function(t,e,n){e.exports=function(t){var e=document.createElement("a"),n=window.location,r={};e.href=t,r.port=e.port;var o=e.href.split("://");!r.port&&o[1]&&(r.port=o[1].split("/")[0].split("@").pop().split(":")[1]),r.port&&"0"!==r.port||(r.port="https"===o[0]?"443":"80"),r.hostname=e.hostname||n.hostname,r.pathname=e.pathname,r.protocol=o[0],"/"!==r.pathname.charAt(0)&&(r.pathname="/"+r.pathname);var i=!e.protocol||":"===e.protocol||e.protocol===n.protocol,a=e.hostname===document.domain&&e.port===n.port;return r.sameOrigin=i&&(!e.hostname||a),r}},{}],16:[function(t,e,n){function r(){}function o(t,e,n){return function(){return i(t,[f.now()].concat(c(arguments)),e?null:this,n),e?void 0:this}}var i=t("handle"),a=t(19),c=t(20),s=t("ee").get("tracer"),f=t("loader"),u=NREUM;"undefined"==typeof window.newrelic&&(newrelic=u);var d=["setPageViewName","setCustomAttribute","setErrorHandler","finished","addToTrace","inlineHit","addRelease"],p="api-",h=p+"ixn-";a(d,function(t,e){u[e]=o(p+e,!0,"api")}),u.addPageAction=o(p+"addPageAction",!0),u.setCurrentRouteName=o(p+"routeName",!0),e.exports=newrelic,u.interaction=function(){return(new r).get()};var l=r.prototype={createTracer:function(t,e){var n={},r=this,o="function"==typeof e;return i(h+"tracer",[f.now(),t,n],r),function(){if(s.emit((o?"":"no-")+"fn-start",[f.now(),r,o],n),o)try{return e.apply(this,arguments)}finally{s.emit("fn-end",[f.now()],n)}}}};a("setName,setAttribute,save,ignore,onEnd,getContext,end,get".split(","),function(t,e){l[e]=o(h+e)}),newrelic.noticeError=function(t){"string"==typeof t&&(t=new Error(t)),i("err",[t,f.now()])}},{}],17:[function(t,e,n){e.exports=function(t){if("string"==typeof t&&t.length)return t.length;if("object"==typeof t){if("undefined"!=typeof ArrayBuffer&&t instanceof ArrayBuffer&&t.byteLength)return t.byteLength;if("undefined"!=typeof Blob&&t instanceof Blob&&t.size)return t.size;if(!("undefined"!=typeof FormData&&t instanceof FormData))try{return JSON.stringify(t).length}catch(e){return}}}},{}],18:[function(t,e,n){var r=0,o=navigator.userAgent.match(/Firefox[\/\s](\d+\.\d+)/);o&&(r=+o[1]),e.exports=r},{}],19:[function(t,e,n){function r(t,e){var n=[],r="",i=0;for(r in t)o.call(t,r)&&(n[i]=e(r,t[r]),i+=1);return n}var o=Object.prototype.hasOwnProperty;e.exports=r},{}],20:[function(t,e,n){function r(t,e,n){e||(e=0),"undefined"==typeof n&&(n=t?t.length:0);for(var r=-1,o=n-e||0,i=Array(o<0?0:o);++r<o;)i[r]=t[e+r];return i}e.exports=r},{}],21:[function(t,e,n){e.exports={exists:"undefined"!=typeof window.performance&&window.performance.timing&&"undefined"!=typeof window.performance.timing.navigationStart}},{}],22:[function(t,e,n){function r(t){return!(t&&t instanceof Function&&t.apply&&!t[a])}var o=t("ee"),i=t(20),a="nr@original",c=Object.prototype.hasOwnProperty,s=!1;e.exports=function(t,e){function n(t,e,n,o){function nrWrapper(){var r,a,c,s;try{a=this,r=i(arguments),c="function"==typeof n?n(r,a):n||{}}catch(f){p([f,"",[r,a,o],c])}u(e+"start",[r,a,o],c);try{return s=t.apply(a,r)}catch(d){throw u(e+"err",[r,a,d],c),d}finally{u(e+"end",[r,a,s],c)}}return r(t)?t:(e||(e=""),nrWrapper[a]=t,d(t,nrWrapper),nrWrapper)}function f(t,e,o,i){o||(o="");var a,c,s,f="-"===o.charAt(0);for(s=0;s<e.length;s++)c=e[s],a=t[c],r(a)||(t[c]=n(a,f?c+o:o,i,c))}function u(n,r,o){if(!s||e){var i=s;s=!0;try{t.emit(n,r,o,e)}catch(a){p([a,n,r,o])}s=i}}function d(t,e){if(Object.defineProperty&&Object.keys)try{var n=Object.keys(t);return n.forEach(function(n){Object.defineProperty(e,n,{get:function(){return t[n]},set:function(e){return t[n]=e,e}})}),e}catch(r){p([r])}for(var o in t)c.call(t,o)&&(e[o]=t[o]);return e}function p(e){try{t.emit("internal-error",e)}catch(n){}}return t||(t=o),n.inPlace=f,n.flag=a,n}},{}],ee:[function(t,e,n){function r(){}function o(t){function e(t){return t&&t instanceof r?t:t?s(t,c,i):i()}function n(n,r,o,i){if(!p.aborted||i){t&&t(n,r,o);for(var a=e(o),c=l(n),s=c.length,f=0;f<s;f++)c[f].apply(a,r);var d=u[y[n]];return d&&d.push([b,n,r,a]),a}}function h(t,e){w[t]=l(t).concat(e)}function l(t){return w[t]||[]}function m(t){return d[t]=d[t]||o(n)}function v(t,e){f(t,function(t,n){e=e||"feature",y[n]=e,e in u||(u[e]=[])})}var w={},y={},b={on:h,emit:n,get:m,listeners:l,context:e,buffer:v,abort:a,aborted:!1};return b}function i(){return new r}function a(){(u.api||u.feature)&&(p.aborted=!0,u=p.backlog={})}var c="nr@context",s=t("gos"),f=t(19),u={},d={},p=e.exports=o();p.backlog=u},{}],gos:[function(t,e,n){function r(t,e,n){if(o.call(t,e))return t[e];var r=n();if(Object.defineProperty&&Object.keys)try{return Object.defineProperty(t,e,{value:r,writable:!0,enumerable:!1}),r}catch(i){}return t[e]=r,r}var o=Object.prototype.hasOwnProperty;e.exports=r},{}],handle:[function(t,e,n){function r(t,e,n,r){o.buffer([t],r),o.emit(t,e,n)}var o=t("ee").get("handle");e.exports=r,r.ee=o},{}],id:[function(t,e,n){function r(t){var e=typeof t;return!t||"object"!==e&&"function"!==e?-1:t===window?0:a(t,i,function(){return o++})}var o=1,i="nr@id",a=t("gos");e.exports=r},{}],loader:[function(t,e,n){function r(){if(!x++){var t=g.info=NREUM.info,e=p.getElementsByTagName("script")[0];if(setTimeout(u.abort,3e4),!(t&&t.licenseKey&&t.applicationID&&e))return u.abort();f(y,function(e,n){t[e]||(t[e]=n)}),s("mark",["onload",a()+g.offset],null,"api");var n=p.createElement("script");n.src="https://"+t.agent,e.parentNode.insertBefore(n,e)}}function o(){"complete"===p.readyState&&i()}function i(){s("mark",["domContent",a()+g.offset],null,"api")}function a(){return E.exists&&performance.now?Math.round(performance.now()):(c=Math.max((new Date).getTime(),c))-g.offset}var c=(new Date).getTime(),s=t("handle"),f=t(19),u=t("ee"),d=window,p=d.document,h="addEventListener",l="attachEvent",m=d.XMLHttpRequest,v=m&&m.prototype;NREUM.o={ST:setTimeout,SI:d.setImmediate,CT:clearTimeout,XHR:m,REQ:d.Request,EV:d.Event,PR:d.Promise,MO:d.MutationObserver};var w=""+location,y={beacon:"bam.nr-data.net",errorBeacon:"bam.nr-data.net",agent:"js-agent.newrelic.com/nr-spa-1044.min.js"},b=m&&v&&v[h]&&!/CriOS/.test(navigator.userAgent),g=e.exports={offset:c,now:a,origin:w,features:{},xhrWrappable:b};t(16),p[h]?(p[h]("DOMContentLoaded",i,!1),d[h]("load",r,!1)):(p[l]("onreadystatechange",o),d[l]("onload",r)),s("mark",["firstbyte",c],null,"api");var x=0,E=t(21)},{}]},{},["loader",2,14,5,3,4]);</script><link rel="apple-touch-icon" href="https://www.safaribooksonline.com/static/images/apple-touch-icon.8cc2fd27400e.png"><link rel="shortcut icon" href="https://www.safaribooksonline.com/favicon.ico" type="image/x-icon"><link href="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/css.css" rel="stylesheet" type="text/css"><title>15. Autoencoders - Hands-On Machine Learning with Scikit-Learn and TensorFlow</title><link rel="stylesheet" href="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/d6ec1592ffb3.css" type="text/css"><link rel="stylesheet" type="text/css" href="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/annotator.css"><link rel="stylesheet" href="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/font-awesome.css"><style type="text/css" title="ibis-book">@charset "utf-8";#sbo-rt-content html,#sbo-rt-content div,#sbo-rt-content div,#sbo-rt-content span,#sbo-rt-content applet,#sbo-rt-content object,#sbo-rt-content iframe,#sbo-rt-content h1,#sbo-rt-content h2,#sbo-rt-content h3,#sbo-rt-content h4,#sbo-rt-content h5,#sbo-rt-content h6,#sbo-rt-content p,#sbo-rt-content blockquote,#sbo-rt-content pre,#sbo-rt-content a,#sbo-rt-content abbr,#sbo-rt-content acronym,#sbo-rt-content address,#sbo-rt-content big,#sbo-rt-content cite,#sbo-rt-content code,#sbo-rt-content del,#sbo-rt-content dfn,#sbo-rt-content em,#sbo-rt-content img,#sbo-rt-content ins,#sbo-rt-content kbd,#sbo-rt-content q,#sbo-rt-content s,#sbo-rt-content samp,#sbo-rt-content small,#sbo-rt-content strike,#sbo-rt-content strong,#sbo-rt-content sub,#sbo-rt-content sup,#sbo-rt-content tt,#sbo-rt-content var,#sbo-rt-content b,#sbo-rt-content u,#sbo-rt-content i,#sbo-rt-content center,#sbo-rt-content dl,#sbo-rt-content dt,#sbo-rt-content dd,#sbo-rt-content ol,#sbo-rt-content ul,#sbo-rt-content li,#sbo-rt-content fieldset,#sbo-rt-content form,#sbo-rt-content label,#sbo-rt-content legend,#sbo-rt-content table,#sbo-rt-content caption,#sbo-rt-content tdiv,#sbo-rt-content tfoot,#sbo-rt-content thead,#sbo-rt-content tr,#sbo-rt-content th,#sbo-rt-content td,#sbo-rt-content article,#sbo-rt-content aside,#sbo-rt-content canvas,#sbo-rt-content details,#sbo-rt-content embed,#sbo-rt-content figure,#sbo-rt-content figcaption,#sbo-rt-content footer,#sbo-rt-content header,#sbo-rt-content hgroup,#sbo-rt-content menu,#sbo-rt-content nav,#sbo-rt-content output,#sbo-rt-content ruby,#sbo-rt-content section,#sbo-rt-content summary,#sbo-rt-content time,#sbo-rt-content mark,#sbo-rt-content audio,#sbo-rt-content video{margin:0;padding:0;border:0;font-size:100%;font:inherit;vertical-align:baseline}#sbo-rt-content article,#sbo-rt-content aside,#sbo-rt-content details,#sbo-rt-content figcaption,#sbo-rt-content figure,#sbo-rt-content footer,#sbo-rt-content header,#sbo-rt-content hgroup,#sbo-rt-content menu,#sbo-rt-content nav,#sbo-rt-content section{display:block}#sbo-rt-content div{line-height:1}#sbo-rt-content ol,#sbo-rt-content ul{list-style:none}#sbo-rt-content blockquote,#sbo-rt-content q{quotes:none}#sbo-rt-content blockquote:before,#sbo-rt-content blockquote:after,#sbo-rt-content q:before,#sbo-rt-content q:after{content:none}#sbo-rt-content table{border-collapse:collapse;border-spacing:0}@page{margin:5px !important}#sbo-rt-content p{margin:10px 0 0;line-height:125%;text-align:left}#sbo-rt-content p.byline{text-align:left;margin:-33px auto 35px;font-style:italic;font-weight:bold}#sbo-rt-content div.preface p+p.byline{margin:1em 0 0}#sbo-rt-content div.preface p.byline+p.byline{margin:0}#sbo-rt-content div.sect1>p.byline{margin:-.25em 0 1em}#sbo-rt-content div.sect1>p.byline+p.byline{margin-top:-1em}#sbo-rt-content em{font-style:italic;font-family:inherit}#sbo-rt-content em strong,#sbo-rt-content strong em{font-weight:bold;font-style:italic;font-family:inherit}#sbo-rt-content strong,#sbo-rt-content span.bold{font-weight:bold}#sbo-rt-content em.replaceable{font-style:italic}#sbo-rt-content strong.userinput{font-weight:bold;font-style:normal}#sbo-rt-content span.bolditalic{font-weight:bold;font-style:italic}#sbo-rt-content a.ulink,#sbo-rt-content a.xref,#sbo-rt-content a.email,#sbo-rt-content a.link,#sbo-rt-content a{text-decoration:none;color:#8e0012}#sbo-rt-content span.lineannotation{font-style:italic;color:#a62a2a;font-family:serif}#sbo-rt-content span.underline{text-decoration:underline}#sbo-rt-content span.strikethrough{text-decoration:line-through}#sbo-rt-content span.smallcaps{font-variant:small-caps}#sbo-rt-content span.cursor{background:#000;color:#fff}#sbo-rt-content span.smaller{font-size:75%}#sbo-rt-content .boxedtext,#sbo-rt-content .keycap{border-style:solid;border-width:1px;border-color:#000;padding:1px}#sbo-rt-content span.gray50{color:#7F7F7F;}#sbo-rt-content h1,#sbo-rt-content div.toc-title,#sbo-rt-content h2,#sbo-rt-content h3,#sbo-rt-content h4,#sbo-rt-content h5{-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;font-weight:bold;text-align:left;page-break-after:avoid !important;font-family:sans-serif,"DejaVuSans"}#sbo-rt-content div.toc-title{font-size:1.5em;margin-top:20px !important;margin-bottom:30px !important}#sbo-rt-content section[data-type="sect1"] h1{font-size:1.3em;color:#8e0012;margin:40px 0 8px 0}#sbo-rt-content section[data-type="sect2"] h2{font-size:1.1em;margin:30px 0 8px 0 !important}#sbo-rt-content section[data-type="sect3"] h3{font-size:1em;color:#555;margin:20px 0 8px 0 !important}#sbo-rt-content section[data-type="sect4"] h4{font-size:1em;font-weight:normal;font-style:italic;margin:15px 0 6px 0 !important}#sbo-rt-content section[data-type="chapter"]>div>h1,#sbo-rt-content section[data-type="preface"]>div>h1,#sbo-rt-content section[data-type="appendix"]>div>h1,#sbo-rt-content section[data-type="glossary"]>div>h1,#sbo-rt-content section[data-type="bibliography"]>div>h1,#sbo-rt-content section[data-type="index"]>div>h1{font-size:2em;line-height:1;margin-bottom:50px;color:#000;padding-bottom:10px;border-bottom:1px solid #000}#sbo-rt-content span.label,#sbo-rt-content span.keep-together{font-size:inherit;font-weight:inherit}#sbo-rt-content div[data-type="part"] h1{font-size:2em;text-align:center;margin-top:0 !important;margin-bottom:50px;padding:50px 0 10px 0;border-bottom:1px solid #000}#sbo-rt-content img.width-ninety{width:90%}#sbo-rt-content img{max-width:95%;margin:0 auto;padding:0}#sbo-rt-content div.figure{background-color:transparent;text-align:center !important;margin:15px 0 15px 0 !important;page-break-inside:avoid}#sbo-rt-content figure{margin:15px 0 15px 0 !important;page-break-inside:avoid}#sbo-rt-content div.figure h6{font-size:90%;text-align:center;font-weight:normal;font-style:italic;font-family:serif !important;color:#000;padding-top:10px !important;page-break-before:avoid;page-break-after:avoid}#sbo-rt-content div.informalfigure{text-align:center !important;padding:5px 0 !important}#sbo-rt-content div.sidebar{margin:15px 0 10px 0 !important;border:1px solid #DCDCDC;background-color:#F7F7F7;padding:15px !important;page-break-inside:avoid}#sbo-rt-content aside[data-type="sidebar"]{margin:15px 0 10px 0 !important;page-break-inside:avoid}#sbo-rt-content div.sidebar-title,#sbo-rt-content aside[data-type="sidebar"] h5{font-weight:bold;font-size:1em;font-family:sans-serif;text-transform:uppercase;letter-spacing:1px;text-align:center;margin:4px 0 6px 0 !important;page-break-inside:avoid}#sbo-rt-content div.sidebar ol,#sbo-rt-content div.sidebar ul,#sbo-rt-content aside[data-type="sidebar"] ol,#sbo-rt-content aside[data-type="sidebar"] ul{margin-left:1.25em !important}#sbo-rt-content div.sidebar div.figure p.title,#sbo-rt-content aside[data-type="sidebar"] figcaption,#sbo-rt-content div.sidebar div.informalfigure div.caption{font-size:90%;text-align:center;font-weight:normal;font-style:italic;font-family:serif !important;color:#000;padding:5px !important;page-break-before:avoid;page-break-after:avoid}#sbo-rt-content div.sidebar div.tip,#sbo-rt-content div.sidebar div[data-type="tip"],#sbo-rt-content div.sidebar div.note,#sbo-rt-content div.sidebar div[data-type="note"],#sbo-rt-content div.sidebar div.warning,#sbo-rt-content div.sidebar div[data-type="warning"],#sbo-rt-content div.sidebar div[data-type="caution"],#sbo-rt-content div.sidebar div[data-type="important"]{margin:20px auto 20px auto !important;font-size:90%;width:85%}#sbo-rt-content aside[data-type="sidebar"] p.byline{font-size:90%;font-weight:bold;font-style:italic;text-align:center;text-indent:0;margin:5px auto 6px;page-break-after:avoid}#sbo-rt-content pre{white-space:pre-wrap;font-family:"Ubuntu Mono",monospace;margin:25px 0 25px 20px;font-size:85%;display:block;-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;overflow-wrap:break-word}#sbo-rt-content div.note pre.programlisting,#sbo-rt-content div.tip pre.programlisting,#sbo-rt-content div.warning pre.programlisting,#sbo-rt-content div.caution pre.programlisting,#sbo-rt-content div.important pre.programlisting{margin-bottom:0}#sbo-rt-content code{font-family:"Ubuntu Mono",monospace;-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;overflow-wrap:break-word}#sbo-rt-content code strong em,#sbo-rt-content code em strong,#sbo-rt-content pre em strong,#sbo-rt-content pre strong em,#sbo-rt-content strong code em code,#sbo-rt-content em code strong code,#sbo-rt-content span.bolditalic code{font-weight:bold;font-style:italic;font-family:"Ubuntu Mono BoldItal",monospace}#sbo-rt-content code em,#sbo-rt-content em code,#sbo-rt-content pre em,#sbo-rt-content em.replaceable{font-family:"Ubuntu Mono Ital",monospace;font-style:italic}#sbo-rt-content code strong,#sbo-rt-content strong code,#sbo-rt-content pre strong,#sbo-rt-content strong.userinput{font-family:"Ubuntu Mono Bold",monospace;font-weight:bold}#sbo-rt-content div[data-type="example"]{margin:10px 0 15px 0 !important}#sbo-rt-content div[data-type="example"] h1,#sbo-rt-content div[data-type="example"] h2,#sbo-rt-content div[data-type="example"] h3,#sbo-rt-content div[data-type="example"] h4,#sbo-rt-content div[data-type="example"] h5,#sbo-rt-content div[data-type="example"] h6{font-style:italic;font-weight:normal;text-align:left !important;text-transform:none !important;font-family:serif !important;margin:10px 0 5px 0 !important;border-bottom:1px solid #000}#sbo-rt-content li pre.example{padding:10px 0 !important}#sbo-rt-content div[data-type="example"] pre[data-type="programlisting"],#sbo-rt-content div[data-type="example"] pre[data-type="screen"]{margin:0}#sbo-rt-content section[data-type="titlepage"]>div>h1{font-size:2em;margin:50px 0 10px 0 !important;line-height:1;text-align:center}#sbo-rt-content section[data-type="titlepage"] h2,#sbo-rt-content section[data-type="titlepage"] p.subtitle,#sbo-rt-content section[data-type="titlepage"] p[data-type="subtitle"]{font-size:1.3em;font-weight:normal;text-align:center;margin-top:.5em;color:#555}#sbo-rt-content section[data-type="titlepage"]>div>h2[data-type="author"],#sbo-rt-content section[data-type="titlepage"] p.author{font-size:1.3em;font-family:serif !important;font-weight:bold;margin:50px 0 !important;text-align:center}#sbo-rt-content section[data-type="titlepage"] p.edition{text-align:center;text-transform:uppercase;margin-top:2em}#sbo-rt-content section[data-type="titlepage"]{text-align:center}#sbo-rt-content section[data-type="titlepage"]:after{content:url(css_assets/titlepage_footer_ebook.png);margin:0 auto;max-width:80%}#sbo-rt-content div.book div.titlepage div.publishername{margin-top:60%;margin-bottom:20px;text-align:center;font-size:1.25em}#sbo-rt-content div.book div.titlepage div.locations p{margin:0;text-align:center}#sbo-rt-content div.book div.titlepage div.locations p.cities{font-size:80%;text-align:center;margin-top:5px}#sbo-rt-content section.preface[title="Dedication"]>div.titlepage h2.title{text-align:center;text-transform:uppercase;font-size:1.5em;margin-top:50px;margin-bottom:50px}#sbo-rt-content ul.stafflist{margin:15px 0 15px 20px !important}#sbo-rt-content ul.stafflist li{list-style-type:none;padding:5px 0}#sbo-rt-content ul.printings li{list-style-type:none}#sbo-rt-content section.preface[title="Dedication"] p{font-style:italic;text-align:center}#sbo-rt-content div.colophon h1.title{font-size:1.3em;margin:0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon h2.subtitle{margin:0 !important;color:#000;font-family:serif !important;font-size:1em;font-weight:normal}#sbo-rt-content div.colophon div.author h3.author{font-size:1.1em;font-family:serif !important;margin:10px 0 0 !important;font-weight:normal}#sbo-rt-content div.colophon div.editor h4,#sbo-rt-content div.colophon div.editor h3.editor{color:#000;font-size:.8em;margin:15px 0 0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon div.editor h3.editor{font-size:.8em;margin:0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon div.publisher{margin-top:10px}#sbo-rt-content div.colophon div.publisher p,#sbo-rt-content div.colophon div.publisher span.publishername{margin:0;font-size:.8em}#sbo-rt-content div.legalnotice p,#sbo-rt-content div.timestamp p{font-size:.8em}#sbo-rt-content div.timestamp p{margin-top:10px}#sbo-rt-content div.colophon[title="About the Author"] h1.title,#sbo-rt-content div.colophon[title="Colophon"] h1.title{font-size:1.5em;margin:0 !important;font-family:sans-serif !important}#sbo-rt-content section.chapter div.titlepage div.author{margin:10px 0 10px 0}#sbo-rt-content section.chapter div.titlepage div.author div.affiliation{font-style:italic}#sbo-rt-content div.attribution{margin:5px 0 0 50px !important}#sbo-rt-content h3.author span.orgname{display:none}#sbo-rt-content div.epigraph{margin:10px 0 10px 20px !important;page-break-inside:avoid;font-size:90%}#sbo-rt-content div.epigraph p{font-style:italic}#sbo-rt-content blockquote,#sbo-rt-content div.blockquote{margin:10px !important;page-break-inside:avoid;font-size:95%}#sbo-rt-content blockquote p,#sbo-rt-content div.blockquote p{font-style:italic;margin:.75em 0 0 !important}#sbo-rt-content blockquote div.attribution,#sbo-rt-content blockquote p[data-type="attribution"]{margin:5px 0 10px 30px !important;text-align:right;width:80%}#sbo-rt-content blockquote div.attribution p,#sbo-rt-content blockquote p[data-type="attribution"]{font-style:normal;margin-top:5px}#sbo-rt-content blockquote div.attribution p:before,#sbo-rt-content blockquote p[data-type="attribution"]:before{font-style:normal;content:"—";-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none}#sbo-rt-content p.right{text-align:right;margin:0}#sbo-rt-content div[data-type="footnotes"]{border-top:1px solid black;margin-top:1.5em}#sbo-rt-content sub,#sbo-rt-content sup{font-size:75%;line-height:0;position:relative}#sbo-rt-content sup{top:-.5em}#sbo-rt-content sub{bottom:-.25em}#sbo-rt-content div.refentry p.refname{font-size:1em;font-family:sans-serif,"DejaVuSans";font-weight:bold;margin-bottom:5px;overflow:auto;width:100%}#sbo-rt-content div.refentry{width:100%;display:block;margin-top:2em}#sbo-rt-content div.refsynopsisdiv{display:block;clear:both}#sbo-rt-content div.refentry header{page-break-inside:avoid !important;display:block;break-inside:avoid !important;padding-top:0;border-bottom:1px solid #000}#sbo-rt-content div.refsect1 h6{font-size:.9em;font-family:sans-serif,"DejaVuSans";font-weight:bold}#sbo-rt-content div.refsect1{margin-top:3em}#sbo-rt-content dt{padding-top:10px !important;padding-bottom:0 !important}#sbo-rt-content dd{margin-left:1.5em !important;margin-bottom:.25em}#sbo-rt-content dd ol,#sbo-rt-content dd ul{padding-left:1em}#sbo-rt-content dd li{margin-top:0;margin-bottom:0}#sbo-rt-content dd,#sbo-rt-content li{text-align:left}#sbo-rt-content ul,#sbo-rt-content ul>li,#sbo-rt-content ol ul,#sbo-rt-content ol ul>li,#sbo-rt-content ul ol ul,#sbo-rt-content ul ol ul>li{list-style-type:disc}#sbo-rt-content ul ul,#sbo-rt-content ul ul>li{list-style-type:square}#sbo-rt-content ul ul ul,#sbo-rt-content ul ul ul>li{list-style-type:circle}#sbo-rt-content ol,#sbo-rt-content ol>li,#sbo-rt-content ol ul ol,#sbo-rt-content ol ul ol>li,#sbo-rt-content ul ol,#sbo-rt-content ul ol>li{list-style-type:decimal}#sbo-rt-content ol ol,#sbo-rt-content ol ol>li{list-style-type:lower-alpha}#sbo-rt-content ol ol ol,#sbo-rt-content ol ol ol>li{list-style-type:lower-roman}#sbo-rt-content ol,#sbo-rt-content ul{list-style-position:outside;margin:15px 0 15px 1.25em;padding-left:2.25em}#sbo-rt-content ol li,#sbo-rt-content ul li{margin:.5em 0 .65em;line-height:125%}#sbo-rt-content div.orderedlistalpha{list-style-type:upper-alpha}#sbo-rt-content table.simplelist,#sbo-rt-content ul.simplelist{margin:15px 0 15px 20px !important}#sbo-rt-content ul.simplelist li{list-style-type:none;padding:5px 0}#sbo-rt-content table.simplelist td{border:none}#sbo-rt-content table.simplelist tr{border-bottom:none}#sbo-rt-content table.simplelist tr:nth-of-type(even){background-color:transparent}#sbo-rt-content dl.calloutlist p:first-child{margin-top:-25px !important}#sbo-rt-content dl.calloutlist dd{padding-left:0;margin-top:-25px}#sbo-rt-content dl.calloutlist img,#sbo-rt-content a.co img{padding:0}#sbo-rt-content div.toc ol{margin-top:8px !important;margin-bottom:8px !important;margin-left:0 !important;padding-left:0 !important}#sbo-rt-content div.toc ol ol{margin-left:30px !important;padding-left:0 !important}#sbo-rt-content div.toc ol li{list-style-type:none}#sbo-rt-content div.toc a{color:#8e0012}#sbo-rt-content div.toc ol a{font-size:1em;font-weight:bold}#sbo-rt-content div.toc ol>li>ol a{font-weight:bold;font-size:1em}#sbo-rt-content div.toc ol>li>ol>li>ol a{text-decoration:none;font-weight:normal;font-size:1em}#sbo-rt-content div.tip,#sbo-rt-content div[data-type="tip"],#sbo-rt-content div.note,#sbo-rt-content div[data-type="note"],#sbo-rt-content div.warning,#sbo-rt-content div[data-type="warning"],#sbo-rt-content div[data-type="caution"],#sbo-rt-content div[data-type="important"]{margin:30px !important;font-size:90%;padding:10px 8px 20px 8px !important;page-break-inside:avoid}#sbo-rt-content div.tip ol,#sbo-rt-content div.tip ul,#sbo-rt-content div[data-type="tip"] ol,#sbo-rt-content div[data-type="tip"] ul,#sbo-rt-content div.note ol,#sbo-rt-content div.note ul,#sbo-rt-content div[data-type="note"] ol,#sbo-rt-content div[data-type="note"] ul,#sbo-rt-content div.warning ol,#sbo-rt-content div.warning ul,#sbo-rt-content div[data-type="warning"] ol,#sbo-rt-content div[data-type="warning"] ul,#sbo-rt-content div[data-type="caution"] ol,#sbo-rt-content div[data-type="caution"] ul,#sbo-rt-content div[data-type="important"] ol,#sbo-rt-content div[data-type="important"] ul{margin-left:1.5em !important}#sbo-rt-content div.tip,#sbo-rt-content div[data-type="tip"],#sbo-rt-content div.note,#sbo-rt-content div[data-type="note"]{border:1px solid #BEBEBE;background-color:transparent}#sbo-rt-content div.warning,#sbo-rt-content div[data-type="warning"],#sbo-rt-content div[data-type="caution"],#sbo-rt-content div[data-type="important"]{border:1px solid #BC8F8F}#sbo-rt-content div.tip h3,#sbo-rt-content div[data-type="tip"] h6,#sbo-rt-content div[data-type="tip"] h1,#sbo-rt-content div.note h3,#sbo-rt-content div[data-type="note"] h6,#sbo-rt-content div[data-type="note"] h1,#sbo-rt-content div.warning h3,#sbo-rt-content div[data-type="warning"] h6,#sbo-rt-content div[data-type="warning"] h1,#sbo-rt-content div[data-type="caution"] h6,#sbo-rt-content div[data-type="caution"] h1,#sbo-rt-content div[data-type="important"] h1,#sbo-rt-content div[data-type="important"] h6{font-weight:bold;font-size:110%;font-family:sans-serif !important;text-transform:uppercase;letter-spacing:1px;text-align:center;margin:4px 0 6px !important}#sbo-rt-content div.tip h3,#sbo-rt-content div[data-type="tip"] h6,#sbo-rt-content div.note h3,#sbo-rt-content div[data-type="note"] h6,#sbo-rt-content div[data-type="tip"] h1,#sbo-rt-content div[data-type="note"] h1{color:#737373}#sbo-rt-content div.warning h3,#sbo-rt-content div[data-type="warning"] h6,#sbo-rt-content div[data-type="caution"] h6,#sbo-rt-content div[data-type="important"] h6,#sbo-rt-content div[data-type="warning"] h1,#sbo-rt-content div[data-type="caution"] h1,#sbo-rt-content div[data-type="important"] h1{color:#C67171}#sbo-rt-content div.sect1[title="Safari® Books Online"] div.note,#sbo-rt-content div.safarienabled{background-color:transparent;margin:8px 0 0 !important;border:0 solid #BEBEBE;font-size:100%;padding:0 !important;page-break-inside:avoid}#sbo-rt-content div.sect1[title="Safari® Books Online"] div.note h3,#sbo-rt-content div.safarienabled h6{display:none}#sbo-rt-content div.table,#sbo-rt-content table{margin:15px 0 30px 0 !important;max-width:95%;border:none !important;background:none;display:table !important}#sbo-rt-content div.table,#sbo-rt-content div.informaltable,#sbo-rt-content table{page-break-inside:avoid}#sbo-rt-content tr,#sbo-rt-content tr td{border-bottom:1px solid #c3c3c3}#sbo-rt-content thead td,#sbo-rt-content thead th{border-bottom:#9d9d9d 1px solid !important;border-top:#9d9d9d 1px solid !important}#sbo-rt-content tr:nth-of-type(even){background-color:#f1f6fc}#sbo-rt-content thead{font-family:sans-serif;font-weight:bold}#sbo-rt-content td,#sbo-rt-content th{display:table-cell;padding:.3em;text-align:left;vertical-align:middle;font-size:80%}#sbo-rt-content div.informaltable table{margin:10px auto !important}#sbo-rt-content div.informaltable table tr{border-bottom:none}#sbo-rt-content div.informaltable table tr:nth-of-type(even){background-color:transparent}#sbo-rt-content div.informaltable td,#sbo-rt-content div.informaltable th{border:#9d9d9d 1px solid}#sbo-rt-content div.table-title,#sbo-rt-content table caption{font-weight:normal;font-style:italic;font-family:serif;font-size:1em;margin:10px 0 10px 0 !important;padding:0;page-break-after:avoid;text-align:left !important}#sbo-rt-content table code{font-size:smaller}#sbo-rt-content div.equation,#sbo-rt-content div[data-type="equation"]{margin:10px 0 15px 0 !important}#sbo-rt-content div.equation-title,#sbo-rt-content div[data-type="equation"] h5{font-style:italic;font-weight:normal;font-family:serif !important;font-size:90%;margin:20px 0 10px 0 !important;page-break-after:avoid}#sbo-rt-content div.equation-contents{margin-left:20px}#sbo-rt-content span.inlinemediaobject{height:.85em;display:inline-block;margin-bottom:.2em}#sbo-rt-content span.inlinemediaobject img{margin:0;height:.85em}#sbo-rt-content div.informalequation{margin:20px 0 20px 20px;width:75%}#sbo-rt-content div.informalequation img{width:75%}#sbo-rt-content div.index{text-indent:0}#sbo-rt-content div.index li{line-height:140%}#sbo-rt-content div.index a.indexterm{color:#8e0012}#sbo-rt-content div.index ul,#sbo-rt-content div[data-type="index"] ul{list-style-type:none;padding-left:0;margin-left:0}#sbo-rt-content div.index ul li{padding-left:0;margin-left:0}#sbo-rt-content div.index ul li ul li{margin-left:1em}#sbo-rt-content code.boolean,#sbo-rt-content .navy{color:rgb(0,0,128);}#sbo-rt-content code.character,#sbo-rt-content .olive{color:rgb(128,128,0);}#sbo-rt-content code.comment,#sbo-rt-content .blue{color:rgb(0,0,255);}#sbo-rt-content code.conditional,#sbo-rt-content .limegreen{color:rgb(50,205,50);}#sbo-rt-content code.constant,#sbo-rt-content .darkorange{color:rgb(255,140,0);}#sbo-rt-content code.debug,#sbo-rt-content .darkred{color:rgb(139,0,0);}#sbo-rt-content code.define,#sbo-rt-content .darkgoldenrod,#sbo-rt-content .gold{color:rgb(184,134,11);}#sbo-rt-content code.delimiter,#sbo-rt-content .dimgray{color:rgb(105,105,105);}#sbo-rt-content code.error,#sbo-rt-content .red{color:rgb(255,0,0);}#sbo-rt-content code.exception,#sbo-rt-content .salmon{color:rgb(250,128,11);}#sbo-rt-content code.float,#sbo-rt-content .steelblue{color:rgb(70,130,180);}#sbo-rt-content pre code.function,#sbo-rt-content .green{color:rgb(0,128,0);}#sbo-rt-content code.identifier,#sbo-rt-content .royalblue{color:rgb(65,105,225);}#sbo-rt-content code.ignore,#sbo-rt-content .gray{color:rgb(128,128,128);}#sbo-rt-content code.include,#sbo-rt-content .purple{color:rgb(128,0,128);}#sbo-rt-content code.keyword,#sbo-rt-content .sienna{color:rgb(160,82,45);}#sbo-rt-content code.label,#sbo-rt-content .deeppink{color:rgb(255,20,147);}#sbo-rt-content code.macro,#sbo-rt-content .orangered{color:rgb(255,69,0);}#sbo-rt-content code.number,#sbo-rt-content .brown{color:rgb(165,42,42);}#sbo-rt-content code.operator,#sbo-rt-content .black{color:#000;}#sbo-rt-content code.preCondit,#sbo-rt-content .teal{color:rgb(0,128,128);}#sbo-rt-content code.preProc,#sbo-rt-content .fuschia{color:rgb(255,0,255);}#sbo-rt-content code.repeat,#sbo-rt-content .indigo{color:rgb(75,0,130);}#sbo-rt-content code.special,#sbo-rt-content .saddlebrown{color:rgb(139,69,19);}#sbo-rt-content code.specialchar,#sbo-rt-content .magenta{color:rgb(255,0,255);}#sbo-rt-content code.specialcomment,#sbo-rt-content .seagreen{color:rgb(46,139,87);}#sbo-rt-content code.statement,#sbo-rt-content .forestgreen{color:rgb(34,139,34);}#sbo-rt-content code.storageclass,#sbo-rt-content .plum{color:rgb(221,160,221);}#sbo-rt-content code.string,#sbo-rt-content .darkred{color:rgb(139,0,0);}#sbo-rt-content code.structure,#sbo-rt-content .chocolate{color:rgb(210,106,30);}#sbo-rt-content code.tag,#sbo-rt-content .darkcyan{color:rgb(0,139,139);}#sbo-rt-content code.todo,#sbo-rt-content .black{color:#000;}#sbo-rt-content code.type,#sbo-rt-content .mediumslateblue{color:rgb(123,104,238);}#sbo-rt-content code.typedef,#sbo-rt-content .darkgreen{color:rgb(0,100,0);}#sbo-rt-content code.underlined{text-decoration:underline;}#sbo-rt-content pre code.hll{background-color:#ffc}#sbo-rt-content pre code.c{color:#09F;font-style:italic}#sbo-rt-content pre code.err{color:#A00}#sbo-rt-content pre code.k{color:#069;font-weight:bold}#sbo-rt-content pre code.o{color:#555}#sbo-rt-content pre code.cm{color:#35586C;font-style:italic}#sbo-rt-content pre code.cp{color:#099}#sbo-rt-content pre code.c1{color:#35586C;font-style:italic}#sbo-rt-content pre code.cs{color:#35586C;font-weight:bold;font-style:italic}#sbo-rt-content pre code.gd{background-color:#FCC}#sbo-rt-content pre code.ge{font-style:italic}#sbo-rt-content pre code.gr{color:#F00}#sbo-rt-content pre code.gh{color:#030;font-weight:bold}#sbo-rt-content pre code.gi{background-color:#CFC}#sbo-rt-content pre code.go{color:#000}#sbo-rt-content pre code.gp{color:#009;font-weight:bold}#sbo-rt-content pre code.gs{font-weight:bold}#sbo-rt-content pre code.gu{color:#030;font-weight:bold}#sbo-rt-content pre code.gt{color:#9C6}#sbo-rt-content pre code.kc{color:#069;font-weight:bold}#sbo-rt-content pre code.kd{color:#069;font-weight:bold}#sbo-rt-content pre code.kn{color:#069;font-weight:bold}#sbo-rt-content pre code.kp{color:#069}#sbo-rt-content pre code.kr{color:#069;font-weight:bold}#sbo-rt-content pre code.kt{color:#078;font-weight:bold}#sbo-rt-content pre code.m{color:#F60}#sbo-rt-content pre code.s{color:#C30}#sbo-rt-content pre code.na{color:#309}#sbo-rt-content pre code.nb{color:#366}#sbo-rt-content pre code.nc{color:#0A8;font-weight:bold}#sbo-rt-content pre code.no{color:#360}#sbo-rt-content pre code.nd{color:#99F}#sbo-rt-content pre code.ni{color:#999;font-weight:bold}#sbo-rt-content pre code.ne{color:#C00;font-weight:bold}#sbo-rt-content pre code.nf{color:#C0F}#sbo-rt-content pre code.nl{color:#99F}#sbo-rt-content pre code.nn{color:#0CF;font-weight:bold}#sbo-rt-content pre code.nt{color:#309;font-weight:bold}#sbo-rt-content pre code.nv{color:#033}#sbo-rt-content pre code.ow{color:#000;font-weight:bold}#sbo-rt-content pre code.w{color:#bbb}#sbo-rt-content pre code.mf{color:#F60}#sbo-rt-content pre code.mh{color:#F60}#sbo-rt-content pre code.mi{color:#F60}#sbo-rt-content pre code.mo{color:#F60}#sbo-rt-content pre code.sb{color:#C30}#sbo-rt-content pre code.sc{color:#C30}#sbo-rt-content pre code.sd{color:#C30;font-style:italic}#sbo-rt-content pre code.s2{color:#C30}#sbo-rt-content pre code.se{color:#C30;font-weight:bold}#sbo-rt-content pre code.sh{color:#C30}#sbo-rt-content pre code.si{color:#A00}#sbo-rt-content pre code.sx{color:#C30}#sbo-rt-content pre code.sr{color:#3AA}#sbo-rt-content pre code.s1{color:#C30}#sbo-rt-content pre code.ss{color:#A60}#sbo-rt-content pre code.bp{color:#366}#sbo-rt-content pre code.vc{color:#033}#sbo-rt-content pre code.vg{color:#033}#sbo-rt-content pre code.vi{color:#033}#sbo-rt-content pre code.il{color:#F60}#sbo-rt-content pre code.g{color:#050}#sbo-rt-content pre code.l{color:#C60}#sbo-rt-content pre code.l{color:#F90}#sbo-rt-content pre code.n{color:#008}#sbo-rt-content pre code.nx{color:#008}#sbo-rt-content pre code.py{color:#96F}#sbo-rt-content pre code.p{color:#000}#sbo-rt-content pre code.x{color:#F06}#sbo-rt-content div.blockquote_sampler_toc{width:95%;margin:5px 5px 5px 10px !important}#sbo-rt-content div{font-family:serif;text-align:left}#sbo-rt-content .gray-background,#sbo-rt-content .reverse-video{background:#2E2E2E;color:#FFF}#sbo-rt-content .light-gray-background{background:#A0A0A0}#sbo-rt-content .preserve-whitespace{white-space:pre-wrap}#sbo-rt-content span.gray{color:#4C4C4C}#sbo-rt-content div[data-type="equation"].fifty-percent img{width:50%}</style><script> // <![CDATA[
    var g = {
      position_cache: {
        
          "chapter": "/api/v1/book/9781491962282/chapter/ch10.html",
          "book_id": "9781491962282",
          "chapter_uri": "ch10.html",
          "position": 2.55275831017,
          "user_uuid": "2d2acfb7-1cff-4dc7-9037-8ffbac19b02e",
          "next_chapter_uri": "/library/view/hands-on-machine-learning/9781491962282/ch11.html"
        
      },
      title: "Hands\u002DOn Machine Learning with Scikit\u002DLearn and TensorFlow",
      author_list: "Aurélien Géron",
      format: "book",
      source: "application/epub+zip",
      is_system_book: true,
      is_public: false,
      loaded_from_server: true,
      allow_scripts: false,
      has_mathml: false,
      show_ios_app_teaser: false
    };
    // ]]></script><script src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/modernizr.js"></script><script>
    
      
        

        

        
          
            window.PUBLIC_ANNOTATIONS = true;
          
        

      

      
        window.MOBILE_PUBLIC_ANNOTATIONS = false;
      

    

    
      window.PRIVACY_CONTROL_OVERRIDE = false;
    

    
      window.PRIVACY_CONTROL_SWITCH = true;
    

    
      window.PUBLISHER_PAGES = true;
    

      window.SBO = {
        "constants": {
          "SITB_ENDPOINT": "https://www.safaribooksonline.com/api/v2/sitb/",
          "SEARCH_SELECT_ENDPOINT": "https://www.safaribooksonline.com/api/v2/search/select/",
          "ENABLE_ONLINE_TRAINING": true
        }
      };
  </script><link rel="canonical" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html"><meta name="description" content=" Chapter 10. Introduction to Artificial Neural Networks Birds inspired us to fly, burdock plants inspired velcro, and nature has inspired many other inventions. It seems only logical, then, to look ... "><meta property="og:title" content="10. Introduction to Artificial Neural Networks"><meta itemprop="isPartOf" content="/library/view/hands-on-machine-learning/9781491962282/"><meta itemprop="name" content="10. Introduction to Artificial Neural Networks"><meta property="og:url" itemprop="url" content="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html"><meta property="og:site_name" content="Safari"><meta property="og:image" itemprop="thumbnailUrl" content="https://www.safaribooksonline.com/library/cover/9781491962282/"><meta property="og:description" itemprop="description" content=" Chapter 10. Introduction to Artificial Neural Networks Birds inspired us to fly, burdock plants inspired velcro, and nature has inspired many other inventions. It seems only logical, then, to look ... "><meta itemprop="inLanguage" content="en"><meta itemprop="publisher" content="O'Reilly Media, Inc."><meta property="og:type" content="book"><meta property="og:book:isbn" itemprop="isbn" content="9781491962299"><meta property="og:book:author" itemprop="author" content="Aurélien Géron"><meta property="og:book:tag" itemprop="about" content="Core Programming"><meta property="og:book:tag" itemprop="about" content="Engineering"><meta property="og:book:tag" itemprop="about" content="Python"><meta name="twitter:card" content="summary"><meta name="twitter:site" content="@safari"><style type="text/css" id="font-styles" data-template="#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-size: &lt;%= font_size %&gt; !important; }"></style><style type="text/css" id="font-family" data-template="#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-family: &lt;%= font_family %&gt; !important; }"></style><style type="text/css" id="column-width" data-template="#sbo-rt-content { max-width: &lt;%= column_width %&gt;% !important; margin: 0 auto !important; }"></style><noscript><meta http-equiv="refresh" content="0; url=/library/no-js/" /></noscript><script type="text/javascript">
  (function(i,s,o,g,r,a,m) {
    i['GoogleAnalyticsObject']=r;
    i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();
    a=s.createElement(o),m=s.getElementsByTagName(o)[0];
    a.async=1;
    a.src=g;
    m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  var matches = document.cookie.match(/BrowserCookie\s*=\s*([a-f0-9\-]{36})/),
      user_uuid = null;

  if (matches && matches.length === 2) {
    user_uuid = matches[1];
  }


  ga('create', 'UA-39299553-7', {'userId': '2d2acfb7-1cff-4dc7-9037-8ffbac19b02e' });



  
    ga('set', 'dimension1', 'Trial');
  


ga('set', 'dimension6', user_uuid);


  ga('set', 'dimension2', '2d2acfb7-1cff-4dc7-9037-8ffbac19b02e');
  






//enable enhanced link tracking
ga('require', 'linkid', 'linkid.js');

// reading interface will track pageviews itself
if (document.location.pathname.indexOf("/library/view") !== 0) {
  ga('send', 'pageview');
}
</script><script>
    (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    '//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-5P4V6Z');
  </script><script defer="defer" src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/vendor.js"></script><script defer="defer" src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/reader.js"></script><script async="" src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/MathJax.js"></script><style id="annotator-dynamic-style">.annotator-adder, .annotator-outer, .annotator-notice {
  z-index: 100019;
}
.annotator-filter {
  z-index: 100009;
}</style><script src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/a_002.js"></script><script src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/a_003.js"></script></head>


<body class="reading sidenav nav-collapsed  scalefonts subscribe-panel library" data-gr-c-s-loaded="true">

    
  
  <noscript> 
    <iframe src="//www.googletagmanager.com/ns.html?id=GTM-5P4V6Z"
            height="0" width="0"
            style="display:none;visibility:hidden">
    </iframe>
  </noscript>
  



    
      <div class="working hide" role="status">
        <div class="working-image"></div>
      </div>
      <div class="sbo-site-nav">
        





<a href="#container" class="skip">Skip to content</a><header class="topbar t-topbar"><nav role="navigation" class="js-site-nav"><ul class="topnav"><li class="t-logo"><a href="https://www.safaribooksonline.com/home/" class="l0 None safari-home nav-icn js-keyboard-nav-home"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width="20" height="20" version="1.1" fill="#4A3C31"><desc>Safari Home Icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M4 9.9L4 9.9 4 18 16 18 16 9.9 10 4 4 9.9ZM2.6 8.1L2.6 8.1 8.7 1.9 10 0.5 11.3 1.9 17.4 8.1 18 8.7 18 9.5 18 18.1 18 20 16.1 20 3.9 20 2 20 2 18.1 2 9.5 2 8.7 2.6 8.1Z"></path><rect x="10" y="12" width="3" height="7"></rect><rect transform="translate(18.121320, 10.121320) rotate(-315.000000) translate(-18.121320, -10.121320) " x="16.1" y="9.1" width="4" height="2"></rect><rect transform="translate(2.121320, 10.121320) scale(-1, 1) rotate(-315.000000) translate(-2.121320, -10.121320) " x="0.1" y="9.1" width="4" height="2"></rect></g></svg><span>Safari Home</span></a></li><li><a href="https://www.safaribooksonline.com/r/" class="t-recommendations-nav l0 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>recommendations icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M50 25C50 18.2 44.9 12.5 38.3 11.7 37.5 5.1 31.8 0 25 0 18.2 0 12.5 5.1 11.7 11.7 5.1 12.5 0 18.2 0 25 0 31.8 5.1 37.5 11.7 38.3 12.5 44.9 18.2 50 25 50 31.8 50 37.5 44.9 38.3 38.3 44.9 37.5 50 31.8 50 25ZM25 3.1C29.7 3.1 33.6 6.9 34.4 11.8 30.4 12.4 26.9 15.1 25 18.8 23.1 15.1 19.6 12.4 15.6 11.8 16.4 6.9 20.3 3.1 25 3.1ZM34.4 15.6C33.6 19.3 30.7 22.2 27.1 22.9 27.8 19.2 30.7 16.3 34.4 15.6ZM22.9 22.9C19.2 22.2 16.3 19.3 15.6 15.6 19.3 16.3 22.2 19.2 22.9 22.9ZM3.1 25C3.1 20.3 6.9 16.4 11.8 15.6 12.4 19.6 15.1 23.1 18.8 25 15.1 26.9 12.4 30.4 11.8 34.4 6.9 33.6 3.1 29.7 3.1 25ZM22.9 27.1C22.2 30.7 19.3 33.6 15.6 34.4 16.3 30.7 19.2 27.8 22.9 27.1ZM25 46.9C20.3 46.9 16.4 43.1 15.6 38.2 19.6 37.6 23.1 34.9 25 31.3 26.9 34.9 30.4 37.6 34.4 38.2 33.6 43.1 29.7 46.9 25 46.9ZM27.1 27.1C30.7 27.8 33.6 30.7 34.4 34.4 30.7 33.6 27.8 30.7 27.1 27.1ZM38.2 34.4C37.6 30.4 34.9 26.9 31.3 25 34.9 23.1 37.6 19.6 38.2 15.6 43.1 16.4 46.9 20.3 46.9 25 46.9 29.7 43.1 33.6 38.2 34.4Z"></path></g></svg><span>Recommended</span></a></li><li><a href="https://www.safaribooksonline.com/s/" class="t-queue-nav l0 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>queue icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M25 29.2C25.4 29.2 25.8 29.1 26.1 28.9L48.7 16.8C49.5 16.4 50 15.5 50 14.6 50 13.7 49.5 12.8 48.7 12.4L26.1 0.3C25.4-0.1 24.6-0.1 23.9 0.3L1.3 12.4C0.5 12.8 0 13.7 0 14.6 0 15.5 0.5 16.4 1.3 16.8L23.9 28.9C24.2 29.1 24.6 29.2 25 29.2ZM7.3 14.6L25 5.2 42.7 14.6 25 24 7.3 14.6ZM48.7 22.4L47.7 21.9 25 34.2 2.3 21.9 1.3 22.4C0.5 22.9 0 23.7 0 24.7 0 25.6 0.5 26.5 1.3 26.9L23.9 39.3C24.2 39.5 24.6 39.6 25 39.6 25.4 39.6 25.8 39.5 26.1 39.3L48.7 26.9C49.5 26.5 50 25.6 50 24.7 50 23.7 49.5 22.9 48.7 22.4ZM48.7 32.8L47.7 32.3 25 44.6 2.3 32.3 1.3 32.8C0.5 33.3 0 34.1 0 35.1 0 36 0.5 36.9 1.3 37.3L23.9 49.7C24.2 49.9 24.6 50 25 50 25.4 50 25.8 49.9 26.1 49.7L48.7 37.3C49.5 36.9 50 36 50 35.1 50 34.1 49.5 33.3 48.7 32.8Z"></path></g></svg><span>
                  Queue
              </span></a></li><li class="search"><a href="#" class="t-search-nav trigger nav-icn l0" data-dropdown-selector=".searchbox"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>search icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M31.3 0C20.9 0 12.5 8.4 12.5 18.8 12.5 22.5 13.6 25.9 15.4 28.8L1.2 42.9C-0.4 44.5-0.4 47.2 1.2 48.8 2 49.6 3.1 50 4.2 50 5.2 50 6.3 49.6 7.1 48.8L21.2 34.6C24.1 36.5 27.5 37.5 31.3 37.5 41.6 37.5 50 29.1 50 18.8 50 8.4 41.6 0 31.3 0ZM31.3 31.3C24.4 31.3 18.8 25.6 18.8 18.8 18.8 11.9 24.4 6.3 31.3 6.3 38.1 6.3 43.8 11.9 43.8 18.8 43.8 25.6 38.1 31.3 31.3 31.3Z"></path></g></svg><span>Search</span></a></li><li class="usermenu dropdown"><a href="#" class="trigger l0 nav-icn nav-dropdown"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width="20" height="20" version="1.1" fill="#4A3C31"><desc>navigation arrow</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M0.1 12.5L9.7 3.1C9.8 3 9.9 3 10 3 10.1 3 10.2 3 10.3 3.1L19.9 12.5C20 12.5 20 12.6 20 12.8 20 12.9 20 13 19.9 13L17 15.9C16.9 16 16.8 16 16.7 16 16.5 16 16.4 16 16.4 15.9L10 9.7 3.6 15.9C3.6 16 3.5 16 3.3 16 3.2 16 3.1 16 3 15.9L0.1 13C0 12.9 0 12.8 0 12.7 0 12.7 0 12.6 0.1 12.5Z"></path></g></svg><span>Expand Nav</span></a><div class="drop-content"><ul><li><a href="https://www.safaribooksonline.com/history/" class="t-recent-nav l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>recent items icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M25 0C11.2 0 0 11.2 0 25 0 38.8 11.2 50 25 50 38.8 50 50 38.8 50 25 50 11.2 38.8 0 25 0ZM6.3 25C6.3 14.6 14.6 6.3 25 6.3 35.4 6.3 43.8 14.6 43.8 25 43.8 35.4 35.4 43.8 25 43.8 14.6 43.8 6.3 35.4 6.3 25ZM31.8 31.5C32.5 30.5 32.4 29.2 31.6 28.3L27.1 23.8 27.1 12.8C27.1 11.5 26.2 10.4 25 10.4 23.9 10.4 22.9 11.5 22.9 12.8L22.9 25.7 28.8 31.7C29.2 32.1 29.7 32.3 30.2 32.3 30.8 32.3 31.3 32 31.8 31.5Z"></path></g></svg><span>History</span></a></li><li><a href="https://www.safaribooksonline.com/topics" class="t-topics-link l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 55" width="20" height="20" version="1.1" fill="#4A3C31"><desc>topics icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M25 55L50 41.262 50 13.762 25 0 0 13.762 0 41.262 25 55ZM8.333 37.032L8.333 17.968 25 8.462 41.667 17.968 41.667 37.032 25 46.538 8.333 37.032Z"></path></g></svg><span>Topics</span></a></li><li><a href="https://www.safaribooksonline.com/tutorials/" class="l1 nav-icn t-tutorials-nav js-toggle-menu-item None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width="20" height="20" version="1.1" fill="#4A3C31"><desc>tutorials icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M15.8 18.2C15.8 18.2 15.9 18.2 16 18.2 16.1 18.2 16.2 18.2 16.4 18.2 16.5 18.2 16.7 18.1 16.9 18 17 17.9 17.1 17.8 17.2 17.7 17.3 17.6 17.4 17.5 17.4 17.4 17.5 17.2 17.6 16.9 17.6 16.7 17.6 16.6 17.6 16.5 17.6 16.4 17.5 16.2 17.5 16.1 17.4 15.9 17.3 15.8 17.2 15.6 17 15.5 16.8 15.3 16.6 15.3 16.4 15.2 16.2 15.2 16 15.2 15.8 15.2 15.7 15.2 15.5 15.3 15.3 15.4 15.2 15.4 15.1 15.5 15 15.7 14.9 15.8 14.8 15.9 14.7 16 14.7 16.1 14.6 16.3 14.6 16.4 14.6 16.5 14.6 16.6 14.6 16.6 14.6 16.7 14.6 16.9 14.6 17 14.6 17.1 14.7 17.3 14.7 17.4 14.8 17.6 15 17.7 15.1 17.9 15.2 18 15.3 18 15.5 18.1 15.5 18.1 15.6 18.2 15.7 18.2 15.7 18.2 15.7 18.2 15.8 18.2L15.8 18.2ZM9.4 11.5C9.5 11.5 9.5 11.5 9.6 11.5 9.7 11.5 9.9 11.5 10 11.5 10.2 11.5 10.3 11.4 10.5 11.3 10.6 11.2 10.8 11.1 10.9 11 10.9 10.9 11 10.8 11.1 10.7 11.2 10.5 11.2 10.2 11.2 10 11.2 9.9 11.2 9.8 11.2 9.7 11.2 9.5 11.1 9.4 11 9.2 10.9 9.1 10.8 8.9 10.6 8.8 10.5 8.7 10.3 8.6 10 8.5 9.9 8.5 9.7 8.5 9.5 8.5 9.3 8.5 9.1 8.6 9 8.7 8.8 8.7 8.7 8.8 8.6 9 8.5 9.1 8.4 9.2 8.4 9.3 8.2 9.5 8.2 9.8 8.2 10 8.2 10.1 8.2 10.2 8.2 10.3 8.2 10.5 8.3 10.6 8.4 10.7 8.5 10.9 8.6 11.1 8.7 11.2 8.9 11.3 9 11.4 9.1 11.4 9.2 11.4 9.3 11.5 9.3 11.5 9.3 11.5 9.4 11.5 9.4 11.5L9.4 11.5ZM3 4.8C3.1 4.8 3.1 4.8 3.2 4.8 3.4 4.8 3.5 4.8 3.7 4.8 3.8 4.8 4 4.7 4.1 4.6 4.3 4.5 4.4 4.4 4.5 4.3 4.6 4.2 4.6 4.1 4.7 4 4.8 3.8 4.8 3.5 4.8 3.3 4.8 3.1 4.8 3 4.8 2.9 4.7 2.8 4.7 2.6 4.6 2.5 4.5 2.3 4.4 2.2 4.2 2.1 4 1.9 3.8 1.9 3.6 1.8 3.5 1.8 3.3 1.8 3.1 1.8 2.9 1.8 2.7 1.9 2.6 2 2.4 2.1 2.3 2.2 2.2 2.3 2.1 2.4 2 2.5 2 2.6 1.8 2.8 1.8 3 1.8 3.3 1.8 3.4 1.8 3.5 1.8 3.6 1.8 3.8 1.9 3.9 2 4 2.1 4.2 2.2 4.4 2.4 4.5 2.5 4.6 2.6 4.7 2.7 4.7 2.8 4.7 2.9 4.8 2.9 4.8 3 4.8 3 4.8 3 4.8L3 4.8ZM13.1 15.2C13.2 15.1 13.2 15.1 13.2 15.1 13.3 14.9 13.4 14.7 13.6 14.5 13.8 14.2 14.1 14 14.4 13.8 14.7 13.6 15.1 13.5 15.5 13.4 15.9 13.4 16.3 13.4 16.7 13.5 17.2 13.5 17.6 13.7 17.9 13.9 18.2 14.1 18.5 14.4 18.7 14.7 18.9 15 19.1 15.3 19.2 15.6 19.3 15.9 19.4 16.1 19.4 16.4 19.4 17 19.3 17.5 19.1 18.1 19 18.3 18.9 18.5 18.7 18.7 18.5 19 18.3 19.2 18 19.4 17.7 19.6 17.3 19.8 16.9 19.9 16.6 20 16.3 20 16 20 15.8 20 15.6 20 15.4 19.9 15.4 19.9 15.4 19.9 15.4 19.9 15.2 19.9 15 19.8 14.9 19.8 14.8 19.7 14.7 19.7 14.6 19.7 14.4 19.6 14.3 19.5 14.1 19.3 13.7 19.1 13.4 18.7 13.2 18.4 13.1 18.1 12.9 17.8 12.9 17.5 12.8 17.3 12.8 17.1 12.8 16.9L3.5 14.9C3.3 14.9 3.1 14.8 3 14.8 2.7 14.7 2.4 14.5 2.1 14.3 1.7 14 1.4 13.7 1.2 13.3 1 13 0.9 12.6 0.8 12.3 0.7 12 0.7 11.7 0.7 11.4 0.7 11 0.8 10.5 1 10.1 1.1 9.8 1.3 9.5 1.6 9.2 1.8 8.9 2.1 8.7 2.4 8.5 2.8 8.3 3.2 8.1 3.6 8.1 3.9 8 4.2 8 4.5 8 4.6 8 4.8 8 4.9 8.1L6.8 8.5C6.8 8.4 6.8 8.4 6.8 8.4 6.9 8.2 7.1 8 7.2 7.8 7.5 7.5 7.7 7.3 8 7.1 8.4 6.9 8.7 6.8 9.1 6.7 9.5 6.7 10 6.7 10.4 6.8 10.8 6.8 11.2 7 11.5 7.2 11.8 7.5 12.1 7.7 12.4 8 12.6 8.3 12.7 8.6 12.8 8.9 12.9 9.2 13 9.4 13 9.7 13 9.7 13 9.8 13 9.8 13.6 9.9 14.2 10.1 14.9 10.2 15 10.2 15 10.2 15.1 10.2 15.3 10.2 15.4 10.2 15.6 10.2 15.8 10.1 16 10 16.2 9.9 16.4 9.8 16.5 9.6 16.6 9.5 16.8 9.2 16.9 8.8 16.9 8.5 16.9 8.3 16.9 8.2 16.8 8 16.8 7.8 16.7 7.7 16.6 7.5 16.5 7.3 16.3 7.2 16.2 7.1 16 7 15.9 6.9 15.8 6.9 15.7 6.9 15.6 6.8 15.5 6.8L6.2 4.8C6.2 5 6 5.2 5.9 5.3 5.7 5.6 5.5 5.8 5.3 6 4.9 6.2 4.5 6.4 4.1 6.5 3.8 6.6 3.5 6.6 3.2 6.6 3 6.6 2.8 6.6 2.7 6.6 2.6 6.6 2.6 6.5 2.6 6.5 2.5 6.5 2.3 6.5 2.1 6.4 1.8 6.3 1.6 6.1 1.3 6 1 5.7 0.7 5.4 0.5 5 0.3 4.7 0.2 4.4 0.1 4.1 0 3.8 0 3.6 0 3.3 0 2.8 0.1 2.2 0.4 1.7 0.5 1.5 0.7 1.3 0.8 1.1 1.1 0.8 1.3 0.6 1.6 0.5 2 0.3 2.3 0.1 2.7 0.1 3.1 0 3.6 0 4 0.1 4.4 0.2 4.8 0.3 5.1 0.5 5.5 0.8 5.7 1 6 1.3 6.2 1.6 6.3 1.9 6.4 2.3 6.5 2.5 6.6 2.7 6.6 3 6.6 3 6.6 3.1 6.6 3.1 9.7 3.8 12.8 4.4 15.9 5.1 16.1 5.1 16.2 5.2 16.4 5.2 16.7 5.3 16.9 5.5 17.2 5.6 17.5 5.9 17.8 6.2 18.1 6.5 18.3 6.8 18.4 7.2 18.6 7.5 18.6 7.9 18.7 8.2 18.7 8.6 18.7 9 18.6 9.4 18.4 9.8 18.3 10.1 18.2 10.3 18 10.6 17.8 10.9 17.5 11.1 17.3 11.3 16.9 11.6 16.5 11.8 16 11.9 15.7 12 15.3 12 15 12 14.8 12 14.7 12 14.5 11.9 13.9 11.8 13.3 11.7 12.6 11.5 12.5 11.7 12.4 11.9 12.3 12 12.1 12.3 11.9 12.5 11.7 12.7 11.3 12.9 10.9 13.1 10.5 13.2 10.2 13.3 9.9 13.3 9.6 13.3 9.4 13.3 9.2 13.3 9 13.2 9 13.2 9 13.2 9 13.2 8.8 13.2 8.7 13.2 8.5 13.1 8.2 13 8 12.8 7.7 12.6 7.4 12.4 7.1 12 6.8 11.7 6.7 11.4 6.6 11.1 6.5 10.8 6.4 10.6 6.4 10.4 6.4 10.2 5.8 10.1 5.2 9.9 4.5 9.8 4.4 9.8 4.4 9.8 4.3 9.8 4.1 9.8 4 9.8 3.8 9.8 3.6 9.9 3.4 10 3.2 10.1 3 10.2 2.9 10.4 2.8 10.5 2.6 10.8 2.5 11.1 2.5 11.5 2.5 11.6 2.5 11.8 2.6 12 2.6 12.1 2.7 12.3 2.8 12.5 2.9 12.6 3.1 12.8 3.2 12.9 3.3 13 3.5 13.1 3.6 13.1 3.7 13.1 3.8 13.2 3.9 13.2L13.1 15.2 13.1 15.2Z"></path></g></svg><span>Tutorials</span></a></li><li class="nav-offers flyout-parent"><a href="#" class="l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>offers icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M35.9 20.6L27 15.5C26.1 15 24.7 15 23.7 15.5L14.9 20.6C13.9 21.1 13.2 22.4 13.2 23.4L13.2 41.4C13.2 42.4 13.9 43.7 14.9 44.2L23.3 49C24.2 49.5 25.6 49.5 26.6 49L35.9 43.6C36.8 43.1 37.6 41.8 37.6 40.8L37.6 23.4C37.6 22.4 36.8 21.1 35.9 20.6L35.9 20.6ZM40 8.2C39.1 7.6 37.6 7.6 36.7 8.2L30.2 11.9C29.3 12.4 29.3 13.2 30.2 13.8L39.1 18.8C40 19.4 40.7 20.6 40.7 21.7L40.7 39C40.7 40.1 41.4 40.5 42.4 40L48.2 36.6C49.1 36.1 49.8 34.9 49.8 33.8L49.8 15.6C49.8 14.6 49.1 13.3 48.2 12.8L40 8.2 40 8.2ZM27 10.1L33.6 6.4C34.5 5.9 34.5 5 33.6 4.5L26.6 0.5C25.6 0 24.2 0 23.3 0.5L16.7 4.2C15.8 4.7 15.8 5.6 16.7 6.1L23.7 10.1C24.7 10.6 26.1 10.6 27 10.1ZM10.1 21.7C10.1 20.6 10.8 19.4 11.7 18.8L20.6 13.8C21.5 13.2 21.5 12.4 20.6 11.9L13.6 7.9C12.7 7.4 11.2 7.4 10.3 7.9L1.6 12.8C0.7 13.3 0 14.6 0 15.6L0 33.8C0 34.9 0.7 36.1 1.6 36.6L8.4 40.5C9.3 41 10.1 40.6 10.1 39.6L10.1 21.7 10.1 21.7Z"></path></g></svg><span>Offers &amp; Deals</span></a><ul class="flyout"><li><a href="https://www.safaribooksonline.com/oreilly-newsletters/" class="l2 nav-icn"><span>Newsletters</span></a></li></ul></li><li class="nav-highlights"><a href="https://www.safaribooksonline.com/u/0011N00001APXw3QAH/" class="t-highlights-nav l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 35" width="20" height="20" version="1.1" fill="#4A3C31"><desc>highlights icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M13.325 18.071L8.036 18.071C8.036 11.335 12.36 7.146 22.5 5.594L22.5 0C6.37 1.113 0 10.632 0 22.113 0 29.406 3.477 35 10.403 35 15.545 35 19.578 31.485 19.578 26.184 19.578 21.556 17.211 18.891 13.325 18.071L13.325 18.071ZM40.825 18.071L35.565 18.071C35.565 11.335 39.86 7.146 50 5.594L50 0C33.899 1.113 27.5 10.632 27.5 22.113 27.5 29.406 30.977 35 37.932 35 43.045 35 47.078 31.485 47.078 26.184 47.078 21.556 44.74 18.891 40.825 18.071L40.825 18.071Z"></path></g></svg><span>Highlights</span></a></li><li><a href="https://www.safaribooksonline.com/u/" class="t-settings-nav l1 js-settings nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 53" width="20" height="20" version="1.1" fill="#4A3C31"><desc>settings icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M44.6 29.6C44.7 28.6 44.8 27.5 44.8 26.5 44.8 25.5 44.7 24.4 44.6 23.4L49.6 19C50 18.8 50.1 18.3 49.9 17.9 48.9 14.7 47.1 11.7 44.9 9.1 44.6 8.8 44.2 8.7 43.8 8.8L37.4 11.1C35.8 9.8 34 8.7 32.1 8L30.9 1.4C30.8 0.9 30.4 0.6 30 0.5 26.7-0.2 23.3-0.2 20 0.5 19.6 0.6 19.2 0.9 19.1 1.4L17.9 8C16 8.7 14.1 9.8 12.6 11.1L6.2 8.8C5.8 8.7 5.4 8.8 5.1 9.1 2.9 11.7 1.1 14.7 0.1 17.9 -0.1 18.3 0 18.8 0.4 19L5.4 23.4C5.3 24.4 5.2 25.5 5.2 26.5 5.2 27.5 5.3 28.6 5.4 29.6L0.4 34C0 34.2-0.1 34.7 0.1 35.1 1.1 38.3 2.9 41.4 5.1 43.9 5.4 44.2 5.8 44.4 6.2 44.2L12.6 42C14.1 43.2 16 44.3 17.9 45L19.1 51.7C19.2 52.1 19.6 52.5 20 52.5 21.6 52.8 23.3 53 25 53 26.7 53 28.4 52.8 30 52.5 30.4 52.5 30.8 52.1 30.9 51.7L32.1 45C34 44.3 35.8 43.2 37.4 42L43.8 44.2C44.2 44.4 44.6 44.2 44.9 43.9 47.1 41.4 48.9 38.3 49.9 35.1 50.1 34.7 50 34.2 49.6 34L44.6 29.6ZM25 36.4C19.6 36.4 15.2 32 15.2 26.5 15.2 21 19.6 16.6 25 16.6 30.4 16.6 34.8 21 34.8 26.5 34.8 32 30.4 36.4 25 36.4Z"></path></g></svg><span>Settings</span></a></li><li><a href="https://www.safaribooksonline.com/public/support" class="l1 no-icon">Support</a></li><li><a href="https://www.safaribooksonline.com/accounts/logout/" class="l1 no-icon">Sign Out</a></li></ul><ul class="profile"><li><a href="https://www.safaribooksonline.com/u/" class="l2 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 53" width="20" height="20" version="1.1" fill="#4A3C31"><desc>settings icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M44.6 29.6C44.7 28.6 44.8 27.5 44.8 26.5 44.8 25.5 44.7 24.4 44.6 23.4L49.6 19C50 18.8 50.1 18.3 49.9 17.9 48.9 14.7 47.1 11.7 44.9 9.1 44.6 8.8 44.2 8.7 43.8 8.8L37.4 11.1C35.8 9.8 34 8.7 32.1 8L30.9 1.4C30.8 0.9 30.4 0.6 30 0.5 26.7-0.2 23.3-0.2 20 0.5 19.6 0.6 19.2 0.9 19.1 1.4L17.9 8C16 8.7 14.1 9.8 12.6 11.1L6.2 8.8C5.8 8.7 5.4 8.8 5.1 9.1 2.9 11.7 1.1 14.7 0.1 17.9 -0.1 18.3 0 18.8 0.4 19L5.4 23.4C5.3 24.4 5.2 25.5 5.2 26.5 5.2 27.5 5.3 28.6 5.4 29.6L0.4 34C0 34.2-0.1 34.7 0.1 35.1 1.1 38.3 2.9 41.4 5.1 43.9 5.4 44.2 5.8 44.4 6.2 44.2L12.6 42C14.1 43.2 16 44.3 17.9 45L19.1 51.7C19.2 52.1 19.6 52.5 20 52.5 21.6 52.8 23.3 53 25 53 26.7 53 28.4 52.8 30 52.5 30.4 52.5 30.8 52.1 30.9 51.7L32.1 45C34 44.3 35.8 43.2 37.4 42L43.8 44.2C44.2 44.4 44.6 44.2 44.9 43.9 47.1 41.4 48.9 38.3 49.9 35.1 50.1 34.7 50 34.2 49.6 34L44.6 29.6ZM25 36.4C19.6 36.4 15.2 32 15.2 26.5 15.2 21 19.6 16.6 25 16.6 30.4 16.6 34.8 21 34.8 26.5 34.8 32 30.4 36.4 25 36.4Z"></path></g></svg><span>Settings</span></a><span class="l2 t-nag-notification" id="nav-nag"><strong class="trial-green">10</strong> days left in your trial.
  
  

  
    
      

<a class="" href="https://www.safaribooksonline.com/subscribe/">Subscribe</a>.


    
  

  

</span></li><li><a href="https://www.safaribooksonline.com/public/support" class="l2">Support</a></li><li><a href="https://www.safaribooksonline.com/accounts/logout/" class="l2">Sign Out</a></li></ul></div></li></ul></nav></header>


      </div>
      <div id="container" class="application" style="height: auto;">
        
          <div class="nav-container clearfix">
            


            
            
          </div>

          

  <div class="js-toc">
    
      <div class="sbo-reading-menu sbo-menu-top"><section class="sbo-toc-container toc-menu"><a href="#" class="sbo-toc-thumb"><span class="sbo-title ss-list"><h1><div class="visuallyhidden">Table of Contents for </div>
      
      Hands-On Machine Learning with Scikit-Learn and TensorFlow
      
    </h1></span></a><div class="toc-contents" style="max-height: 0px;">
  <div class="sbo-toc ">
    <button type="button" class="sbo-toc-thumb close"><div class="visuallyhidden">Close</div></button>
      <section class="ios-app-teaser">
        <ul>
            <li><a class="js-toc-link toc-link" href="https://itunes.apple.com/gb/app/safari-queue-library-over/id881697395?mt=8" role="button">Install App</a></li>
            <li><a class="js-toc-link toc-link" href="safaridetail://9781491962282" role="button">Open in App</a></li>
        </ul>
      </section>
      <div class="sbo-book-meta">
        
        <span class="cover">
         <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/">
          <img src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/a.jpg" alt="Cover image for Hands-On Machine Learning with Scikit-Learn and TensorFlow" width="140" height="184">
        </a>
        </span>
        <span class="title">
          
            
                <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/publisher/oreilly-media-inc/">
                  <img src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/ORM_logo_box_rgb.png" class="publisher-logo video" alt="publisher logo">
                </a>
            
          

          <a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/">Hands-On Machine Learning with Scikit-Learn and TensorFlow</a>
        </span>
        
        <span class="authors">by Aurélien Géron</span>
        

        
        <span class="publishers t-publishers">Published by
          <!-- Show publisher page link if publisher pages switch is on -->
          
            <a class="t-publisher-link toc-link js-toc-link" href="https://www.safaribooksonline.com/library/publisher/oreilly-media-inc/">
              O'Reilly Media, Inc.</a>, 2017
          
        </span>
        

    

    </div>
  <ol class="tocList">
    
    
    
     

     <li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/preface01.html#idm140583011384384">
        Preface 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/part01.html#fundamentals_part">
        I. The Fundamentals of Machine Learning 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch01.html#landscape_chapter">
        1. The Machine Learning Landscape 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch02.html#project_chapter">
        2. End-to-End Machine Learning Project 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch03.html#classification_chapter">
        3. Classification 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch04.html#linear_models_chapter">
        4. Training Models 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch05.html#svm_chapter">
        5. Support Vector Machines 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch06.html#trees_chapter">
        6. Decision Trees 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch07.html#ensembles_chapter">
        7. Ensemble Learning and Random Forests 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch08.html#dim_reduction_chapter">
        8. Dimensionality Reduction 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/part02.html#neural_nets_part">
        II. Neural Networks and Deep Learning 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch09.html#tensorflow_chapter">
        9. Up and Running with TensorFlow 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html#ann_chapter">
        10. Introduction to Artificial Neural Networks 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#deep_chapter">
        11. Training Deep Neural Nets 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch12.html#distributed_chapter">
        12. Distributing TensorFlow Across Devices and Servers 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch13.html#cnn_chapter">
        13. Convolutional Neural Networks 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1 currently-reading">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch14.html#rnn_chapter">
        14. Recurrent Neural Networks 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch15.html#autoencoders_chapter">
        15. Autoencoders 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch16.html#rl_chapter">
        16. Reinforcement Learning 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app01.html#solutions_appendix">
        A. Exercise Solutions 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app02.html#project_checklist_appendix">
        B. Machine Learning Project Checklist 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app03.html#svm_dual_problem_appendix">
        C. SVM Dual Problem 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app04.html#autodiff_appendix">
        D. Autodiff 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app05.html#other_ann_appendix">
        E. Other Popular ANN Architectures 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ix01.html#idm140582977822192">
        Index 
       </a>
      
        
      
   </li></ol>
 </div>



</div></section></div>

    

    <div class="interface-controls interface-controls-top">
      <ul class="interface-control-btns js-bitlist js-reader">
        <li class="js-search-in-archive search-in-archive t-search-in-archive"><a href="#" title="Search in archive" class="js-search-controls search-controls"><span class="icon">Search in book...</span></a><form class="search-archive-bar js-search-form"><input name="query" placeholder="Search inside this book..." autocomplete="off" type="search"></form><div class="search-archive-results"><div class="js-sitb-results-region"></div></div></li><li class="queue-control"><button type="button" class="rec-fav ss-queue js-queue js-current-chapter-queue" data-queue-endpoint="/api/v1/book/9781491962282/chapter/ch15.html" data-for-analytics="9781491962282:ch15.html" aria-label="Add to Queue"><span>Add to Queue</span></button></li><li class="js-font-control-panel font-control-activator"><a href="#" data-push-state="false" id="font-controls" title="Change font size" aria-label="Change font size"><span class="icon">Toggle Font Controls</span></a></li><li class="dropdown sharing-controls"><a href="#" class="trigger" data-push-state="false" title="Share" aria-label="Share"><i class="fa fa-share"></i></a><ul class="social-sharing dropdown-menu"><li class=""><a class="twitter share-button t-twitter" target="_blank" aria-label="Share this section on Twitter" title="Share this section on Twitter" href="https://twitter.com/share?url=https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html&amp;text=Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow&amp;via=safari"><span>Twitter</span></a></li><li class=""><a class="facebook share-button t-facebook" target="_blank" aria-label="Share this section on Facebook" title="Share this section on Facebook" href="https://www.facebook.com/sharer/sharer.php?u=https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html"><span>Facebook</span></a></li><li class=""><a class="googleplus share-button t-googleplus" target="_blank" aria-label="Share this secton on Google Plus" title="Share this secton on Google Plus" href="https://plus.google.com/share?url=https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html"><span>Google Plus</span></a></li><li class=""><a class="email share-button t-email" aria-label="Share this section via email" title="Share this section via email" href="mailto:?subject=Safari:%2010.%20Introduction%20to%20Artificial%20Neural%20Networks&amp;body=https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html%0D%0Afrom%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow%0D%0A"><span>Email</span></a></li></ul></li>
      </ul>
    </div>

    <section role="document">
	  <div class="t-sbo-prev sbo-prev sbo-nav-top">
  
    
      
        <a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch14.html" class="prev nav-link">
      
          <span aria-hidden="true" class="pagination-label t-prev-label">Prev</span>
          <span class="visuallyhidden">Previous Chapter</span>
          <div class="pagination-title t-prev-title">14. Recurrent Neural Networks</div>
        </a>
    
  
  </div>

  <div class="t-sbo-next sbo-next sbo-nav-top">
  
    
      
        <a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch16.html" class="next nav-link">
      
          <span aria-hidden="true" class="pagination-label t-next-label">Next</span>
          <span class="visuallyhidden">Next Chapter</span>
          <div class="pagination-title t-next-title">16. Reinforcement Learning</div>
        </a>
    
  
  </div>



<div id="sbo-rt-content"><div class="annotator-wrapper"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 15. Autoencoders"><div class="chapter" id="autoencoders_chapter">
<h1><span class="label">Chapter 15. </span>Autoencoders</h1>


<p>Autoencoders <a data-type="indexterm" data-primary="autoencoders" id="a15"></a>are artificial neural networks capable of learning efficient representations of the input data, called <em>codings</em>, <a data-type="indexterm" data-primary="codings" id="idm140582986878896"></a>without
 any supervision (i.e., the training set is unlabeled). These codings 
typically have a much lower dimensionality than the input data, making 
autoencoders useful for <a data-type="indexterm" data-primary="dimensionality reduction" id="idm140582986877840"></a>dimensionality reduction (see <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch08.html#dim_reduction_chapter">Chapter&nbsp;8</a>). More importantly, autoencoders act as powerful <a data-type="indexterm" data-primary="feature detection" id="idm140582986876272"></a>feature detectors, and they can be used for unsupervised pretraining of deep neural networks (as we discussed in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#deep_chapter">Chapter&nbsp;11</a>). Lastly, they are capable of randomly generating new data that looks very similar to the training data; this is called <a data-type="indexterm" data-primary="generative models" id="idm140582986874400"></a>a <em>generative model</em>. For example, you could train an autoencoder on pictures of faces, and it would then be able to generate new faces.</p>

<p>Surprisingly, autoencoders work by simply learning to copy their 
inputs to their outputs. This may sound like a trivial task, but we will
 see that constraining the network in various ways can make it rather 
difficult. For example, you can limit the size of the internal 
representation, or you can add noise to the inputs and train the network
 to recover the original inputs. These constraints prevent the 
autoencoder from trivially copying the inputs directly to the outputs, 
which forces it to learn efficient ways of representing the data. In 
short, the codings are byproducts of the autoencoder’s attempt to learn 
the identity function under some constraints.</p>

<p>In this chapter we will explain in more depth how autoencoders work, 
what types of constraints can be imposed, and how to implement them 
using TensorFlow, whether it is for dimensionality reduction, feature 
extraction, unsupervised pretraining, or as generative models.</p>






<section data-type="sect1" class="pagebreak-before" data-pdf-bookmark="Efficient Data Representations"><div class="sect1" id="idm140582986871248">
<h1>Efficient Data Representations</h1>

<p>Which <a data-type="indexterm" data-primary="autoencoders" data-secondary="efficient data representations" id="a15edr"></a>of the following number sequences do you find the easiest to memorize?</p>

<ul>
<li>
<p>40, 27, 25, 36, 81, 57, 10, 73, 19, 68</p>
</li>
<li>
<p>50, 25, 76, 38, 19, 58, 29, 88, 44, 22, 11, 34, 17, 52, 26, 13, 40, 20</p>
</li>
</ul>

<p>At first glance, it would seem that the first sequence should be 
easier, since it is much shorter. However, if you look carefully at the 
second sequence, you may notice that it follows two simple rules: even 
numbers are followed by their half, and odd numbers are followed by 
their triple plus one (this is a famous sequence known as <a data-type="indexterm" data-primary="hailstone sequence" id="idm140582986788912"></a>the <em>hailstone sequence</em>).
 Once you notice this pattern, the second sequence becomes much easier 
to memorize than the first because you only need to memorize the two 
rules, the first number, and the length of the sequence. Note that if 
you could quickly and easily memorize very long sequences, you would not
 care much about the existence of a pattern in the second sequence. You 
would just learn every number by heart, and that would be that. It is 
the fact that it is hard to memorize long sequences that makes it useful
 to recognize patterns, and hopefully this clarifies why constraining an
 autoencoder during training pushes it to discover and exploit patterns 
in the data.</p>

<p>The relationship between memory, perception, and pattern matching was <a href="https://goo.gl/kSNcX0">famously studied by William Chase and Herbert Simon in the early 1970s</a>.<sup><a data-type="noteref" id="idm140582986786144-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch15.html#idm140582986786144" class="totri-footnote">1</a></sup>
 They observed that expert chess players were able to memorize the 
positions of all the pieces in a game by looking at the board for just 5
 seconds, a task that most people would find impossible. However, this 
was only the case when the pieces were placed in realistic positions 
(from actual games), not when the pieces were placed randomly. Chess 
experts don’t have a much better memory than you and I, they just see 
chess patterns more easily thanks to their experience with the game. 
Noticing patterns helps them store information efficiently.</p>

<p>Just like the chess players in this memory experiment, an autoencoder
 looks at the inputs, converts them to an efficient internal 
representation, and then spits out something that (hopefully) looks very
 close to the inputs. An autoencoder is always composed of two parts: an
 <em>encoder</em> <a data-type="indexterm" data-primary="encoder" id="idm140582986783424"></a><a data-type="indexterm" data-primary="recognition network" id="idm140582986782688"></a>(or <em>recognition network</em>) that converts the inputs to an internal representation, followed by a <em>decoder</em> <a data-type="indexterm" data-primary="decoder" id="idm140582986781056"></a>(or <em>generative network</em>) that converts the internal representation to the outputs (see <a data-type="xref" href="#encoder_decoder_diagram">Figure&nbsp;15-1</a>).</p>

<p>As you can see, an autoencoder typically has the same architecture as a Multi-Layer Perceptron (MLP; see <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html#ann_chapter">Chapter&nbsp;10</a>),
 except that the number of neurons in the output layer must be equal to 
the number of inputs. In this example, there is just one hidden layer 
composed of two neurons (the encoder), and one output layer composed of 
three neurons (the decoder). The outputs are often called the <em>reconstructions</em> <a data-type="indexterm" data-primary="reconstructions" id="idm140582986776752"></a><a data-type="indexterm" data-primary="autoencoders" data-secondary="reconstructions" id="idm140582986776016"></a>since the autoencoder tries to reconstruct the inputs, and the cost function contains a <em>reconstruction loss</em> <a data-type="indexterm" data-primary="reconstruction loss" id="idm140582986774448"></a>that penalizes the model when the reconstructions are different from the inputs.</p>

<figure class="smallerseventy"><div id="encoder_decoder_diagram" class="figure">
<img src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/mlst_1501.png" alt="mlst 1501" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1501.png" width="1440" height="869">
<h6><span class="label">Figure 15-1. </span>The chess memory experiment (left) and a simple autoencoder (right)</h6>
</div></figure>

<p>Because the internal representation has a lower dimensionality than 
the input data (it is 2D instead of 3D), the autoencoder is said to be <em>undercomplete</em>. <a data-type="indexterm" data-primary="autoencoders" data-secondary="undercomplete" id="idm140582986770464"></a>An
 undercomplete autoencoder cannot trivially copy its inputs to the 
codings, yet it must find a way to output a copy of its inputs. It is 
forced to learn the most important features in the input data (and drop 
the unimportant ones).</p>

<p>Let’s see how to implement a very simple undercomplete autoencoder for dimensionality reduction.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Performing PCA with an Undercomplete Linear Autoencoder"><div class="sect1" id="idm140582986870624">
<h1>Performing PCA with an Undercomplete Linear Autoencoder</h1>

<p>If <a data-type="indexterm" data-primary="autoencoders" data-secondary="PCA with undercomplete linear autoencoder" id="idm140582986766912"></a>the
 autoencoder uses only linear activations and the cost function is the 
Mean Squared Error (MSE), then it can be shown that it ends up 
performing Principal Component Analysis (see <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch08.html#dim_reduction_chapter">Chapter&nbsp;8</a>).</p>

<p>The following code builds a simple linear autoencoder to perform PCA on a 3D dataset, projecting it to 2D:</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">import</code> <code class="nn">tensorflow</code> <code class="kn">as</code> <code class="nn">tf</code>

<code class="n">n_inputs</code> <code class="o">=</code> <code class="mi">3</code>  <code class="c1"># 3D inputs</code>
<code class="n">n_hidden</code> <code class="o">=</code> <code class="mi">2</code>  <code class="c1"># 2D codings</code>
<code class="n">n_outputs</code> <code class="o">=</code> <code class="n">n_inputs</code>

<code class="n">learning_rate</code> <code class="o">=</code> <code class="mf">0.01</code>

<code class="n">X</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">placeholder</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">,</code> <code class="n">shape</code><code class="o">=</code><code class="p">[</code><code class="bp">None</code><code class="p">,</code> <code class="n">n_inputs</code><code class="p">])</code>
<code class="n">hidden</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">dense</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">n_hidden</code><code class="p">)</code>
<code class="n">outputs</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">dense</code><code class="p">(</code><code class="n">hidden</code><code class="p">,</code> <code class="n">n_outputs</code><code class="p">)</code>

<code class="n">reconstruction_loss</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">reduce_mean</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">square</code><code class="p">(</code><code class="n">outputs</code> <code class="o">-</code> <code class="n">X</code><code class="p">))</code>  <code class="c1"># MSE</code>

<code class="n">optimizer</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">train</code><code class="o">.</code><code class="n">AdamOptimizer</code><code class="p">(</code><code class="n">learning_rate</code><code class="p">)</code>
<code class="n">training_op</code> <code class="o">=</code> <code class="n">optimizer</code><code class="o">.</code><code class="n">minimize</code><code class="p">(</code><code class="n">reconstruction_loss</code><code class="p">)</code>

<code class="n">init</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">global_variables_initializer</code><code class="p">()</code></pre>

<p>This code is <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.reduce_mean()" id="idm140582986762112"></a> <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.square()" id="idm140582986761248"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.train.AdamOptimizer" id="idm140582986697056"></a>really not very different from all the MLPs we built in past chapters. The two things to note are:</p>

<ul>
<li>
<p>The number of outputs is equal to the number of inputs.</p>
</li>
<li>
<p>To perform simple PCA, we do not use any activation function (i.e., 
all neurons are linear) and the cost function is the MSE. We will see 
more complex autoencoders shortly.</p>
</li>
</ul>

<p>Now let’s load the dataset, train the model on the training set, and use it to encode the test set (i.e., project it to 2D):</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">X_train</code><code class="p">,</code> <code class="n">X_test</code> <code class="o">=</code> <code class="p">[</code><code class="o">...</code><code class="p">]</code> <code class="c1"># load the dataset</code>

<code class="n">n_iterations</code> <code class="o">=</code> <code class="mi">1000</code>
<code class="n">codings</code> <code class="o">=</code> <code class="n">hidden</code>  <code class="c1"># the output of the hidden layer provides the codings</code>

<code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">Session</code><code class="p">()</code> <code class="k">as</code> <code class="n">sess</code><code class="p">:</code>
    <code class="n">init</code><code class="o">.</code><code class="n">run</code><code class="p">()</code>
    <code class="k">for</code> <code class="n">iteration</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">n_iterations</code><code class="p">):</code>
        <code class="n">training_op</code><code class="o">.</code><code class="n">run</code><code class="p">(</code><code class="n">feed_dict</code><code class="o">=</code><code class="p">{</code><code class="n">X</code><code class="p">:</code> <code class="n">X_train</code><code class="p">})</code>  <code class="c1"># no labels (unsupervised)</code>
    <code class="n">codings_val</code> <code class="o">=</code> <code class="n">codings</code><code class="o">.</code><code class="n">eval</code><code class="p">(</code><code class="n">feed_dict</code><code class="o">=</code><code class="p">{</code><code class="n">X</code><code class="p">:</code> <code class="n">X_test</code><code class="p">})</code></pre>

<p><a data-type="xref" href="#linear_autoencoder_pca_diagram">Figure&nbsp;15-2</a>
 shows the original 3D dataset (at the left) and the output of the 
autoencoder’s hidden layer (i.e., the coding layer, at the right). As 
you can see, the autoencoder found the best 2D plane to project the data
 onto, preserving as much variance in the data as it could (just like 
PCA).</p>

<figure><div id="linear_autoencoder_pca_diagram" class="figure">
<img src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/mlst_1502.png" alt="mlst 1502" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1502.png" width="1440" height="535">
<h6><span class="label">Figure 15-2. </span>PCA performed by an undercomplete linear autoencoder</h6>
</div></figure>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Stacked Autoencoders"><div class="sect1" id="idm140582986768112">
<h1>Stacked Autoencoders</h1>

<p>Just <a data-type="indexterm" data-primary="autoencoders" data-secondary="stacked" id="a15s"></a><a data-type="indexterm" data-primary="stacked autoencoders" id="sa15"></a>like other neural networks we have discussed, autoencoders can have multiple hidden layers. In this case they are called <em>stacked autoencoders</em> (or <em>deep autoencoders</em>). <a data-type="indexterm" data-primary="deep autoencoders" data-see="stacked autoencoders" id="idm140582986667936"></a>Adding
 more layers helps the autoencoder learn more complex codings. However, 
one must be careful not to make the autoencoder too powerful. Imagine an
 encoder so powerful that it just learns to map each input to a single 
arbitrary number (and the decoder learns the reverse mapping). Obviously
 such an autoencoder will reconstruct the training data perfectly, but 
it will not have learned any useful data representation in the process 
(and it is unlikely to generalize well to new instances).</p>

<p>The architecture of a stacked autoencoder is typically symmetrical 
with regards to the central hidden layer (the coding layer). To put it 
simply, it looks like a sandwich. For example, an autoencoder for MNIST 
(introduced in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch03.html#classification_chapter">Chapter&nbsp;3</a>)
 may have 784 inputs, followed by a hidden layer with 300 neurons, then a
 central hidden layer of 150 neurons, then another hidden layer with 300
 neurons, and an output layer with 784 neurons. This stacked autoencoder
 is represented in <a data-type="xref" href="#stacked_autoencoder_diagram">Figure&nbsp;15-3</a>.</p>

<figure class="smallerseventy"><div id="stacked_autoencoder_diagram" class="figure">
<img src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/mlst_1503.png" alt="mlst 1503" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1503.png" width="1440" height="741">
<h6><span class="label">Figure 15-3. </span>Stacked autoencoder</h6>
</div></figure>








<section data-type="sect2" data-pdf-bookmark="TensorFlow Implementation"><div class="sect2" id="idm140582986661472">
<h2>TensorFlow Implementation</h2>

<p>You <a data-type="indexterm" data-primary="stacked autoencoders" data-secondary="TensorFlow implementation" id="idm140582986659680"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="and stacked autoencoders" data-secondary-sortas="stacked" id="idm140582986658704"></a>can implement a stacked autoencoder very much like a regular deep MLP. In particular, the same techniques we used in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#deep_chapter">Chapter&nbsp;11</a>
 for training deep nets can be applied. For example, the following code 
builds a stacked autoencoder for MNIST, using He initialization, the ELU
 activation function, and ℓ<sub>2</sub> regularization. The code should look very familiar, except that there are no labels (no <code>y</code>):<a data-type="indexterm" data-primary="functools.partial()" id="idm140582986655360"></a></p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">functools</code> <code class="kn">import</code> <code class="n">partial</code>

<code class="n">n_inputs</code> <code class="o">=</code> <code class="mi">28</code> <code class="o">*</code> <code class="mi">28</code>  <code class="c1"># for MNIST</code>
<code class="n">n_hidden1</code> <code class="o">=</code> <code class="mi">300</code>
<code class="n">n_hidden2</code> <code class="o">=</code> <code class="mi">150</code>  <code class="c1"># codings</code>
<code class="n">n_hidden3</code> <code class="o">=</code> <code class="n">n_hidden1</code>
<code class="n">n_outputs</code> <code class="o">=</code> <code class="n">n_inputs</code>

<code class="n">learning_rate</code> <code class="o">=</code> <code class="mf">0.01</code>
<code class="n">l2_reg</code> <code class="o">=</code> <code class="mf">0.0001</code>

<code class="n">X</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">placeholder</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">,</code> <code class="n">shape</code><code class="o">=</code><code class="p">[</code><code class="bp">None</code><code class="p">,</code> <code class="n">n_inputs</code><code class="p">])</code>

<code class="n">he_init</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">contrib</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">variance_scaling_initializer</code><code class="p">()</code>
<code class="n">l2_regularizer</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">contrib</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">l2_regularizer</code><code class="p">(</code><code class="n">l2_reg</code><code class="p">)</code>
<code class="n">my_dense_layer</code> <code class="o">=</code> <code class="n">partial</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">dense</code><code class="p">,</code>
                         <code class="n">activation</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">elu</code><code class="p">,</code>
                         <code class="n">kernel_initializer</code><code class="o">=</code><code class="n">he_init</code><code class="p">,</code>
                         <code class="n">kernel_regularizer</code><code class="o">=</code><code class="n">l2_regularizer</code><code class="p">)</code>

<code class="n">hidden1</code> <code class="o">=</code> <code class="n">my_dense_layer</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">n_hidden1</code><code class="p">)</code>
<code class="n">hidden2</code> <code class="o">=</code> <code class="n">my_dense_layer</code><code class="p">(</code><code class="n">hidden1</code><code class="p">,</code> <code class="n">n_hidden2</code><code class="p">)</code>  <code class="c1"># codings</code>
<code class="n">hidden3</code> <code class="o">=</code> <code class="n">my_dense_layer</code><code class="p">(</code><code class="n">hidden2</code><code class="p">,</code> <code class="n">n_hidden3</code><code class="p">)</code>
<code class="n">outputs</code> <code class="o">=</code> <code class="n">my_dense_layer</code><code class="p">(</code><code class="n">hidden3</code><code class="p">,</code> <code class="n">n_outputs</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="bp">None</code><code class="p">)</code>

<code class="n">reconstruction_loss</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">reduce_mean</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">square</code><code class="p">(</code><code class="n">outputs</code> <code class="o">-</code> <code class="n">X</code><code class="p">))</code>  <code class="c1"># MSE</code>

<code class="n">reg_losses</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">get_collection</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">GraphKeys</code><code class="o">.</code><code class="n">REGULARIZATION_LOSSES</code><code class="p">)</code>
<code class="n">loss</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">add_n</code><code class="p">([</code><code class="n">reconstruction_loss</code><code class="p">]</code> <code class="o">+</code> <code class="n">reg_losses</code><code class="p">)</code>

<code class="n">optimizer</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">train</code><code class="o">.</code><code class="n">AdamOptimizer</code><code class="p">(</code><code class="n">learning_rate</code><code class="p">)</code>
<code class="n">training_op</code> <code class="o">=</code> <code class="n">optimizer</code><code class="o">.</code><code class="n">minimize</code><code class="p">(</code><code class="n">loss</code><code class="p">)</code>

<code class="n">init</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">global_variables_initializer</code><code class="p">()</code></pre>

<p>You can then train <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.train.AdamOptimizer" id="tftraadopch15"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.GraphKeys.REGULARIZATION_LOSSES" id="idm140582986652960"></a> <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.get_collection()" id="idm140582986350672"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.reduce_mean()" id="idm140582986349696"></a> <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.square()" id="idm140582986348624"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.contrib.layers.l2_regularizer()" id="tfconlayl2regch15"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.contrib.layers.variance_scaling_initializer()" id="tfclvsich15"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.nn.elu()" id="tfnneluch15"></a>the model normally. Note that the digit labels (<code>y_batch</code>) are unused:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">n_epochs</code> <code class="o">=</code> <code class="mi">5</code>
<code class="n">batch_size</code> <code class="o">=</code> <code class="mi">150</code>

<code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">Session</code><code class="p">()</code> <code class="k">as</code> <code class="n">sess</code><code class="p">:</code>
    <code class="n">init</code><code class="o">.</code><code class="n">run</code><code class="p">()</code>
    <code class="k">for</code> <code class="n">epoch</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">n_epochs</code><code class="p">):</code>
        <code class="n">n_batches</code> <code class="o">=</code> <code class="n">mnist</code><code class="o">.</code><code class="n">train</code><code class="o">.</code><code class="n">num_examples</code> <code class="o">//</code> <code class="n">batch_size</code>
        <code class="k">for</code> <code class="n">iteration</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">n_batches</code><code class="p">):</code>
            <code class="n">X_batch</code><code class="p">,</code> <code class="n">y_batch</code> <code class="o">=</code> <code class="n">mnist</code><code class="o">.</code><code class="n">train</code><code class="o">.</code><code class="n">next_batch</code><code class="p">(</code><code class="n">batch_size</code><code class="p">)</code>
            <code class="n">sess</code><code class="o">.</code><code class="n">run</code><code class="p">(</code><code class="n">training_op</code><code class="p">,</code> <code class="n">feed_dict</code><code class="o">=</code><code class="p">{</code><code class="n">X</code><code class="p">:</code> <code class="n">X_batch</code><code class="p">})</code></pre>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Tying Weights"><div class="sect2" id="idm140582986342272">
<h2>Tying Weights</h2>

<p>When <a data-type="indexterm" data-primary="stacked autoencoders" data-secondary="tying weights" id="sa15tw"></a>an autoencoder is neatly symmetrical, like the one we just built, a common technique is to <em>tie the weights</em> of <a data-type="indexterm" data-primary="tying weights" id="idm140582986272464"></a><a data-type="indexterm" data-primary="weight-tying" id="idm140582986271728"></a>the
 decoder layers to the weights of the encoder layers. This halves the 
number of weights in the model, speeding up training and limiting the 
risk of overfitting. Specifically, if the autoencoder has a total of <em>N</em> layers (not counting the input layer), and <strong>W</strong><sub><em>L</em></sub> represents the connection weights of the <em>L</em><sup>th</sup> layer (e.g., layer 1 is the first hidden layer, layer <img src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_132.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_132.png" width="16" height="30"> is the coding layer, and layer <em>N</em> is the output layer), then the decoder layer weights can be defined simply as: <strong>W</strong><sub><em>N–L</em>+1</sub> = <strong>W</strong><sub><em>L</em></sub><sup><em>T</em></sup> (with  <em>L</em> = 1, 2, <img src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_133.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_133.png" width="61" height="30">).</p>

<p>Unfortunately, implementing tied weights in TensorFlow using the <code>dense()</code> <a data-type="indexterm" data-primary="dense()" id="idm140582986263984"></a>function
 is a bit cumbersome; it’s actually easier to just define the layers 
manually. The code ends up significantly more verbose:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">activation</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">elu</code>
<code class="n">regularizer</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">contrib</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">l2_regularizer</code><code class="p">(</code><code class="n">l2_reg</code><code class="p">)</code>
<code class="n">initializer</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">contrib</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">variance_scaling_initializer</code><code class="p">()</code>

<code class="n">X</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">placeholder</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">,</code> <code class="n">shape</code><code class="o">=</code><code class="p">[</code><code class="bp">None</code><code class="p">,</code> <code class="n">n_inputs</code><code class="p">])</code>

<code class="n">weights1_init</code> <code class="o">=</code> <code class="n">initializer</code><code class="p">([</code><code class="n">n_inputs</code><code class="p">,</code> <code class="n">n_hidden1</code><code class="p">])</code>
<code class="n">weights2_init</code> <code class="o">=</code> <code class="n">initializer</code><code class="p">([</code><code class="n">n_hidden1</code><code class="p">,</code> <code class="n">n_hidden2</code><code class="p">])</code>

<code class="n">weights1</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">Variable</code><code class="p">(</code><code class="n">weights1_init</code><code class="p">,</code> <code class="n">dtype</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"weights1"</code><code class="p">)</code>
<code class="n">weights2</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">Variable</code><code class="p">(</code><code class="n">weights2_init</code><code class="p">,</code> <code class="n">dtype</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"weights2"</code><code class="p">)</code>
<code class="n">weights3</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">transpose</code><code class="p">(</code><code class="n">weights2</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"weights3"</code><code class="p">)</code>  <code class="c1"># tied weights</code>
<code class="n">weights4</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">transpose</code><code class="p">(</code><code class="n">weights1</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"weights4"</code><code class="p">)</code>  <code class="c1"># tied weights</code>

<code class="n">biases1</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">Variable</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">zeros</code><code class="p">(</code><code class="n">n_hidden1</code><code class="p">),</code> <code class="n">name</code><code class="o">=</code><code class="s2">"biases1"</code><code class="p">)</code>
<code class="n">biases2</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">Variable</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">zeros</code><code class="p">(</code><code class="n">n_hidden2</code><code class="p">),</code> <code class="n">name</code><code class="o">=</code><code class="s2">"biases2"</code><code class="p">)</code>
<code class="n">biases3</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">Variable</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">zeros</code><code class="p">(</code><code class="n">n_hidden3</code><code class="p">),</code> <code class="n">name</code><code class="o">=</code><code class="s2">"biases3"</code><code class="p">)</code>
<code class="n">biases4</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">Variable</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">zeros</code><code class="p">(</code><code class="n">n_outputs</code><code class="p">),</code> <code class="n">name</code><code class="o">=</code><code class="s2">"biases4"</code><code class="p">)</code>

<code class="n">hidden1</code> <code class="o">=</code> <code class="n">activation</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">matmul</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">weights1</code><code class="p">)</code> <code class="o">+</code> <code class="n">biases1</code><code class="p">)</code>
<code class="n">hidden2</code> <code class="o">=</code> <code class="n">activation</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">matmul</code><code class="p">(</code><code class="n">hidden1</code><code class="p">,</code> <code class="n">weights2</code><code class="p">)</code> <code class="o">+</code> <code class="n">biases2</code><code class="p">)</code>
<code class="n">hidden3</code> <code class="o">=</code> <code class="n">activation</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">matmul</code><code class="p">(</code><code class="n">hidden2</code><code class="p">,</code> <code class="n">weights3</code><code class="p">)</code> <code class="o">+</code> <code class="n">biases3</code><code class="p">)</code>
<code class="n">outputs</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">matmul</code><code class="p">(</code><code class="n">hidden3</code><code class="p">,</code> <code class="n">weights4</code><code class="p">)</code> <code class="o">+</code> <code class="n">biases4</code>

<code class="n">reconstruction_loss</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">reduce_mean</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">square</code><code class="p">(</code><code class="n">outputs</code> <code class="o">-</code> <code class="n">X</code><code class="p">))</code>
<code class="n">reg_loss</code> <code class="o">=</code> <code class="n">regularizer</code><code class="p">(</code><code class="n">weights1</code><code class="p">)</code> <code class="o">+</code> <code class="n">regularizer</code><code class="p">(</code><code class="n">weights2</code><code class="p">)</code>
<code class="n">loss</code> <code class="o">=</code> <code class="n">reconstruction_loss</code> <code class="o">+</code> <code class="n">reg_loss</code>

<code class="n">optimizer</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">train</code><code class="o">.</code><code class="n">AdamOptimizer</code><code class="p">(</code><code class="n">learning_rate</code><code class="p">)</code>
<code class="n">training_op</code> <code class="o">=</code> <code class="n">optimizer</code><code class="o">.</code><code class="n">minimize</code><code class="p">(</code><code class="n">loss</code><code class="p">)</code>

<code class="n">init</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">global_variables_initializer</code><code class="p">()</code></pre>

<p>This code is fairly straightforward, <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.train.AdamOptimizer" data-startref="tftraadopch15" id="idm140582986261344"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.matmul()" id="idm140582986260224"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.zeros()" id="idm140582986259280"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.transpose()" id="idm140582986258336"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.contrib.layers.variance_scaling_initializer()" data-startref="tfclvsich15" id="idm140582986257392"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.contrib.layers.l2_regularizer()" data-startref="tfconlayl2regch15" id="idm140582985862832"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.nn.elu()" data-startref="tfnneluch15" id="idm140582985861648"></a>but there are a few important things to note:</p>

<ul>
<li>
<p>First, <code>weight3</code> and <code>weights4</code> are not variables, they are respectively the transpose of <code>weights2</code> and <code>weights1</code> (they are “tied” to them).</p>
</li>
<li>
<p>Second, since they are not variables, it’s no use regularizing them: we only regularize <code>weights1</code> and <code>weights2</code>.</p>
</li>
<li>
<p>Third, biases are never tied, and never <a data-type="indexterm" data-primary="stacked autoencoders" data-secondary="tying weights" data-startref="sa15tw" id="idm140582985854720"></a>regularized.</p>
</li>
</ul>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Training One Autoencoder at a Time"><div class="sect2" id="idm140582985852960">
<h2>Training One Autoencoder at a Time</h2>

<p>Rather <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.reduce_mean()" id="idm140582985851552"></a> <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.square()" id="idm140582985850416"></a><a data-type="indexterm" data-primary="stacked autoencoders" data-secondary="training one-at-a-time" id="sa15toaat"></a>than
 training the whole stacked autoencoder in one go like we just did, it 
is often much faster to train one shallow autoencoder at a time, then 
stack all of them into a single stacked autoencoder (hence the name), as
 shown on <a data-type="xref" href="#stacking_autoencoders_diagram">Figure&nbsp;15-4</a>. This is especially useful for very deep autoencoders.</p>

<figure><div id="stacking_autoencoders_diagram" class="figure">
<img src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/mlst_1504.png" alt="mlst 1504" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1504.png" width="2197" height="937">
<h6><span class="label">Figure 15-4. </span>Training one autoencoder at a time</h6>
</div></figure>

<p>During the first phase of training, the first autoencoder learns to 
reconstruct the inputs. During the second phase, the second autoencoder 
learns to reconstruct the output of the first autoencoder’s hidden 
layer. Finally, you just build a big sandwich using all these 
autoencoders, as shown in <a data-type="xref" href="#stacking_autoencoders_diagram">Figure&nbsp;15-4</a>
 (i.e., you first stack the hidden layers of each autoencoder, then the 
output layers in reverse order). This gives you the final stacked 
autoencoder. You could easily train more autoencoders this way, building
 a very deep stacked autoencoder.</p>

<p>To implement this multiphase training algorithm, the simplest 
approach is to use a different TensorFlow graph for each phase. After 
training an autoencoder, you just run the training set through it and 
capture the output of the hidden layer. This output then serves as the 
training set for the next autoencoder. Once all autoencoders have been 
trained this way, you simply copy the weights and biases from each 
autoencoder and use them to build the stacked autoencoder. Implementing 
this approach is quite straightforward, so we won’t detail it here, but 
please check out the code in the <a href="https://github.com/ageron/handson-ml">Jupyter notebooks</a> for an example.</p>

<p>Another approach is to use a single graph containing the whole 
stacked autoencoder, plus some extra operations to perform each training
 phase, as shown in <a data-type="xref" href="#single_graph_stacked_diagram">Figure&nbsp;15-5</a>.</p>

<figure><div id="single_graph_stacked_diagram" class="figure">
<img src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/mlst_1505.png" alt="mlst 1505" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1505.png" width="1440" height="769">
<h6><span class="label">Figure 15-5. </span>A single graph to train a stacked autoencoder</h6>
</div></figure>

<p>This deserves a bit of explanation:</p>

<ul>
<li>
<p>The central column in the graph is the full stacked autoencoder. This part can be used after training.</p>
</li>
<li>
<p>The left column is the set of operations needed to run the first 
phase of training. It creates an output layer that bypasses hidden 
layers 2 and 3. This output layer shares the same weights and biases as 
the stacked autoencoder’s output layer. On top of that are the training 
operations that will aim at making the output as close as possible to 
the inputs. Thus, this phase will train the weights and biases for the 
hidden layer 1 and the output layer (i.e., the first autoencoder).</p>
</li>
<li>
<p>The right column in the graph is the set of operations needed to run 
the second phase of training. It adds the training operation that will 
aim at making the output of hidden layer 3 as close as possible to the 
output of hidden layer 1. Note that we must freeze hidden layer 1 while 
running phase 2. This phase will train the weights and biases for hidden
 layers 2 and 3 (i.e., the second autoencoder).</p>
</li>
</ul>

<p>The TensorFlow code looks <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.train.AdamOptimizer" id="idm140582985833024"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.name_scope()" id="tfnamescopech15"></a>like this:</p>

<pre data-type="programlisting" data-code-language="python"><code class="p">[</code><code class="o">...</code><code class="p">]</code> <code class="c1"># Build the whole stacked autoencoder normally.</code>
      <code class="c1"># In this example, the weights are not tied.</code>

<code class="n">optimizer</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">train</code><code class="o">.</code><code class="n">AdamOptimizer</code><code class="p">(</code><code class="n">learning_rate</code><code class="p">)</code>

<code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">name_scope</code><code class="p">(</code><code class="s2">"phase1"</code><code class="p">):</code>
    <code class="n">phase1_outputs</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">matmul</code><code class="p">(</code><code class="n">hidden1</code><code class="p">,</code> <code class="n">weights4</code><code class="p">)</code> <code class="o">+</code> <code class="n">biases4</code>
    <code class="n">phase1_reconstruction_loss</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">reduce_mean</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">square</code><code class="p">(</code><code class="n">phase1_outputs</code> <code class="o">-</code> <code class="n">X</code><code class="p">))</code>
    <code class="n">phase1_reg_loss</code> <code class="o">=</code> <code class="n">regularizer</code><code class="p">(</code><code class="n">weights1</code><code class="p">)</code> <code class="o">+</code> <code class="n">regularizer</code><code class="p">(</code><code class="n">weights4</code><code class="p">)</code>
    <code class="n">phase1_loss</code> <code class="o">=</code> <code class="n">phase1_reconstruction_loss</code> <code class="o">+</code> <code class="n">phase1_reg_loss</code>
    <code class="n">phase1_training_op</code> <code class="o">=</code> <code class="n">optimizer</code><code class="o">.</code><code class="n">minimize</code><code class="p">(</code><code class="n">phase1_loss</code><code class="p">)</code>

<code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">name_scope</code><code class="p">(</code><code class="s2">"phase2"</code><code class="p">):</code>
    <code class="n">phase2_reconstruction_loss</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">reduce_mean</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">square</code><code class="p">(</code><code class="n">hidden3</code> <code class="o">-</code> <code class="n">hidden1</code><code class="p">))</code>
    <code class="n">phase2_reg_loss</code> <code class="o">=</code> <code class="n">regularizer</code><code class="p">(</code><code class="n">weights2</code><code class="p">)</code> <code class="o">+</code> <code class="n">regularizer</code><code class="p">(</code><code class="n">weights3</code><code class="p">)</code>
    <code class="n">phase2_loss</code> <code class="o">=</code> <code class="n">phase2_reconstruction_loss</code> <code class="o">+</code> <code class="n">phase2_reg_loss</code>
    <code class="n">train_vars</code> <code class="o">=</code> <code class="p">[</code><code class="n">weights2</code><code class="p">,</code> <code class="n">biases2</code><code class="p">,</code> <code class="n">weights3</code><code class="p">,</code> <code class="n">biases3</code><code class="p">]</code>
    <code class="n">phase2_training_op</code> <code class="o">=</code> <code class="n">optimizer</code><code class="o">.</code><code class="n">minimize</code><code class="p">(</code><code class="n">phase2_loss</code><code class="p">,</code> <code class="n">var_list</code><code class="o">=</code><code class="n">train_vars</code><code class="p">)</code></pre>

<p>The first phase is rather straightforward: we <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.name_scope()" data-startref="tfnamescopech15" id="idm140582985828448"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.matmul()" id="idm140582985827360"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.reduce_mean()" id="idm140582985826416"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.square()" id="idm140582985322768"></a>just
 create an output layer that skips hidden layers 2 and 3, then build the
 training operations to minimize the distance between the outputs and 
the inputs (plus some regularization).</p>

<p>The second phase just adds the operations needed to minimize the 
distance between the output of hidden layer 3 and hidden layer 1 (also 
with some regularization). Most importantly, we provide the list of 
trainable variables to the <code>minimize()</code> method, making sure to leave out <code>weights1</code> and <code>biases1</code>; this effectively freezes hidden layer 1 during phase 2.</p>

<p>During the execution phase, all you need to do is run the phase 1 
training op for a number of epochs, then the phase 2 training op for 
some more epochs.</p>
<div data-type="tip"><h6>Tip</h6>
<p>Since hidden layer 1 is frozen during phase 2, its output will always
 be the same for any given training instance. To avoid having to 
recompute the output of hidden layer 1 at every single epoch, you can 
compute it for the whole training set at the end of phase 1, then 
directly feed the cached output of hidden layer 1 during phase 2. This 
can give you a nice performance <a data-type="indexterm" data-primary="stacked autoencoders" data-secondary="training one-at-a-time" data-startref="sa15toaat" id="idm140582985317600"></a>boost.</p>
</div>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Visualizing the Reconstructions"><div class="sect2" id="idm140582985852336">
<h2>Visualizing the Reconstructions</h2>

<p>One <a data-type="indexterm" data-primary="stacked autoencoders" data-secondary="visualizing the reconstructions" id="sa15vtr"></a>way
 to ensure that an autoencoder is properly trained is to compare the 
inputs and the outputs. They must be fairly similar, and the differences
 should be unimportant details. Let’s plot two random digits and their 
reconstructions:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">n_test_digits</code> <code class="o">=</code> <code class="mi">2</code>
<code class="n">X_test</code> <code class="o">=</code> <code class="n">mnist</code><code class="o">.</code><code class="n">test</code><code class="o">.</code><code class="n">images</code><code class="p">[:</code><code class="n">n_test_digits</code><code class="p">]</code>

<code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">Session</code><code class="p">()</code> <code class="k">as</code> <code class="n">sess</code><code class="p">:</code>
    <code class="p">[</code><code class="o">...</code><code class="p">]</code> <code class="c1"># Train the Autoencoder</code>
    <code class="n">outputs_val</code> <code class="o">=</code> <code class="n">outputs</code><code class="o">.</code><code class="n">eval</code><code class="p">(</code><code class="n">feed_dict</code><code class="o">=</code><code class="p">{</code><code class="n">X</code><code class="p">:</code> <code class="n">X_test</code><code class="p">})</code>

<code class="k">def</code> <code class="nf">plot_image</code><code class="p">(</code><code class="n">image</code><code class="p">,</code> <code class="n">shape</code><code class="o">=</code><code class="p">[</code><code class="mi">28</code><code class="p">,</code> <code class="mi">28</code><code class="p">]):</code>
    <code class="n">plt</code><code class="o">.</code><code class="n">imshow</code><code class="p">(</code><code class="n">image</code><code class="o">.</code><code class="n">reshape</code><code class="p">(</code><code class="n">shape</code><code class="p">),</code> <code class="n">cmap</code><code class="o">=</code><code class="s2">"Greys"</code><code class="p">,</code> <code class="n">interpolation</code><code class="o">=</code><code class="s2">"nearest"</code><code class="p">)</code>
    <code class="n">plt</code><code class="o">.</code><code class="n">axis</code><code class="p">(</code><code class="s2">"off"</code><code class="p">)</code>

<code class="k">for</code> <code class="n">digit_index</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">n_test_digits</code><code class="p">):</code>
    <code class="n">plt</code><code class="o">.</code><code class="n">subplot</code><code class="p">(</code><code class="n">n_test_digits</code><code class="p">,</code> <code class="mi">2</code><code class="p">,</code> <code class="n">digit_index</code> <code class="o">*</code> <code class="mi">2</code> <code class="o">+</code> <code class="mi">1</code><code class="p">)</code>
    <code class="n">plot_image</code><code class="p">(</code><code class="n">X_test</code><code class="p">[</code><code class="n">digit_index</code><code class="p">])</code>
    <code class="n">plt</code><code class="o">.</code><code class="n">subplot</code><code class="p">(</code><code class="n">n_test_digits</code><code class="p">,</code> <code class="mi">2</code><code class="p">,</code> <code class="n">digit_index</code> <code class="o">*</code> <code class="mi">2</code> <code class="o">+</code> <code class="mi">2</code><code class="p">)</code>
    <code class="n">plot_image</code><code class="p">(</code><code class="n">outputs_val</code><code class="p">[</code><code class="n">digit_index</code><code class="p">])</code></pre>

<p><a data-type="xref" href="#reconstruction_plot">Figure&nbsp;15-6</a> shows the resulting images.</p>

<figure class="smallerthirty"><div id="reconstruction_plot" class="figure">
<img src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/mlst_1506.png" alt="mlst 1506" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1506.png" width="1440" height="1376">
<h6><span class="label">Figure 15-6. </span>Original digits (left) and their reconstructions (right)</h6>
</div></figure>

<p>Looks close enough. So the autoencoder has properly learned to reproduce its inputs, but has it learned useful features? <a data-type="indexterm" data-primary="stacked autoencoders" data-secondary="visualizing the reconstructions" data-startref="sa15vtr" id="idm140582985236480"></a>Let’s take a look.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Visualizing Features"><div class="sect2" id="idm140582985235008">
<h2>Visualizing Features</h2>

<p>Once <a data-type="indexterm" data-primary="autoencoders" data-secondary="visualizing features" id="a15vf"></a>your
 autoencoder has learned some features, you may want to take a look at 
them. There are various techniques for this. Arguably the simplest 
technique is to consider each neuron in every hidden layer, and find the
 training instances that activate it the most. This is especially useful
 for the top hidden layers since they often capture relatively large 
features that you can easily spot in a group of training instances that 
contain them. For example, if a neuron strongly activates when it sees a
 cat in a picture, it will be pretty obvious that the pictures that 
activate it the most all contain cats. However, for lower layers, this 
technique does not work so well, as the features are smaller and more 
abstract, so it’s often hard to understand exactly what the neuron is 
getting all excited about.</p>

<p>Let’s look at another technique. For each neuron in the first hidden 
layer, you can create an image where a pixel’s intensity corresponds to 
the weight of the connection to the given neuron. For example, the 
following code plots the features learned by five neurons in the first 
hidden layer:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">Session</code><code class="p">()</code> <code class="k">as</code> <code class="n">sess</code><code class="p">:</code>
    <code class="p">[</code><code class="o">...</code><code class="p">]</code> <code class="c1"># train autoencoder</code>
    <code class="n">weights1_val</code> <code class="o">=</code> <code class="n">weights1</code><code class="o">.</code><code class="n">eval</code><code class="p">()</code>

<code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="mi">5</code><code class="p">):</code>
    <code class="n">plt</code><code class="o">.</code><code class="n">subplot</code><code class="p">(</code><code class="mi">1</code><code class="p">,</code> <code class="mi">5</code><code class="p">,</code> <code class="n">i</code> <code class="o">+</code> <code class="mi">1</code><code class="p">)</code>
    <code class="n">plot_image</code><code class="p">(</code><code class="n">weights1_val</code><code class="o">.</code><code class="n">T</code><code class="p">[</code><code class="n">i</code><code class="p">])</code></pre>

<p>You may get low-level features such as the ones shown in <a data-type="xref" href="#extracted_features_plot">Figure&nbsp;15-7</a>.</p>

<figure><div id="extracted_features_plot" class="figure">
<img src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/mlst_1507.png" alt="mlst 1507" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1507.png" width="1440" height="193">
<h6><span class="label">Figure 15-7. </span>Features learned by five neurons from the first hidden layer</h6>
</div></figure>

<p>The first four features seem to correspond to small patches, while 
the fifth feature seems to look for vertical strokes (note that these 
features come from the <a data-type="indexterm" data-primary="stacked denoising autoencoders" id="idm140582985116128"></a>stacked denoising autoencoder that we will discuss later).</p>

<p>Another technique is to feed the autoencoder a random input image, 
measure the activation of the neuron you are interested in, and then 
perform backpropagation <a data-type="indexterm" data-primary="backpropagation" id="idm140582985114768"></a>to
 tweak the image in such a way that the neuron will activate even more. 
If you iterate several times (performing gradient ascent), the image 
will gradually turn into the most exciting image (for the neuron). This 
is a useful technique to visualize the kinds of inputs that a neuron is 
looking for.</p>

<p>Finally, if you are using an autoencoder to perform unsupervised 
pretraining—for example, for a classification task—a simple way to 
verify that the features learned by the autoencoder are useful is to 
measure the performance of the <a data-type="indexterm" data-primary="autoencoders" data-secondary="visualizing features" data-startref="a15vf" id="idm140582985112976"></a>classifier.</p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Unsupervised Pretraining Using Stacked Autoencoders"><div class="sect1" id="idm140582985111472">
<h1>Unsupervised Pretraining Using Stacked Autoencoders</h1>

<p>As <a data-type="indexterm" data-primary="unsupervised pretraining" id="up15"></a><a data-type="indexterm" data-primary="stacked autoencoders" data-secondary="unsupervised pretraining with" id="sa15upw"></a>we discussed in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#deep_chapter">Chapter&nbsp;11</a>,
 if you are tackling a complex supervised task but you do not have a lot
 of labeled training data, one solution is to find a neural network that
 performs a similar task, and then reuse its lower layers. This makes it
 possible to train a high-performance model using only little training 
data because your neural network won’t have to learn all the low-level 
features; it will just reuse the feature detectors learned by the 
existing net.</p>

<p>Similarly, if you have a large dataset but most of it is unlabeled, 
you can first train a stacked autoencoder using all the data, then reuse
 the lower layers to create a neural network for your actual task, and 
train it using the labeled data. For example, <a data-type="xref" href="#unsupervised_pretraining_autoencoders_diagram">Figure&nbsp;15-8</a>
 shows how to use a stacked autoencoder to perform unsupervised 
pretraining for a classification neural network. The stacked autoencoder
 itself is typically trained one autoencoder at a time, as discussed 
earlier. When training the classifier, if you really don’t have much 
labeled training data, you may want to freeze the pretrained layers (at 
least the lower ones).</p>

<figure class="smallereighty"><div id="unsupervised_pretraining_autoencoders_diagram" class="figure">
<img src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/mlst_1508.png" alt="mlst 1508" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1508.png" width="1628" height="991">
<h6><span class="label">Figure 15-8. </span>Unsupervised pretraining using autoencoders</h6>
</div></figure>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>This situation is actually quite common, because building a large 
unlabeled dataset is often cheap (e.g., a simple script can download 
millions of images off the internet), but labeling them can only be done
 reliably by humans (e.g., classifying images as cute or not). Labeling 
instances is time-consuming and costly, so it is quite common to have 
only a few thousand labeled instances.</p>
</div>

<p>As we discussed earlier, one of the triggers of the current Deep 
Learning tsunami is the discovery in 2006 by Geoffrey Hinton et al. that
 deep neural networks can be pretrained in an unsupervised fashion. They
 used restricted Boltzmann machines for that (see <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app05.html#other_ann_appendix">Appendix&nbsp;E</a>), but in <a href="https://goo.gl/R5L7HJ">2007 Yoshua Bengio et al. showed</a><sup><a data-type="noteref" id="idm140582985697696-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch15.html#idm140582985697696" class="totri-footnote">2</a></sup> that autoencoders worked just as well.</p>

<p>There is nothing special about the TensorFlow implementation: just 
train an autoencoder using all the training data, then reuse its encoder
 layers to create a new neural network (see <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#deep_chapter">Chapter&nbsp;11</a> for more details on how to reuse pretrained layers, or check out the code examples in the Jupyter notebooks).</p>

<p>Up to now, in order to force the autoencoder to learn interesting 
features, we have limited the size of the coding layer, making it 
undercomplete. There are actually many other kinds of constraints that 
can be used, including ones that allow the coding layer to be just as 
large as the inputs, or even larger, resulting in <a data-type="indexterm" data-primary="overcomplete autoencoder" id="idm140582985694560"></a><a data-type="indexterm" data-primary="autoencoders" data-secondary="overcomplete" id="idm140582985693888"></a>an <em>overcomplete autoencoder</em>. Let’s look at some of those <a data-type="indexterm" data-primary="stacked autoencoders" data-secondary="unsupervised pretraining with" data-startref="sa15upw" id="idm140582985692352"></a><a data-type="indexterm" data-primary="autoencoders" data-secondary="stacked" data-startref="a15s" id="idm140582985691072"></a><a data-type="indexterm" data-primary="stacked autoencoders" data-startref="sa15" id="idm140582985689856"></a><a data-type="indexterm" data-primary="unsupervised pretraining" data-startref="up15" id="idm140582985688912"></a>approaches now.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Denoising Autoencoders"><div class="sect1" id="idm140582985687824">
<h1>Denoising Autoencoders</h1>

<p>Another <a data-type="indexterm" data-primary="autoencoders" data-secondary="denoising" id="a15d"></a><a data-type="indexterm" data-primary="denoising autoencoders" id="da15"></a>way
 to force the autoencoder to learn useful features is to add noise to 
its inputs, training it to recover the original, noise-free inputs. This
 prevents the autoencoder from trivially copying its inputs to its 
outputs, so it ends up having to find patterns in the data.</p>

<p>The idea of using autoencoders to remove noise has been around since 
the 1980s (e.g., it is mentioned in Yann LeCun’s 1987 master’s thesis). 
In a <a href="https://goo.gl/K9pqcx">2008 paper</a>,<sup><a data-type="noteref" id="idm140582985682160-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch15.html#idm140582985682160" class="totri-footnote">3</a></sup> Pascal Vincent et al. showed that autoencoders could also be used for feature extraction. In a <a href="https://goo.gl/HgCDIA">2010 paper</a>,<sup><a data-type="noteref" id="idm140582985680560-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch15.html#idm140582985680560" class="totri-footnote">4</a></sup> Vincent et al. <a data-type="indexterm" data-primary="stacked denoising encoders" id="idm140582985679680"></a>introduced <em>stacked denoising autoencoders</em>.</p>

<p>The <a data-type="indexterm" data-primary="stacked denoising autoencoders" id="idm140582985678176"></a>noise
 can be pure Gaussian noise added to the inputs, or it can be randomly 
switched off inputs, just like in dropout (introduced in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#deep_chapter">Chapter&nbsp;11</a>). <a data-type="xref" href="#denoising_autoencoders_diagram">Figure&nbsp;15-9</a> shows both options.</p>

<figure class="smallereighty"><div id="denoising_autoencoders_diagram" class="figure">
<img src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/mlst_1509.png" alt="mlst 1509" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1509.png" width="1440" height="881">
<h6><span class="label">Figure 15-9. </span>Denoising autoencoders, with Gaussian noise (left) or dropout (right)</h6>
</div></figure>








<section data-type="sect2" data-pdf-bookmark="TensorFlow Implementation"><div class="sect2" id="idm140582985673120">
<h2>TensorFlow Implementation</h2>

<p>Implementing <a data-type="indexterm" data-primary="TensorFlow" data-secondary="denoising autoencoders" id="tf15da"></a>denoising
 autoencoders in TensorFlow is not too hard. Let’s start with Gaussian 
noise. It’s really just like training a regular autoencoder, except you 
add noise to the inputs, and the reconstruction loss is calculated based
 on the original inputs:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">noise_level</code> <code class="o">=</code> <code class="mf">1.0</code>
<code class="n">X</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">placeholder</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">,</code> <code class="n">shape</code><code class="o">=</code><code class="p">[</code><code class="bp">None</code><code class="p">,</code> <code class="n">n_inputs</code><code class="p">])</code>
<code class="n">X_noisy</code> <code class="o">=</code> <code class="n">X</code> <code class="o">+</code> <code class="n">noise_level</code> <code class="o">*</code> <code class="n">tf</code><code class="o">.</code><code class="n">random_normal</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">shape</code><code class="p">(</code><code class="n">X</code><code class="p">))</code>

<code class="n">hidden1</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">dense</code><code class="p">(</code><code class="n">X_noisy</code><code class="p">,</code> <code class="n">n_hidden1</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">relu</code><code class="p">,</code>
                          <code class="n">name</code><code class="o">=</code><code class="s2">"hidden1"</code><code class="p">)</code>
<code class="p">[</code><code class="o">...</code><code class="p">]</code>
<code class="n">reconstruction_loss</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">reduce_mean</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">square</code><code class="p">(</code><code class="n">outputs</code> <code class="o">-</code> <code class="n">X</code><code class="p">))</code> <code class="c1"># MSE</code>
<code class="p">[</code><code class="o">...</code><code class="p">]</code></pre>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>Since the shape of <code>X</code> is only partially defined during the construction phase, we cannot know in advance the shape of the noise that we must add to <code>X</code>. We cannot call <code>X.get_shape()</code> because this would just return the partially defined shape of <code>X</code> (<code>[None, n_inputs]</code>), and <code>random_normal()</code> expects a fully defined shape so it would raise an exception. Instead, we call <code>tf.shape(X)</code>, which creates an operation that will return the shape of <code>X</code> at runtime, which will be fully defined at that point.</p>
</div>

<p>Implementing the dropout version, <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.shape()" id="idm140582985066144"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.matmul()" id="idm140582985065168"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.random_normal()" id="idm140582985064224"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.reduce_mean()" id="idm140582985063280"></a> <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.square()" id="idm140582985062208"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.placeholder_with_default()" id="idm140582985061232"></a>which is more common, is not much harder:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">dropout_rate</code> <code class="o">=</code> <code class="mf">0.3</code>

<code class="n">training</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">placeholder_with_default</code><code class="p">(</code><code class="bp">False</code><code class="p">,</code> <code class="n">shape</code><code class="o">=</code><code class="p">(),</code> <code class="n">name</code><code class="o">=</code><code class="s1">'training'</code><code class="p">)</code>

<code class="n">X</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">placeholder</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">,</code> <code class="n">shape</code><code class="o">=</code><code class="p">[</code><code class="bp">None</code><code class="p">,</code> <code class="n">n_inputs</code><code class="p">])</code>
<code class="n">X_drop</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">dropout</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">dropout_rate</code><code class="p">,</code> <code class="n">training</code><code class="o">=</code><code class="n">training</code><code class="p">)</code>

<code class="n">hidden1</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">dense</code><code class="p">(</code><code class="n">X_drop</code><code class="p">,</code> <code class="n">n_hidden1</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">relu</code><code class="p">,</code>
                          <code class="n">name</code><code class="o">=</code><code class="s2">"hidden1"</code><code class="p">)</code>
<code class="p">[</code><code class="o">...</code><code class="p">]</code>
<code class="n">reconstruction_loss</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">reduce_mean</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">square</code><code class="p">(</code><code class="n">outputs</code> <code class="o">-</code> <code class="n">X</code><code class="p">))</code> <code class="c1"># MSE</code>
<code class="p">[</code><code class="o">...</code><code class="p">]</code></pre>

<p>During training we must set <code>training</code> to <code>True</code> (as explained in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#deep_chapter">Chapter&nbsp;11</a>) using the <code>feed_dict</code>:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">sess</code><code class="o">.</code><code class="n">run</code><code class="p">(</code><code class="n">training_op</code><code class="p">,</code> <code class="n">feed_dict</code><code class="o">=</code><code class="p">{</code><code class="n">X</code><code class="p">:</code> <code class="n">X_batch</code><code class="p">,</code> <code class="n">training</code><code class="p">:</code> <code class="bp">True</code><code class="p">})</code></pre>

<p>During testing it is not necessary to set <code>training</code> to <code>False</code>, since we set that as the default in the call to the <code>placeholder_with_default()</code> <a data-type="indexterm" data-primary="autoencoders" data-secondary="denoising" data-startref="a15d" id="idm140582984947680"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="denoising autoencoders" data-startref="tf15da" id="idm140582984946464"></a><a data-type="indexterm" data-primary="denoising autoencoders" data-startref="da15" id="idm140582984945248"></a>function.</p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Sparse Autoencoders"><div class="sect1" id="idm140582984944176">
<h1>Sparse Autoencoders</h1>

<p>Another <a data-type="indexterm" data-primary="sparse autoencoders" id="sparseauto15"></a><a data-type="indexterm" data-primary="autoencoders" data-secondary="sparse" id="a15sp"></a>kind of constraint that often leads to good feature extraction is <em>sparsity</em>:
 by adding an appropriate term to the cost function, the autoencoder is 
pushed to reduce the number of active neurons in the coding layer. For 
example, it may be pushed to have on average only 5% significantly 
active neurons in the coding layer. This forces the autoencoder to 
represent each input as a combination of a small number of activations. 
As a result, each neuron in the coding layer typically ends up 
representing a useful feature (if you could speak only a few words per 
month, you would probably try to make them worth listening to).</p>

<p>In order to favor sparse models, we must first measure the actual 
sparsity of the coding layer at each training iteration. We do so by 
computing the average activation of each neuron in the coding layer, 
over the whole training batch. The batch size must not be too small, or 
else the mean will not be accurate.</p>

<p>Once we have the mean activation per neuron, we want to penalize the neurons that are too active by adding <a data-type="indexterm" data-primary="sparsity loss" id="idm140582984937648"></a>a <em>sparsity loss</em>
 to the cost function. For example, if we measure that a neuron has an 
average activation of 0.3, but the target sparsity is 0.1, it must be 
penalized to activate less. One approach could be simply adding the 
squared error (0.3 – 0.1)<sup>2</sup> to the cost function, but in practice a better approach is to use the <a data-type="indexterm" data-primary="Kullback–Leibler divergence" id="idm140582984787232"></a>Kullback–Leibler divergence (briefly discussed in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch04.html#linear_models_chapter">Chapter&nbsp;4</a>), which has much stronger gradients than the Mean Squared Error, <a data-type="indexterm" data-primary="Mean Square Error (MSE)" id="idm140582984785632"></a>as you can see in <a data-type="xref" href="#sparsity_loss_plot">Figure&nbsp;15-10</a>.</p>

<figure class="smallereighty"><div id="sparsity_loss_plot" class="figure">
<img src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/mlst_1510.png" alt="mlst 1510" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1510.png" width="1440" height="935">
<h6><span class="label">Figure 15-10. </span>Sparsity loss</h6>
</div></figure>

<p>Given two discrete probability distributions <em>P</em> and <em>Q</em>, the KL divergence between these distributions, noted <em>D</em><sub>KL</sub>(<em>P</em> ∥ <em>Q</em>), can be computed using <a data-type="xref" href="#kl_divergence_equation">Equation 15-1</a>.</p>
<div id="kl_divergence_equation" data-type="equation" class="fifty-percent">
<h5><span class="label">Equation 15-1. </span>Kullback–Leibler divergence</h5>
<img src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_134.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_134.png" width="804" height="160">
</div>

<p>In our case, we want to measure the divergence between the target probability <em>p</em> that a neuron in the coding layer will activate, and the actual probability <em>q</em> (i.e., the mean activation over the training batch). So the KL divergence simplifies to <a data-type="xref" href="#kl_divergence_equation_simplified">Equation 15-2</a>.</p>
<div id="kl_divergence_equation_simplified" data-type="equation">
<h5><span class="label">Equation 15-2. </span>KL divergence between the target sparsity <em>p</em> and the actual sparsity <em>q</em></h5>
<img src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_135.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_135.png" width="1056" height="124">
</div>

<p>Once we have computed the sparsity loss for each neuron in the coding
 layer, we just sum up these losses, and add the result to the cost 
function. In order to control the relative importance of the sparsity 
loss and the reconstruction loss, we can multiply the sparsity loss by a
 sparsity weight hyperparameter. If this weight is too high, the model 
will stick closely to the target sparsity, but it may not reconstruct 
the inputs properly, making the model useless. Conversely, if it is too 
low, the model will mostly ignore the sparsity objective and it will not
 learn any interesting features.</p>








<section data-type="sect2" data-pdf-bookmark="TensorFlow Implementation"><div class="sect2" id="idm140582984884608">
<h2>TensorFlow Implementation</h2>

<p>We <a data-type="indexterm" data-primary="TensorFlow" data-secondary="sparse autoencoders with" id="idm140582984883072"></a>now have all we need to implement a sparse autoencoder <a data-type="indexterm" data-primary="reduce_sum()" id="reducesumch15"></a>using TensorFlow:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">def</code> <code class="nf">kl_divergence</code><code class="p">(</code><code class="n">p</code><code class="p">,</code> <code class="n">q</code><code class="p">):</code>
    <code class="k">return</code> <code class="n">p</code> <code class="o">*</code> <code class="n">tf</code><code class="o">.</code><code class="n">log</code><code class="p">(</code><code class="n">p</code> <code class="o">/</code> <code class="n">q</code><code class="p">)</code> <code class="o">+</code> <code class="p">(</code><code class="mi">1</code> <code class="o">-</code> <code class="n">p</code><code class="p">)</code> <code class="o">*</code> <code class="n">tf</code><code class="o">.</code><code class="n">log</code><code class="p">((</code><code class="mi">1</code> <code class="o">-</code> <code class="n">p</code><code class="p">)</code> <code class="o">/</code> <code class="p">(</code><code class="mi">1</code> <code class="o">-</code> <code class="n">q</code><code class="p">))</code>

<code class="n">learning_rate</code> <code class="o">=</code> <code class="mf">0.01</code>
<code class="n">sparsity_target</code> <code class="o">=</code> <code class="mf">0.1</code>
<code class="n">sparsity_weight</code> <code class="o">=</code> <code class="mf">0.2</code>

<code class="p">[</code><code class="o">...</code><code class="p">]</code> <code class="c1"># Build a normal autoencoder (in this example the coding layer is hidden1)</code>

<code class="n">hidden1_mean</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">reduce_mean</code><code class="p">(</code><code class="n">hidden1</code><code class="p">,</code> <code class="n">axis</code><code class="o">=</code><code class="mi">0</code><code class="p">)</code> <code class="c1"># batch mean</code>
<code class="n">sparsity_loss</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">reduce_sum</code><code class="p">(</code><code class="n">kl_divergence</code><code class="p">(</code><code class="n">sparsity_target</code><code class="p">,</code> <code class="n">hidden1_mean</code><code class="p">))</code>
<code class="n">reconstruction_loss</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">reduce_mean</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">square</code><code class="p">(</code><code class="n">outputs</code> <code class="o">-</code> <code class="n">X</code><code class="p">))</code> <code class="c1"># MSE</code>
<code class="n">loss</code> <code class="o">=</code> <code class="n">reconstruction_loss</code> <code class="o">+</code> <code class="n">sparsity_weight</code> <code class="o">*</code> <code class="n">sparsity_loss</code>
<code class="n">optimizer</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">train</code><code class="o">.</code><code class="n">AdamOptimizer</code><code class="p">(</code><code class="n">learning_rate</code><code class="p">)</code>
<code class="n">training_op</code> <code class="o">=</code> <code class="n">optimizer</code><code class="o">.</code><code class="n">minimize</code><code class="p">(</code><code class="n">loss</code><code class="p">)</code></pre>

<p>An important detail is the fact that <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.log()" id="idm140582984878768"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.reduce_sum()" id="tfredsumch15"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.train.AdamOptimizer" id="idm140582984876736"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.reduce_mean()" id="idm140582984695136"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.square()" id="idm140582984694192"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.matmul()" id="tfmatmulch15"></a>the
 activations of the coding layer must be between 0 and 1 (but not equal 
to 0 or 1), or else the KL divergence will return NaN (Not a Number). A 
simple solution is to use the logistic activation function for the 
coding layer:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">hidden1</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">dense</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">n_hidden1</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">sigmoid</code><code class="p">)</code></pre>

<p>One simple trick can speed up convergence: instead of using the MSE, we can choose a <a data-type="indexterm" data-primary="reconstruction loss" id="idm140582984679072"></a>reconstruction loss that will have larger gradients. <a data-type="indexterm" data-primary="cross entropy" id="idm140582984678384"></a>Cross
 entropy is often a good choice. To use it, we must normalize the inputs
 to make them take on values from 0 to 1, and use the logistic 
activation function in the output layer so the outputs also take on 
values from 0 to 1. TensorFlow’s <code>sigmoid_cross_entropy_with_logits()</code> function <a data-type="indexterm" data-primary="sigmoid_cross_entropy_with_logits()" id="idm140582984677008"></a>takes care of efficiently applying the logistic (sigmoid) activation function to the outputs and computing the cross <a data-type="indexterm" data-primary="reduce_sum()" data-startref="reducesumch15" id="idm140582984676080"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.nn.sigmoid_cross_entropy_with_logits()" id="idm140582984675136"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.matmul()" data-startref="tfmatmulch15" id="idm140582984554304"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.reduce_sum()" data-startref="tfredsumch15" id="idm140582984553088"></a>entropy:</p>

<pre data-type="programlisting" data-code-language="python"><code class="p">[</code><code class="o">...</code><code class="p">]</code>
<code class="n">logits</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">dense</code><code class="p">(</code><code class="n">hidden1</code><code class="p">,</code> <code class="n">n_outputs</code><code class="p">)</code>
<code class="n">outputs</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">sigmoid</code><code class="p">(</code><code class="n">logits</code><code class="p">)</code>

<code class="n">xentropy</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">sigmoid_cross_entropy_with_logits</code><code class="p">(</code><code class="n">labels</code><code class="o">=</code><code class="n">X</code><code class="p">,</code> <code class="n">logits</code><code class="o">=</code><code class="n">logits</code><code class="p">)</code>
<code class="n">reconstruction_loss</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">reduce_sum</code><code class="p">(</code><code class="n">xentropy</code><code class="p">)</code></pre>

<p>Note that the <code>outputs</code> operation is not needed during training (we use it only when we want to look at the <a data-type="indexterm" data-primary="sparse autoencoders" data-startref="sparseauto15" id="idm140582984624816"></a><a data-type="indexterm" data-primary="autoencoders" data-secondary="sparse" data-startref="a15sp" id="idm140582984623904"></a>reconstructions).</p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Variational Autoencoders"><div class="sect1" id="idm140582984943552">
<h1>Variational Autoencoders</h1>

<p>Another <a data-type="indexterm" data-primary="variational autoencoders" id="va15"></a><a data-type="indexterm" data-primary="autoencoders" data-secondary="variational" id="a15v"></a>important category of autoencoders was <a href="https://goo.gl/NZq7r2">introduced in 2014</a> by Diederik Kingma and Max Welling,<sup><a data-type="noteref" id="idm140582984617920-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch15.html#idm140582984617920" class="totri-footnote">5</a></sup> and has quickly become one of the most popular types of autoencoders: <em>variational autoencoders</em>.</p>

<p>They are quite different from all the autoencoders we have discussed so far, in particular:</p>

<ul>
<li>
<p>They are <em>probabilistic autoencoders</em>, <a data-type="indexterm" data-primary="probabilistic autoencoders" id="idm140582984614816"></a>meaning
 that their outputs are partly determined by chance, even after training
 (as opposed to denoising autoencoders, which use randomness only during
 training).</p>
</li>
<li>
<p>Most importantly, they are <em>generative autoencoders</em>, <a data-type="indexterm" data-primary="generative autoencoders" id="idm140582984612496"></a>meaning that they can generate new instances that look like they were sampled from the training set.</p>
</li>
</ul>

<p>Both these properties make them rather similar to RBMs (see <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app05.html#other_ann_appendix">Appendix&nbsp;E</a>),
 but they are easier to train and the sampling process is much faster 
(with RBMs you need to wait for the network to stabilize into a “thermal
 equilibrium” before you can sample a new instance).</p>

<p>Let’s take a look at how they work. <a data-type="xref" href="#variational_autoencoders_diagram">Figure&nbsp;15-11</a>
 (left) shows a variational autoencoder. You can recognize, of course, 
the basic structure of all autoencoders, with an encoder followed by a 
decoder (in this example, they both have two hidden layers), but there 
is a twist: instead of directly producing a coding for a given input, 
the encoder produces <a data-type="indexterm" data-primary="mean coding" id="idm140582984607840"></a>a <em>mean coding</em> <em>μ</em> and a standard deviation <em>σ</em>. The actual coding is then sampled randomly from a <a data-type="indexterm" data-primary="Gaussian distribution" id="idm140582984605760"></a>Gaussian distribution with mean <em>μ</em> and standard deviation <em>σ</em>.
 After that the decoder just decodes the sampled coding normally. The 
right part of the diagram shows a training instance going through this 
autoencoder. First, the encoder produces <em>μ</em> and <em>σ</em>, then a coding is sampled randomly (notice that it is not exactly located at <em>μ</em>), and finally this coding is decoded, and the final output resembles the training instance.</p>

<figure class="smallereighty"><div id="variational_autoencoders_diagram" class="figure">
<img src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/mlst_1511.png" alt="mlst 1511" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1511.png" width="1440" height="1164">
<h6><span class="label">Figure 15-11. </span>Variational autoencoder (left), and an instance going through it (right)</h6>
</div></figure>

<p>As you can see on the diagram, although the inputs may have a very 
convoluted distribution, a variational autoencoder tends to produce 
codings that look as though they were sampled from a simple Gaussian 
distribution:<sup><a data-type="noteref" id="idm140582984468800-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch15.html#idm140582984468800" class="totri-footnote">6</a></sup> during training, the cost function (discussed next) pushes the codings to gradually migrate within the <a data-type="indexterm" data-primary="coding space" id="idm140582984467856"></a>coding space (also called <a data-type="indexterm" data-primary="latent space" id="idm140582984467056"></a>the <em>latent space</em>)
 to occupy a roughly (hyper)spherical region that looks like a cloud of 
Gaussian points. One great consequence is that after training a 
variational autoencoder, you can very easily generate a new instance: 
just sample a random coding from the Gaussian distribution, decode it, <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.reduce_sum()" id="tfredsumch15part2"></a>and voilà!</p>

<p>So let’s look at the <a data-type="indexterm" data-primary="cost function" data-secondary="in variational autoencoders" id="idm140582984463664"></a>cost function. It is composed of two parts. The first is the usual <a data-type="indexterm" data-primary="reconstruction loss" id="idm140582984462512"></a>reconstruction
 loss that pushes the autoencoder to reproduce its inputs (we can use 
cross entropy for this, as discussed earlier). The second is the <em>latent loss</em> <a data-type="indexterm" data-primary="latent loss" id="idm140582984461168"></a>that
 pushes the autoencoder to have codings that look as though they were 
sampled from a simple Gaussian distribution, for which we use the KL 
divergence between the target distribution (the Gaussian distribution) 
and the actual distribution of the codings. The math is a bit more 
complex than earlier, in particular because of the Gaussian noise, which
 limits the amount of information that can be transmitted to the coding 
layer (thus pushing the autoencoder to learn useful features). Luckily, 
the equations <a data-type="indexterm" data-primary="smoothing terms" id="idm140582984459776"></a>simplify to the following code for the <a data-type="indexterm" data-primary="reduce_sum()" id="idm140582984458976"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.square()" id="tfsquarech15"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.log()" id="idm140582984457088"></a>latent loss:<sup><a data-type="noteref" id="idm140582984456016-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch15.html#idm140582984456016" class="totri-footnote">7</a></sup></p>

<pre data-type="programlisting" data-code-language="python"><code class="n">eps</code> <code class="o">=</code> <code class="mf">1e-10</code>  <code class="c1"># smoothing term to avoid computing log(0) which is NaN</code>
<code class="n">latent_loss</code> <code class="o">=</code> <code class="mf">0.5</code> <code class="o">*</code> <code class="n">tf</code><code class="o">.</code><code class="n">reduce_sum</code><code class="p">(</code>
    <code class="n">tf</code><code class="o">.</code><code class="n">square</code><code class="p">(</code><code class="n">hidden3_sigma</code><code class="p">)</code> <code class="o">+</code> <code class="n">tf</code><code class="o">.</code><code class="n">square</code><code class="p">(</code><code class="n">hidden3_mean</code><code class="p">)</code>
    <code class="o">-</code> <code class="mi">1</code> <code class="o">-</code> <code class="n">tf</code><code class="o">.</code><code class="n">log</code><code class="p">(</code><code class="n">eps</code> <code class="o">+</code> <code class="n">tf</code><code class="o">.</code><code class="n">square</code><code class="p">(</code><code class="n">hidden3_sigma</code><code class="p">)))</code></pre>

<p>One common variant is to train the encoder to output <em>γ</em> = log(<em>σ</em><sup>2</sup>) rather than <em>σ</em>. Wherever we need <em>σ</em> we can just compute <img src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_136.png" alt="sigma equals exp left-parenthesis StartFraction gamma Over 2 EndFraction right-parenthesis" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_136.png" width="128" height="30">.
 This makes it a bit easier for the encoder to capture sigmas of 
different scales, and thus it helps speed up convergence. The latent <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.exp()" id="tfexpch15"></a>loss ends up a bit simpler:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">latent_loss</code> <code class="o">=</code> <code class="mf">0.5</code> <code class="o">*</code> <code class="n">tf</code><code class="o">.</code><code class="n">reduce_sum</code><code class="p">(</code>
    <code class="n">tf</code><code class="o">.</code><code class="n">exp</code><code class="p">(</code><code class="n">hidden3_gamma</code><code class="p">)</code> <code class="o">+</code> <code class="n">tf</code><code class="o">.</code><code class="n">square</code><code class="p">(</code><code class="n">hidden3_mean</code><code class="p">)</code> <code class="o">-</code> <code class="mi">1</code> <code class="o">-</code> <code class="n">hidden3_gamma</code><code class="p">)</code></pre>

<p>The following code builds the variational autoencoder shown in <a data-type="xref" href="#variational_autoencoders_diagram">Figure&nbsp;15-11</a> (left), <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.nn.elu()" id="idm140582984370576"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.contrib.layers.variance_scaling_initializer()" id="idm140582984271072"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.shape()" id="idm140582984270032"></a> <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.random_normal()" id="idm140582984268960"></a>using the log(<em>σ</em><sup>2</sup>) variant:<a data-type="indexterm" data-primary="functools.partial()" id="idm140582984267152"></a></p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">functools</code> <code class="kn">import</code> <code class="n">partial</code>

<code class="n">n_inputs</code> <code class="o">=</code> <code class="mi">28</code> <code class="o">*</code> <code class="mi">28</code>
<code class="n">n_hidden1</code> <code class="o">=</code> <code class="mi">500</code>
<code class="n">n_hidden2</code> <code class="o">=</code> <code class="mi">500</code>
<code class="n">n_hidden3</code> <code class="o">=</code> <code class="mi">20</code>  <code class="c1"># codings</code>
<code class="n">n_hidden4</code> <code class="o">=</code> <code class="n">n_hidden2</code>
<code class="n">n_hidden5</code> <code class="o">=</code> <code class="n">n_hidden1</code>
<code class="n">n_outputs</code> <code class="o">=</code> <code class="n">n_inputs</code>
<code class="n">learning_rate</code> <code class="o">=</code> <code class="mf">0.001</code>

<code class="n">initializer</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">contrib</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">variance_scaling_initializer</code><code class="p">()</code>
<code class="n">my_dense_layer</code> <code class="o">=</code> <code class="n">partial</code><code class="p">(</code>
    <code class="n">tf</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">dense</code><code class="p">,</code>
    <code class="n">activation</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">elu</code><code class="p">,</code>
    <code class="n">kernel_initializer</code><code class="o">=</code><code class="n">initializer</code><code class="p">)</code>

<code class="n">X</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">placeholder</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">,</code> <code class="p">[</code><code class="bp">None</code><code class="p">,</code> <code class="n">n_inputs</code><code class="p">])</code>
<code class="n">hidden1</code> <code class="o">=</code> <code class="n">my_dense_layer</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">n_hidden1</code><code class="p">)</code>
<code class="n">hidden2</code> <code class="o">=</code> <code class="n">my_dense_layer</code><code class="p">(</code><code class="n">hidden1</code><code class="p">,</code> <code class="n">n_hidden2</code><code class="p">)</code>
<code class="n">hidden3_mean</code> <code class="o">=</code> <code class="n">my_dense_layer</code><code class="p">(</code><code class="n">hidden2</code><code class="p">,</code> <code class="n">n_hidden3</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="bp">None</code><code class="p">)</code>
<code class="n">hidden3_gamma</code> <code class="o">=</code> <code class="n">my_dense_layer</code><code class="p">(</code><code class="n">hidden2</code><code class="p">,</code> <code class="n">n_hidden3</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="bp">None</code><code class="p">)</code>
<code class="n">noise</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">random_normal</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">shape</code><code class="p">(</code><code class="n">hidden3_gamma</code><code class="p">),</code> <code class="n">dtype</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">)</code>
<code class="n">hidden3</code> <code class="o">=</code> <code class="n">hidden3_mean</code> <code class="o">+</code> <code class="n">tf</code><code class="o">.</code><code class="n">exp</code><code class="p">(</code><code class="mf">0.5</code> <code class="o">*</code> <code class="n">hidden3_gamma</code><code class="p">)</code> <code class="o">*</code> <code class="n">noise</code>
<code class="n">hidden4</code> <code class="o">=</code> <code class="n">my_dense_layer</code><code class="p">(</code><code class="n">hidden3</code><code class="p">,</code> <code class="n">n_hidden4</code><code class="p">)</code>
<code class="n">hidden5</code> <code class="o">=</code> <code class="n">my_dense_layer</code><code class="p">(</code><code class="n">hidden4</code><code class="p">,</code> <code class="n">n_hidden5</code><code class="p">)</code>
<code class="n">logits</code> <code class="o">=</code> <code class="n">my_dense_layer</code><code class="p">(</code><code class="n">hidden5</code><code class="p">,</code> <code class="n">n_outputs</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="bp">None</code><code class="p">)</code>
<code class="n">outputs</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">sigmoid</code><code class="p">(</code><code class="n">logits</code><code class="p">)</code>

<code class="n">xentropy</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">sigmoid_cross_entropy_with_logits</code><code class="p">(</code><code class="n">labels</code><code class="o">=</code><code class="n">X</code><code class="p">,</code> <code class="n">logits</code><code class="o">=</code><code class="n">logits</code><code class="p">)</code>
<code class="n">reconstruction_loss</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">reduce_sum</code><code class="p">(</code><code class="n">xentropy</code><code class="p">)</code>
<code class="n">latent_loss</code> <code class="o">=</code> <code class="mf">0.5</code> <code class="o">*</code> <code class="n">tf</code><code class="o">.</code><code class="n">reduce_sum</code><code class="p">(</code>
    <code class="n">tf</code><code class="o">.</code><code class="n">exp</code><code class="p">(</code><code class="n">hidden3_gamma</code><code class="p">)</code> <code class="o">+</code> <code class="n">tf</code><code class="o">.</code><code class="n">square</code><code class="p">(</code><code class="n">hidden3_mean</code><code class="p">)</code> <code class="o">-</code> <code class="mi">1</code> <code class="o">-</code> <code class="n">hidden3_gamma</code><code class="p">)</code>
<code class="n">loss</code> <code class="o">=</code> <code class="n">reconstruction_loss</code> <code class="o">+</code> <code class="n">latent_loss</code>

<code class="n">optimizer</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">train</code><code class="o">.</code><code class="n">AdamOptimizer</code><code class="p">(</code><code class="n">learning_rate</code><code class="o">=</code><code class="n">learning_rate</code><code class="p">)</code>
<code class="n">training_op</code> <code class="o">=</code> <code class="n">optimizer</code><code class="o">.</code><code class="n">minimize</code><code class="p">(</code><code class="n">loss</code><code class="p">)</code>

<code class="n">init</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">global_variables_initializer</code><code class="p">()</code>
<code class="n">saver</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">train</code><code class="o">.</code><code class="n">Saver</code><code class="p">()</code></pre>








<section data-type="sect2" data-pdf-bookmark="Generating Digits"><div class="sect2" id="idm140582984259424">
<h2>Generating Digits</h2>

<p>Now let’s use this variational <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.reduce_sum()" data-startref="tfredsumch15part2" id="idm140582984257984"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.nn.sigmoid_cross_entropy_with_logits()" id="idm140582984256736"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.square()" data-startref="tfsquarech15" id="idm140582984255824"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.exp()" data-startref="tfexpch15" id="idm140582984254608"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.train.AdamOptimizer" id="idm140582984040352"></a>autoencoder
 to generate images that look like handwritten digits. All we need to do
 is train the model, then sample random codings from a <a data-type="indexterm" data-primary="Gaussian distribution" id="idm140582984039120"></a>Gaussian distribution and decode them.</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">import</code> <code class="nn">numpy</code> <code class="kn">as</code> <code class="nn">np</code>

<code class="n">n_digits</code> <code class="o">=</code> <code class="mi">60</code>
<code class="n">n_epochs</code> <code class="o">=</code> <code class="mi">50</code>
<code class="n">batch_size</code> <code class="o">=</code> <code class="mi">150</code>

<code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">Session</code><code class="p">()</code> <code class="k">as</code> <code class="n">sess</code><code class="p">:</code>
    <code class="n">init</code><code class="o">.</code><code class="n">run</code><code class="p">()</code>
    <code class="k">for</code> <code class="n">epoch</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">n_epochs</code><code class="p">):</code>
        <code class="n">n_batches</code> <code class="o">=</code> <code class="n">mnist</code><code class="o">.</code><code class="n">train</code><code class="o">.</code><code class="n">num_examples</code> <code class="o">//</code> <code class="n">batch_size</code>
        <code class="k">for</code> <code class="n">iteration</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">n_batches</code><code class="p">):</code>
            <code class="n">X_batch</code><code class="p">,</code> <code class="n">y_batch</code> <code class="o">=</code> <code class="n">mnist</code><code class="o">.</code><code class="n">train</code><code class="o">.</code><code class="n">next_batch</code><code class="p">(</code><code class="n">batch_size</code><code class="p">)</code>
            <code class="n">sess</code><code class="o">.</code><code class="n">run</code><code class="p">(</code><code class="n">training_op</code><code class="p">,</code> <code class="n">feed_dict</code><code class="o">=</code><code class="p">{</code><code class="n">X</code><code class="p">:</code> <code class="n">X_batch</code><code class="p">})</code>

    <code class="n">codings_rnd</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">normal</code><code class="p">(</code><code class="n">size</code><code class="o">=</code><code class="p">[</code><code class="n">n_digits</code><code class="p">,</code> <code class="n">n_hidden3</code><code class="p">])</code>
    <code class="n">outputs_val</code> <code class="o">=</code> <code class="n">outputs</code><code class="o">.</code><code class="n">eval</code><code class="p">(</code><code class="n">feed_dict</code><code class="o">=</code><code class="p">{</code><code class="n">hidden3</code><code class="p">:</code> <code class="n">codings_rnd</code><code class="p">})</code></pre>

<p>That’s it. Now we can see what the “handwritten” digits produced by the autoencoder look like (see <a data-type="xref" href="#generated_digits_plot">Figure&nbsp;15-12</a>):</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">for</code> <code class="n">iteration</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">n_digits</code><code class="p">):</code>
    <code class="n">plt</code><code class="o">.</code><code class="n">subplot</code><code class="p">(</code><code class="n">n_digits</code><code class="p">,</code> <code class="mi">10</code><code class="p">,</code> <code class="n">iteration</code> <code class="o">+</code> <code class="mi">1</code><code class="p">)</code>
    <code class="n">plot_image</code><code class="p">(</code><code class="n">outputs_val</code><code class="p">[</code><code class="n">iteration</code><code class="p">])</code></pre>

<figure><div id="generated_digits_plot" class="figure">
<img src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/mlst_1512.png" alt="mlst 1512" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1512.png" width="1440" height="879">
<h6><span class="label">Figure 15-12. </span>Images of handwritten digits generated by the variational autoencoder</h6>
</div></figure>

<p>A majority of these digits look pretty convincing, while a few are 
rather “creative.” But don’t be too harsh on the autoencoder—it only 
started learning less than an hour ago. Give it a bit more training 
time, and those digits will look better and <a data-type="indexterm" data-primary="variational autoencoders" data-startref="va15" id="idm140582983963376"></a><a data-type="indexterm" data-primary="autoencoders" data-secondary="variational" data-startref="a15v" id="idm140582983837200"></a>better.</p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Other Autoencoders"><div class="sect1" id="idm140582984621968">
<h1>Other Autoencoders</h1>

<p>The amazing successes of supervised learning in image recognition, 
speech recognition, text translation, and more have somewhat 
overshadowed unsupervised learning, but it is actually booming. New 
architectures for autoencoders and other unsupervised learning 
algorithms are invented regularly, so much so that we cannot cover them 
all in this book. Here is a brief (by no means exhaustive) overview of a
 few more types of autoencoders that you may want to check out:</p>
<dl>
<dt><a href="https://goo.gl/U5t9Ux"><em>Contractive autoencoder</em> (CAE)</a><sup><a data-type="noteref" id="idm140582983832240-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch15.html#idm140582983832240" class="totri-footnote">8</a></sup></dt>
<dd>
<p><a data-type="indexterm" data-primary="autoencoders" data-secondary="contractive" id="idm140582983830992"></a>The
 autoencoder is constrained during training so that the derivatives of 
the codings with regards to the inputs are small. In other words, two 
similar inputs must have similar codings.</p>
</dd>
<dt><a href="https://goo.gl/PTwsol"><em>Stacked convolutional autoencoders</em></a><sup><a data-type="noteref" id="idm140582983828576-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch15.html#idm140582983828576" class="totri-footnote">9</a></sup></dt>
<dd>
<p><a data-type="indexterm" data-primary="autoencoders" data-secondary="stacked convolutional" id="idm140582983827392"></a>Autoencoders that learn to extract visual features by reconstructing images processed through convolutional layers.</p>
</dd>
<dt><a href="https://goo.gl/HjON1m"><em>Generative stochastic network</em> (GSN)</a><sup><a data-type="noteref" id="idm140582983824928-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch15.html#idm140582983824928">10</a></sup></dt>
<dd>
<p><a data-type="indexterm" data-primary="autoencoders" data-secondary="generative stochastic network (GSN)" id="idm140582983823824"></a>A generalization of denoising autoencoders, with the added capability to generate data.</p>
</dd>
<dt><a href="https://goo.gl/I1LvzL"><em>Winner-take-all (WTA) autoencoder</em></a><sup><a data-type="noteref" id="idm140582983821648-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch15.html#idm140582983821648">11</a></sup></dt>
<dd>
<p><a data-type="indexterm" data-primary="autoencoders" data-secondary="winner-take-all (WTA)" id="idm140582983957504"></a>During training, after computing the activations of all the neurons in the coding layer, only the top <em>k</em>%
 activations for each neuron over the training batch are preserved, and 
the rest are set to zero. Naturally this leads to sparse codings. 
Moreover, a similar WTA approach can be used to produce sparse 
convolutional autoencoders.</p>
</dd>
<dt><a href="https://goo.gl/qd4Rhn"><em>Generative Adversarial Network (GAN)</em></a><sup><a data-type="noteref" id="idm140582983954528-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch15.html#idm140582983954528">12</a></sup></dt>
<dd>
<p><a data-type="indexterm" data-primary="autoencoders" data-secondary="adversarial" id="idm140582983953456"></a>One
 network, called the “discriminator,” is trained to distinguish actual 
data from fake data produced by a second network, called the 
“generator.” The generator learns to trick the discriminator, while the 
discriminator learns to avoid the generator’s tricks. This competition 
leads to increasingly realistic fake data, and quite robust codings. 
Adversarial training is a very powerful idea, currently gaining a lot of
 momentum. Yann Lecun even called it “the coolest thing since sliced 
bread.”</p>
</dd>
</dl>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Exercises"><div class="sect1" id="idm140582983833248">
<h1>Exercises</h1>
<ol>
<li>
<p>What are the main tasks that autoencoders are used for?</p>
</li>
<li>
<p>Suppose you want to train a classifier and you have plenty of 
unlabeled training data, but only a few thousand labeled instances. How 
can autoencoders help? How would you proceed?</p>
</li>
<li>
<p>If an autoencoder perfectly reconstructs the inputs, is it 
necessarily a good autoencoder? How can you evaluate the performance of 
an autoencoder?</p>
</li>
<li>
<p>What are undercomplete and overcomplete autoencoders? What is the 
main risk of an excessively undercomplete autoencoder? What about the 
main risk of an overcomplete autoencoder?</p>
</li>
<li>
<p>How do you tie weights in a stacked autoencoder? What is the point of doing so?</p>
</li>
<li>
<p>What is a common technique to visualize features learned by the lower layer of a stacked autoencoder? What about higher layers?</p>
</li>
<li>
<p>What is a generative model? Can you name a type of generative autoencoder?</p>
</li>
<li>
<p>Let’s use a denoising autoencoder to pretrain an image classifier:</p>

<ul>
<li>
<p>You can use MNIST (simplest), or another large set of images such as <a href="https://goo.gl/VbsmxG">CIFAR10</a>
 if you want a bigger challenge. If you choose CIFAR10, you need to 
write code to load batches of images for training. If you want to skip 
this part, TensorFlow’s model zoo contains <a href="https://goo.gl/3iENgb">tools to do just that</a>.</p>
</li>
<li>
<p>Split the dataset into a training set and a test set. Train a deep denoising autoencoder on the full training set.</p>
</li>
<li>
<p>Check that the images are fairly well reconstructed, and visualize 
the low-level features. Visualize the images that most activate each 
neuron in the coding layer.</p>
</li>
<li>
<p>Build a classification deep neural network, reusing the lower layers 
of the autoencoder. Train it using only 10% of the training set. Can you
 get it to perform as well as the same classifier trained on the full 
training set?</p>
</li>
</ul>
</li>
<li>
<p><em>Semantic hashing</em>, <a href="https://goo.gl/LXzFX6">introduced in 2008 by Ruslan Salakhutdinov and Geoffrey Hinton</a>,<sup><a data-type="noteref" id="idm140582983934608-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch15.html#idm140582983934608">13</a></sup> is <a data-type="indexterm" data-primary="semantic hashing" id="idm140582983933920"></a>a technique used for efficient <em>information retrieval</em>:
 a document (e.g., an image) is passed through a system, typically a 
neural network, which outputs a fairly low-dimensional binary vector 
(e.g., 30 bits). Two similar documents are likely to have identical or 
very similar hashes. By indexing each document using its hash, it is 
possible to retrieve many documents similar to a particular document 
almost instantly, even if there are billions of documents: just compute 
the hash of the document and look up all documents with that same hash 
(or hashes differing by just one or two bits). Let’s implement semantic 
hashing using a slightly tweaked stacked autoencoder:</p>

<ul>
<li>
<p>Create a stacked autoencoder containing two hidden layers below the 
coding layer, and train it on the image dataset you used in the previous
 exercise. The coding layer should contain 30 neurons and use the 
logistic activation function to output values between 0 and 1. After 
training, to produce the hash of an image, you can simply run it through
 the autoencoder, take the output of the coding layer, and round every 
value to the closest integer (0 or 1).</p>
</li>
<li>
<p>One neat trick proposed by Salakhutdinov and Hinton is to add 
Gaussian noise (with zero mean) to the inputs of the coding layer, 
during training only. In order to preserve a high signal-to-noise ratio,
 the autoencoder will learn to feed large values to the coding layer (so
 that the noise becomes negligible). In turn, this means that the 
logistic function of the coding layer will likely saturate at 0 or 1. As
 a result, rounding the codings to 0 or 1 won’t distort them too much, 
and this will improve the reliability of the hashes.</p>
</li>
<li>
<p>Compute the hash of every image, and see if images with identical 
hashes look alike. Since MNIST and CIFAR10 are labeled, a more objective
 way to measure the performance of the autoencoder for semantic hashing 
is to ensure that images with the same hash generally have the same 
class. One way to do this is to measure the average Gini purity 
(introduced in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch06.html#trees_chapter">Chapter&nbsp;6</a>) of the sets of images with identical (or very similar) hashes.</p>
</li>
<li>
<p>Try fine-tuning the hyperparameters using cross-validation.</p>
</li>
<li>
<p>Note that with a labeled dataset, another approach is to train a convolutional neural network (see <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch13.html#cnn_chapter">Chapter&nbsp;13</a>) for classification, then use the layer below the output layer to produce the hashes. See Jinma Gua and Jianmin Li’s <a href="https://goo.gl/i9FTln">2015 paper</a>.<sup><a data-type="noteref" id="idm140582983923136-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch15.html#idm140582983923136">14</a></sup> See if that performs better.</p>
</li>
</ul>
</li>
<li>
<p>Train a variational autoencoder on the image dataset used in the 
previous exercises (MNIST or CIFAR10), and make it generate images. 
Alternatively, you can try to find an unlabeled dataset that you are 
interested in and see if you can generate new samples.</p>
</li>

</ol>

<p>Solutions to these exercises are <a data-type="indexterm" data-primary="autoencoders" data-startref="a15" id="idm140582983920720"></a>available in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app01.html#solutions_appendix">Appendix&nbsp;A</a>.</p>
</div></section>







<div data-type="footnotes"><p data-type="footnote" id="idm140582986786144"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch15.html#idm140582986786144-marker" class="totri-footnote">1</a></sup> “Perception in chess,” W. Chase and H. Simon (1973).</p><p data-type="footnote" id="idm140582985697696"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch15.html#idm140582985697696-marker" class="totri-footnote">2</a></sup> “Greedy Layer-Wise Training of Deep Networks,” Y. Bengio et al. (2007).</p><p data-type="footnote" id="idm140582985682160"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch15.html#idm140582985682160-marker" class="totri-footnote">3</a></sup> “Extracting and Composing Robust Features with Denoising Autoencoders,” P. Vincent et al. (2008).</p><p data-type="footnote" id="idm140582985680560"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch15.html#idm140582985680560-marker" class="totri-footnote">4</a></sup>
 “Stacked Denoising Autoencoders: Learning Useful Representations in a 
Deep Network with a Local Denoising Criterion,” P. Vincent et al. 
(2010).</p><p data-type="footnote" id="idm140582984617920"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch15.html#idm140582984617920-marker" class="totri-footnote">5</a></sup> “Auto-Encoding Variational Bayes,” D. Kingma and M. Welling (2014).</p><p data-type="footnote" id="idm140582984468800"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch15.html#idm140582984468800-marker" class="totri-footnote">6</a></sup> Variational autoencoders are actually more general; the codings are not limited to Gaussian distributions.</p><p data-type="footnote" id="idm140582984456016"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch15.html#idm140582984456016-marker" class="totri-footnote">7</a></sup> For more mathematical details, check out the original paper on variational autoencoders, or Carl Doersch’s <a href="https://goo.gl/ViiAzQ">great tutorial</a> (2016).</p><p data-type="footnote" id="idm140582983832240"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch15.html#idm140582983832240-marker" class="totri-footnote">8</a></sup> “Contractive Auto-Encoders: Explicit Invariance During Feature Extraction,” S. Rifai et al. (2011).</p><p data-type="footnote" id="idm140582983828576"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch15.html#idm140582983828576-marker" class="totri-footnote">9</a></sup> “Stacked Convolutional Auto-Encoders for Hierarchical Feature Extraction,” J. Masci et al. (2011).</p><p data-type="footnote" id="idm140582983824928"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch15.html#idm140582983824928-marker">10</a></sup> “GSNs: Generative Stochastic Networks,” G. Alain et al. (2015).</p><p data-type="footnote" id="idm140582983821648"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch15.html#idm140582983821648-marker">11</a></sup> “Winner-Take-All Autoencoders,” A. Makhzani and B. Frey (2015).</p><p data-type="footnote" id="idm140582983954528"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch15.html#idm140582983954528-marker">12</a></sup> “Generative Adversarial Networks,” I. Goodfellow et al. (2014).</p><p data-type="footnote" id="idm140582983934608"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch15.html#idm140582983934608-marker">13</a></sup> “Semantic Hashing,” R. Salakhutdinov and G. Hinton (2008).</p><p data-type="footnote" id="idm140582983923136"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch15.html#idm140582983923136-marker">14</a></sup> “CNN Based Hashing for Image Retrieval,” J. Gua and J. Li (2015).</p></div></div></section><div class="annotator-outer annotator-viewer viewer annotator-hide">
  <ul class="annotator-widget annotator-listing"></ul>
</div><div class="annotator-modal-wrapper annotator-editor-modal annotator-editor annotator-hide">
	<div class="annotator-outer editor">
		<h2 class="title">Highlight</h2>
		<form class="annotator-widget">
			<ul class="annotator-listing">
			<li class="annotator-item"><textarea id="annotator-field-5" placeholder="Add a note using markdown (optional)" class="js-editor" maxlength="750"></textarea></li></ul>
			<div class="annotator-controls">
				<a class="link-to-markdown" href="https://daringfireball.net/projects/markdown/basics" target="_blank">?</a>
				<ul>
					<li class="delete annotator-hide"><a href="#delete" class="annotator-delete-note button positive">Delete Note</a></li>
					<li class="save"><a href="#save" class="annotator-save annotator-focus button positive">Save Note</a></li>
					<li class="cancel"><a href="#cancel" class="annotator-cancel button">Cancel</a></li>
				</ul>
			</div>
		</form>
	</div>
</div><div class="annotator-modal-wrapper annotator-delete-confirm-modal" style="display: none;">
  <div class="annotator-outer">
    <h2 class="title">Highlight</h2>
      <a class="js-close-delete-confirm annotator-cancel close" href="#close">Close</a>
      <div class="annotator-widget">
         <div class="delete-confirm">
            Are you sure you want to permanently delete this note?
         </div>
         <div class="annotator-controls">
            <a href="#cancel" class="annotator-cancel button js-cancel-delete-confirm">No, I changed my mind</a>
            <a href="#delete" class="annotator-delete button positive js-delete-confirm">Yes, delete it</a>
         </div>
       </div>
   </div>
</div><div class="annotator-adder" style="display: none;">
	<ul class="adders ">
		
		<li class="copy"><a href="#">Copy</a></li>
		
		<li class="add-highlight"><a href="#">Add Highlight</a></li>
		<li class="add-note"><a href="#">
			
				Add Note
			
		</a></li>
		
	</ul>
</div></div></div>



  <div class="t-sbo-prev sbo-prev sbo-nav-bottom">
  
    
      
        <a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch14.html" class="prev nav-link">
      
          <span aria-hidden="true" class="pagination-label t-prev-label">Prev</span>
          <span class="visuallyhidden">Previous Chapter</span>
          <div class="pagination-title t-prev-title">14. Recurrent Neural Networks</div>
        </a>
    
  
  </div>

  <div class="t-sbo-next sbo-next sbo-nav-bottom">
  
    
      
        <a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch16.html" class="next nav-link">
      
          <span aria-hidden="true" class="pagination-label t-next-label">Next</span>
          <span class="visuallyhidden">Next Chapter</span>
          <div class="pagination-title t-next-title">16. Reinforcement Learning</div>
        </a>
    
  
  </div>

</section>
  </div>
<section class="sbo-saved-archives"></section>



          
          
  




    
    
      <div id="js-subscribe-nag" class="subscribe-nag clearfix trial-panel t-subscribe-nag collapsed slideUp">
        
        
          
          
            <p class="usage-data">Find answers on the fly, or master something new. Subscribe today. <a href="https://www.safaribooksonline.com/subscribe/" class="ga-active-trial-subscribe-nag">See pricing options.</a></p>
          

          
        
        

      </div>

    
    



        
      </div>
      




  <footer class="pagefoot t-pagefoot" style="padding-bottom: 69px;">
    <a href="#" class="icon-up" style="display: none;"><div class="visuallyhidden">Back to top</div></a>
    <ul class="js-footer-nav">
      
        <li><a class="t-recommendations-footer" href="https://www.safaribooksonline.com/r/">Recommended</a></li>
      
      <li>
      
      <a class="t-queue-footer" href="https://www.safaribooksonline.com/s/">Queue</a>
      
      </li>
      
        <li><a class="t-recent-footer" href="https://www.safaribooksonline.com/history/">History</a></li>
        <li><a class="t-topics-footer" href="https://www.safaribooksonline.com/topics?q=*&amp;limit=21">Topics</a></li>
      
      
        <li><a class="t-tutorials-footer" href="https://www.safaribooksonline.com/tutorials/">Tutorials</a></li>
      
      <li><a class="t-settings-footer js-settings" href="https://www.safaribooksonline.com/u/">Settings</a></li>
      <li class="full-support"><a href="https://www.safaribooksonline.com/public/support">Support</a></li>
      <li><a href="https://www.safaribooksonline.com/apps/">Get the App</a></li>
      <li><a href="https://www.safaribooksonline.com/accounts/logout/">Sign Out</a></li>
    </ul>
    <span class="copyright">© 2017 <a href="https://www.safaribooksonline.com/" target="_blank">Safari</a>.</span>
    <a href="https://www.safaribooksonline.com/terms/">Terms of Service</a> /
    <a href="https://www.safaribooksonline.com/privacy/">Privacy Policy</a>
  </footer>

<script type="text/javascript">window.NREUM||(NREUM={});NREUM.info={"beacon":"bam.nr-data.net","queueTime":0,"licenseKey":"510f1a6865","errorBeacon":"bam.nr-data.net","transactionName":"YgdaZ0NSW0cEB0RdWltNfkZfUEFdCgofXFBHDVYdR1pQQxZeRl1QQj1aWkU=","applicationTime":651,"applicationID":"3275661","agent":""}</script>


    

    <script src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/a_005.js" charset="utf-8"></script><script type="text/javascript" id="">!function(b,e,f,g,a,c,d){b.fbq||(a=b.fbq=function(){a.callMethod?a.callMethod.apply(a,arguments):a.queue.push(arguments)},b._fbq||(b._fbq=a),a.push=a,a.loaded=!0,a.version="2.0",a.queue=[],c=e.createElement(f),c.async=!0,c.src=g,d=e.getElementsByTagName(f)[0],d.parentNode.insertBefore(c,d))}(window,document,"script","https://connect.facebook.net/en_US/fbevents.js");fbq("init","1732687426968531");fbq("track","PageView");</script>
<noscript><img height="1" width="1" style="display:none" src="https://www.facebook.com/tr?id=1732687426968531&amp;ev=PageView&amp;noscript=1"></noscript><div style="width:0px; height:0px; display:none; visibility:hidden;" id="batBeacon0.3743867347277554"><img style="width:0px; height:0px; display:none; visibility:hidden;" id="batBeacon0.3342180628024528" alt="" src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/0.txt" width="0" height="0"></div>
    <script src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/a_004.js" charset="utf-8"></script>
  

<div class="annotator-notice"></div><div class="font-flyout" style="top: 200px; left: 1257px;"><div class="font-controls-panel">
	<div class="nightmodes">
		<ul>
			<li class="day"><a href="#" id="day-mode" title="Day Mode">
				<i class="fa fa-sun-o"></i>
				<span>Day Mode</span></a></li>
			<li class="cloudy"><a href="#" id="cloudy-mode" title="Cloudy Mode">
				<i class="fa fa-cloud"></i>
				<span>Cloud Mode</span>
			</a></li>
			<li class="night"><a href="#" id="night-mode" title="Night Mode">
				<i class="fa fa-moon-o"></i>
				<span>Night Mode</span>
			</a></li>
		</ul>
	</div>

	<div class="font-resizer resizer">
		<div class="draggable-containment-wrapper">
			<i class="fa fa-font left"></i>
			<span class="filler" style="width: 50%;"></span>
			<div id="js-font-size-draggable" class="draggable ui-widget-content ui-draggable ui-draggable-handle" style="position: relative; left: 80px;"></div>
			<i class="fa fa-font right"></i>
		</div>
	</div>

	<div class="column-resizer resizer">
		<div class="draggable-containment-wrapper">
			<i class="fa fa-compress left"></i>
			<span class="filler" style="width: 50%;"></span>
			<div id="js-column-size-draggable" class="draggable ui-widget-content ui-draggable ui-draggable-handle" style="position: relative; left: 80px;"></div>
			<i class="fa fa-expand right"></i>
		</div>
	</div>

	<a id="reset" class="button" href="#">Reset</a>
</div>
</div><iframe style="display: none;" src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/pixel.html"></iframe><script src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/a.js" type="text/javascript"></script><script src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/a" type="text/javascript"></script><img src="15.%20Autoencoders%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/seg.gif" alt="" style="display: none;" width="1" height="1" border="0"></body></html>