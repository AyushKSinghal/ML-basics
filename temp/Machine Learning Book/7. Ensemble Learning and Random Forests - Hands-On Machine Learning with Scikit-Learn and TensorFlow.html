<!--[if IE]><![endif]-->
<!DOCTYPE html>
<!--[if IE 8]><html class="no-js ie8 oldie" lang="en" prefix="og: http://ogp.me/ns/# og:book: http://ogp.me/ns/book# og:video: http://ogp.me/ns/video#"

    
        itemscope itemtype="http://schema.org/Book http://schema.org/ItemPage"" data-login-url="/accounts/login/"
data-offline-url="/"
data-url="/library/view/hands-on-machine-learning/9781491962282/ch03.html"
data-csrf-cookie="csrfsafari"
data-highlight-privacy=""


  data-user-id="2309833"
  data-user-uuid="2d2acfb7-1cff-4dc7-9037-8ffbac19b02e"
  data-username="ayushksinghal"
  data-account-type="Trial"
  
  data-activated-trial-date="12/02/2017"


  data-archive="9781491962282"
  data-publishers="O&#39;Reilly Media, Inc."



  data-htmlfile-name="ch03.html"
  data-epub-title="Hands-On Machine Learning with Scikit-Learn and TensorFlow" data-debug=0 data-testing=0><![endif]-->
<!--[if gt IE 8]><!-->
<html class="js flexbox flexboxlegacy no-touch no-websqldatabase indexeddb history csscolumns csstransforms localstorage sessionstorage applicationcache svg inlinesvg no-zoom gr__safaribooksonline_com" prefix="og: http://ogp.me/ns/# og:book: http://ogp.me/ns/book# og:video: http://ogp.me/ns/video#" itemscope="" itemtype="http://schema.org/Book http://schema.org/ItemPage" "="" data-login-url="/accounts/login/" data-offline-url="/" data-url="/library/view/hands-on-machine-learning/9781491962282/ch03.html" data-csrf-cookie="csrfsafari" data-highlight-privacy="" data-user-id="2309833" data-user-uuid="2d2acfb7-1cff-4dc7-9037-8ffbac19b02e" data-username="ayushksinghal" data-account-type="Trial" data-activated-trial-date="12/02/2017" data-archive="9781491962282" data-publishers="O'Reilly Media, Inc." data-htmlfile-name="ch03.html" data-epub-title="Hands-On Machine Learning with Scikit-Learn and TensorFlow" data-debug="0" data-testing="0" style="" data-ember-extension="1" lang="en"><!--<![endif]--><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="author" content="Safari Books Online"><meta name="format-detection" content="telephone=no"><meta http-equiv="cleartype" content="on"><meta name="HandheldFriendly" content="True"><meta name="MobileOptimized" content="320"><meta name="apple-itunes-app" content="app-id=881697395, app-argument=safaridetail://9781491962282"><meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, maximum-scale=1.0"><meta property="twitter:account_id" content="4503599627559754"><script type="text/javascript" src="7.%20Ensemble%20Learning%20and%20Random%20Forests%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/510f1a6865.js"></script><script src="7.%20Ensemble%20Learning%20and%20Random%20Forests%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/nr-spa-1044.js"></script><script type="text/javascript" async="" src="7.%20Ensemble%20Learning%20and%20Random%20Forests%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/linkid.js"></script><script src="7.%20Ensemble%20Learning%20and%20Random%20Forests%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/1732687426968531.js" async=""></script><script async="" src="7.%20Ensemble%20Learning%20and%20Random%20Forests%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/fbevents.js"></script><script type="text/javascript" async="" src="7.%20Ensemble%20Learning%20and%20Random%20Forests%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/bat.js"></script><script type="text/javascript" async="" src="7.%20Ensemble%20Learning%20and%20Random%20Forests%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/conversion_async.js"></script><script type="text/javascript" async="" src="7.%20Ensemble%20Learning%20and%20Random%20Forests%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/insight.js"></script><script type="text/javascript" async="" src="7.%20Ensemble%20Learning%20and%20Random%20Forests%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/conversion_async.js"></script><script async="" src="7.%20Ensemble%20Learning%20and%20Random%20Forests%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/gtm.js"></script><script async="" src="7.%20Ensemble%20Learning%20and%20Random%20Forests%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/analytics.js"></script><script type="text/javascript">(window.NREUM||(NREUM={})).loader_config={xpid:"VQQDUVVVGwACU1RUAQA="};window.NREUM||(NREUM={}),__nr_require=function(t,e,n){function r(n){if(!e[n]){var o=e[n]={exports:{}};t[n][0].call(o.exports,function(e){var o=t[n][1][e];return r(o||e)},o,o.exports)}return e[n].exports}if("function"==typeof __nr_require)return __nr_require;for(var o=0;o<n.length;o++)r(n[o]);return r}({1:[function(t,e,n){function r(t){try{c.console&&console.log(t)}catch(e){}}var o,i=t("ee"),a=t(19),c={};try{o=localStorage.getItem("__nr_flags").split(","),console&&"function"==typeof console.log&&(c.console=!0,o.indexOf("dev")!==-1&&(c.dev=!0),o.indexOf("nr_dev")!==-1&&(c.nrDev=!0))}catch(s){}c.nrDev&&i.on("internal-error",function(t){r(t.stack)}),c.dev&&i.on("fn-err",function(t,e,n){r(n.stack)}),c.dev&&(r("NR AGENT IN DEVELOPMENT MODE"),r("flags: "+a(c,function(t,e){return t}).join(", ")))},{}],2:[function(t,e,n){function r(t,e,n,r,o){try{d?d-=1:i("err",[o||new UncaughtException(t,e,n)])}catch(c){try{i("ierr",[c,s.now(),!0])}catch(u){}}return"function"==typeof f&&f.apply(this,a(arguments))}function UncaughtException(t,e,n){this.message=t||"Uncaught error with no additional information",this.sourceURL=e,this.line=n}function o(t){i("err",[t,s.now()])}var i=t("handle"),a=t(20),c=t("ee"),s=t("loader"),f=window.onerror,u=!1,d=0;s.features.err=!0,t(1),window.onerror=r;try{throw new Error}catch(p){"stack"in p&&(t(12),t(11),"addEventListener"in window&&t(6),s.xhrWrappable&&t(13),u=!0)}c.on("fn-start",function(t,e,n){u&&(d+=1)}),c.on("fn-err",function(t,e,n){u&&(this.thrown=!0,o(n))}),c.on("fn-end",function(){u&&!this.thrown&&d>0&&(d-=1)}),c.on("internal-error",function(t){i("ierr",[t,s.now(),!0])})},{}],3:[function(t,e,n){t("loader").features.ins=!0},{}],4:[function(t,e,n){function r(){C++,M=y.hash,this[u]=b.now()}function o(){C--,y.hash!==M&&i(0,!0);var t=b.now();this[l]=~~this[l]+t-this[u],this[d]=t}function i(t,e){E.emit("newURL",[""+y,e])}function a(t,e){t.on(e,function(){this[e]=b.now()})}var c="-start",s="-end",f="-body",u="fn"+c,d="fn"+s,p="cb"+c,h="cb"+s,l="jsTime",m="fetch",v="addEventListener",w=window,y=w.location,b=t("loader");if(w[v]&&b.xhrWrappable){var g=t(9),x=t(10),E=t(8),O=t(6),R=t(12),P=t(7),T=t(13),S=t("ee"),N=S.get("tracer");t(14),b.features.spa=!0;var M,j=w[v],C=0;S.on(u,r),S.on(p,r),S.on(d,o),S.on(h,o),S.buffer([u,d,"xhr-done","xhr-resolved"]),O.buffer([u]),R.buffer(["setTimeout"+s,"clearTimeout"+c,u]),T.buffer([u,"new-xhr","send-xhr"+c]),P.buffer([m+c,m+"-done",m+f+c,m+f+s]),E.buffer(["newURL"]),g.buffer([u]),x.buffer(["propagate",p,h,"executor-err","resolve"+c]),N.buffer([u,"no-"+u]),a(T,"send-xhr"+c),a(S,"xhr-resolved"),a(S,"xhr-done"),a(P,m+c),a(P,m+"-done"),E.on("pushState-end",i),E.on("replaceState-end",i),j("hashchange",i,!0),j("load",i,!0),j("popstate",function(){i(0,C>1)},!0)}},{}],5:[function(t,e,n){function r(t){}if(window.performance&&window.performance.timing&&window.performance.getEntriesByType){var o=t("ee"),i=t("handle"),a=t(12),c=t(11),s="learResourceTimings",f="addEventListener",u="resourcetimingbufferfull",d="bstResource",p="resource",h="-start",l="-end",m="fn"+h,v="fn"+l,w="bstTimer",y="pushState",b=t("loader");b.features.stn=!0,t(8);var g=NREUM.o.EV;o.on(m,function(t,e){var n=t[0];n instanceof g&&(this.bstStart=b.now())}),o.on(v,function(t,e){var n=t[0];n instanceof g&&i("bst",[n,e,this.bstStart,b.now()])}),a.on(m,function(t,e,n){this.bstStart=b.now(),this.bstType=n}),a.on(v,function(t,e){i(w,[e,this.bstStart,b.now(),this.bstType])}),c.on(m,function(){this.bstStart=b.now()}),c.on(v,function(t,e){i(w,[e,this.bstStart,b.now(),"requestAnimationFrame"])}),o.on(y+h,function(t){this.time=b.now(),this.startPath=location.pathname+location.hash}),o.on(y+l,function(t){i("bstHist",[location.pathname+location.hash,this.startPath,this.time])}),f in window.performance&&(window.performance["c"+s]?window.performance[f](u,function(t){i(d,[window.performance.getEntriesByType(p)]),window.performance["c"+s]()},!1):window.performance[f]("webkit"+u,function(t){i(d,[window.performance.getEntriesByType(p)]),window.performance["webkitC"+s]()},!1)),document[f]("scroll",r,{passive:!0}),document[f]("keypress",r,!1),document[f]("click",r,!1)}},{}],6:[function(t,e,n){function r(t){for(var e=t;e&&!e.hasOwnProperty(u);)e=Object.getPrototypeOf(e);e&&o(e)}function o(t){c.inPlace(t,[u,d],"-",i)}function i(t,e){return t[1]}var a=t("ee").get("events"),c=t(22)(a,!0),s=t("gos"),f=XMLHttpRequest,u="addEventListener",d="removeEventListener";e.exports=a,"getPrototypeOf"in Object?(r(document),r(window),r(f.prototype)):f.prototype.hasOwnProperty(u)&&(o(window),o(f.prototype)),a.on(u+"-start",function(t,e){var n=t[1],r=s(n,"nr@wrapped",function(){function t(){if("function"==typeof n.handleEvent)return n.handleEvent.apply(n,arguments)}var e={object:t,"function":n}[typeof n];return e?c(e,"fn-",null,e.name||"anonymous"):n});this.wrapped=t[1]=r}),a.on(d+"-start",function(t){t[1]=this.wrapped||t[1]})},{}],7:[function(t,e,n){function r(t,e,n){var r=t[e];"function"==typeof r&&(t[e]=function(){var t=r.apply(this,arguments);return o.emit(n+"start",arguments,t),t.then(function(e){return o.emit(n+"end",[null,e],t),e},function(e){throw o.emit(n+"end",[e],t),e})})}var o=t("ee").get("fetch"),i=t(19);e.exports=o;var a=window,c="fetch-",s=c+"body-",f=["arrayBuffer","blob","json","text","formData"],u=a.Request,d=a.Response,p=a.fetch,h="prototype";u&&d&&p&&(i(f,function(t,e){r(u[h],e,s),r(d[h],e,s)}),r(a,"fetch",c),o.on(c+"end",function(t,e){var n=this;e?e.clone().arrayBuffer().then(function(t){n.rxSize=t.byteLength,o.emit(c+"done",[null,e],n)}):o.emit(c+"done",[t],n)}))},{}],8:[function(t,e,n){var r=t("ee").get("history"),o=t(22)(r);e.exports=r,o.inPlace(window.history,["pushState","replaceState"],"-")},{}],9:[function(t,e,n){var r=t("ee").get("mutation"),o=t(22)(r),i=NREUM.o.MO;e.exports=r,i&&(window.MutationObserver=function(t){return this instanceof i?new i(o(t,"fn-")):i.apply(this,arguments)},MutationObserver.prototype=i.prototype)},{}],10:[function(t,e,n){function r(t){var e=a.context(),n=c(t,"executor-",e),r=new f(n);return a.context(r).getCtx=function(){return e},a.emit("new-promise",[r,e],e),r}function o(t,e){return e}var i=t(22),a=t("ee").get("promise"),c=i(a),s=t(19),f=NREUM.o.PR;e.exports=a,f&&(window.Promise=r,["all","race"].forEach(function(t){var e=f[t];f[t]=function(n){function r(t){return function(){a.emit("propagate",[null,!o],i),o=o||!t}}var o=!1;s(n,function(e,n){Promise.resolve(n).then(r("all"===t),r(!1))});var i=e.apply(f,arguments),c=f.resolve(i);return c}}),["resolve","reject"].forEach(function(t){var e=f[t];f[t]=function(t){var n=e.apply(f,arguments);return t!==n&&a.emit("propagate",[t,!0],n),n}}),f.prototype["catch"]=function(t){return this.then(null,t)},f.prototype=Object.create(f.prototype,{constructor:{value:r}}),s(Object.getOwnPropertyNames(f),function(t,e){try{r[e]=f[e]}catch(n){}}),a.on("executor-start",function(t){t[0]=c(t[0],"resolve-",this),t[1]=c(t[1],"resolve-",this)}),a.on("executor-err",function(t,e,n){t[1](n)}),c.inPlace(f.prototype,["then"],"then-",o),a.on("then-start",function(t,e){this.promise=e,t[0]=c(t[0],"cb-",this),t[1]=c(t[1],"cb-",this)}),a.on("then-end",function(t,e,n){this.nextPromise=n;var r=this.promise;a.emit("propagate",[r,!0],n)}),a.on("cb-end",function(t,e,n){a.emit("propagate",[n,!0],this.nextPromise)}),a.on("propagate",function(t,e,n){this.getCtx&&!e||(this.getCtx=function(){if(t instanceof Promise)var e=a.context(t);return e&&e.getCtx?e.getCtx():this})}),r.toString=function(){return""+f})},{}],11:[function(t,e,n){var r=t("ee").get("raf"),o=t(22)(r),i="equestAnimationFrame";e.exports=r,o.inPlace(window,["r"+i,"mozR"+i,"webkitR"+i,"msR"+i],"raf-"),r.on("raf-start",function(t){t[0]=o(t[0],"fn-")})},{}],12:[function(t,e,n){function r(t,e,n){t[0]=a(t[0],"fn-",null,n)}function o(t,e,n){this.method=n,this.timerDuration=isNaN(t[1])?0:+t[1],t[0]=a(t[0],"fn-",this,n)}var i=t("ee").get("timer"),a=t(22)(i),c="setTimeout",s="setInterval",f="clearTimeout",u="-start",d="-";e.exports=i,a.inPlace(window,[c,"setImmediate"],c+d),a.inPlace(window,[s],s+d),a.inPlace(window,[f,"clearImmediate"],f+d),i.on(s+u,r),i.on(c+u,o)},{}],13:[function(t,e,n){function r(t,e){d.inPlace(e,["onreadystatechange"],"fn-",c)}function o(){var t=this,e=u.context(t);t.readyState>3&&!e.resolved&&(e.resolved=!0,u.emit("xhr-resolved",[],t)),d.inPlace(t,y,"fn-",c)}function i(t){b.push(t),l&&(x?x.then(a):v?v(a):(E=-E,O.data=E))}function a(){for(var t=0;t<b.length;t++)r([],b[t]);b.length&&(b=[])}function c(t,e){return e}function s(t,e){for(var n in t)e[n]=t[n];return e}t(6);var f=t("ee"),u=f.get("xhr"),d=t(22)(u),p=NREUM.o,h=p.XHR,l=p.MO,m=p.PR,v=p.SI,w="readystatechange",y=["onload","onerror","onabort","onloadstart","onloadend","onprogress","ontimeout"],b=[];e.exports=u;var g=window.XMLHttpRequest=function(t){var e=new h(t);try{u.emit("new-xhr",[e],e),e.addEventListener(w,o,!1)}catch(n){try{u.emit("internal-error",[n])}catch(r){}}return e};if(s(h,g),g.prototype=h.prototype,d.inPlace(g.prototype,["open","send"],"-xhr-",c),u.on("send-xhr-start",function(t,e){r(t,e),i(e)}),u.on("open-xhr-start",r),l){var x=m&&m.resolve();if(!v&&!m){var E=1,O=document.createTextNode(E);new l(a).observe(O,{characterData:!0})}}else f.on("fn-end",function(t){t[0]&&t[0].type===w||a()})},{}],14:[function(t,e,n){function r(t){var e=this.params,n=this.metrics;if(!this.ended){this.ended=!0;for(var r=0;r<d;r++)t.removeEventListener(u[r],this.listener,!1);if(!e.aborted){if(n.duration=a.now()-this.startTime,4===t.readyState){e.status=t.status;var i=o(t,this.lastSize);if(i&&(n.rxSize=i),this.sameOrigin){var s=t.getResponseHeader("X-NewRelic-App-Data");s&&(e.cat=s.split(", ").pop())}}else e.status=0;n.cbTime=this.cbTime,f.emit("xhr-done",[t],t),c("xhr",[e,n,this.startTime])}}}function o(t,e){var n=t.responseType;if("json"===n&&null!==e)return e;var r="arraybuffer"===n||"blob"===n||"json"===n?t.response:t.responseText;return l(r)}function i(t,e){var n=s(e),r=t.params;r.host=n.hostname+":"+n.port,r.pathname=n.pathname,t.sameOrigin=n.sameOrigin}var a=t("loader");if(a.xhrWrappable){var c=t("handle"),s=t(15),f=t("ee"),u=["load","error","abort","timeout"],d=u.length,p=t("id"),h=t(18),l=t(17),m=window.XMLHttpRequest;a.features.xhr=!0,t(13),f.on("new-xhr",function(t){var e=this;e.totalCbs=0,e.called=0,e.cbTime=0,e.end=r,e.ended=!1,e.xhrGuids={},e.lastSize=null,h&&(h>34||h<10)||window.opera||t.addEventListener("progress",function(t){e.lastSize=t.loaded},!1)}),f.on("open-xhr-start",function(t){this.params={method:t[0]},i(this,t[1]),this.metrics={}}),f.on("open-xhr-end",function(t,e){"loader_config"in NREUM&&"xpid"in NREUM.loader_config&&this.sameOrigin&&e.setRequestHeader("X-NewRelic-ID",NREUM.loader_config.xpid)}),f.on("send-xhr-start",function(t,e){var n=this.metrics,r=t[0],o=this;if(n&&r){var i=l(r);i&&(n.txSize=i)}this.startTime=a.now(),this.listener=function(t){try{"abort"===t.type&&(o.params.aborted=!0),("load"!==t.type||o.called===o.totalCbs&&(o.onloadCalled||"function"!=typeof e.onload))&&o.end(e)}catch(n){try{f.emit("internal-error",[n])}catch(r){}}};for(var c=0;c<d;c++)e.addEventListener(u[c],this.listener,!1)}),f.on("xhr-cb-time",function(t,e,n){this.cbTime+=t,e?this.onloadCalled=!0:this.called+=1,this.called!==this.totalCbs||!this.onloadCalled&&"function"==typeof n.onload||this.end(n)}),f.on("xhr-load-added",function(t,e){var n=""+p(t)+!!e;this.xhrGuids&&!this.xhrGuids[n]&&(this.xhrGuids[n]=!0,this.totalCbs+=1)}),f.on("xhr-load-removed",function(t,e){var n=""+p(t)+!!e;this.xhrGuids&&this.xhrGuids[n]&&(delete this.xhrGuids[n],this.totalCbs-=1)}),f.on("addEventListener-end",function(t,e){e instanceof m&&"load"===t[0]&&f.emit("xhr-load-added",[t[1],t[2]],e)}),f.on("removeEventListener-end",function(t,e){e instanceof m&&"load"===t[0]&&f.emit("xhr-load-removed",[t[1],t[2]],e)}),f.on("fn-start",function(t,e,n){e instanceof m&&("onload"===n&&(this.onload=!0),("load"===(t[0]&&t[0].type)||this.onload)&&(this.xhrCbStart=a.now()))}),f.on("fn-end",function(t,e){this.xhrCbStart&&f.emit("xhr-cb-time",[a.now()-this.xhrCbStart,this.onload,e],e)})}},{}],15:[function(t,e,n){e.exports=function(t){var e=document.createElement("a"),n=window.location,r={};e.href=t,r.port=e.port;var o=e.href.split("://");!r.port&&o[1]&&(r.port=o[1].split("/")[0].split("@").pop().split(":")[1]),r.port&&"0"!==r.port||(r.port="https"===o[0]?"443":"80"),r.hostname=e.hostname||n.hostname,r.pathname=e.pathname,r.protocol=o[0],"/"!==r.pathname.charAt(0)&&(r.pathname="/"+r.pathname);var i=!e.protocol||":"===e.protocol||e.protocol===n.protocol,a=e.hostname===document.domain&&e.port===n.port;return r.sameOrigin=i&&(!e.hostname||a),r}},{}],16:[function(t,e,n){function r(){}function o(t,e,n){return function(){return i(t,[f.now()].concat(c(arguments)),e?null:this,n),e?void 0:this}}var i=t("handle"),a=t(19),c=t(20),s=t("ee").get("tracer"),f=t("loader"),u=NREUM;"undefined"==typeof window.newrelic&&(newrelic=u);var d=["setPageViewName","setCustomAttribute","setErrorHandler","finished","addToTrace","inlineHit","addRelease"],p="api-",h=p+"ixn-";a(d,function(t,e){u[e]=o(p+e,!0,"api")}),u.addPageAction=o(p+"addPageAction",!0),u.setCurrentRouteName=o(p+"routeName",!0),e.exports=newrelic,u.interaction=function(){return(new r).get()};var l=r.prototype={createTracer:function(t,e){var n={},r=this,o="function"==typeof e;return i(h+"tracer",[f.now(),t,n],r),function(){if(s.emit((o?"":"no-")+"fn-start",[f.now(),r,o],n),o)try{return e.apply(this,arguments)}finally{s.emit("fn-end",[f.now()],n)}}}};a("setName,setAttribute,save,ignore,onEnd,getContext,end,get".split(","),function(t,e){l[e]=o(h+e)}),newrelic.noticeError=function(t){"string"==typeof t&&(t=new Error(t)),i("err",[t,f.now()])}},{}],17:[function(t,e,n){e.exports=function(t){if("string"==typeof t&&t.length)return t.length;if("object"==typeof t){if("undefined"!=typeof ArrayBuffer&&t instanceof ArrayBuffer&&t.byteLength)return t.byteLength;if("undefined"!=typeof Blob&&t instanceof Blob&&t.size)return t.size;if(!("undefined"!=typeof FormData&&t instanceof FormData))try{return JSON.stringify(t).length}catch(e){return}}}},{}],18:[function(t,e,n){var r=0,o=navigator.userAgent.match(/Firefox[\/\s](\d+\.\d+)/);o&&(r=+o[1]),e.exports=r},{}],19:[function(t,e,n){function r(t,e){var n=[],r="",i=0;for(r in t)o.call(t,r)&&(n[i]=e(r,t[r]),i+=1);return n}var o=Object.prototype.hasOwnProperty;e.exports=r},{}],20:[function(t,e,n){function r(t,e,n){e||(e=0),"undefined"==typeof n&&(n=t?t.length:0);for(var r=-1,o=n-e||0,i=Array(o<0?0:o);++r<o;)i[r]=t[e+r];return i}e.exports=r},{}],21:[function(t,e,n){e.exports={exists:"undefined"!=typeof window.performance&&window.performance.timing&&"undefined"!=typeof window.performance.timing.navigationStart}},{}],22:[function(t,e,n){function r(t){return!(t&&t instanceof Function&&t.apply&&!t[a])}var o=t("ee"),i=t(20),a="nr@original",c=Object.prototype.hasOwnProperty,s=!1;e.exports=function(t,e){function n(t,e,n,o){function nrWrapper(){var r,a,c,s;try{a=this,r=i(arguments),c="function"==typeof n?n(r,a):n||{}}catch(f){p([f,"",[r,a,o],c])}u(e+"start",[r,a,o],c);try{return s=t.apply(a,r)}catch(d){throw u(e+"err",[r,a,d],c),d}finally{u(e+"end",[r,a,s],c)}}return r(t)?t:(e||(e=""),nrWrapper[a]=t,d(t,nrWrapper),nrWrapper)}function f(t,e,o,i){o||(o="");var a,c,s,f="-"===o.charAt(0);for(s=0;s<e.length;s++)c=e[s],a=t[c],r(a)||(t[c]=n(a,f?c+o:o,i,c))}function u(n,r,o){if(!s||e){var i=s;s=!0;try{t.emit(n,r,o,e)}catch(a){p([a,n,r,o])}s=i}}function d(t,e){if(Object.defineProperty&&Object.keys)try{var n=Object.keys(t);return n.forEach(function(n){Object.defineProperty(e,n,{get:function(){return t[n]},set:function(e){return t[n]=e,e}})}),e}catch(r){p([r])}for(var o in t)c.call(t,o)&&(e[o]=t[o]);return e}function p(e){try{t.emit("internal-error",e)}catch(n){}}return t||(t=o),n.inPlace=f,n.flag=a,n}},{}],ee:[function(t,e,n){function r(){}function o(t){function e(t){return t&&t instanceof r?t:t?s(t,c,i):i()}function n(n,r,o,i){if(!p.aborted||i){t&&t(n,r,o);for(var a=e(o),c=l(n),s=c.length,f=0;f<s;f++)c[f].apply(a,r);var d=u[y[n]];return d&&d.push([b,n,r,a]),a}}function h(t,e){w[t]=l(t).concat(e)}function l(t){return w[t]||[]}function m(t){return d[t]=d[t]||o(n)}function v(t,e){f(t,function(t,n){e=e||"feature",y[n]=e,e in u||(u[e]=[])})}var w={},y={},b={on:h,emit:n,get:m,listeners:l,context:e,buffer:v,abort:a,aborted:!1};return b}function i(){return new r}function a(){(u.api||u.feature)&&(p.aborted=!0,u=p.backlog={})}var c="nr@context",s=t("gos"),f=t(19),u={},d={},p=e.exports=o();p.backlog=u},{}],gos:[function(t,e,n){function r(t,e,n){if(o.call(t,e))return t[e];var r=n();if(Object.defineProperty&&Object.keys)try{return Object.defineProperty(t,e,{value:r,writable:!0,enumerable:!1}),r}catch(i){}return t[e]=r,r}var o=Object.prototype.hasOwnProperty;e.exports=r},{}],handle:[function(t,e,n){function r(t,e,n,r){o.buffer([t],r),o.emit(t,e,n)}var o=t("ee").get("handle");e.exports=r,r.ee=o},{}],id:[function(t,e,n){function r(t){var e=typeof t;return!t||"object"!==e&&"function"!==e?-1:t===window?0:a(t,i,function(){return o++})}var o=1,i="nr@id",a=t("gos");e.exports=r},{}],loader:[function(t,e,n){function r(){if(!x++){var t=g.info=NREUM.info,e=p.getElementsByTagName("script")[0];if(setTimeout(u.abort,3e4),!(t&&t.licenseKey&&t.applicationID&&e))return u.abort();f(y,function(e,n){t[e]||(t[e]=n)}),s("mark",["onload",a()+g.offset],null,"api");var n=p.createElement("script");n.src="https://"+t.agent,e.parentNode.insertBefore(n,e)}}function o(){"complete"===p.readyState&&i()}function i(){s("mark",["domContent",a()+g.offset],null,"api")}function a(){return E.exists&&performance.now?Math.round(performance.now()):(c=Math.max((new Date).getTime(),c))-g.offset}var c=(new Date).getTime(),s=t("handle"),f=t(19),u=t("ee"),d=window,p=d.document,h="addEventListener",l="attachEvent",m=d.XMLHttpRequest,v=m&&m.prototype;NREUM.o={ST:setTimeout,SI:d.setImmediate,CT:clearTimeout,XHR:m,REQ:d.Request,EV:d.Event,PR:d.Promise,MO:d.MutationObserver};var w=""+location,y={beacon:"bam.nr-data.net",errorBeacon:"bam.nr-data.net",agent:"js-agent.newrelic.com/nr-spa-1044.min.js"},b=m&&v&&v[h]&&!/CriOS/.test(navigator.userAgent),g=e.exports={offset:c,now:a,origin:w,features:{},xhrWrappable:b};t(16),p[h]?(p[h]("DOMContentLoaded",i,!1),d[h]("load",r,!1)):(p[l]("onreadystatechange",o),d[l]("onload",r)),s("mark",["firstbyte",c],null,"api");var x=0,E=t(21)},{}]},{},["loader",2,14,5,3,4]);</script><link rel="apple-touch-icon" href="https://www.safaribooksonline.com/static/images/apple-touch-icon.8cc2fd27400e.png"><link rel="shortcut icon" href="https://www.safaribooksonline.com/favicon.ico" type="image/x-icon"><link href="7.%20Ensemble%20Learning%20and%20Random%20Forests%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/css.css" rel="stylesheet" type="text/css"><title>9. Up and Running with TensorFlow - Hands-On Machine Learning with Scikit-Learn and TensorFlow</title><link rel="stylesheet" href="7.%20Ensemble%20Learning%20and%20Random%20Forests%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/d6ec1592ffb3.css" type="text/css"><link rel="stylesheet" type="text/css" href="7.%20Ensemble%20Learning%20and%20Random%20Forests%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/annotator.css"><link rel="stylesheet" href="7.%20Ensemble%20Learning%20and%20Random%20Forests%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/font-awesome.css"><style type="text/css" title="ibis-book">@charset "utf-8";#sbo-rt-content html,#sbo-rt-content div,#sbo-rt-content div,#sbo-rt-content span,#sbo-rt-content applet,#sbo-rt-content object,#sbo-rt-content iframe,#sbo-rt-content h1,#sbo-rt-content h2,#sbo-rt-content h3,#sbo-rt-content h4,#sbo-rt-content h5,#sbo-rt-content h6,#sbo-rt-content p,#sbo-rt-content blockquote,#sbo-rt-content pre,#sbo-rt-content a,#sbo-rt-content abbr,#sbo-rt-content acronym,#sbo-rt-content address,#sbo-rt-content big,#sbo-rt-content cite,#sbo-rt-content code,#sbo-rt-content del,#sbo-rt-content dfn,#sbo-rt-content em,#sbo-rt-content img,#sbo-rt-content ins,#sbo-rt-content kbd,#sbo-rt-content q,#sbo-rt-content s,#sbo-rt-content samp,#sbo-rt-content small,#sbo-rt-content strike,#sbo-rt-content strong,#sbo-rt-content sub,#sbo-rt-content sup,#sbo-rt-content tt,#sbo-rt-content var,#sbo-rt-content b,#sbo-rt-content u,#sbo-rt-content i,#sbo-rt-content center,#sbo-rt-content dl,#sbo-rt-content dt,#sbo-rt-content dd,#sbo-rt-content ol,#sbo-rt-content ul,#sbo-rt-content li,#sbo-rt-content fieldset,#sbo-rt-content form,#sbo-rt-content label,#sbo-rt-content legend,#sbo-rt-content table,#sbo-rt-content caption,#sbo-rt-content tdiv,#sbo-rt-content tfoot,#sbo-rt-content thead,#sbo-rt-content tr,#sbo-rt-content th,#sbo-rt-content td,#sbo-rt-content article,#sbo-rt-content aside,#sbo-rt-content canvas,#sbo-rt-content details,#sbo-rt-content embed,#sbo-rt-content figure,#sbo-rt-content figcaption,#sbo-rt-content footer,#sbo-rt-content header,#sbo-rt-content hgroup,#sbo-rt-content menu,#sbo-rt-content nav,#sbo-rt-content output,#sbo-rt-content ruby,#sbo-rt-content section,#sbo-rt-content summary,#sbo-rt-content time,#sbo-rt-content mark,#sbo-rt-content audio,#sbo-rt-content video{margin:0;padding:0;border:0;font-size:100%;font:inherit;vertical-align:baseline}#sbo-rt-content article,#sbo-rt-content aside,#sbo-rt-content details,#sbo-rt-content figcaption,#sbo-rt-content figure,#sbo-rt-content footer,#sbo-rt-content header,#sbo-rt-content hgroup,#sbo-rt-content menu,#sbo-rt-content nav,#sbo-rt-content section{display:block}#sbo-rt-content div{line-height:1}#sbo-rt-content ol,#sbo-rt-content ul{list-style:none}#sbo-rt-content blockquote,#sbo-rt-content q{quotes:none}#sbo-rt-content blockquote:before,#sbo-rt-content blockquote:after,#sbo-rt-content q:before,#sbo-rt-content q:after{content:none}#sbo-rt-content table{border-collapse:collapse;border-spacing:0}@page{margin:5px !important}#sbo-rt-content p{margin:10px 0 0;line-height:125%;text-align:left}#sbo-rt-content p.byline{text-align:left;margin:-33px auto 35px;font-style:italic;font-weight:bold}#sbo-rt-content div.preface p+p.byline{margin:1em 0 0}#sbo-rt-content div.preface p.byline+p.byline{margin:0}#sbo-rt-content div.sect1>p.byline{margin:-.25em 0 1em}#sbo-rt-content div.sect1>p.byline+p.byline{margin-top:-1em}#sbo-rt-content em{font-style:italic;font-family:inherit}#sbo-rt-content em strong,#sbo-rt-content strong em{font-weight:bold;font-style:italic;font-family:inherit}#sbo-rt-content strong,#sbo-rt-content span.bold{font-weight:bold}#sbo-rt-content em.replaceable{font-style:italic}#sbo-rt-content strong.userinput{font-weight:bold;font-style:normal}#sbo-rt-content span.bolditalic{font-weight:bold;font-style:italic}#sbo-rt-content a.ulink,#sbo-rt-content a.xref,#sbo-rt-content a.email,#sbo-rt-content a.link,#sbo-rt-content a{text-decoration:none;color:#8e0012}#sbo-rt-content span.lineannotation{font-style:italic;color:#a62a2a;font-family:serif}#sbo-rt-content span.underline{text-decoration:underline}#sbo-rt-content span.strikethrough{text-decoration:line-through}#sbo-rt-content span.smallcaps{font-variant:small-caps}#sbo-rt-content span.cursor{background:#000;color:#fff}#sbo-rt-content span.smaller{font-size:75%}#sbo-rt-content .boxedtext,#sbo-rt-content .keycap{border-style:solid;border-width:1px;border-color:#000;padding:1px}#sbo-rt-content span.gray50{color:#7F7F7F;}#sbo-rt-content h1,#sbo-rt-content div.toc-title,#sbo-rt-content h2,#sbo-rt-content h3,#sbo-rt-content h4,#sbo-rt-content h5{-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;font-weight:bold;text-align:left;page-break-after:avoid !important;font-family:sans-serif,"DejaVuSans"}#sbo-rt-content div.toc-title{font-size:1.5em;margin-top:20px !important;margin-bottom:30px !important}#sbo-rt-content section[data-type="sect1"] h1{font-size:1.3em;color:#8e0012;margin:40px 0 8px 0}#sbo-rt-content section[data-type="sect2"] h2{font-size:1.1em;margin:30px 0 8px 0 !important}#sbo-rt-content section[data-type="sect3"] h3{font-size:1em;color:#555;margin:20px 0 8px 0 !important}#sbo-rt-content section[data-type="sect4"] h4{font-size:1em;font-weight:normal;font-style:italic;margin:15px 0 6px 0 !important}#sbo-rt-content section[data-type="chapter"]>div>h1,#sbo-rt-content section[data-type="preface"]>div>h1,#sbo-rt-content section[data-type="appendix"]>div>h1,#sbo-rt-content section[data-type="glossary"]>div>h1,#sbo-rt-content section[data-type="bibliography"]>div>h1,#sbo-rt-content section[data-type="index"]>div>h1{font-size:2em;line-height:1;margin-bottom:50px;color:#000;padding-bottom:10px;border-bottom:1px solid #000}#sbo-rt-content span.label,#sbo-rt-content span.keep-together{font-size:inherit;font-weight:inherit}#sbo-rt-content div[data-type="part"] h1{font-size:2em;text-align:center;margin-top:0 !important;margin-bottom:50px;padding:50px 0 10px 0;border-bottom:1px solid #000}#sbo-rt-content img.width-ninety{width:90%}#sbo-rt-content img{max-width:95%;margin:0 auto;padding:0}#sbo-rt-content div.figure{background-color:transparent;text-align:center !important;margin:15px 0 15px 0 !important;page-break-inside:avoid}#sbo-rt-content figure{margin:15px 0 15px 0 !important;page-break-inside:avoid}#sbo-rt-content div.figure h6{font-size:90%;text-align:center;font-weight:normal;font-style:italic;font-family:serif !important;color:#000;padding-top:10px !important;page-break-before:avoid;page-break-after:avoid}#sbo-rt-content div.informalfigure{text-align:center !important;padding:5px 0 !important}#sbo-rt-content div.sidebar{margin:15px 0 10px 0 !important;border:1px solid #DCDCDC;background-color:#F7F7F7;padding:15px !important;page-break-inside:avoid}#sbo-rt-content aside[data-type="sidebar"]{margin:15px 0 10px 0 !important;page-break-inside:avoid}#sbo-rt-content div.sidebar-title,#sbo-rt-content aside[data-type="sidebar"] h5{font-weight:bold;font-size:1em;font-family:sans-serif;text-transform:uppercase;letter-spacing:1px;text-align:center;margin:4px 0 6px 0 !important;page-break-inside:avoid}#sbo-rt-content div.sidebar ol,#sbo-rt-content div.sidebar ul,#sbo-rt-content aside[data-type="sidebar"] ol,#sbo-rt-content aside[data-type="sidebar"] ul{margin-left:1.25em !important}#sbo-rt-content div.sidebar div.figure p.title,#sbo-rt-content aside[data-type="sidebar"] figcaption,#sbo-rt-content div.sidebar div.informalfigure div.caption{font-size:90%;text-align:center;font-weight:normal;font-style:italic;font-family:serif !important;color:#000;padding:5px !important;page-break-before:avoid;page-break-after:avoid}#sbo-rt-content div.sidebar div.tip,#sbo-rt-content div.sidebar div[data-type="tip"],#sbo-rt-content div.sidebar div.note,#sbo-rt-content div.sidebar div[data-type="note"],#sbo-rt-content div.sidebar div.warning,#sbo-rt-content div.sidebar div[data-type="warning"],#sbo-rt-content div.sidebar div[data-type="caution"],#sbo-rt-content div.sidebar div[data-type="important"]{margin:20px auto 20px auto !important;font-size:90%;width:85%}#sbo-rt-content aside[data-type="sidebar"] p.byline{font-size:90%;font-weight:bold;font-style:italic;text-align:center;text-indent:0;margin:5px auto 6px;page-break-after:avoid}#sbo-rt-content pre{white-space:pre-wrap;font-family:"Ubuntu Mono",monospace;margin:25px 0 25px 20px;font-size:85%;display:block;-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;overflow-wrap:break-word}#sbo-rt-content div.note pre.programlisting,#sbo-rt-content div.tip pre.programlisting,#sbo-rt-content div.warning pre.programlisting,#sbo-rt-content div.caution pre.programlisting,#sbo-rt-content div.important pre.programlisting{margin-bottom:0}#sbo-rt-content code{font-family:"Ubuntu Mono",monospace;-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;overflow-wrap:break-word}#sbo-rt-content code strong em,#sbo-rt-content code em strong,#sbo-rt-content pre em strong,#sbo-rt-content pre strong em,#sbo-rt-content strong code em code,#sbo-rt-content em code strong code,#sbo-rt-content span.bolditalic code{font-weight:bold;font-style:italic;font-family:"Ubuntu Mono BoldItal",monospace}#sbo-rt-content code em,#sbo-rt-content em code,#sbo-rt-content pre em,#sbo-rt-content em.replaceable{font-family:"Ubuntu Mono Ital",monospace;font-style:italic}#sbo-rt-content code strong,#sbo-rt-content strong code,#sbo-rt-content pre strong,#sbo-rt-content strong.userinput{font-family:"Ubuntu Mono Bold",monospace;font-weight:bold}#sbo-rt-content div[data-type="example"]{margin:10px 0 15px 0 !important}#sbo-rt-content div[data-type="example"] h1,#sbo-rt-content div[data-type="example"] h2,#sbo-rt-content div[data-type="example"] h3,#sbo-rt-content div[data-type="example"] h4,#sbo-rt-content div[data-type="example"] h5,#sbo-rt-content div[data-type="example"] h6{font-style:italic;font-weight:normal;text-align:left !important;text-transform:none !important;font-family:serif !important;margin:10px 0 5px 0 !important;border-bottom:1px solid #000}#sbo-rt-content li pre.example{padding:10px 0 !important}#sbo-rt-content div[data-type="example"] pre[data-type="programlisting"],#sbo-rt-content div[data-type="example"] pre[data-type="screen"]{margin:0}#sbo-rt-content section[data-type="titlepage"]>div>h1{font-size:2em;margin:50px 0 10px 0 !important;line-height:1;text-align:center}#sbo-rt-content section[data-type="titlepage"] h2,#sbo-rt-content section[data-type="titlepage"] p.subtitle,#sbo-rt-content section[data-type="titlepage"] p[data-type="subtitle"]{font-size:1.3em;font-weight:normal;text-align:center;margin-top:.5em;color:#555}#sbo-rt-content section[data-type="titlepage"]>div>h2[data-type="author"],#sbo-rt-content section[data-type="titlepage"] p.author{font-size:1.3em;font-family:serif !important;font-weight:bold;margin:50px 0 !important;text-align:center}#sbo-rt-content section[data-type="titlepage"] p.edition{text-align:center;text-transform:uppercase;margin-top:2em}#sbo-rt-content section[data-type="titlepage"]{text-align:center}#sbo-rt-content section[data-type="titlepage"]:after{content:url(css_assets/titlepage_footer_ebook.png);margin:0 auto;max-width:80%}#sbo-rt-content div.book div.titlepage div.publishername{margin-top:60%;margin-bottom:20px;text-align:center;font-size:1.25em}#sbo-rt-content div.book div.titlepage div.locations p{margin:0;text-align:center}#sbo-rt-content div.book div.titlepage div.locations p.cities{font-size:80%;text-align:center;margin-top:5px}#sbo-rt-content section.preface[title="Dedication"]>div.titlepage h2.title{text-align:center;text-transform:uppercase;font-size:1.5em;margin-top:50px;margin-bottom:50px}#sbo-rt-content ul.stafflist{margin:15px 0 15px 20px !important}#sbo-rt-content ul.stafflist li{list-style-type:none;padding:5px 0}#sbo-rt-content ul.printings li{list-style-type:none}#sbo-rt-content section.preface[title="Dedication"] p{font-style:italic;text-align:center}#sbo-rt-content div.colophon h1.title{font-size:1.3em;margin:0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon h2.subtitle{margin:0 !important;color:#000;font-family:serif !important;font-size:1em;font-weight:normal}#sbo-rt-content div.colophon div.author h3.author{font-size:1.1em;font-family:serif !important;margin:10px 0 0 !important;font-weight:normal}#sbo-rt-content div.colophon div.editor h4,#sbo-rt-content div.colophon div.editor h3.editor{color:#000;font-size:.8em;margin:15px 0 0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon div.editor h3.editor{font-size:.8em;margin:0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon div.publisher{margin-top:10px}#sbo-rt-content div.colophon div.publisher p,#sbo-rt-content div.colophon div.publisher span.publishername{margin:0;font-size:.8em}#sbo-rt-content div.legalnotice p,#sbo-rt-content div.timestamp p{font-size:.8em}#sbo-rt-content div.timestamp p{margin-top:10px}#sbo-rt-content div.colophon[title="About the Author"] h1.title,#sbo-rt-content div.colophon[title="Colophon"] h1.title{font-size:1.5em;margin:0 !important;font-family:sans-serif !important}#sbo-rt-content section.chapter div.titlepage div.author{margin:10px 0 10px 0}#sbo-rt-content section.chapter div.titlepage div.author div.affiliation{font-style:italic}#sbo-rt-content div.attribution{margin:5px 0 0 50px !important}#sbo-rt-content h3.author span.orgname{display:none}#sbo-rt-content div.epigraph{margin:10px 0 10px 20px !important;page-break-inside:avoid;font-size:90%}#sbo-rt-content div.epigraph p{font-style:italic}#sbo-rt-content blockquote,#sbo-rt-content div.blockquote{margin:10px !important;page-break-inside:avoid;font-size:95%}#sbo-rt-content blockquote p,#sbo-rt-content div.blockquote p{font-style:italic;margin:.75em 0 0 !important}#sbo-rt-content blockquote div.attribution,#sbo-rt-content blockquote p[data-type="attribution"]{margin:5px 0 10px 30px !important;text-align:right;width:80%}#sbo-rt-content blockquote div.attribution p,#sbo-rt-content blockquote p[data-type="attribution"]{font-style:normal;margin-top:5px}#sbo-rt-content blockquote div.attribution p:before,#sbo-rt-content blockquote p[data-type="attribution"]:before{font-style:normal;content:"—";-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none}#sbo-rt-content p.right{text-align:right;margin:0}#sbo-rt-content div[data-type="footnotes"]{border-top:1px solid black;margin-top:1.5em}#sbo-rt-content sub,#sbo-rt-content sup{font-size:75%;line-height:0;position:relative}#sbo-rt-content sup{top:-.5em}#sbo-rt-content sub{bottom:-.25em}#sbo-rt-content div.refentry p.refname{font-size:1em;font-family:sans-serif,"DejaVuSans";font-weight:bold;margin-bottom:5px;overflow:auto;width:100%}#sbo-rt-content div.refentry{width:100%;display:block;margin-top:2em}#sbo-rt-content div.refsynopsisdiv{display:block;clear:both}#sbo-rt-content div.refentry header{page-break-inside:avoid !important;display:block;break-inside:avoid !important;padding-top:0;border-bottom:1px solid #000}#sbo-rt-content div.refsect1 h6{font-size:.9em;font-family:sans-serif,"DejaVuSans";font-weight:bold}#sbo-rt-content div.refsect1{margin-top:3em}#sbo-rt-content dt{padding-top:10px !important;padding-bottom:0 !important}#sbo-rt-content dd{margin-left:1.5em !important;margin-bottom:.25em}#sbo-rt-content dd ol,#sbo-rt-content dd ul{padding-left:1em}#sbo-rt-content dd li{margin-top:0;margin-bottom:0}#sbo-rt-content dd,#sbo-rt-content li{text-align:left}#sbo-rt-content ul,#sbo-rt-content ul>li,#sbo-rt-content ol ul,#sbo-rt-content ol ul>li,#sbo-rt-content ul ol ul,#sbo-rt-content ul ol ul>li{list-style-type:disc}#sbo-rt-content ul ul,#sbo-rt-content ul ul>li{list-style-type:square}#sbo-rt-content ul ul ul,#sbo-rt-content ul ul ul>li{list-style-type:circle}#sbo-rt-content ol,#sbo-rt-content ol>li,#sbo-rt-content ol ul ol,#sbo-rt-content ol ul ol>li,#sbo-rt-content ul ol,#sbo-rt-content ul ol>li{list-style-type:decimal}#sbo-rt-content ol ol,#sbo-rt-content ol ol>li{list-style-type:lower-alpha}#sbo-rt-content ol ol ol,#sbo-rt-content ol ol ol>li{list-style-type:lower-roman}#sbo-rt-content ol,#sbo-rt-content ul{list-style-position:outside;margin:15px 0 15px 1.25em;padding-left:2.25em}#sbo-rt-content ol li,#sbo-rt-content ul li{margin:.5em 0 .65em;line-height:125%}#sbo-rt-content div.orderedlistalpha{list-style-type:upper-alpha}#sbo-rt-content table.simplelist,#sbo-rt-content ul.simplelist{margin:15px 0 15px 20px !important}#sbo-rt-content ul.simplelist li{list-style-type:none;padding:5px 0}#sbo-rt-content table.simplelist td{border:none}#sbo-rt-content table.simplelist tr{border-bottom:none}#sbo-rt-content table.simplelist tr:nth-of-type(even){background-color:transparent}#sbo-rt-content dl.calloutlist p:first-child{margin-top:-25px !important}#sbo-rt-content dl.calloutlist dd{padding-left:0;margin-top:-25px}#sbo-rt-content dl.calloutlist img,#sbo-rt-content a.co img{padding:0}#sbo-rt-content div.toc ol{margin-top:8px !important;margin-bottom:8px !important;margin-left:0 !important;padding-left:0 !important}#sbo-rt-content div.toc ol ol{margin-left:30px !important;padding-left:0 !important}#sbo-rt-content div.toc ol li{list-style-type:none}#sbo-rt-content div.toc a{color:#8e0012}#sbo-rt-content div.toc ol a{font-size:1em;font-weight:bold}#sbo-rt-content div.toc ol>li>ol a{font-weight:bold;font-size:1em}#sbo-rt-content div.toc ol>li>ol>li>ol a{text-decoration:none;font-weight:normal;font-size:1em}#sbo-rt-content div.tip,#sbo-rt-content div[data-type="tip"],#sbo-rt-content div.note,#sbo-rt-content div[data-type="note"],#sbo-rt-content div.warning,#sbo-rt-content div[data-type="warning"],#sbo-rt-content div[data-type="caution"],#sbo-rt-content div[data-type="important"]{margin:30px !important;font-size:90%;padding:10px 8px 20px 8px !important;page-break-inside:avoid}#sbo-rt-content div.tip ol,#sbo-rt-content div.tip ul,#sbo-rt-content div[data-type="tip"] ol,#sbo-rt-content div[data-type="tip"] ul,#sbo-rt-content div.note ol,#sbo-rt-content div.note ul,#sbo-rt-content div[data-type="note"] ol,#sbo-rt-content div[data-type="note"] ul,#sbo-rt-content div.warning ol,#sbo-rt-content div.warning ul,#sbo-rt-content div[data-type="warning"] ol,#sbo-rt-content div[data-type="warning"] ul,#sbo-rt-content div[data-type="caution"] ol,#sbo-rt-content div[data-type="caution"] ul,#sbo-rt-content div[data-type="important"] ol,#sbo-rt-content div[data-type="important"] ul{margin-left:1.5em !important}#sbo-rt-content div.tip,#sbo-rt-content div[data-type="tip"],#sbo-rt-content div.note,#sbo-rt-content div[data-type="note"]{border:1px solid #BEBEBE;background-color:transparent}#sbo-rt-content div.warning,#sbo-rt-content div[data-type="warning"],#sbo-rt-content div[data-type="caution"],#sbo-rt-content div[data-type="important"]{border:1px solid #BC8F8F}#sbo-rt-content div.tip h3,#sbo-rt-content div[data-type="tip"] h6,#sbo-rt-content div[data-type="tip"] h1,#sbo-rt-content div.note h3,#sbo-rt-content div[data-type="note"] h6,#sbo-rt-content div[data-type="note"] h1,#sbo-rt-content div.warning h3,#sbo-rt-content div[data-type="warning"] h6,#sbo-rt-content div[data-type="warning"] h1,#sbo-rt-content div[data-type="caution"] h6,#sbo-rt-content div[data-type="caution"] h1,#sbo-rt-content div[data-type="important"] h1,#sbo-rt-content div[data-type="important"] h6{font-weight:bold;font-size:110%;font-family:sans-serif !important;text-transform:uppercase;letter-spacing:1px;text-align:center;margin:4px 0 6px !important}#sbo-rt-content div.tip h3,#sbo-rt-content div[data-type="tip"] h6,#sbo-rt-content div.note h3,#sbo-rt-content div[data-type="note"] h6,#sbo-rt-content div[data-type="tip"] h1,#sbo-rt-content div[data-type="note"] h1{color:#737373}#sbo-rt-content div.warning h3,#sbo-rt-content div[data-type="warning"] h6,#sbo-rt-content div[data-type="caution"] h6,#sbo-rt-content div[data-type="important"] h6,#sbo-rt-content div[data-type="warning"] h1,#sbo-rt-content div[data-type="caution"] h1,#sbo-rt-content div[data-type="important"] h1{color:#C67171}#sbo-rt-content div.sect1[title="Safari® Books Online"] div.note,#sbo-rt-content div.safarienabled{background-color:transparent;margin:8px 0 0 !important;border:0 solid #BEBEBE;font-size:100%;padding:0 !important;page-break-inside:avoid}#sbo-rt-content div.sect1[title="Safari® Books Online"] div.note h3,#sbo-rt-content div.safarienabled h6{display:none}#sbo-rt-content div.table,#sbo-rt-content table{margin:15px 0 30px 0 !important;max-width:95%;border:none !important;background:none;display:table !important}#sbo-rt-content div.table,#sbo-rt-content div.informaltable,#sbo-rt-content table{page-break-inside:avoid}#sbo-rt-content tr,#sbo-rt-content tr td{border-bottom:1px solid #c3c3c3}#sbo-rt-content thead td,#sbo-rt-content thead th{border-bottom:#9d9d9d 1px solid !important;border-top:#9d9d9d 1px solid !important}#sbo-rt-content tr:nth-of-type(even){background-color:#f1f6fc}#sbo-rt-content thead{font-family:sans-serif;font-weight:bold}#sbo-rt-content td,#sbo-rt-content th{display:table-cell;padding:.3em;text-align:left;vertical-align:middle;font-size:80%}#sbo-rt-content div.informaltable table{margin:10px auto !important}#sbo-rt-content div.informaltable table tr{border-bottom:none}#sbo-rt-content div.informaltable table tr:nth-of-type(even){background-color:transparent}#sbo-rt-content div.informaltable td,#sbo-rt-content div.informaltable th{border:#9d9d9d 1px solid}#sbo-rt-content div.table-title,#sbo-rt-content table caption{font-weight:normal;font-style:italic;font-family:serif;font-size:1em;margin:10px 0 10px 0 !important;padding:0;page-break-after:avoid;text-align:left !important}#sbo-rt-content table code{font-size:smaller}#sbo-rt-content div.equation,#sbo-rt-content div[data-type="equation"]{margin:10px 0 15px 0 !important}#sbo-rt-content div.equation-title,#sbo-rt-content div[data-type="equation"] h5{font-style:italic;font-weight:normal;font-family:serif !important;font-size:90%;margin:20px 0 10px 0 !important;page-break-after:avoid}#sbo-rt-content div.equation-contents{margin-left:20px}#sbo-rt-content span.inlinemediaobject{height:.85em;display:inline-block;margin-bottom:.2em}#sbo-rt-content span.inlinemediaobject img{margin:0;height:.85em}#sbo-rt-content div.informalequation{margin:20px 0 20px 20px;width:75%}#sbo-rt-content div.informalequation img{width:75%}#sbo-rt-content div.index{text-indent:0}#sbo-rt-content div.index li{line-height:140%}#sbo-rt-content div.index a.indexterm{color:#8e0012}#sbo-rt-content div.index ul,#sbo-rt-content div[data-type="index"] ul{list-style-type:none;padding-left:0;margin-left:0}#sbo-rt-content div.index ul li{padding-left:0;margin-left:0}#sbo-rt-content div.index ul li ul li{margin-left:1em}#sbo-rt-content code.boolean,#sbo-rt-content .navy{color:rgb(0,0,128);}#sbo-rt-content code.character,#sbo-rt-content .olive{color:rgb(128,128,0);}#sbo-rt-content code.comment,#sbo-rt-content .blue{color:rgb(0,0,255);}#sbo-rt-content code.conditional,#sbo-rt-content .limegreen{color:rgb(50,205,50);}#sbo-rt-content code.constant,#sbo-rt-content .darkorange{color:rgb(255,140,0);}#sbo-rt-content code.debug,#sbo-rt-content .darkred{color:rgb(139,0,0);}#sbo-rt-content code.define,#sbo-rt-content .darkgoldenrod,#sbo-rt-content .gold{color:rgb(184,134,11);}#sbo-rt-content code.delimiter,#sbo-rt-content .dimgray{color:rgb(105,105,105);}#sbo-rt-content code.error,#sbo-rt-content .red{color:rgb(255,0,0);}#sbo-rt-content code.exception,#sbo-rt-content .salmon{color:rgb(250,128,11);}#sbo-rt-content code.float,#sbo-rt-content .steelblue{color:rgb(70,130,180);}#sbo-rt-content pre code.function,#sbo-rt-content .green{color:rgb(0,128,0);}#sbo-rt-content code.identifier,#sbo-rt-content .royalblue{color:rgb(65,105,225);}#sbo-rt-content code.ignore,#sbo-rt-content .gray{color:rgb(128,128,128);}#sbo-rt-content code.include,#sbo-rt-content .purple{color:rgb(128,0,128);}#sbo-rt-content code.keyword,#sbo-rt-content .sienna{color:rgb(160,82,45);}#sbo-rt-content code.label,#sbo-rt-content .deeppink{color:rgb(255,20,147);}#sbo-rt-content code.macro,#sbo-rt-content .orangered{color:rgb(255,69,0);}#sbo-rt-content code.number,#sbo-rt-content .brown{color:rgb(165,42,42);}#sbo-rt-content code.operator,#sbo-rt-content .black{color:#000;}#sbo-rt-content code.preCondit,#sbo-rt-content .teal{color:rgb(0,128,128);}#sbo-rt-content code.preProc,#sbo-rt-content .fuschia{color:rgb(255,0,255);}#sbo-rt-content code.repeat,#sbo-rt-content .indigo{color:rgb(75,0,130);}#sbo-rt-content code.special,#sbo-rt-content .saddlebrown{color:rgb(139,69,19);}#sbo-rt-content code.specialchar,#sbo-rt-content .magenta{color:rgb(255,0,255);}#sbo-rt-content code.specialcomment,#sbo-rt-content .seagreen{color:rgb(46,139,87);}#sbo-rt-content code.statement,#sbo-rt-content .forestgreen{color:rgb(34,139,34);}#sbo-rt-content code.storageclass,#sbo-rt-content .plum{color:rgb(221,160,221);}#sbo-rt-content code.string,#sbo-rt-content .darkred{color:rgb(139,0,0);}#sbo-rt-content code.structure,#sbo-rt-content .chocolate{color:rgb(210,106,30);}#sbo-rt-content code.tag,#sbo-rt-content .darkcyan{color:rgb(0,139,139);}#sbo-rt-content code.todo,#sbo-rt-content .black{color:#000;}#sbo-rt-content code.type,#sbo-rt-content .mediumslateblue{color:rgb(123,104,238);}#sbo-rt-content code.typedef,#sbo-rt-content .darkgreen{color:rgb(0,100,0);}#sbo-rt-content code.underlined{text-decoration:underline;}#sbo-rt-content pre code.hll{background-color:#ffc}#sbo-rt-content pre code.c{color:#09F;font-style:italic}#sbo-rt-content pre code.err{color:#A00}#sbo-rt-content pre code.k{color:#069;font-weight:bold}#sbo-rt-content pre code.o{color:#555}#sbo-rt-content pre code.cm{color:#35586C;font-style:italic}#sbo-rt-content pre code.cp{color:#099}#sbo-rt-content pre code.c1{color:#35586C;font-style:italic}#sbo-rt-content pre code.cs{color:#35586C;font-weight:bold;font-style:italic}#sbo-rt-content pre code.gd{background-color:#FCC}#sbo-rt-content pre code.ge{font-style:italic}#sbo-rt-content pre code.gr{color:#F00}#sbo-rt-content pre code.gh{color:#030;font-weight:bold}#sbo-rt-content pre code.gi{background-color:#CFC}#sbo-rt-content pre code.go{color:#000}#sbo-rt-content pre code.gp{color:#009;font-weight:bold}#sbo-rt-content pre code.gs{font-weight:bold}#sbo-rt-content pre code.gu{color:#030;font-weight:bold}#sbo-rt-content pre code.gt{color:#9C6}#sbo-rt-content pre code.kc{color:#069;font-weight:bold}#sbo-rt-content pre code.kd{color:#069;font-weight:bold}#sbo-rt-content pre code.kn{color:#069;font-weight:bold}#sbo-rt-content pre code.kp{color:#069}#sbo-rt-content pre code.kr{color:#069;font-weight:bold}#sbo-rt-content pre code.kt{color:#078;font-weight:bold}#sbo-rt-content pre code.m{color:#F60}#sbo-rt-content pre code.s{color:#C30}#sbo-rt-content pre code.na{color:#309}#sbo-rt-content pre code.nb{color:#366}#sbo-rt-content pre code.nc{color:#0A8;font-weight:bold}#sbo-rt-content pre code.no{color:#360}#sbo-rt-content pre code.nd{color:#99F}#sbo-rt-content pre code.ni{color:#999;font-weight:bold}#sbo-rt-content pre code.ne{color:#C00;font-weight:bold}#sbo-rt-content pre code.nf{color:#C0F}#sbo-rt-content pre code.nl{color:#99F}#sbo-rt-content pre code.nn{color:#0CF;font-weight:bold}#sbo-rt-content pre code.nt{color:#309;font-weight:bold}#sbo-rt-content pre code.nv{color:#033}#sbo-rt-content pre code.ow{color:#000;font-weight:bold}#sbo-rt-content pre code.w{color:#bbb}#sbo-rt-content pre code.mf{color:#F60}#sbo-rt-content pre code.mh{color:#F60}#sbo-rt-content pre code.mi{color:#F60}#sbo-rt-content pre code.mo{color:#F60}#sbo-rt-content pre code.sb{color:#C30}#sbo-rt-content pre code.sc{color:#C30}#sbo-rt-content pre code.sd{color:#C30;font-style:italic}#sbo-rt-content pre code.s2{color:#C30}#sbo-rt-content pre code.se{color:#C30;font-weight:bold}#sbo-rt-content pre code.sh{color:#C30}#sbo-rt-content pre code.si{color:#A00}#sbo-rt-content pre code.sx{color:#C30}#sbo-rt-content pre code.sr{color:#3AA}#sbo-rt-content pre code.s1{color:#C30}#sbo-rt-content pre code.ss{color:#A60}#sbo-rt-content pre code.bp{color:#366}#sbo-rt-content pre code.vc{color:#033}#sbo-rt-content pre code.vg{color:#033}#sbo-rt-content pre code.vi{color:#033}#sbo-rt-content pre code.il{color:#F60}#sbo-rt-content pre code.g{color:#050}#sbo-rt-content pre code.l{color:#C60}#sbo-rt-content pre code.l{color:#F90}#sbo-rt-content pre code.n{color:#008}#sbo-rt-content pre code.nx{color:#008}#sbo-rt-content pre code.py{color:#96F}#sbo-rt-content pre code.p{color:#000}#sbo-rt-content pre code.x{color:#F06}#sbo-rt-content div.blockquote_sampler_toc{width:95%;margin:5px 5px 5px 10px !important}#sbo-rt-content div{font-family:serif;text-align:left}#sbo-rt-content .gray-background,#sbo-rt-content .reverse-video{background:#2E2E2E;color:#FFF}#sbo-rt-content .light-gray-background{background:#A0A0A0}#sbo-rt-content .preserve-whitespace{white-space:pre-wrap}#sbo-rt-content span.gray{color:#4C4C4C}#sbo-rt-content div[data-type="equation"].fifty-percent img{width:50%}</style><script> // <![CDATA[
    var g = {
      position_cache: {
        
          "chapter": "/api/v1/book/9781491962282/chapter/ch03.html",
          "book_id": "9781491962282",
          "chapter_uri": "ch03.html",
          "position": 1.94296272015,
          "user_uuid": "2d2acfb7-1cff-4dc7-9037-8ffbac19b02e",
          "next_chapter_uri": "/library/view/hands-on-machine-learning/9781491962282/ch04.html"
        
      },
      title: "Hands\u002DOn Machine Learning with Scikit\u002DLearn and TensorFlow",
      author_list: "Aurélien Géron",
      format: "book",
      source: "application/epub+zip",
      is_system_book: true,
      is_public: false,
      loaded_from_server: true,
      allow_scripts: false,
      has_mathml: false,
      show_ios_app_teaser: false
    };
    // ]]></script><script src="7.%20Ensemble%20Learning%20and%20Random%20Forests%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/modernizr.js"></script><script>
    
      
        

        

        
          
            window.PUBLIC_ANNOTATIONS = true;
          
        

      

      
        window.MOBILE_PUBLIC_ANNOTATIONS = false;
      

    

    
      window.PRIVACY_CONTROL_OVERRIDE = false;
    

    
      window.PRIVACY_CONTROL_SWITCH = true;
    

    
      window.PUBLISHER_PAGES = true;
    

      window.SBO = {
        "constants": {
          "SITB_ENDPOINT": "https://www.safaribooksonline.com/api/v2/sitb/",
          "SEARCH_SELECT_ENDPOINT": "https://www.safaribooksonline.com/api/v2/search/select/",
          "ENABLE_ONLINE_TRAINING": true
        }
      };
  </script><link rel="canonical" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch03.html"><meta name="description" content=" Chapter 3. Classification In Chapter&nbsp;1 we mentioned that the most common supervised learning tasks are regression (predicting values) and classification (predicting classes). In Chapter&nbsp;2 we explored a regression ... "><meta property="og:title" content="3. Classification"><meta itemprop="isPartOf" content="/library/view/hands-on-machine-learning/9781491962282/"><meta itemprop="name" content="3. Classification"><meta property="og:url" itemprop="url" content="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch03.html"><meta property="og:site_name" content="Safari"><meta property="og:image" itemprop="thumbnailUrl" content="https://www.safaribooksonline.com/library/cover/9781491962282/"><meta property="og:description" itemprop="description" content=" Chapter 3. Classification In Chapter&nbsp;1 we mentioned that the most common supervised learning tasks are regression (predicting values) and classification (predicting classes). In Chapter&nbsp;2 we explored a regression ... "><meta itemprop="inLanguage" content="en"><meta itemprop="publisher" content="O'Reilly Media, Inc."><meta property="og:type" content="book"><meta property="og:book:isbn" itemprop="isbn" content="9781491962299"><meta property="og:book:author" itemprop="author" content="Aurélien Géron"><meta property="og:book:tag" itemprop="about" content="Core Programming"><meta property="og:book:tag" itemprop="about" content="Engineering"><meta property="og:book:tag" itemprop="about" content="Python"><meta name="twitter:card" content="summary"><meta name="twitter:site" content="@safari"><style type="text/css" id="font-styles" data-template="#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-size: &lt;%= font_size %&gt; !important; }"></style><style type="text/css" id="font-family" data-template="#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-family: &lt;%= font_family %&gt; !important; }"></style><style type="text/css" id="column-width" data-template="#sbo-rt-content { max-width: &lt;%= column_width %&gt;% !important; margin: 0 auto !important; }"></style><noscript><meta http-equiv="refresh" content="0; url=/library/no-js/" /></noscript><script type="text/javascript">
  (function(i,s,o,g,r,a,m) {
    i['GoogleAnalyticsObject']=r;
    i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();
    a=s.createElement(o),m=s.getElementsByTagName(o)[0];
    a.async=1;
    a.src=g;
    m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  var matches = document.cookie.match(/BrowserCookie\s*=\s*([a-f0-9\-]{36})/),
      user_uuid = null;

  if (matches && matches.length === 2) {
    user_uuid = matches[1];
  }


  ga('create', 'UA-39299553-7', {'userId': '2d2acfb7-1cff-4dc7-9037-8ffbac19b02e' });



  
    ga('set', 'dimension1', 'Trial');
  


ga('set', 'dimension6', user_uuid);


  ga('set', 'dimension2', '2d2acfb7-1cff-4dc7-9037-8ffbac19b02e');
  






//enable enhanced link tracking
ga('require', 'linkid', 'linkid.js');

// reading interface will track pageviews itself
if (document.location.pathname.indexOf("/library/view") !== 0) {
  ga('send', 'pageview');
}
</script><script>
    (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    '//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-5P4V6Z');
  </script><script defer="defer" src="7.%20Ensemble%20Learning%20and%20Random%20Forests%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/vendor.js"></script><script defer="defer" src="7.%20Ensemble%20Learning%20and%20Random%20Forests%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/reader.js"></script><script async="" src="7.%20Ensemble%20Learning%20and%20Random%20Forests%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/MathJax.js"></script><style id="annotator-dynamic-style">.annotator-adder, .annotator-outer, .annotator-notice {
  z-index: 100019;
}
.annotator-filter {
  z-index: 100009;
}</style><script src="7.%20Ensemble%20Learning%20and%20Random%20Forests%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/a_003.js"></script><script src="7.%20Ensemble%20Learning%20and%20Random%20Forests%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/a_002.js"></script></head>


<body class="reading sidenav nav-collapsed  scalefonts subscribe-panel library" data-gr-c-s-loaded="true">

    
  
  <noscript> 
    <iframe src="//www.googletagmanager.com/ns.html?id=GTM-5P4V6Z"
            height="0" width="0"
            style="display:none;visibility:hidden">
    </iframe>
  </noscript>
  



    
      <div class="hide working" role="status">
        <div class="working-image"></div>
      </div>
      <div class="sbo-site-nav">
        





<a href="#container" class="skip">Skip to content</a><header class="topbar t-topbar"><nav role="navigation" class="js-site-nav"><ul class="topnav"><li class="t-logo"><a href="https://www.safaribooksonline.com/home/" class="l0 None safari-home nav-icn js-keyboard-nav-home"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width="20" height="20" version="1.1" fill="#4A3C31"><desc>Safari Home Icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M4 9.9L4 9.9 4 18 16 18 16 9.9 10 4 4 9.9ZM2.6 8.1L2.6 8.1 8.7 1.9 10 0.5 11.3 1.9 17.4 8.1 18 8.7 18 9.5 18 18.1 18 20 16.1 20 3.9 20 2 20 2 18.1 2 9.5 2 8.7 2.6 8.1Z"></path><rect x="10" y="12" width="3" height="7"></rect><rect transform="translate(18.121320, 10.121320) rotate(-315.000000) translate(-18.121320, -10.121320) " x="16.1" y="9.1" width="4" height="2"></rect><rect transform="translate(2.121320, 10.121320) scale(-1, 1) rotate(-315.000000) translate(-2.121320, -10.121320) " x="0.1" y="9.1" width="4" height="2"></rect></g></svg><span>Safari Home</span></a></li><li><a href="https://www.safaribooksonline.com/r/" class="t-recommendations-nav l0 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>recommendations icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M50 25C50 18.2 44.9 12.5 38.3 11.7 37.5 5.1 31.8 0 25 0 18.2 0 12.5 5.1 11.7 11.7 5.1 12.5 0 18.2 0 25 0 31.8 5.1 37.5 11.7 38.3 12.5 44.9 18.2 50 25 50 31.8 50 37.5 44.9 38.3 38.3 44.9 37.5 50 31.8 50 25ZM25 3.1C29.7 3.1 33.6 6.9 34.4 11.8 30.4 12.4 26.9 15.1 25 18.8 23.1 15.1 19.6 12.4 15.6 11.8 16.4 6.9 20.3 3.1 25 3.1ZM34.4 15.6C33.6 19.3 30.7 22.2 27.1 22.9 27.8 19.2 30.7 16.3 34.4 15.6ZM22.9 22.9C19.2 22.2 16.3 19.3 15.6 15.6 19.3 16.3 22.2 19.2 22.9 22.9ZM3.1 25C3.1 20.3 6.9 16.4 11.8 15.6 12.4 19.6 15.1 23.1 18.8 25 15.1 26.9 12.4 30.4 11.8 34.4 6.9 33.6 3.1 29.7 3.1 25ZM22.9 27.1C22.2 30.7 19.3 33.6 15.6 34.4 16.3 30.7 19.2 27.8 22.9 27.1ZM25 46.9C20.3 46.9 16.4 43.1 15.6 38.2 19.6 37.6 23.1 34.9 25 31.3 26.9 34.9 30.4 37.6 34.4 38.2 33.6 43.1 29.7 46.9 25 46.9ZM27.1 27.1C30.7 27.8 33.6 30.7 34.4 34.4 30.7 33.6 27.8 30.7 27.1 27.1ZM38.2 34.4C37.6 30.4 34.9 26.9 31.3 25 34.9 23.1 37.6 19.6 38.2 15.6 43.1 16.4 46.9 20.3 46.9 25 46.9 29.7 43.1 33.6 38.2 34.4Z"></path></g></svg><span>Recommended</span></a></li><li><a href="https://www.safaribooksonline.com/s/" class="t-queue-nav l0 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>queue icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M25 29.2C25.4 29.2 25.8 29.1 26.1 28.9L48.7 16.8C49.5 16.4 50 15.5 50 14.6 50 13.7 49.5 12.8 48.7 12.4L26.1 0.3C25.4-0.1 24.6-0.1 23.9 0.3L1.3 12.4C0.5 12.8 0 13.7 0 14.6 0 15.5 0.5 16.4 1.3 16.8L23.9 28.9C24.2 29.1 24.6 29.2 25 29.2ZM7.3 14.6L25 5.2 42.7 14.6 25 24 7.3 14.6ZM48.7 22.4L47.7 21.9 25 34.2 2.3 21.9 1.3 22.4C0.5 22.9 0 23.7 0 24.7 0 25.6 0.5 26.5 1.3 26.9L23.9 39.3C24.2 39.5 24.6 39.6 25 39.6 25.4 39.6 25.8 39.5 26.1 39.3L48.7 26.9C49.5 26.5 50 25.6 50 24.7 50 23.7 49.5 22.9 48.7 22.4ZM48.7 32.8L47.7 32.3 25 44.6 2.3 32.3 1.3 32.8C0.5 33.3 0 34.1 0 35.1 0 36 0.5 36.9 1.3 37.3L23.9 49.7C24.2 49.9 24.6 50 25 50 25.4 50 25.8 49.9 26.1 49.7L48.7 37.3C49.5 36.9 50 36 50 35.1 50 34.1 49.5 33.3 48.7 32.8Z"></path></g></svg><span>
                  Queue
              </span></a></li><li class="search"><a href="#" class="t-search-nav trigger nav-icn l0" data-dropdown-selector=".searchbox"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>search icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M31.3 0C20.9 0 12.5 8.4 12.5 18.8 12.5 22.5 13.6 25.9 15.4 28.8L1.2 42.9C-0.4 44.5-0.4 47.2 1.2 48.8 2 49.6 3.1 50 4.2 50 5.2 50 6.3 49.6 7.1 48.8L21.2 34.6C24.1 36.5 27.5 37.5 31.3 37.5 41.6 37.5 50 29.1 50 18.8 50 8.4 41.6 0 31.3 0ZM31.3 31.3C24.4 31.3 18.8 25.6 18.8 18.8 18.8 11.9 24.4 6.3 31.3 6.3 38.1 6.3 43.8 11.9 43.8 18.8 43.8 25.6 38.1 31.3 31.3 31.3Z"></path></g></svg><span>Search</span></a></li><li class="usermenu dropdown"><a href="#" class="trigger l0 nav-icn nav-dropdown"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width="20" height="20" version="1.1" fill="#4A3C31"><desc>navigation arrow</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M0.1 12.5L9.7 3.1C9.8 3 9.9 3 10 3 10.1 3 10.2 3 10.3 3.1L19.9 12.5C20 12.5 20 12.6 20 12.8 20 12.9 20 13 19.9 13L17 15.9C16.9 16 16.8 16 16.7 16 16.5 16 16.4 16 16.4 15.9L10 9.7 3.6 15.9C3.6 16 3.5 16 3.3 16 3.2 16 3.1 16 3 15.9L0.1 13C0 12.9 0 12.8 0 12.7 0 12.7 0 12.6 0.1 12.5Z"></path></g></svg><span>Expand Nav</span></a><div class="drop-content"><ul><li><a href="https://www.safaribooksonline.com/history/" class="t-recent-nav l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>recent items icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M25 0C11.2 0 0 11.2 0 25 0 38.8 11.2 50 25 50 38.8 50 50 38.8 50 25 50 11.2 38.8 0 25 0ZM6.3 25C6.3 14.6 14.6 6.3 25 6.3 35.4 6.3 43.8 14.6 43.8 25 43.8 35.4 35.4 43.8 25 43.8 14.6 43.8 6.3 35.4 6.3 25ZM31.8 31.5C32.5 30.5 32.4 29.2 31.6 28.3L27.1 23.8 27.1 12.8C27.1 11.5 26.2 10.4 25 10.4 23.9 10.4 22.9 11.5 22.9 12.8L22.9 25.7 28.8 31.7C29.2 32.1 29.7 32.3 30.2 32.3 30.8 32.3 31.3 32 31.8 31.5Z"></path></g></svg><span>History</span></a></li><li><a href="https://www.safaribooksonline.com/topics" class="t-topics-link l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 55" width="20" height="20" version="1.1" fill="#4A3C31"><desc>topics icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M25 55L50 41.262 50 13.762 25 0 0 13.762 0 41.262 25 55ZM8.333 37.032L8.333 17.968 25 8.462 41.667 17.968 41.667 37.032 25 46.538 8.333 37.032Z"></path></g></svg><span>Topics</span></a></li><li><a href="https://www.safaribooksonline.com/tutorials/" class="l1 nav-icn t-tutorials-nav js-toggle-menu-item None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width="20" height="20" version="1.1" fill="#4A3C31"><desc>tutorials icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M15.8 18.2C15.8 18.2 15.9 18.2 16 18.2 16.1 18.2 16.2 18.2 16.4 18.2 16.5 18.2 16.7 18.1 16.9 18 17 17.9 17.1 17.8 17.2 17.7 17.3 17.6 17.4 17.5 17.4 17.4 17.5 17.2 17.6 16.9 17.6 16.7 17.6 16.6 17.6 16.5 17.6 16.4 17.5 16.2 17.5 16.1 17.4 15.9 17.3 15.8 17.2 15.6 17 15.5 16.8 15.3 16.6 15.3 16.4 15.2 16.2 15.2 16 15.2 15.8 15.2 15.7 15.2 15.5 15.3 15.3 15.4 15.2 15.4 15.1 15.5 15 15.7 14.9 15.8 14.8 15.9 14.7 16 14.7 16.1 14.6 16.3 14.6 16.4 14.6 16.5 14.6 16.6 14.6 16.6 14.6 16.7 14.6 16.9 14.6 17 14.6 17.1 14.7 17.3 14.7 17.4 14.8 17.6 15 17.7 15.1 17.9 15.2 18 15.3 18 15.5 18.1 15.5 18.1 15.6 18.2 15.7 18.2 15.7 18.2 15.7 18.2 15.8 18.2L15.8 18.2ZM9.4 11.5C9.5 11.5 9.5 11.5 9.6 11.5 9.7 11.5 9.9 11.5 10 11.5 10.2 11.5 10.3 11.4 10.5 11.3 10.6 11.2 10.8 11.1 10.9 11 10.9 10.9 11 10.8 11.1 10.7 11.2 10.5 11.2 10.2 11.2 10 11.2 9.9 11.2 9.8 11.2 9.7 11.2 9.5 11.1 9.4 11 9.2 10.9 9.1 10.8 8.9 10.6 8.8 10.5 8.7 10.3 8.6 10 8.5 9.9 8.5 9.7 8.5 9.5 8.5 9.3 8.5 9.1 8.6 9 8.7 8.8 8.7 8.7 8.8 8.6 9 8.5 9.1 8.4 9.2 8.4 9.3 8.2 9.5 8.2 9.8 8.2 10 8.2 10.1 8.2 10.2 8.2 10.3 8.2 10.5 8.3 10.6 8.4 10.7 8.5 10.9 8.6 11.1 8.7 11.2 8.9 11.3 9 11.4 9.1 11.4 9.2 11.4 9.3 11.5 9.3 11.5 9.3 11.5 9.4 11.5 9.4 11.5L9.4 11.5ZM3 4.8C3.1 4.8 3.1 4.8 3.2 4.8 3.4 4.8 3.5 4.8 3.7 4.8 3.8 4.8 4 4.7 4.1 4.6 4.3 4.5 4.4 4.4 4.5 4.3 4.6 4.2 4.6 4.1 4.7 4 4.8 3.8 4.8 3.5 4.8 3.3 4.8 3.1 4.8 3 4.8 2.9 4.7 2.8 4.7 2.6 4.6 2.5 4.5 2.3 4.4 2.2 4.2 2.1 4 1.9 3.8 1.9 3.6 1.8 3.5 1.8 3.3 1.8 3.1 1.8 2.9 1.8 2.7 1.9 2.6 2 2.4 2.1 2.3 2.2 2.2 2.3 2.1 2.4 2 2.5 2 2.6 1.8 2.8 1.8 3 1.8 3.3 1.8 3.4 1.8 3.5 1.8 3.6 1.8 3.8 1.9 3.9 2 4 2.1 4.2 2.2 4.4 2.4 4.5 2.5 4.6 2.6 4.7 2.7 4.7 2.8 4.7 2.9 4.8 2.9 4.8 3 4.8 3 4.8 3 4.8L3 4.8ZM13.1 15.2C13.2 15.1 13.2 15.1 13.2 15.1 13.3 14.9 13.4 14.7 13.6 14.5 13.8 14.2 14.1 14 14.4 13.8 14.7 13.6 15.1 13.5 15.5 13.4 15.9 13.4 16.3 13.4 16.7 13.5 17.2 13.5 17.6 13.7 17.9 13.9 18.2 14.1 18.5 14.4 18.7 14.7 18.9 15 19.1 15.3 19.2 15.6 19.3 15.9 19.4 16.1 19.4 16.4 19.4 17 19.3 17.5 19.1 18.1 19 18.3 18.9 18.5 18.7 18.7 18.5 19 18.3 19.2 18 19.4 17.7 19.6 17.3 19.8 16.9 19.9 16.6 20 16.3 20 16 20 15.8 20 15.6 20 15.4 19.9 15.4 19.9 15.4 19.9 15.4 19.9 15.2 19.9 15 19.8 14.9 19.8 14.8 19.7 14.7 19.7 14.6 19.7 14.4 19.6 14.3 19.5 14.1 19.3 13.7 19.1 13.4 18.7 13.2 18.4 13.1 18.1 12.9 17.8 12.9 17.5 12.8 17.3 12.8 17.1 12.8 16.9L3.5 14.9C3.3 14.9 3.1 14.8 3 14.8 2.7 14.7 2.4 14.5 2.1 14.3 1.7 14 1.4 13.7 1.2 13.3 1 13 0.9 12.6 0.8 12.3 0.7 12 0.7 11.7 0.7 11.4 0.7 11 0.8 10.5 1 10.1 1.1 9.8 1.3 9.5 1.6 9.2 1.8 8.9 2.1 8.7 2.4 8.5 2.8 8.3 3.2 8.1 3.6 8.1 3.9 8 4.2 8 4.5 8 4.6 8 4.8 8 4.9 8.1L6.8 8.5C6.8 8.4 6.8 8.4 6.8 8.4 6.9 8.2 7.1 8 7.2 7.8 7.5 7.5 7.7 7.3 8 7.1 8.4 6.9 8.7 6.8 9.1 6.7 9.5 6.7 10 6.7 10.4 6.8 10.8 6.8 11.2 7 11.5 7.2 11.8 7.5 12.1 7.7 12.4 8 12.6 8.3 12.7 8.6 12.8 8.9 12.9 9.2 13 9.4 13 9.7 13 9.7 13 9.8 13 9.8 13.6 9.9 14.2 10.1 14.9 10.2 15 10.2 15 10.2 15.1 10.2 15.3 10.2 15.4 10.2 15.6 10.2 15.8 10.1 16 10 16.2 9.9 16.4 9.8 16.5 9.6 16.6 9.5 16.8 9.2 16.9 8.8 16.9 8.5 16.9 8.3 16.9 8.2 16.8 8 16.8 7.8 16.7 7.7 16.6 7.5 16.5 7.3 16.3 7.2 16.2 7.1 16 7 15.9 6.9 15.8 6.9 15.7 6.9 15.6 6.8 15.5 6.8L6.2 4.8C6.2 5 6 5.2 5.9 5.3 5.7 5.6 5.5 5.8 5.3 6 4.9 6.2 4.5 6.4 4.1 6.5 3.8 6.6 3.5 6.6 3.2 6.6 3 6.6 2.8 6.6 2.7 6.6 2.6 6.6 2.6 6.5 2.6 6.5 2.5 6.5 2.3 6.5 2.1 6.4 1.8 6.3 1.6 6.1 1.3 6 1 5.7 0.7 5.4 0.5 5 0.3 4.7 0.2 4.4 0.1 4.1 0 3.8 0 3.6 0 3.3 0 2.8 0.1 2.2 0.4 1.7 0.5 1.5 0.7 1.3 0.8 1.1 1.1 0.8 1.3 0.6 1.6 0.5 2 0.3 2.3 0.1 2.7 0.1 3.1 0 3.6 0 4 0.1 4.4 0.2 4.8 0.3 5.1 0.5 5.5 0.8 5.7 1 6 1.3 6.2 1.6 6.3 1.9 6.4 2.3 6.5 2.5 6.6 2.7 6.6 3 6.6 3 6.6 3.1 6.6 3.1 9.7 3.8 12.8 4.4 15.9 5.1 16.1 5.1 16.2 5.2 16.4 5.2 16.7 5.3 16.9 5.5 17.2 5.6 17.5 5.9 17.8 6.2 18.1 6.5 18.3 6.8 18.4 7.2 18.6 7.5 18.6 7.9 18.7 8.2 18.7 8.6 18.7 9 18.6 9.4 18.4 9.8 18.3 10.1 18.2 10.3 18 10.6 17.8 10.9 17.5 11.1 17.3 11.3 16.9 11.6 16.5 11.8 16 11.9 15.7 12 15.3 12 15 12 14.8 12 14.7 12 14.5 11.9 13.9 11.8 13.3 11.7 12.6 11.5 12.5 11.7 12.4 11.9 12.3 12 12.1 12.3 11.9 12.5 11.7 12.7 11.3 12.9 10.9 13.1 10.5 13.2 10.2 13.3 9.9 13.3 9.6 13.3 9.4 13.3 9.2 13.3 9 13.2 9 13.2 9 13.2 9 13.2 8.8 13.2 8.7 13.2 8.5 13.1 8.2 13 8 12.8 7.7 12.6 7.4 12.4 7.1 12 6.8 11.7 6.7 11.4 6.6 11.1 6.5 10.8 6.4 10.6 6.4 10.4 6.4 10.2 5.8 10.1 5.2 9.9 4.5 9.8 4.4 9.8 4.4 9.8 4.3 9.8 4.1 9.8 4 9.8 3.8 9.8 3.6 9.9 3.4 10 3.2 10.1 3 10.2 2.9 10.4 2.8 10.5 2.6 10.8 2.5 11.1 2.5 11.5 2.5 11.6 2.5 11.8 2.6 12 2.6 12.1 2.7 12.3 2.8 12.5 2.9 12.6 3.1 12.8 3.2 12.9 3.3 13 3.5 13.1 3.6 13.1 3.7 13.1 3.8 13.2 3.9 13.2L13.1 15.2 13.1 15.2Z"></path></g></svg><span>Tutorials</span></a></li><li class="nav-offers flyout-parent"><a href="#" class="l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>offers icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M35.9 20.6L27 15.5C26.1 15 24.7 15 23.7 15.5L14.9 20.6C13.9 21.1 13.2 22.4 13.2 23.4L13.2 41.4C13.2 42.4 13.9 43.7 14.9 44.2L23.3 49C24.2 49.5 25.6 49.5 26.6 49L35.9 43.6C36.8 43.1 37.6 41.8 37.6 40.8L37.6 23.4C37.6 22.4 36.8 21.1 35.9 20.6L35.9 20.6ZM40 8.2C39.1 7.6 37.6 7.6 36.7 8.2L30.2 11.9C29.3 12.4 29.3 13.2 30.2 13.8L39.1 18.8C40 19.4 40.7 20.6 40.7 21.7L40.7 39C40.7 40.1 41.4 40.5 42.4 40L48.2 36.6C49.1 36.1 49.8 34.9 49.8 33.8L49.8 15.6C49.8 14.6 49.1 13.3 48.2 12.8L40 8.2 40 8.2ZM27 10.1L33.6 6.4C34.5 5.9 34.5 5 33.6 4.5L26.6 0.5C25.6 0 24.2 0 23.3 0.5L16.7 4.2C15.8 4.7 15.8 5.6 16.7 6.1L23.7 10.1C24.7 10.6 26.1 10.6 27 10.1ZM10.1 21.7C10.1 20.6 10.8 19.4 11.7 18.8L20.6 13.8C21.5 13.2 21.5 12.4 20.6 11.9L13.6 7.9C12.7 7.4 11.2 7.4 10.3 7.9L1.6 12.8C0.7 13.3 0 14.6 0 15.6L0 33.8C0 34.9 0.7 36.1 1.6 36.6L8.4 40.5C9.3 41 10.1 40.6 10.1 39.6L10.1 21.7 10.1 21.7Z"></path></g></svg><span>Offers &amp; Deals</span></a><ul class="flyout"><li><a href="https://www.safaribooksonline.com/oreilly-newsletters/" class="l2 nav-icn"><span>Newsletters</span></a></li></ul></li><li class="nav-highlights"><a href="https://www.safaribooksonline.com/u/0011N00001APXw3QAH/" class="t-highlights-nav l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 35" width="20" height="20" version="1.1" fill="#4A3C31"><desc>highlights icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M13.325 18.071L8.036 18.071C8.036 11.335 12.36 7.146 22.5 5.594L22.5 0C6.37 1.113 0 10.632 0 22.113 0 29.406 3.477 35 10.403 35 15.545 35 19.578 31.485 19.578 26.184 19.578 21.556 17.211 18.891 13.325 18.071L13.325 18.071ZM40.825 18.071L35.565 18.071C35.565 11.335 39.86 7.146 50 5.594L50 0C33.899 1.113 27.5 10.632 27.5 22.113 27.5 29.406 30.977 35 37.932 35 43.045 35 47.078 31.485 47.078 26.184 47.078 21.556 44.74 18.891 40.825 18.071L40.825 18.071Z"></path></g></svg><span>Highlights</span></a></li><li><a href="https://www.safaribooksonline.com/u/" class="t-settings-nav l1 js-settings nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 53" width="20" height="20" version="1.1" fill="#4A3C31"><desc>settings icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M44.6 29.6C44.7 28.6 44.8 27.5 44.8 26.5 44.8 25.5 44.7 24.4 44.6 23.4L49.6 19C50 18.8 50.1 18.3 49.9 17.9 48.9 14.7 47.1 11.7 44.9 9.1 44.6 8.8 44.2 8.7 43.8 8.8L37.4 11.1C35.8 9.8 34 8.7 32.1 8L30.9 1.4C30.8 0.9 30.4 0.6 30 0.5 26.7-0.2 23.3-0.2 20 0.5 19.6 0.6 19.2 0.9 19.1 1.4L17.9 8C16 8.7 14.1 9.8 12.6 11.1L6.2 8.8C5.8 8.7 5.4 8.8 5.1 9.1 2.9 11.7 1.1 14.7 0.1 17.9 -0.1 18.3 0 18.8 0.4 19L5.4 23.4C5.3 24.4 5.2 25.5 5.2 26.5 5.2 27.5 5.3 28.6 5.4 29.6L0.4 34C0 34.2-0.1 34.7 0.1 35.1 1.1 38.3 2.9 41.4 5.1 43.9 5.4 44.2 5.8 44.4 6.2 44.2L12.6 42C14.1 43.2 16 44.3 17.9 45L19.1 51.7C19.2 52.1 19.6 52.5 20 52.5 21.6 52.8 23.3 53 25 53 26.7 53 28.4 52.8 30 52.5 30.4 52.5 30.8 52.1 30.9 51.7L32.1 45C34 44.3 35.8 43.2 37.4 42L43.8 44.2C44.2 44.4 44.6 44.2 44.9 43.9 47.1 41.4 48.9 38.3 49.9 35.1 50.1 34.7 50 34.2 49.6 34L44.6 29.6ZM25 36.4C19.6 36.4 15.2 32 15.2 26.5 15.2 21 19.6 16.6 25 16.6 30.4 16.6 34.8 21 34.8 26.5 34.8 32 30.4 36.4 25 36.4Z"></path></g></svg><span>Settings</span></a></li><li><a href="https://www.safaribooksonline.com/public/support" class="l1 no-icon">Support</a></li><li><a href="https://www.safaribooksonline.com/accounts/logout/" class="l1 no-icon">Sign Out</a></li></ul><ul class="profile"><li><a href="https://www.safaribooksonline.com/u/" class="l2 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 53" width="20" height="20" version="1.1" fill="#4A3C31"><desc>settings icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M44.6 29.6C44.7 28.6 44.8 27.5 44.8 26.5 44.8 25.5 44.7 24.4 44.6 23.4L49.6 19C50 18.8 50.1 18.3 49.9 17.9 48.9 14.7 47.1 11.7 44.9 9.1 44.6 8.8 44.2 8.7 43.8 8.8L37.4 11.1C35.8 9.8 34 8.7 32.1 8L30.9 1.4C30.8 0.9 30.4 0.6 30 0.5 26.7-0.2 23.3-0.2 20 0.5 19.6 0.6 19.2 0.9 19.1 1.4L17.9 8C16 8.7 14.1 9.8 12.6 11.1L6.2 8.8C5.8 8.7 5.4 8.8 5.1 9.1 2.9 11.7 1.1 14.7 0.1 17.9 -0.1 18.3 0 18.8 0.4 19L5.4 23.4C5.3 24.4 5.2 25.5 5.2 26.5 5.2 27.5 5.3 28.6 5.4 29.6L0.4 34C0 34.2-0.1 34.7 0.1 35.1 1.1 38.3 2.9 41.4 5.1 43.9 5.4 44.2 5.8 44.4 6.2 44.2L12.6 42C14.1 43.2 16 44.3 17.9 45L19.1 51.7C19.2 52.1 19.6 52.5 20 52.5 21.6 52.8 23.3 53 25 53 26.7 53 28.4 52.8 30 52.5 30.4 52.5 30.8 52.1 30.9 51.7L32.1 45C34 44.3 35.8 43.2 37.4 42L43.8 44.2C44.2 44.4 44.6 44.2 44.9 43.9 47.1 41.4 48.9 38.3 49.9 35.1 50.1 34.7 50 34.2 49.6 34L44.6 29.6ZM25 36.4C19.6 36.4 15.2 32 15.2 26.5 15.2 21 19.6 16.6 25 16.6 30.4 16.6 34.8 21 34.8 26.5 34.8 32 30.4 36.4 25 36.4Z"></path></g></svg><span>Settings</span></a><span class="l2 t-nag-notification" id="nav-nag"><strong class="trial-green">10</strong> days left in your trial.
  
  

  
    
      

<a class="" href="https://www.safaribooksonline.com/subscribe/">Subscribe</a>.


    
  

  

</span></li><li><a href="https://www.safaribooksonline.com/public/support" class="l2">Support</a></li><li><a href="https://www.safaribooksonline.com/accounts/logout/" class="l2">Sign Out</a></li></ul></div></li></ul></nav></header>


      </div>
      <div id="container" class="application" style="height: auto;">
        
          <div class="nav-container clearfix">
            


            
            
          </div>

          

  <div class="js-toc">
    
      <div class="sbo-reading-menu sbo-menu-top"><section class="sbo-toc-container toc-menu"><a href="#" class="sbo-toc-thumb"><span class="sbo-title ss-list"><h1><div class="visuallyhidden">Table of Contents for </div>
      
      Hands-On Machine Learning with Scikit-Learn and TensorFlow
      
    </h1></span></a><div class="toc-contents"></div></section></div>

    

    <div class="interface-controls interface-controls-top">
      <ul class="interface-control-btns js-bitlist js-reader">
        <li class="js-search-in-archive search-in-archive t-search-in-archive"><a href="#" title="Search in archive" class="js-search-controls search-controls"><span class="icon">Search in book...</span></a><form class="search-archive-bar js-search-form"><input name="query" placeholder="Search inside this book..." autocomplete="off" type="search"></form><div class="search-archive-results"><div class="js-sitb-results-region"></div></div></li><li class="queue-control"><button type="button" class="rec-fav ss-queue js-queue js-current-chapter-queue" data-queue-endpoint="/api/v1/book/9781491962282/chapter/ch09.html" data-for-analytics="9781491962282:ch09.html" aria-label="Add to Queue"><span>Add to Queue</span></button></li><li class="js-font-control-panel font-control-activator"><a href="#" data-push-state="false" id="font-controls" title="Change font size" aria-label="Change font size"><span class="icon">Toggle Font Controls</span></a></li><li class="dropdown sharing-controls"><a href="#" class="trigger" data-push-state="false" title="Share" aria-label="Share"><i class="fa fa-share"></i></a><ul class="social-sharing dropdown-menu"><li><a class="twitter share-button t-twitter" target="_blank" aria-label="Share this section on Twitter" title="Share this section on Twitter" href="https://twitter.com/share?url=https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch03.html&amp;text=Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow&amp;via=safari"><span>Twitter</span></a></li><li><a class="facebook share-button t-facebook" target="_blank" aria-label="Share this section on Facebook" title="Share this section on Facebook" href="https://www.facebook.com/sharer/sharer.php?u=https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch03.html"><span>Facebook</span></a></li><li><a class="googleplus share-button t-googleplus" target="_blank" aria-label="Share this secton on Google Plus" title="Share this secton on Google Plus" href="https://plus.google.com/share?url=https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch03.html"><span>Google Plus</span></a></li><li><a class="email share-button t-email" aria-label="Share this section via email" title="Share this section via email" href="mailto:?subject=Safari:%203.%20Classification&amp;body=https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch03.html%0D%0Afrom%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow%0D%0A"><span>Email</span></a></li></ul></li>
      </ul>
    </div>

    <section role="document">
	  <div class="t-sbo-prev sbo-prev sbo-nav-top">
  
    
      
        <a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/part02.html" class="prev nav-link">
      
          <span aria-hidden="true" class="pagination-label t-prev-label">Prev</span>
          <span class="visuallyhidden">Previous Chapter</span>
          <div class="pagination-title t-prev-title">II. Neural Networks and Deep Learning</div>
        </a>
    
  
  </div>

  <div class="t-sbo-next sbo-next sbo-nav-top">
  
    
      
        <a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html" class="next nav-link">
      
          <span aria-hidden="true" class="pagination-label t-next-label">Next</span>
          <span class="visuallyhidden">Next Chapter</span>
          <div class="pagination-title t-next-title">10. Introduction to Artificial Neural Networks</div>
        </a>
    
  
  </div>



<div id="sbo-rt-content"><div class="annotator-wrapper"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 9. Up and Running with TensorFlow"><div class="chapter" id="tensorflow_chapter">
<h1><span class="label">Chapter 9. </span>Up and Running with TensorFlow</h1>


<p><em>TensorFlow</em> <a data-type="indexterm" data-primary="TensorFlow" id="t9"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="overview" id="t9o"></a><a data-type="indexterm" data-primary="Machine Learning" data-secondary="large-scale projects" data-see="TensorFlow" id="idm140583006322688"></a>is
 a powerful open source software library for numerical computation, 
particularly well suited and fine-tuned for large-scale Machine 
Learning. Its basic principle is simple: you first define in Python a 
graph of computations to perform (for example, the one in <a data-type="xref" href="#computation_graph_diagram">Figure&nbsp;9-1</a>), and then TensorFlow takes that graph and runs it efficiently using optimized C++ code.</p>

<figure class="smallerseventy"><div id="computation_graph_diagram" class="figure">
<img src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_0901.png" alt="mlst 0901" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_0901.png" width="1440" height="828">
<h6><span class="label">Figure 9-1. </span>A simple computation graph</h6>
</div></figure>

<p>Most importantly, it is possible to break up the graph into several 
chunks and run them in parallel across multiple CPUs or GPUs (as shown 
in <a data-type="xref" href="#parallel_computation_diagram">Figure&nbsp;9-2</a>). TensorFlow also supports distributed computing, <a data-type="indexterm" data-primary="distributed computing" id="idm140583006316336"></a>so
 you can train colossal neural networks on humongous training sets in a 
reasonable amount of time by splitting the computations across hundreds 
of servers (see <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch12.html#distributed_chapter">Chapter&nbsp;12</a>).
 TensorFlow can train a network with millions of parameters on a 
training set composed of billions of instances with millions of features
 each. This should come as no surprise, since TensorFlow was developed 
by <a data-type="indexterm" data-primary="Google" id="idm140583006314336"></a>the
 Google Brain team and it powers many of Google’s large-scale services, 
such as Google Cloud Speech, Google Photos, and Google Search.</p>

<figure class="smallerseventy"><div id="parallel_computation_diagram" class="figure">
<img src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_0902.png" alt="mlst 0902" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_0902.png" width="1423" height="1377">
<h6><span class="label">Figure 9-2. </span>Parallel computation on multiple CPUs/GPUs/servers</h6>
</div></figure>

<p>When TensorFlow was open-sourced in November 2015, there were already many popular open source libraries for <a data-type="indexterm" data-primary="Deep Learning" data-secondary="libraries" id="deeplearnlibch9"></a>Deep Learning (<a data-type="xref" href="#deep_learning_libraries">Table&nbsp;9-1</a>
 lists a few), and to be fair most of TensorFlow’s features already 
existed in one library or another. Nevertheless, TensorFlow’s clean 
design, scalability, flexibility,<sup><a data-type="noteref" id="idm140583006206368-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch09.html#idm140583006206368" class="totri-footnote">1</a></sup>
 and great documentation (not to mention Google’s name) quickly boosted 
it to the top of the list. In short, TensorFlow was designed to be 
flexible, scalable, and production-ready, and existing frameworks 
arguably  hit only two out of the three of these. Here are some of 
TensorFlow’s highlights:</p>

<ul>
<li>
<p>It runs not only on Windows, Linux, and macOS, but also on mobile devices, including both iOS and Android.</p>
</li>
<li>
<p>It provides a very simple Python API <a data-type="indexterm" data-primary="TF.Learn" id="idm140583006202848"></a>called <em>TF.Learn</em><sup><a data-type="noteref" id="idm140583006201856-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch09.html#idm140583006201856" class="totri-footnote">2</a></sup> (<code>tensorflow.contrib.learn</code>), compatible with <a data-type="indexterm" data-primary="Scikit-Learn" data-secondary="TF.Learn" id="idm140583006200752"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.contrib.slim module" id="idm140583006199808"></a>Scikit-Learn.
 As you will see, you can use it to train various types of neural 
networks in just a few lines of code. It was previously an independent 
project <a data-type="indexterm" data-primary="Scikit Flow" id="idm140583006198560"></a>called <em>Scikit Flow</em> (or <em>skflow</em>).</p>
</li>
<li>
<p>It also provides another simple API <a data-type="indexterm" data-primary="TF-slim" id="idm140583006196096"></a>called <em>TF-slim</em> (<code>tensorflow.contrib.slim</code>) to simplify building, training, and evaluating neural networks.</p>
</li>
<li>
<p>Several other high-level APIs have been <a data-type="indexterm" data-primary="Keras" id="idm140583006193296"></a><a data-type="indexterm" data-primary="Pretty Tensor" id="idm140583006192592"></a>built independently on top of TensorFlow, such as <a href="http://keras.io/">Keras</a> (now available in <code>tensorflow.contrib.keras</code>) or <a href="https://github.com/google/prettytensor/">Pretty Tensor</a>.</p>
</li>
<li>
<p>Its main Python API offers much more flexibility (at the cost of 
higher complexity) to create all sorts of computations, including any 
neural network architecture you can think of.</p>
</li>
<li>
<p>It includes highly efficient C++ implementations of many ML 
operations, particularly those needed to build neural networks. There is
 also a C++ API to define your own high-performance operations.</p>
</li>
<li>
<p>It provides several advanced optimization nodes to search for the 
parameters that minimize a cost function. These are very easy to use 
since TensorFlow automatically takes care of computing the gradients of 
the functions you define. This is <a data-type="indexterm" data-primary="automatic differentiating" id="idm140583006186688"></a>called <em>automatic differentiating</em> (or <em>autodiff</em>).</p>
</li>
<li>
<p>It also comes with a great visualization tool <a data-type="indexterm" data-primary="TensorBoard" id="idm140583006184096"></a>called <em>TensorBoard</em> that allows you to browse through the computation graph, view learning curves, and more.</p>
</li>
<li>
<p>Google also launched a <a href="https://cloud.google.com/ml">cloud service to run TensorFlow graphs</a>.</p>
</li>
<li>
<p>Last but not least, it has a dedicated team of passionate and helpful
 developers, and a growing community contributing to improving it. It is
 one of the most popular open source projects on GitHub, and more and 
more great projects are being built on top of it (for examples, check 
out the resources page on <a href="https://www.tensorflow.org/"><em class="hyperlink">https://www.tensorflow.org/</em></a>, or <a href="https://github.com/jtoy/awesome-tensorflow"><em class="hyperlink">https://github.com/jtoy/awesome-tensorflow</em></a>). To ask technical questions, you should use <a href="http://stackoverflow.com/"><em class="hyperlink">http://stackoverflow.com/</em></a> and tag your question with <code>"tensorflow"</code>. You can file bugs and feature requests through GitHub. For general discussions, join the <a href="http://goo.gl/N7kRF9">Google group</a>.</p>
</li>
</ul>

<p>In this chapter, we will go through the basics of TensorFlow, from 
installation to creating, running, saving, and visualizing simple 
computational graphs. Mastering these basics is important before you 
build your first neural network <a data-type="indexterm" data-primary="TensorFlow" data-secondary="overview" data-startref="t9o" id="idm140583006174512"></a>(which we will do in the <a data-type="indexterm" data-primary="Deep Learning" data-secondary="libraries" data-startref="deeplearnlibch9" id="idm140583006173136"></a>next chapter).</p>
<table id="deep_learning_libraries">
<caption><span class="label">Table 9-1. </span>Open source Deep Learning libraries (not an exhaustive list)</caption>
<thead>
<tr>
<th>Library</th>
<th>API</th>
<th>Platforms</th>
<th>Started by</th>
<th>Year</th>
</tr>
</thead>
<tbody>
<tr>
<td><p>Caffe</p></td>
<td><p>Python, C++, Matlab</p></td>
<td><p>Linux, macOS, Windows</p></td>
<td><p>Y. Jia, UC Berkeley (BVLC)</p></td>
<td><p>2013</p></td>
</tr>
<tr>
<td><p>Deeplearning4j</p></td>
<td><p>Java, Scala, Clojure</p></td>
<td><p>Linux, macOS, Windows, Android</p></td>
<td><p>A. Gibson, J.Patterson</p></td>
<td><p>2014</p></td>
</tr>
<tr>
<td><p>H2O</p></td>
<td><p>Python, R</p></td>
<td><p>Linux, macOS, Windows</p></td>
<td><p>H2O.ai</p></td>
<td><p>2014</p></td>
</tr>
<tr>
<td><p>MXNet</p></td>
<td><p>Python, C++, others</p></td>
<td><p>Linux, macOS, Windows, iOS, Android</p></td>
<td><p>DMLC</p></td>
<td><p>2015</p></td>
</tr>
<tr>
<td><p>TensorFlow</p></td>
<td><p>Python, C++</p></td>
<td><p>Linux, macOS, Windows, iOS, Android</p></td>
<td><p>Google</p></td>
<td><p>2015</p></td>
</tr>
<tr>
<td><p>Theano</p></td>
<td><p>Python</p></td>
<td><p>Linux, macOS, iOS</p></td>
<td><p>University of Montreal</p></td>
<td><p>2010</p></td>
</tr>
<tr>
<td><p>Torch</p></td>
<td><p>C++, Lua</p></td>
<td><p>Linux, macOS, iOS, Android</p></td>
<td><p>R. Collobert, K. Kavukcuoglu, C. Farabet</p></td>
<td><p>2002</p></td>
</tr>
</tbody>
</table>






<section data-type="sect1" data-pdf-bookmark="Installation"><div class="sect1" id="idm140583006142864">
<h1>Installation</h1>

<p>Let’s <a data-type="indexterm" data-primary="TensorFlow" data-secondary="installation" id="idm140583006141360"></a>get started! Assuming you installed Jupyter and Scikit-Learn by following the installation instructions in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch02.html#project_chapter">Chapter&nbsp;2</a>,
 you can simply use pip to install TensorFlow. If you created an 
isolated environment using virtualenv, you first need to activate it:</p>

<pre data-type="programlisting" data-code-language="shell-session"><code class="go">$ cd $ML_PATH               # Your ML working directory (e.g., $HOME/ml)</code>
<code class="go">$ source env/bin/activate</code></pre>

<p>Next, install TensorFlow (if you are not using a virtualenv, you will need administrator rights, or to add the <code>--user</code> option):</p>

<pre data-type="programlisting" data-code-language="shell-session"><code class="go">$ pip3 install --upgrade tensorflow</code></pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>For GPU support, you need to install <code>tensorflow-gpu</code> instead of <code>tensorflow</code>. See <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch12.html#distributed_chapter">Chapter&nbsp;12</a> for more details.</p>
</div>

<p>To test your installation, type the following command. It should output the version of TensorFlow you installed.</p>

<pre data-type="programlisting" data-code-language="shell-session"><code class="go">$ python3 -c 'import tensorflow; print(tensorflow.__version__)'</code>
<code class="go">1.3.0</code></pre>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Creating Your First Graph and Running It in a Session"><div class="sect1" id="idm140583006132160">
<h1>Creating Your First Graph and Running It in a Session</h1>

<p>The following code creates the <a data-type="indexterm" data-primary="TensorFlow" data-secondary="initial graph creation and session run" id="tf9igcasr"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.Graph" id="idm140583006129312"></a>graph represented in <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.Variable" id="idm140583006083712"></a><a data-type="xref" href="#computation_graph_diagram">Figure&nbsp;9-1</a>:</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">import</code> <code class="nn">tensorflow</code> <code class="kn">as</code> <code class="nn">tf</code>

<code class="n">x</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">Variable</code><code class="p">(</code><code class="mi">3</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"x"</code><code class="p">)</code>
<code class="n">y</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">Variable</code><code class="p">(</code><code class="mi">4</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"y"</code><code class="p">)</code>
<code class="n">f</code> <code class="o">=</code> <code class="n">x</code><code class="o">*</code><code class="n">x</code><code class="o">*</code><code class="n">y</code> <code class="o">+</code> <code class="n">y</code> <code class="o">+</code> <code class="mi">2</code></pre>

<p>That’s all there is to it! The most important thing to understand is 
that this code does not actually perform any computation, even though it
 looks like it does (especially the last line). It just creates a 
computation graph. In fact, even the variables are not initialized yet. 
To evaluate this graph, you need to open a TensorFlow <em>session</em> and use it to initialize the variables and evaluate <code>f</code>. A TensorFlow session takes care of placing the operations onto <em>devices</em> such as CPUs and GPUs and running them, and it holds all the variable values.<sup><a data-type="noteref" id="idm140583006120656-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch09.html#idm140583006120656" class="totri-footnote">3</a></sup> The following code creates a session, initializes the variables, and evaluates, and <code>f</code> then closes the session (which frees up resources):</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">sess</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">Session</code><code class="p">()</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">sess</code><code class="o">.</code><code class="n">run</code><code class="p">(</code><code class="n">x</code><code class="o">.</code><code class="n">initializer</code><code class="p">)</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">sess</code><code class="o">.</code><code class="n">run</code><code class="p">(</code><code class="n">y</code><code class="o">.</code><code class="n">initializer</code><code class="p">)</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">result</code> <code class="o">=</code> <code class="n">sess</code><code class="o">.</code><code class="n">run</code><code class="p">(</code><code class="n">f</code><code class="p">)</code>
<code class="gp">&gt;&gt;&gt; </code><code class="k">print</code><code class="p">(</code><code class="n">result</code><code class="p">)</code>
<code class="go">42</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">sess</code><code class="o">.</code><code class="n">close</code><code class="p">()</code></pre>

<p>Having to repeat <code>sess.run()</code> all <a data-type="indexterm" data-primary="run()" id="idm140583005953952"></a>the time is a bit cumbersome, <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.Session" id="idm140583005953184"></a>but fortunately there is a better way:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">Session</code><code class="p">()</code> <code class="k">as</code> <code class="n">sess</code><code class="p">:</code>
    <code class="n">x</code><code class="o">.</code><code class="n">initializer</code><code class="o">.</code><code class="n">run</code><code class="p">()</code>
    <code class="n">y</code><code class="o">.</code><code class="n">initializer</code><code class="o">.</code><code class="n">run</code><code class="p">()</code>
    <code class="n">result</code> <code class="o">=</code> <code class="n">f</code><code class="o">.</code><code class="n">eval</code><code class="p">()</code></pre>

<p>Inside the <code>with</code> block, the session is set as the <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.get_default_session()" id="idm140583005800560"></a>default session. Calling <code>x.initializer.run()</code> is equivalent to calling <code>tf.get_default_session().run(x.initializer)</code>, and similarly <code>f.eval()</code> is equivalent to calling <code>tf.get_default_session().run(f)</code>. This makes the code easier to read. Moreover, the session is automatically closed at the end of the block.</p>

<p>Instead of manually running the <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.global_variables_initializer()" id="idm140583005797520"></a>initializer for every single variable, you can use the <code>global_variables_initializer()</code> <a data-type="indexterm" data-primary="global_variables_initializer()" id="idm140583005795904"></a>function.
 Note that it does not actually perform the initialization immediately, 
but rather creates a node in the graph that will initialize all 
variables when it is run:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">init</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">global_variables_initializer</code><code class="p">()</code>  <code class="c1"># prepare an init node</code>

<code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">Session</code><code class="p">()</code> <code class="k">as</code> <code class="n">sess</code><code class="p">:</code>
    <code class="n">init</code><code class="o">.</code><code class="n">run</code><code class="p">()</code>  <code class="c1"># actually initialize all the variables</code>
    <code class="n">result</code> <code class="o">=</code> <code class="n">f</code><code class="o">.</code><code class="n">eval</code><code class="p">()</code></pre>

<p>Inside Jupyter or within a Python shell you may prefer to <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.InteractiveSession" id="idm140583005917952"></a><a data-type="indexterm" data-primary="InteractiveSession" id="idm140583005917104"></a>create an <code>InteractiveSession</code>. The only difference from a regular <code>Session</code> is that when an <code>InteractiveSession</code> is created it automatically sets itself as the default session, so you don’t need a <code>with</code> block (but you do need to close the session manually when you are done with it):</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">sess</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">InteractiveSession</code><code class="p">()</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">init</code><code class="o">.</code><code class="n">run</code><code class="p">()</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">result</code> <code class="o">=</code> <code class="n">f</code><code class="o">.</code><code class="n">eval</code><code class="p">()</code>
<code class="gp">&gt;&gt;&gt; </code><code class="k">print</code><code class="p">(</code><code class="n">result</code><code class="p">)</code>
<code class="go">42</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">sess</code><code class="o">.</code><code class="n">close</code><code class="p">()</code></pre>

<p>A TensorFlow program is typically split into two parts: the first part builds a computation graph (this is called the <em>construction phase</em>), <a data-type="indexterm" data-primary="TensorFlow" data-secondary="construction phase" id="idm140583005709920"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="execution phase" id="idm140583005709040"></a>and the second part runs it (this is the <em>execution phase</em>).
 The construction phase typically builds a computation graph 
representing the ML model and the computations required to train it. The
 execution phase generally runs a loop that evaluates a training step 
repeatedly (for example, one step per mini-batch), gradually improving 
the <a data-type="indexterm" data-primary="model parameters" id="idm140583005707280"></a>model parameters. We will go through an example <a data-type="indexterm" data-primary="TensorFlow" data-secondary="initial graph creation and session run" data-startref="tf9igcasr" id="idm140583005706448"></a>shortly.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Managing Graphs"><div class="sect1" id="idm140583006131568">
<h1>Managing Graphs</h1>

<p>Any <a data-type="indexterm" data-primary="TensorFlow" data-secondary="graphs, managing" id="idm140583005703728"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.get_default_graph()" id="idm140583005702720"></a>node you create is automatically added to the default graph:</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">x1</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">Variable</code><code class="p">(</code><code class="mi">1</code><code class="p">)</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">x1</code><code class="o">.</code><code class="n">graph</code> <code class="ow">is</code> <code class="n">tf</code><code class="o">.</code><code class="n">get_default_graph</code><code class="p">()</code>
<code class="go">True</code></pre>

<p>In most cases this is fine, but sometimes you may want to manage multiple independent graphs. You can do this by creating a <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.Graph" id="idm140583005692768"></a>new <code>Graph</code> and temporarily making it the default graph inside a <code>with</code> block, like so:</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">graph</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">Graph</code><code class="p">()</code>
<code class="gp">&gt;&gt;&gt; </code><code class="k">with</code> <code class="n">graph</code><code class="o">.</code><code class="n">as_default</code><code class="p">():</code>
<code class="gp">... </code>    <code class="n">x2</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">Variable</code><code class="p">(</code><code class="mi">2</code><code class="p">)</code>
<code class="gp">...</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">x2</code><code class="o">.</code><code class="n">graph</code> <code class="ow">is</code> <code class="n">graph</code>
<code class="go">True</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">x2</code><code class="o">.</code><code class="n">graph</code> <code class="ow">is</code> <code class="n">tf</code><code class="o">.</code><code class="n">get_default_graph</code><code class="p">()</code>
<code class="go">False</code></pre>
<div data-type="tip"><h6>Tip</h6>
<p>In Jupyter (or in a Python shell), it is common to run the same 
commands more than once while you are experimenting. As a result, you 
may end up with a <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.reset_default_graph()" id="idm140583005885216"></a>default
 graph containing many duplicate nodes. One solution is to restart the 
Jupyter kernel (or the Python shell), but a more convenient solution is 
to just reset the default graph by <a data-type="indexterm" data-primary="reset_default_graph()" id="idm140583005884000"></a>running <code>tf.reset_default_graph()</code>.</p>
</div>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Lifecycle of a Node Value"><div class="sect1" id="idm140583005882528">
<h1>Lifecycle of a Node Value</h1>

<p>When <a data-type="indexterm" data-primary="TensorFlow" data-secondary="node value lifecycle" id="idm140583005880992"></a>you
 evaluate a node, TensorFlow automatically determines the set of nodes 
that it depends on and it evaluates these nodes first. For example, 
consider the <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.constant()" id="tfconstantch9"></a>following code:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">w</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">constant</code><code class="p">(</code><code class="mi">3</code><code class="p">)</code>
<code class="n">x</code> <code class="o">=</code> <code class="n">w</code> <code class="o">+</code> <code class="mi">2</code>
<code class="n">y</code> <code class="o">=</code> <code class="n">x</code> <code class="o">+</code> <code class="mi">5</code>
<code class="n">z</code> <code class="o">=</code> <code class="n">x</code> <code class="o">*</code> <code class="mi">3</code>

<code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">Session</code><code class="p">()</code> <code class="k">as</code> <code class="n">sess</code><code class="p">:</code>
    <code class="k">print</code><code class="p">(</code><code class="n">y</code><code class="o">.</code><code class="n">eval</code><code class="p">())</code>  <code class="c1"># 10</code>
    <code class="k">print</code><code class="p">(</code><code class="n">z</code><code class="o">.</code><code class="n">eval</code><code class="p">())</code>  <code class="c1"># 15</code></pre>

<p>First, this code defines a very simple graph. Then it starts a session and runs the graph to evaluate <code>y</code>: TensorFlow automatically detects that <code>y</code> depends on <code>x</code>, which depends on <code>w</code>, so it first evaluates <code>w</code>, then <code>x</code>, then <code>y</code>, and returns the value of <code>y</code>. Finally, the code runs the graph to evaluate <code>z</code>. Once again, TensorFlow detects that it must first evaluate <code>w</code> and <code>x</code>. It is important to note that it will <em>not</em> reuse the result of the previous evaluation of <code>w</code> and <code>x</code>. In short, the preceding code evaluates <code>w</code> and <code>x</code> twice.</p>

<p>All node values are dropped between graph runs, except variable 
values, which are maintained by the session across graph runs (queues 
and readers also maintain some state, as we will see in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch12.html#distributed_chapter">Chapter&nbsp;12</a>). A variable starts its life when its initializer is run, and it ends when the session is closed.</p>

<p>If you want to evaluate <code>y</code> and <code>z</code> efficiently, without evaluating <code>w</code> and <code>x</code> twice as in the previous code, you must ask TensorFlow to evaluate both <code>y</code> and <code>z</code> in just one graph run, as shown in the following code:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">Session</code><code class="p">()</code> <code class="k">as</code> <code class="n">sess</code><code class="p">:</code>
    <code class="n">y_val</code><code class="p">,</code> <code class="n">z_val</code> <code class="o">=</code> <code class="n">sess</code><code class="o">.</code><code class="n">run</code><code class="p">([</code><code class="n">y</code><code class="p">,</code> <code class="n">z</code><code class="p">])</code>
    <code class="k">print</code><code class="p">(</code><code class="n">y_val</code><code class="p">)</code>  <code class="c1"># 10</code>
    <code class="k">print</code><code class="p">(</code><code class="n">z_val</code><code class="p">)</code>  <code class="c1"># 15</code></pre>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>In single-process TensorFlow, multiple sessions do not share any 
state, even if they reuse the same graph (each session would have its 
own copy of every variable). In distributed TensorFlow (see <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch12.html#distributed_chapter">Chapter&nbsp;12</a>), variable state is stored on the servers, not in the sessions, so multiple sessions can share the same variables.</p>
</div>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Linear Regression with TensorFlow"><div class="sect1" id="idm140583005472368">
<h1>Linear Regression with TensorFlow</h1>

<p>TensorFlow <a data-type="indexterm" data-primary="TensorFlow" data-secondary="Linear Regression with" id="tf9lrw"></a><a data-type="indexterm" data-primary="Linear Regression" data-secondary="with TensorFlow" id="lr9wtf"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="operations (ops)" id="idm140583005468144"></a>operations (also called <em>ops</em>
 for short) can take any number of inputs and produce any number of 
outputs. For example, the addition and multiplication ops each take two 
inputs and produce one output. Constants and variables take no input 
(they are called <em>source ops</em>). <a data-type="indexterm" data-primary="source ops" id="idm140583005426192"></a>The inputs and outputs are multidimensional arrays, called <em>tensors</em>
 (hence the name “tensor flow”). Just like NumPy arrays, tensors have a 
type and a shape. In fact, in the Python API tensors are simply 
represented by NumPy ndarrays. They typically contain floats, but you 
can also use them to carry strings (arbitrary byte arrays).</p>

<p>In the examples so far, the tensors just contained a single scalar 
value, but you can of course perform computations on arrays of any 
shape. For example, the following code manipulates 2D arrays to perform 
Linear Regression on the California housing dataset (introduced in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch02.html#project_chapter">Chapter&nbsp;2</a>). It starts by fetching the dataset; then it adds an extra bias input feature (<em>x</em><sub>0</sub> = 1) to all training instances (it does so using NumPy so it runs immediately); then it creates two TensorFlow constant nodes, <code>X</code> and <code>y</code>, to hold this data and the targets,<sup><a data-type="noteref" id="idm140583005420832-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch09.html#idm140583005420832" class="totri-footnote">4</a></sup> and it uses some of the matrix operations provided by TensorFlow to define <code>theta</code>. These matrix functions—<code>transpose()</code>,<a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.matmul()" id="tfmatmulch9"></a> <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.matrix_inverse()" id="idm140583005416464"></a> <code>matmul()</code>, and <code>matrix_inverse()</code>—are
 self-explanatory, but as usual they do not perform any computations 
immediately; instead, they create nodes in the graph that will perform 
them when the graph is run. You may recognize that the definition of <code>theta</code> corresponds to the Normal Equation (<img src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_96.png" alt="ModifyingAbove theta With caret" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_96.png" width="11" height="24"> = (<strong>X</strong><sup><em>T</em></sup> · <strong>X</strong>)<sup>–1</sup> · <strong>X</strong><sup><em>T</em></sup> · <strong>y</strong>; see <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch04.html#linear_models_chapter">Chapter&nbsp;4</a>). Finally, the code creates a session and uses it <a data-type="indexterm" data-primary="Scikit-Learn" data-secondary="sklearn.datasets.fetch_california_housing()" id="idm140583005409008"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.float32" id="idm140583005407968"></a> <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.transpose()" id="tftransposech9"></a>to evaluate <code>theta</code>.</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">import</code> <code class="nn">numpy</code> <code class="kn">as</code> <code class="nn">np</code>
<code class="kn">from</code> <code class="nn">sklearn.datasets</code> <code class="kn">import</code> <code class="n">fetch_california_housing</code>

<code class="n">housing</code> <code class="o">=</code> <code class="n">fetch_california_housing</code><code class="p">()</code>
<code class="n">m</code><code class="p">,</code> <code class="n">n</code> <code class="o">=</code> <code class="n">housing</code><code class="o">.</code><code class="n">data</code><code class="o">.</code><code class="n">shape</code>
<code class="n">housing_data_plus_bias</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">c_</code><code class="p">[</code><code class="n">np</code><code class="o">.</code><code class="n">ones</code><code class="p">((</code><code class="n">m</code><code class="p">,</code> <code class="mi">1</code><code class="p">)),</code> <code class="n">housing</code><code class="o">.</code><code class="n">data</code><code class="p">]</code>

<code class="n">X</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">constant</code><code class="p">(</code><code class="n">housing_data_plus_bias</code><code class="p">,</code> <code class="n">dtype</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"X"</code><code class="p">)</code>
<code class="n">y</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">constant</code><code class="p">(</code><code class="n">housing</code><code class="o">.</code><code class="n">target</code><code class="o">.</code><code class="n">reshape</code><code class="p">(</code><code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="mi">1</code><code class="p">),</code> <code class="n">dtype</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"y"</code><code class="p">)</code>
<code class="n">XT</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">transpose</code><code class="p">(</code><code class="n">X</code><code class="p">)</code>
<code class="n">theta</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">matmul</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">matmul</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">matrix_inverse</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">matmul</code><code class="p">(</code><code class="n">XT</code><code class="p">,</code> <code class="n">X</code><code class="p">)),</code> <code class="n">XT</code><code class="p">),</code> <code class="n">y</code><code class="p">)</code>

<code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">Session</code><code class="p">()</code> <code class="k">as</code> <code class="n">sess</code><code class="p">:</code>
    <code class="n">theta_value</code> <code class="o">=</code> <code class="n">theta</code><code class="o">.</code><code class="n">eval</code><code class="p">()</code></pre>

<p>The main benefit of this code versus computing the Normal Equation 
directly using NumPy is that TensorFlow will automatically run this on 
your GPU card if you have one (provided you installed TensorFlow with 
GPU support, of course; see <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch12.html#distributed_chapter">Chapter&nbsp;12</a> for <a data-type="indexterm" data-primary="TensorFlow" data-secondary="Linear Regression with" data-startref="tf9lrw" id="idm140583005402528"></a><a data-type="indexterm" data-primary="Linear Regression" data-secondary="with TensorFlow" data-startref="lr9wtf" id="idm140583005329760"></a>more details).</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Implementing Gradient Descent"><div class="sect1" id="idm140583005328400">
<h1>Implementing Gradient Descent</h1>

<p>Let’s <a data-type="indexterm" data-primary="TensorFlow" data-secondary="Gradient Descent with" id="tf9igd"></a><a data-type="indexterm" data-primary="Gradient Descent (GD)" data-secondary="with TensorFlow" data-secondary-sortas="TensorFlow" id="d9wtf"></a>try using Batch Gradient Descent (introduced in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch04.html#linear_models_chapter">Chapter&nbsp;4</a>)
 instead of the Normal Equation. First we will do this by manually 
computing the gradients, then we will use TensorFlow’s autodiff feature 
to let TensorFlow compute the gradients automatically, and finally we 
will use a couple of TensorFlow’s out-of-the-box optimizers.</p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>When using Gradient Descent, remember that it is important to first normalize the input <a data-type="indexterm" data-primary="feature vector" id="idm140583005321792"></a>feature vectors, or else training may be much slower. You can do this using TensorFlow, NumPy, <a data-type="indexterm" data-primary="Scikit-Learn" data-secondary="StandardScaler" id="idm140583005320848"></a><a data-type="indexterm" data-primary="StandardScaler" id="idm140583005319904"></a><a data-type="indexterm" data-primary="Scikit-Learn" data-secondary="sklearn.preprocessing.StandardScaler" id="idm140583005319232"></a>Scikit-Learn’s <code>StandardScaler</code>, or any other solution you prefer. The following code assumes that this normalization has already been done.</p>
</div>








<section data-type="sect2" data-pdf-bookmark="Manually Computing the Gradients"><div class="sect2" id="idm140583005317392">
<h2>Manually Computing the Gradients</h2>

<p>The <a data-type="indexterm" data-primary="Gradient Descent (GD)" data-secondary="manually computing gradients" id="idm140583005316096"></a>following code should be fairly self-explanatory, except for a few new elements:</p>

<ul>
<li>
<p>The <code>random_uniform()</code> <a data-type="indexterm" data-primary="random_uniform()" id="idm140583005313520"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.random_uniform()" id="idm140583005312784"></a>function
 creates a node in the graph that will generate a tensor containing 
random values, given its shape and value range, much like NumPy’s <code>rand()</code> function.</p>
</li>
<li>
<p>The <code>assign()</code> <a data-type="indexterm" data-primary="assign()" id="idm140583005309600"></a>function creates a node that will assign a new value to a variable. In this case, it implements the Batch Gradient Descent step <em>θ</em><sup>(next step)</sup> = <em>θ</em> – <em>η</em>∇<sub><em>θ</em></sub>MSE(<em>θ</em>).</p>
</li>
<li>
<p>The main loop executes the training step over and over again (<code>n_epochs</code> times), and every 100 iterations it prints out the current <a data-type="indexterm" data-primary="Mean Square Error (MSE)" id="idm140583005304592"></a>Mean Squared Error (<code>mse</code>). You should see the MSE go down at <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.constant()" data-startref="tfconstantch9" id="idm140583005303344"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.matmul()" data-startref="tfmatmulch9" id="idm140583005302096"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.reduce_mean()" id="idm140583005300880"></a> <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.square()" id="idm140583005299808"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.transpose()" data-startref="tftransposech9" id="idm140583005298832"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.assign()" id="idm140583005297616"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.global_variables_initializer()" id="idm140583005296672"></a>every iteration.</p>
</li>
</ul>

<pre data-type="programlisting" data-code-language="python"><code class="n">n_epochs</code> <code class="o">=</code> <code class="mi">1000</code>
<code class="n">learning_rate</code> <code class="o">=</code> <code class="mf">0.01</code>

<code class="n">X</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">constant</code><code class="p">(</code><code class="n">scaled_housing_data_plus_bias</code><code class="p">,</code> <code class="n">dtype</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"X"</code><code class="p">)</code>
<code class="n">y</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">constant</code><code class="p">(</code><code class="n">housing</code><code class="o">.</code><code class="n">target</code><code class="o">.</code><code class="n">reshape</code><code class="p">(</code><code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="mi">1</code><code class="p">),</code> <code class="n">dtype</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"y"</code><code class="p">)</code>
<code class="n">theta</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">Variable</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">random_uniform</code><code class="p">([</code><code class="n">n</code> <code class="o">+</code> <code class="mi">1</code><code class="p">,</code> <code class="mi">1</code><code class="p">],</code> <code class="o">-</code><code class="mf">1.0</code><code class="p">,</code> <code class="mf">1.0</code><code class="p">),</code> <code class="n">name</code><code class="o">=</code><code class="s2">"theta"</code><code class="p">)</code>
<code class="n">y_pred</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">matmul</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">theta</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"predictions"</code><code class="p">)</code>
<code class="n">error</code> <code class="o">=</code> <code class="n">y_pred</code> <code class="o">-</code> <code class="n">y</code>
<code class="n">mse</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">reduce_mean</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">square</code><code class="p">(</code><code class="n">error</code><code class="p">),</code> <code class="n">name</code><code class="o">=</code><code class="s2">"mse"</code><code class="p">)</code>
<code class="n">gradients</code> <code class="o">=</code> <code class="mi">2</code><code class="o">/</code><code class="n">m</code> <code class="o">*</code> <code class="n">tf</code><code class="o">.</code><code class="n">matmul</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">transpose</code><code class="p">(</code><code class="n">X</code><code class="p">),</code> <code class="n">error</code><code class="p">)</code>
<code class="n">training_op</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">assign</code><code class="p">(</code><code class="n">theta</code><code class="p">,</code> <code class="n">theta</code> <code class="o">-</code> <code class="n">learning_rate</code> <code class="o">*</code> <code class="n">gradients</code><code class="p">)</code>

<code class="n">init</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">global_variables_initializer</code><code class="p">()</code>

<code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">Session</code><code class="p">()</code> <code class="k">as</code> <code class="n">sess</code><code class="p">:</code>
    <code class="n">sess</code><code class="o">.</code><code class="n">run</code><code class="p">(</code><code class="n">init</code><code class="p">)</code>

    <code class="k">for</code> <code class="n">epoch</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">n_epochs</code><code class="p">):</code>
        <code class="k">if</code> <code class="n">epoch</code> <code class="o">%</code> <code class="mi">100</code> <code class="o">==</code> <code class="mi">0</code><code class="p">:</code>
            <code class="k">print</code><code class="p">(</code><code class="s2">"Epoch"</code><code class="p">,</code> <code class="n">epoch</code><code class="p">,</code> <code class="s2">"MSE ="</code><code class="p">,</code> <code class="n">mse</code><code class="o">.</code><code class="n">eval</code><code class="p">())</code>
        <code class="n">sess</code><code class="o">.</code><code class="n">run</code><code class="p">(</code><code class="n">training_op</code><code class="p">)</code>

    <code class="n">best_theta</code> <code class="o">=</code> <code class="n">theta</code><code class="o">.</code><code class="n">eval</code><code class="p">()</code></pre>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Using autodiff"><div class="sect2" id="idm140583005293792">
<h2>Using autodiff</h2>

<p>The <a data-type="indexterm" data-primary="TensorFlow" data-secondary="autodiff" id="tf9ad"></a><a data-type="indexterm" data-primary="autodiff" id="ad9"></a><a data-type="indexterm" data-primary="Gradient Descent (GD)" data-secondary="automatically computing gradients" id="gd9acg"></a>preceding code works fine, but it requires mathematically deriving the gradients from the <a data-type="indexterm" data-primary="cost function" data-secondary="in autodiff" data-secondary-sortas="autodiff" id="idm140583005154000"></a>cost
 function (MSE). In the case of Linear Regression, it is reasonably 
easy, but if you had to do this with deep neural networks you would get 
quite a headache: it would be tedious and error-prone. You could use <em>symbolic differentiation</em> to <a data-type="indexterm" data-primary="symbolic differentiation" id="idm140583005152048"></a>automatically
 find the equations for the partial derivatives for you, but the 
resulting code would not necessarily be very efficient.</p>

<p>To understand why, consider the function <em>f</em>(<em>x</em>)= exp(exp(exp(<em>x</em>))). If you know calculus, you can figure out its derivative <em>f′</em>(<em>x</em>) = exp(<em>x</em>) × exp(exp(<em>x</em>)) × exp(exp(exp(<em>x</em>))). If you code <em>f</em>(<em>x</em>) and <em>f′</em>(<em>x</em>)
 separately and exactly as they appear, your code will not be as 
efficient as it could be. A more efficient solution would be to write a 
function that first computes exp(<em>x</em>), then exp(exp(<em>x</em>)), then exp(exp(exp(<em>x</em>))), and returns all three. This gives you <em>f</em>(<em>x</em>)
 directly (the third term), and if you need the derivative you can just 
multiply all three terms and you are done. With the naïve approach you 
would have had to call the <code>exp</code> function nine times to compute both <em>f</em>(<em>x</em>) and <em>f′</em>(<em>x</em>). With this approach you just need to call it three times.</p>

<p>It gets worse when your function is defined by some arbitrary code. 
Can you find the equation (or the code) to compute the partial 
derivatives of the following function? Hint: don’t even try.</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">def</code> <code class="nf">my_func</code><code class="p">(</code><code class="n">a</code><code class="p">,</code> <code class="n">b</code><code class="p">):</code>
    <code class="n">z</code> <code class="o">=</code> <code class="mi">0</code>
    <code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="mi">100</code><code class="p">):</code>
        <code class="n">z</code> <code class="o">=</code> <code class="n">a</code> <code class="o">*</code> <code class="n">np</code><code class="o">.</code><code class="n">cos</code><code class="p">(</code><code class="n">z</code> <code class="o">+</code> <code class="n">i</code><code class="p">)</code> <code class="o">+</code> <code class="n">z</code> <code class="o">*</code> <code class="n">np</code><code class="o">.</code><code class="n">sin</code><code class="p">(</code><code class="n">b</code> <code class="o">-</code> <code class="n">i</code><code class="p">)</code>
    <code class="k">return</code> <code class="n">z</code></pre>

<p>Fortunately, TensorFlow’s autodiff feature comes to the rescue: it 
can automatically and efficiently compute the gradients for you. Simply 
replace the <code>gradients = ...</code> line in the Gradient Descent 
code in the previous section with the following line, and the code will 
continue to work just fine:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">gradients</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">gradients</code><code class="p">(</code><code class="n">mse</code><code class="p">,</code> <code class="p">[</code><code class="n">theta</code><code class="p">])[</code><code class="mi">0</code><code class="p">]</code></pre>

<p>The <code>gradients()</code> <a data-type="indexterm" data-primary="gradients()" id="idm140583005029312"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.gradients()" id="idm140583005028640"></a>function takes an op (in this case <code>mse</code>) and a list of variables (in this case just <code>theta</code>), and it creates a list of ops (one per variable) to compute the gradients of the op with regards to each variable. So the <code>gradients</code> node will compute the gradient vector of the MSE with regards to <code>theta</code>.</p>

<p>There are four main approaches to computing gradients automatically. They are summarized in <a data-type="xref" href="#automatic_gradients_table">Table&nbsp;9-2</a>. TensorFlow uses <em>reverse-mode autodiff</em>,
 which is perfect (efficient and accurate) when there are many inputs 
and few outputs, as is often the case in neural networks. It computes 
all the partial derivatives of the outputs with regards to all the 
inputs in just <em>n</em><sub>outputs</sub> + 1 graph traversals.</p>
<table id="automatic_gradients_table">
<caption><span class="label">Table 9-2. </span>Main solutions to compute gradients automatically</caption>
<thead>
<tr>
<th>Technique</th>
<th>Nb of graph traversals to compute all gradients</th>
<th>Accuracy</th>
<th>Supports arbitrary code</th>
<th>Comment</th>
</tr>
</thead>
<tbody>
<tr>
<td><p>Numerical differentiation</p></td>
<td><p><em>n</em><sub>inputs</sub> + 1</p></td>
<td><p>Low</p></td>
<td><p>Yes</p></td>
<td><p>Trivial to implement</p></td>
</tr>
<tr>
<td><p>Symbolic differentiation</p></td>
<td><p>N/A</p></td>
<td><p>High</p></td>
<td><p>No</p></td>
<td><p>Builds a very different graph</p></td>
</tr>
<tr>
<td><p>Forward-mode autodiff</p></td>
<td><p><em>n</em><sub>inputs</sub></p></td>
<td><p>High</p></td>
<td><p>Yes</p></td>
<td><p>Uses <em>dual numbers</em></p></td>
</tr>
<tr>
<td><p>Reverse-mode autodiff</p></td>
<td><p><em>n</em><sub>outputs</sub> + 1</p></td>
<td><p>High</p></td>
<td><p>Yes</p></td>
<td><p>Implemented by TensorFlow</p></td>
</tr>
</tbody>
</table>

<p>If you are interested in how this magic <a data-type="indexterm" data-primary="TensorFlow" data-secondary="autodiff" data-startref="tf9ad" id="idm140583004992240"></a><a data-type="indexterm" data-primary="autodiff" data-startref="ad9" id="idm140583004990992"></a><a data-type="indexterm" data-primary="Gradient Descent (GD)" data-secondary="automatically computing gradients" data-startref="gd9acg" id="idm140583004990048"></a>works, check out <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app04.html#autodiff_appendix">Appendix&nbsp;D</a>.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Using an Optimizer"><div class="sect2" id="idm140583005293200">
<h2>Using an Optimizer</h2>

<p>So <a data-type="indexterm" data-primary="TensorFlow" data-secondary="optimizer" id="idm140583004986320"></a><a data-type="indexterm" data-primary="Gradient Descent (GD)" data-secondary="optimizer" id="idm140583004985312"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.train.GradientDescentOptimizer" id="idm140583004984368"></a>TensorFlow
 computes the gradients for you. But it gets even easier: it also 
provides a number of optimizers out of the box, including a Gradient 
Descent optimizer. You can simply replace the preceding <code>gradients = ...</code> and <code>training_op = ...</code> lines with the following code, and once again everything will just work fine:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">optimizer</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">train</code><code class="o">.</code><code class="n">GradientDescentOptimizer</code><code class="p">(</code><code class="n">learning_rate</code><code class="o">=</code><code class="n">learning_rate</code><code class="p">)</code>
<code class="n">training_op</code> <code class="o">=</code> <code class="n">optimizer</code><code class="o">.</code><code class="n">minimize</code><code class="p">(</code><code class="n">mse</code><code class="p">)</code></pre>

<p>If you want to use a different type of optimizer, you just need to 
change one line. For example, you can use a momentum optimizer (which 
often converges much faster than Gradient Descent; see <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#deep_chapter">Chapter&nbsp;11</a>) by defining the optimizer <a data-type="indexterm" data-primary="TensorFlow" data-secondary="Gradient Descent with" data-startref="tf9igd" id="idm140583004966464"></a><a data-type="indexterm" data-primary="Gradient Descent (GD)" data-secondary="with TensorFlow" data-secondary-sortas="TensorFlow" data-startref="d9wtf" id="idm140583004965312"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.train.MomentumOptimizer" id="idm140583004963824"></a>like this:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">optimizer</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">train</code><code class="o">.</code><code class="n">MomentumOptimizer</code><code class="p">(</code><code class="n">learning_rate</code><code class="o">=</code><code class="n">learning_rate</code><code class="p">,</code>
                                       <code class="n">momentum</code><code class="o">=</code><code class="mf">0.9</code><code class="p">)</code></pre>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Feeding Data to the Training Algorithm"><div class="sect1" id="idm140583005328064">
<h1>Feeding Data to the Training Algorithm</h1>

<p>Let’s <a data-type="indexterm" data-primary="TensorFlow" data-secondary="feeding data to the training algorithm" id="tf9fdttta"></a>try to modify the previous code to implement <a data-type="indexterm" data-primary="Mini-batch Gradient Descent" id="mbgd9"></a><a data-type="indexterm" data-primary="Gradient Descent (GD)" data-secondary="Mini-batch GD" id="gd9mbgd"></a>Mini-batch Gradient Descent. For this, we need a way to replace <code>X</code> and <code>y</code> at every iteration with the next mini-batch. The simplest way to do this is to use <a data-type="indexterm" data-primary="placeholder nodes" id="idm140583004954832"></a>placeholder
 nodes. These nodes are special because they don’t actually perform any 
computation, they just output the data you tell them to output at 
runtime. They are typically used to pass the training data to TensorFlow
 during training. If you don’t specify a value at runtime for a 
placeholder, you get an exception.</p>

<p>To create a placeholder node, <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.placeholder()" id="tfplaceholderch9"></a>you must call the <code>placeholder()</code>
 function and specify the output tensor’s data type. Optionally, you can
 also specify its shape, if you want to enforce it. If you specify <code>None</code> for a dimension, it means “any size.” For example, the following code creates a placeholder node <code>A</code>, and also a node <code>B = A + 5</code>. When we evaluate <code>B</code>, we pass a <code>feed_dict</code> <a data-type="indexterm" data-primary="feed_dict" id="idm140583004633232"></a>to the <code>eval()</code> <a data-type="indexterm" data-primary="eval()" id="idm140583004631952"></a>method that specifies the value of <code>A</code>. Note that <code>A</code>
 must have rank 2 (i.e., it must be two-dimensional) and there must be 
three columns (or else an exception is raised), but it can have any 
number of rows.</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">A</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">placeholder</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">,</code> <code class="n">shape</code><code class="o">=</code><code class="p">(</code><code class="bp">None</code><code class="p">,</code> <code class="mi">3</code><code class="p">))</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">B</code> <code class="o">=</code> <code class="n">A</code> <code class="o">+</code> <code class="mi">5</code>
<code class="gp">&gt;&gt;&gt; </code><code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">Session</code><code class="p">()</code> <code class="k">as</code> <code class="n">sess</code><code class="p">:</code>
<code class="gp">... </code>    <code class="n">B_val_1</code> <code class="o">=</code> <code class="n">B</code><code class="o">.</code><code class="n">eval</code><code class="p">(</code><code class="n">feed_dict</code><code class="o">=</code><code class="p">{</code><code class="n">A</code><code class="p">:</code> <code class="p">[[</code><code class="mi">1</code><code class="p">,</code> <code class="mi">2</code><code class="p">,</code> <code class="mi">3</code><code class="p">]]})</code>
<code class="gp">... </code>    <code class="n">B_val_2</code> <code class="o">=</code> <code class="n">B</code><code class="o">.</code><code class="n">eval</code><code class="p">(</code><code class="n">feed_dict</code><code class="o">=</code><code class="p">{</code><code class="n">A</code><code class="p">:</code> <code class="p">[[</code><code class="mi">4</code><code class="p">,</code> <code class="mi">5</code><code class="p">,</code> <code class="mi">6</code><code class="p">],</code> <code class="p">[</code><code class="mi">7</code><code class="p">,</code> <code class="mi">8</code><code class="p">,</code> <code class="mi">9</code><code class="p">]]})</code>
<code class="gp">...</code>
<code class="gp">&gt;&gt;&gt; </code><code class="k">print</code><code class="p">(</code><code class="n">B_val_1</code><code class="p">)</code>
<code class="go">[[ 6.  7.  8.]]</code>
<code class="gp">&gt;&gt;&gt; </code><code class="k">print</code><code class="p">(</code><code class="n">B_val_2</code><code class="p">)</code>
<code class="go">[[  9.  10.  11.]</code>
<code class="go"> [ 12.  13.  14.]]</code></pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>You can actually feed the output of <em>any</em> operations, not just
 placeholders. In this case TensorFlow does not try to evaluate these 
operations; it uses the values you feed it.</p>
</div>

<p>To implement Mini-batch Gradient Descent, we only need to tweak the existing code slightly. First change the definition of <code>X</code> and <code>y</code> in the construction phase to make them <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.placeholder()" data-startref="tfplaceholderch9" id="idm140583004538528"></a>placeholder nodes:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">X</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">placeholder</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">,</code> <code class="n">shape</code><code class="o">=</code><code class="p">(</code><code class="bp">None</code><code class="p">,</code> <code class="n">n</code> <code class="o">+</code> <code class="mi">1</code><code class="p">),</code> <code class="n">name</code><code class="o">=</code><code class="s2">"X"</code><code class="p">)</code>
<code class="n">y</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">placeholder</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">,</code> <code class="n">shape</code><code class="o">=</code><code class="p">(</code><code class="bp">None</code><code class="p">,</code> <code class="mi">1</code><code class="p">),</code> <code class="n">name</code><code class="o">=</code><code class="s2">"y"</code><code class="p">)</code></pre>

<p>Then define the batch size and compute the total number of batches:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">batch_size</code> <code class="o">=</code> <code class="mi">100</code>
<code class="n">n_batches</code> <code class="o">=</code> <code class="nb">int</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">ceil</code><code class="p">(</code><code class="n">m</code> <code class="o">/</code> <code class="n">batch_size</code><code class="p">))</code></pre>

<p>Finally, in the execution phase, fetch the mini-batches one by one, then provide the value of <code>X</code> and <code>y</code> via the <code>feed_dict</code> parameter when evaluating a node that depends on either of them.</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">def</code> <code class="nf">fetch_batch</code><code class="p">(</code><code class="n">epoch</code><code class="p">,</code> <code class="n">batch_index</code><code class="p">,</code> <code class="n">batch_size</code><code class="p">):</code>
    <code class="p">[</code><code class="o">...</code><code class="p">]</code> <code class="c1"># load the data from disk</code>
    <code class="k">return</code> <code class="n">X_batch</code><code class="p">,</code> <code class="n">y_batch</code>

<code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">Session</code><code class="p">()</code> <code class="k">as</code> <code class="n">sess</code><code class="p">:</code>
    <code class="n">sess</code><code class="o">.</code><code class="n">run</code><code class="p">(</code><code class="n">init</code><code class="p">)</code>

    <code class="k">for</code> <code class="n">epoch</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">n_epochs</code><code class="p">):</code>
        <code class="k">for</code> <code class="n">batch_index</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">n_batches</code><code class="p">):</code>
            <code class="n">X_batch</code><code class="p">,</code> <code class="n">y_batch</code> <code class="o">=</code> <code class="n">fetch_batch</code><code class="p">(</code><code class="n">epoch</code><code class="p">,</code> <code class="n">batch_index</code><code class="p">,</code> <code class="n">batch_size</code><code class="p">)</code>
            <code class="n">sess</code><code class="o">.</code><code class="n">run</code><code class="p">(</code><code class="n">training_op</code><code class="p">,</code> <code class="n">feed_dict</code><code class="o">=</code><code class="p">{</code><code class="n">X</code><code class="p">:</code> <code class="n">X_batch</code><code class="p">,</code> <code class="n">y</code><code class="p">:</code> <code class="n">y_batch</code><code class="p">})</code>

    <code class="n">best_theta</code> <code class="o">=</code> <code class="n">theta</code><code class="o">.</code><code class="n">eval</code><code class="p">()</code></pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>We don’t need to pass the value of <code>X</code> and <code>y</code> when evaluating <code>theta</code> since it does not depend on <a data-type="indexterm" data-primary="TensorFlow" data-secondary="feeding data to the training algorithm" data-startref="tf9fdttta" id="idm140583004325584"></a><a data-type="indexterm" data-primary="Mini-batch Gradient Descent" data-startref="mbgd9" id="idm140583004324368"></a><a data-type="indexterm" data-primary="Gradient Descent (GD)" data-secondary="Mini-batch GD" data-startref="gd9mbgd" id="idm140583004323456"></a>either of them.</p>
</div>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Saving and Restoring Models"><div class="sect1" id="idm140583004946192">
<h1>Saving and Restoring Models</h1>

<p>Once <a data-type="indexterm" data-primary="TensorFlow" data-secondary="saving and restoring models" id="tf9sarm"></a>you
 have trained your model, you should save its parameters to disk so you 
can come back to it whenever you want, use it in another program, 
compare it to other models, and so on. Moreover, you probably want to 
save checkpoints at regular intervals during training so that if your 
computer crashes during training you can continue from the last 
checkpoint rather than start over from scratch.</p>

<p>TensorFlow makes saving and restoring a model very easy. Just create a <code>Saver</code> node <a data-type="indexterm" data-primary="Saver  node" id="idm140583004317760"></a>at the end of the construction phase (after all variable nodes are created); then, in the execution phase, just call its <code>save()</code> method <a data-type="indexterm" data-primary="save()" id="idm140583004316368"></a>whenever you want to save the model, passing it the session and path of <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.random_uniform()" id="idm140583004315504"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.train.Saver" id="tftrainsaverch9"></a>the checkpoint file:</p>

<pre data-type="programlisting" data-code-language="python"><code class="p">[</code><code class="o">...</code><code class="p">]</code>
<code class="n">theta</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">Variable</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">random_uniform</code><code class="p">([</code><code class="n">n</code> <code class="o">+</code> <code class="mi">1</code><code class="p">,</code> <code class="mi">1</code><code class="p">],</code> <code class="o">-</code><code class="mf">1.0</code><code class="p">,</code> <code class="mf">1.0</code><code class="p">),</code> <code class="n">name</code><code class="o">=</code><code class="s2">"theta"</code><code class="p">)</code>
<code class="p">[</code><code class="o">...</code><code class="p">]</code>
<code class="n">init</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">global_variables_initializer</code><code class="p">()</code>
<code class="n">saver</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">train</code><code class="o">.</code><code class="n">Saver</code><code class="p">()</code>

<code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">Session</code><code class="p">()</code> <code class="k">as</code> <code class="n">sess</code><code class="p">:</code>
    <code class="n">sess</code><code class="o">.</code><code class="n">run</code><code class="p">(</code><code class="n">init</code><code class="p">)</code>

    <code class="k">for</code> <code class="n">epoch</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">n_epochs</code><code class="p">):</code>
        <code class="k">if</code> <code class="n">epoch</code> <code class="o">%</code> <code class="mi">100</code> <code class="o">==</code> <code class="mi">0</code><code class="p">:</code>  <code class="c1"># checkpoint every 100 epochs</code>
            <code class="n">save_path</code> <code class="o">=</code> <code class="n">saver</code><code class="o">.</code><code class="n">save</code><code class="p">(</code><code class="n">sess</code><code class="p">,</code> <code class="s2">"/tmp/my_model.ckpt"</code><code class="p">)</code>

        <code class="n">sess</code><code class="o">.</code><code class="n">run</code><code class="p">(</code><code class="n">training_op</code><code class="p">)</code>

    <code class="n">best_theta</code> <code class="o">=</code> <code class="n">theta</code><code class="o">.</code><code class="n">eval</code><code class="p">()</code>
    <code class="n">save_path</code> <code class="o">=</code> <code class="n">saver</code><code class="o">.</code><code class="n">save</code><code class="p">(</code><code class="n">sess</code><code class="p">,</code> <code class="s2">"/tmp/my_model_final.ckpt"</code><code class="p">)</code></pre>

<p>Restoring a model is just as easy: you create a <code>Saver</code> at
 the end of the construction phase just like before, but then at the 
beginning of the execution phase, instead of initializing the variables <a data-type="indexterm" data-primary="init   node" id="idm140583004310592"></a>using the <code>init</code> node, you call the <code>restore()</code> method <a data-type="indexterm" data-primary="restore()" id="idm140583004237456"></a>of the <code>Saver</code> object:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">Session</code><code class="p">()</code> <code class="k">as</code> <code class="n">sess</code><code class="p">:</code>
    <code class="n">saver</code><code class="o">.</code><code class="n">restore</code><code class="p">(</code><code class="n">sess</code><code class="p">,</code> <code class="s2">"/tmp/my_model_final.ckpt"</code><code class="p">)</code>
    <code class="p">[</code><code class="o">...</code><code class="p">]</code></pre>

<p>By default a <code>Saver</code> saves and restores all variables 
under their own name, but if you need more control, you can specify 
which variables to save or restore, and what names to use. For example, 
the following <code>Saver</code> will save or restore only the <code>theta</code> variable under the <a data-type="indexterm" data-primary="TensorFlow" data-secondary="saving and restoring models" data-startref="tf9sarm" id="idm140583004230672"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.train.Saver" data-startref="tftrainsaverch9" id="idm140583004229456"></a>name <code>weights</code>:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">saver</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">train</code><code class="o">.</code><code class="n">Saver</code><code class="p">({</code><code class="s2">"weights"</code><code class="p">:</code> <code class="n">theta</code><code class="p">})</code></pre>

<p>By default, the <code>save()</code> method also saves the structure of the graph in a second file with the same name plus a <code>.meta</code> extension. You can load this graph structure using <code>tf.train.import_meta_graph()</code>. This adds the graph to the default graph, and returns a <code>Saver</code> instance that you can then use to restore the graph’s state (i.e., the variable values):</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">saver</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">train</code><code class="o">.</code><code class="n">import_meta_graph</code><code class="p">(</code><code class="s2">"/tmp/my_model_final.ckpt.meta"</code><code class="p">)</code>

<code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">Session</code><code class="p">()</code> <code class="k">as</code> <code class="n">sess</code><code class="p">:</code>
    <code class="n">saver</code><code class="o">.</code><code class="n">restore</code><code class="p">(</code><code class="n">sess</code><code class="p">,</code> <code class="s2">"/tmp/my_model_final.ckpt"</code><code class="p">)</code>
    <code class="p">[</code><code class="o">...</code><code class="p">]</code></pre>

<p>This allows you to fully restore a saved model, including both the 
graph structure and the variable values, without having to search for 
the code that built it.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Visualizing the Graph and Training Curves Using TensorBoard"><div class="sect1" id="idm140583004321520">
<h1>Visualizing the Graph and Training Curves Using TensorBoard</h1>

<p>So <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.Graph" id="idm140583003945008"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="TensorBoard" id="tf9tb"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="visualizing graph and training curves" id="tf9vgatc"></a><a data-type="indexterm" data-primary="visualization" id="v9wtb"></a>now
 we have a computation graph that trains a Linear Regression model using
 Mini-batch Gradient Descent, and we are saving checkpoints at regular 
intervals. Sounds sophisticated, doesn’t it? However, we are still 
relying on the <code>print()</code> function to visualize progress 
during training. There is a better way: enter TensorBoard. If you feed 
it some training stats, it will display nice interactive visualizations 
of these stats in your web browser (e.g., learning curves). You can also
 provide it the graph’s definition and it will give you a great 
interface to browse through it. This is very useful to identify errors 
in the graph, to find bottlenecks, and so on.</p>

<p>The first step is to tweak your program a bit so it writes the graph 
definition and some training stats—for example, the training error 
(MSE)—to a log directory that TensorBoard will read from. You need to 
use a different log directory every time you run your program, or else 
TensorBoard will merge stats from different runs, which will mess up the
 visualizations. The simplest solution for this is to include a 
timestamp in the log directory name. Add the following code at the 
beginning of the program:</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">datetime</code> <code class="kn">import</code> <code class="n">datetime</code>

<code class="n">now</code> <code class="o">=</code> <code class="n">datetime</code><code class="o">.</code><code class="n">utcnow</code><code class="p">()</code><code class="o">.</code><code class="n">strftime</code><code class="p">(</code><code class="s2">"</code><code class="si">%Y%m%d%H%M%S</code><code class="s2">"</code><code class="p">)</code>
<code class="n">root_logdir</code> <code class="o">=</code> <code class="s2">"tf_logs"</code>
<code class="n">logdir</code> <code class="o">=</code> <code class="s2">"{}/run-{}/"</code><code class="o">.</code><code class="n">format</code><code class="p">(</code><code class="n">root_logdir</code><code class="p">,</code> <code class="n">now</code><code class="p">)</code></pre>

<p>Next, add the following code at the very end of the <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.summary.scalar()" id="idm140583003936880"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.summary.FileWriter" id="tfsummfwch9"></a> <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.get_default_graph()" id="idm140583003880512"></a>construction phase:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">mse_summary</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">summary</code><code class="o">.</code><code class="n">scalar</code><code class="p">(</code><code class="s1">'MSE'</code><code class="p">,</code> <code class="n">mse</code><code class="p">)</code>
<code class="n">file_writer</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">summary</code><code class="o">.</code><code class="n">FileWriter</code><code class="p">(</code><code class="n">logdir</code><code class="p">,</code> <code class="n">tf</code><code class="o">.</code><code class="n">get_default_graph</code><code class="p">())</code></pre>

<p>The first line creates a node in the graph that will evaluate the MSE
 value and write it to a TensorBoard-compatible binary log string called
 a <em>summary</em>. The second line creates a <code>FileWriter</code> 
that you will use to write summaries to logfiles in the log directory. 
The first parameter indicates the path of the log directory (in this 
case something like <em>tf_logs/run-20160906091959/</em>, relative to the current directory). The second (optional) parameter is the graph you want to visualize. Upon creation, the <code>FileWriter</code>
 creates the log directory if it does not already exist (and its parent 
directories if needed), and writes the graph definition in a binary 
logfile called an <em>events file</em>.</p>

<p>Next you need to update the execution phase to evaluate the <code>mse_summary</code>
 node regularly during training (e.g., every 10 mini-batches). This will
 output a summary that you can then write to the events file using the <code>file_writer</code>. Here is the updated code:</p>

<pre data-type="programlisting" data-code-language="python">    <code class="p">[</code><code class="o">...</code><code class="p">]</code>
    <code class="k">for</code> <code class="n">batch_index</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">n_batches</code><code class="p">):</code>
        <code class="n">X_batch</code><code class="p">,</code> <code class="n">y_batch</code> <code class="o">=</code> <code class="n">fetch_batch</code><code class="p">(</code><code class="n">epoch</code><code class="p">,</code> <code class="n">batch_index</code><code class="p">,</code> <code class="n">batch_size</code><code class="p">)</code>
        <code class="k">if</code> <code class="n">batch_index</code> <code class="o">%</code> <code class="mi">10</code> <code class="o">==</code> <code class="mi">0</code><code class="p">:</code>
            <code class="n">summary_str</code> <code class="o">=</code> <code class="n">mse_summary</code><code class="o">.</code><code class="n">eval</code><code class="p">(</code><code class="n">feed_dict</code><code class="o">=</code><code class="p">{</code><code class="n">X</code><code class="p">:</code> <code class="n">X_batch</code><code class="p">,</code> <code class="n">y</code><code class="p">:</code> <code class="n">y_batch</code><code class="p">})</code>
            <code class="n">step</code> <code class="o">=</code> <code class="n">epoch</code> <code class="o">*</code> <code class="n">n_batches</code> <code class="o">+</code> <code class="n">batch_index</code>
            <code class="n">file_writer</code><code class="o">.</code><code class="n">add_summary</code><code class="p">(</code><code class="n">summary_str</code><code class="p">,</code> <code class="n">step</code><code class="p">)</code>
        <code class="n">sess</code><code class="o">.</code><code class="n">run</code><code class="p">(</code><code class="n">training_op</code><code class="p">,</code> <code class="n">feed_dict</code><code class="o">=</code><code class="p">{</code><code class="n">X</code><code class="p">:</code> <code class="n">X_batch</code><code class="p">,</code> <code class="n">y</code><code class="p">:</code> <code class="n">y_batch</code><code class="p">})</code>
    <code class="p">[</code><code class="o">...</code><code class="p">]</code></pre>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>Avoid logging training stats at every single training step, as this would significantly slow down training.</p>
</div>

<p>Finally, you want to close the <code>FileWriter</code> at the end of <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.summary.FileWriter" data-startref="tfsummfwch9" id="idm140583003742944"></a>the program:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">file_writer</code><code class="o">.</code><code class="n">close</code><code class="p">()</code></pre>

<p>Now run this program: it will create the log directory and write an 
events file in this directory, containing both the graph definition and 
the MSE values. Open up a shell and go to your working directory, then 
type <code><strong>ls -l tf_logs/run*</strong></code> to list the contents of the log directory:</p>

<pre data-type="programlisting" data-code-language="shell-session"><code class="go">$ cd $ML_PATH               # Your ML working directory (e.g., $HOME/ml)</code>
<code class="go">$ ls -l tf_logs/run*</code>
<code class="go">total 40</code>
<code class="go">-rw-r--r-- 1 ageron staff 18620 Sep 6 11:10 events.out.tfevents.1472553182.mymac</code></pre>

<p>If you run the program a second time, you should see a second directory in the <em>tf_logs/</em> directory:</p>

<pre data-type="programlisting" data-code-language="shell-session"><code class="go">$ ls -l tf_logs/</code>
<code class="go">total 0</code>
<code class="go">drwxr-xr-x  3 ageron  staff  102 Sep  6 10:07 run-20160906091959</code>
<code class="go">drwxr-xr-x  3 ageron  staff  102 Sep  6 10:22 run-20160906092202</code></pre>

<p>Great! Now it’s time to fire up the TensorBoard server. You need to 
activate your virtualenv environment if you created one, then start the 
server by running the <code>tensorboard</code> command, pointing it to 
the root log directory. This starts the TensorBoard web server, 
listening on port 6006 (which is “goog” written upside down):</p>

<pre data-type="programlisting" data-code-language="shell-session"><code class="go">$ source env/bin/activate</code>
<code class="go">$ tensorboard --logdir tf_logs/</code>
<code class="go">Starting TensorBoard  on port 6006</code>
<code class="go">(You can navigate to http://0.0.0.0:6006)</code></pre>

<p>Next open a browser and go to <em><a href="http://0.0.0.0:6006/"><em class="hyperlink">http://0.0.0.0:6006/</em></a></em> (or <em><a href="http://localhost:6006/"><em class="hyperlink">http://localhost:6006/</em></a></em>).
 Welcome to TensorBoard! In the Events tab you should see MSE on the 
right. If you click on it, you will see a plot of the MSE during 
training, for both runs (<a data-type="xref" href="#tensorboard_events_screenshot">Figure&nbsp;9-3</a>). You can check or uncheck the runs you want to see, zoom in or out, hover over the curve to get details, and so on.</p>

<figure><div id="tensorboard_events_screenshot" class="figure">
<img src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_0903.png" alt="mlst 0903" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_0903.png" width="1436" height="779">
<h6><span class="label">Figure 9-3. </span>Visualizing training stats using TensorBoard</h6>
</div></figure>

<p>Now click on the Graphs tab. You should see the graph shown in <a data-type="xref" href="#tensorboard_graphs_screenshot">Figure&nbsp;9-4</a>.</p>

<p>To reduce clutter, the nodes that have <a data-type="indexterm" data-primary="node edges" id="idm140583003658896"></a>many <em>edges</em>
 (i.e., connections to other nodes) are separated out to an auxiliary 
area on the right (you can move a node back and forth between the main 
graph and the auxiliary area by right-clicking on it). Some parts of the
 graph are also collapsed by default. For example, try hovering over the
 <code>gradients</code> node, then click on the ⊕ icon to expand this subgraph. Next, in this subgraph, try expanding the <code>mse_grad</code> subgraph.</p>

<figure><div id="tensorboard_graphs_screenshot" class="figure">
<img src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_0904.png" alt="mlst 0904" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_0904.png" width="1436" height="779">
<h6><span class="label">Figure 9-4. </span>Visualizing the graph using TensorBoard</h6>
</div></figure>
<div data-type="tip"><h6>Tip</h6>
<p>If you want to take a peek at the graph directly within Jupyter, you can use the <code>show_graph()</code> <a data-type="indexterm" data-primary="show_graph()" id="idm140583003617008"></a>function available in the notebook for this chapter. It was originally written by A. Mordvintsev in his great <a href="http://goo.gl/EtCWUc">deepdream tutorial notebook</a>. Another option is to install E. Jang’s <a href="https://github.com/ericjang/tdb">TensorFlow debugger tool</a> which includes a Jupyter extension <a data-type="indexterm" data-primary="TensorFlow" data-secondary="TensorBoard" data-startref="tf9tb" id="idm140583003614528"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="visualizing graph and training curves" data-startref="tf9vgatc" id="idm140583003613312"></a><a data-type="indexterm" data-primary="visualization" data-startref="v9wtb" id="idm140583003725072"></a>for graph visualization (and more).</p>
</div>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Name Scopes"><div class="sect1" id="idm140583003945920">
<h1>Name Scopes</h1>

<p>When <a data-type="indexterm" data-primary="TensorFlow" data-secondary="name scopes" id="idm140583003722592"></a><a data-type="indexterm" data-primary="name scopes" id="idm140583003721584"></a>dealing
 with more complex models such as neural networks, the graph can easily 
become cluttered with thousands of nodes. To avoid this, you can create <em>name scopes</em> to group related nodes. For example, let’s modify the previous code to define the <code>error</code> and <code>mse</code> ops within a name <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.name_scope()" id="idm140583003719376"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.reduce_mean()" id="idm140583003718368"></a> <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.square()" id="idm140583003717296"></a>scope called <code>"loss"</code>:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">name_scope</code><code class="p">(</code><code class="s2">"loss"</code><code class="p">)</code> <code class="k">as</code> <code class="n">scope</code><code class="p">:</code>
    <code class="n">error</code> <code class="o">=</code> <code class="n">y_pred</code> <code class="o">-</code> <code class="n">y</code>
    <code class="n">mse</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">reduce_mean</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">square</code><code class="p">(</code><code class="n">error</code><code class="p">),</code> <code class="n">name</code><code class="o">=</code><code class="s2">"mse"</code><code class="p">)</code></pre>

<p>The name of each op defined within the scope is now prefixed with <code>"loss/"</code>:</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="k">print</code><code class="p">(</code><code class="n">error</code><code class="o">.</code><code class="n">op</code><code class="o">.</code><code class="n">name</code><code class="p">)</code>
<code class="go">loss/sub</code>
<code class="gp">&gt;&gt;&gt; </code><code class="k">print</code><code class="p">(</code><code class="n">mse</code><code class="o">.</code><code class="n">op</code><code class="o">.</code><code class="n">name</code><code class="p">)</code>
<code class="go">loss/mse</code></pre>

<p>In TensorBoard, the <code>mse</code> and <code>error</code> nodes now appear inside the <code>loss</code> namescope, which appears collapsed by default (<a data-type="xref" href="#tensorboard_namescope_screenshot">Figure&nbsp;9-5</a>).</p>

<figure class="smallersixty"><div id="tensorboard_namescope_screenshot" class="figure">
<img src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_0905.png" alt="mlst 0905" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_0905.png" width="651" height="485">
<h6><span class="label">Figure 9-5. </span>A collapsed namescope in TensorBoard</h6>
</div></figure>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Modularity"><div class="sect1" id="idm140583003445808">
<h1>Modularity</h1>

<p>Suppose <a data-type="indexterm" data-primary="TensorFlow" data-secondary="modularity" id="tf9m"></a>you want to create a graph that adds the output of <a data-type="indexterm" data-primary="ReLU (rectified   linear  units)" id="relu9"></a>two <em>rectified linear units</em>
 (ReLU). A ReLU computes a linear function of the inputs, and outputs 
the result if it is positive, and 0 otherwise, as shown in <a data-type="xref" href="#relu_function">Equation 9-1</a>.</p>
<div class="fifty-percent" id="relu_function" data-type="equation"><h5><span class="label">Equation 9-1. </span>Rectified linear unit</h5>
<img src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_97.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_97.png" width="713" height="69"></div>

<p>The following code does the job, but it’s quite <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.random_normal()" id="idm140583003437808"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.matmul()" id="idm140583003436832"></a> <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.add()" id="idm140583003435760"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.maximum()" id="idm140583003434784"></a>repetitive:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">n_features</code> <code class="o">=</code> <code class="mi">3</code>
<code class="n">X</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">placeholder</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">,</code> <code class="n">shape</code><code class="o">=</code><code class="p">(</code><code class="bp">None</code><code class="p">,</code> <code class="n">n_features</code><code class="p">),</code> <code class="n">name</code><code class="o">=</code><code class="s2">"X"</code><code class="p">)</code>

<code class="n">w1</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">Variable</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">random_normal</code><code class="p">((</code><code class="n">n_features</code><code class="p">,</code> <code class="mi">1</code><code class="p">)),</code> <code class="n">name</code><code class="o">=</code><code class="s2">"weights1"</code><code class="p">)</code>
<code class="n">w2</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">Variable</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">random_normal</code><code class="p">((</code><code class="n">n_features</code><code class="p">,</code> <code class="mi">1</code><code class="p">)),</code> <code class="n">name</code><code class="o">=</code><code class="s2">"weights2"</code><code class="p">)</code>
<code class="n">b1</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">Variable</code><code class="p">(</code><code class="mf">0.0</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"bias1"</code><code class="p">)</code>
<code class="n">b2</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">Variable</code><code class="p">(</code><code class="mf">0.0</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"bias2"</code><code class="p">)</code>

<code class="n">z1</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">matmul</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">w1</code><code class="p">),</code> <code class="n">b1</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"z1"</code><code class="p">)</code>
<code class="n">z2</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">matmul</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">w2</code><code class="p">),</code> <code class="n">b2</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"z2"</code><code class="p">)</code>

<code class="n">relu1</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">maximum</code><code class="p">(</code><code class="n">z1</code><code class="p">,</code> <code class="mf">0.</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"relu1"</code><code class="p">)</code>
<code class="n">relu2</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">maximum</code><code class="p">(</code><code class="n">z1</code><code class="p">,</code> <code class="mf">0.</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"relu2"</code><code class="p">)</code>

<code class="n">output</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">relu1</code><code class="p">,</code> <code class="n">relu2</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"output"</code><code class="p">)</code></pre>

<p>Such repetitive code is hard to maintain and error-prone (in fact, 
this code contains a cut-and-paste error; did you spot it?). It would 
become even worse if you wanted to add a few more ReLUs. Fortunately, 
TensorFlow lets you stay <a data-type="indexterm" data-primary="DRY (Don’t Repeat Yourself)" id="idm140583003426704"></a>DRY (Don’t Repeat Yourself): simply create a function to build a ReLU. The following code creates five ReLUs and <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.add_n()" id="tfaddnch9"></a>outputs their sum (note that <code>add_n()</code> creates an operation that will compute the sum of a list of tensors):</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">def</code> <code class="nf">relu</code><code class="p">(</code><code class="n">X</code><code class="p">):</code>
    <code class="n">w_shape</code> <code class="o">=</code> <code class="p">(</code><code class="nb">int</code><code class="p">(</code><code class="n">X</code><code class="o">.</code><code class="n">get_shape</code><code class="p">()[</code><code class="mi">1</code><code class="p">]),</code> <code class="mi">1</code><code class="p">)</code>
    <code class="n">w</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">Variable</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">random_normal</code><code class="p">(</code><code class="n">w_shape</code><code class="p">),</code> <code class="n">name</code><code class="o">=</code><code class="s2">"weights"</code><code class="p">)</code>
    <code class="n">b</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">Variable</code><code class="p">(</code><code class="mf">0.0</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"bias"</code><code class="p">)</code>
    <code class="n">z</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">matmul</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">w</code><code class="p">),</code> <code class="n">b</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"z"</code><code class="p">)</code>
    <code class="k">return</code> <code class="n">tf</code><code class="o">.</code><code class="n">maximum</code><code class="p">(</code><code class="n">z</code><code class="p">,</code> <code class="mf">0.</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"relu"</code><code class="p">)</code>

<code class="n">n_features</code> <code class="o">=</code> <code class="mi">3</code>
<code class="n">X</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">placeholder</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">,</code> <code class="n">shape</code><code class="o">=</code><code class="p">(</code><code class="bp">None</code><code class="p">,</code> <code class="n">n_features</code><code class="p">),</code> <code class="n">name</code><code class="o">=</code><code class="s2">"X"</code><code class="p">)</code>
<code class="n">relus</code> <code class="o">=</code> <code class="p">[</code><code class="n">relu</code><code class="p">(</code><code class="n">X</code><code class="p">)</code> <code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="mi">5</code><code class="p">)]</code>
<code class="n">output</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">add_n</code><code class="p">(</code><code class="n">relus</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"output"</code><code class="p">)</code></pre>

<p>Note that when you create a node, TensorFlow checks whether its name 
already exists, and if it does it appends an underscore followed by an 
index to make the name unique. So the first ReLU contains nodes named <code>"weights"</code>, <code>"bias"</code>, <code>"z"</code>, and <code>"relu"</code> (plus many more nodes with their default name, such as <code>"MatMul"</code>); the second ReLU contains nodes named <code>"weights_1"</code>, <code>"bias_1"</code>, and so on; the third ReLU contains nodes named <code>"weights_2"</code>, <code>"bias_2"</code>, and so on. TensorBoard identifies such series and collapses them together to reduce clutter (as you can see in <a data-type="xref" href="#tensorboard_series_screenshot">Figure&nbsp;9-6</a>).</p>

<figure class="smallertwentyfive"><div id="tensorboard_series_screenshot" class="figure">
<img src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_0906.png" alt="mlst 0906" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_0906.png" width="281" height="666">
<h6><span class="label">Figure 9-6. </span>Collapsed node series</h6>
</div></figure>

<p>Using name scopes, you can make the graph much clearer. Simply move all the content of the <code>relu()</code> function inside a name scope. <a data-type="xref" href="#tensorboard_simpler_graph_screenshot">Figure&nbsp;9-7</a> shows the resulting graph. Notice that TensorFlow also gives the name scopes unique names by appending <code>_1</code>, <code>_2</code>, and so <a data-type="indexterm" data-primary="ReLU (rectified   linear  units)" data-startref="relu9" id="idm140583002998272"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="modularity" data-startref="tf9m" id="idm140583002997296"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.name_scope()" id="tfnamescopech9"></a>on.</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">def</code> <code class="nf">relu</code><code class="p">(</code><code class="n">X</code><code class="p">):</code>
    <code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">name_scope</code><code class="p">(</code><code class="s2">"relu"</code><code class="p">):</code>
        <code class="p">[</code><code class="o">...</code><code class="p">]</code></pre>

<figure><div id="tensorboard_simpler_graph_screenshot" class="figure">
<img src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_0907.png" alt="mlst 0907" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_0907.png" width="1142" height="347">
<h6><span class="label">Figure 9-7. </span>A clearer graph using name-scoped units</h6>
</div></figure>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Sharing Variables"><div class="sect1" id="idm140583003445184">
<h1>Sharing Variables</h1>

<p>If <a data-type="indexterm" data-primary="TensorFlow" data-secondary="sharing variables" id="tf9sv"></a><a data-type="indexterm" data-primary="variables, sharing" id="vs9"></a>you
 want to share a variable between various components of your graph, one 
simple option is to create it first, then pass it as a parameter to the 
functions that need it. For example, suppose you want to control the 
ReLU threshold (currently hardcoded to 0) using a shared <code>threshold</code> <a data-type="indexterm" data-primary="threshold  variable" id="tv9"></a>variable for all ReLUs. You could just create that variable first, and then pass it to the <code>relu()</code> function:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">def</code> <code class="nf">relu</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">threshold</code><code class="p">):</code>
    <code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">name_scope</code><code class="p">(</code><code class="s2">"relu"</code><code class="p">):</code>
        <code class="p">[</code><code class="o">...</code><code class="p">]</code>
        <code class="k">return</code> <code class="n">tf</code><code class="o">.</code><code class="n">maximum</code><code class="p">(</code><code class="n">z</code><code class="p">,</code> <code class="n">threshold</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"max"</code><code class="p">)</code>

<code class="n">threshold</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">Variable</code><code class="p">(</code><code class="mf">0.0</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"threshold"</code><code class="p">)</code>
<code class="n">X</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">placeholder</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">,</code> <code class="n">shape</code><code class="o">=</code><code class="p">(</code><code class="bp">None</code><code class="p">,</code> <code class="n">n_features</code><code class="p">),</code> <code class="n">name</code><code class="o">=</code><code class="s2">"X"</code><code class="p">)</code>
<code class="n">relus</code> <code class="o">=</code> <code class="p">[</code><code class="n">relu</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">threshold</code><code class="p">)</code> <code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="mi">5</code><code class="p">)]</code>
<code class="n">output</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">add_n</code><code class="p">(</code><code class="n">relus</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"output"</code><code class="p">)</code></pre>

<p>This works fine: <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.maximum()" id="tfmaxch9"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.add_n()" data-startref="tfaddnch9" id="idm140583003270288"></a>now you can control the threshold for all ReLUs using the <code>threshold</code>
 variable. However, if there are many shared parameters such as this 
one, it will be painful to have to pass them around as parameters all 
the time. Many people create a Python dictionary containing all the 
variables in their model, and pass it around to every function. Others 
create a class for each module (e.g., a <code>ReLU</code> class using 
class variables to handle the shared parameter). Yet another option is 
to set the shared variable as an attribute of the <code>relu()</code> function upon the first call, like so:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">def</code> <code class="nf">relu</code><code class="p">(</code><code class="n">X</code><code class="p">):</code>
    <code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">name_scope</code><code class="p">(</code><code class="s2">"relu"</code><code class="p">):</code>
        <code class="k">if</code> <code class="ow">not</code> <code class="nb">hasattr</code><code class="p">(</code><code class="n">relu</code><code class="p">,</code> <code class="s2">"threshold"</code><code class="p">):</code>
            <code class="n">relu</code><code class="o">.</code><code class="n">threshold</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">Variable</code><code class="p">(</code><code class="mf">0.0</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"threshold"</code><code class="p">)</code>
        <code class="p">[</code><code class="o">...</code><code class="p">]</code>
        <code class="k">return</code> <code class="n">tf</code><code class="o">.</code><code class="n">maximum</code><code class="p">(</code><code class="n">z</code><code class="p">,</code> <code class="n">relu</code><code class="o">.</code><code class="n">threshold</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"max"</code><code class="p">)</code></pre>

<p>TensorFlow <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.name_scope()" data-startref="tfnamescopech9" id="idm140583003265808"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.variable_scope()" id="tfcvarscopecha9"></a> <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.get_variable()" id="tfgetvarch9"></a>offers another option, which may lead to slightly cleaner and more modular code than the previous solutions.<sup><a data-type="noteref" id="idm140583002712640-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch09.html#idm140583002712640" class="totri-footnote">5</a></sup>
 This solution is a bit tricky to understand at first, but since it is 
used a lot in TensorFlow it is worth going into a bit of detail. The 
idea is to use the <code>get_variable()</code> <a data-type="indexterm" data-primary="get_variable()" id="gv9"></a>function
 to create the shared variable if it does not exist yet, or reuse it if 
it already exists. The desired behavior (creating or reusing) is 
controlled by an attribute of the <a data-type="indexterm" data-primary="variable_scope()" id="varscopechap9"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.constant_initializer()" id="tfconstantinitch9"></a>current <code>variable_scope()</code>. For example, the following code will create a variable named <code>"relu/threshold"</code> (as a scalar, since <code>shape=()</code>, and using <code>0.0</code> as the initial value):</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">variable_scope</code><code class="p">(</code><code class="s2">"relu"</code><code class="p">):</code>
    <code class="n">threshold</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">get_variable</code><code class="p">(</code><code class="s2">"threshold"</code><code class="p">,</code> <code class="n">shape</code><code class="o">=</code><code class="p">(),</code>
                                <code class="n">initializer</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">constant_initializer</code><code class="p">(</code><code class="mf">0.0</code><code class="p">))</code></pre>

<p>Note that if the variable has already been created by an earlier call to <code>get_variable()</code>,
 this code will raise an exception. This behavior prevents reusing 
variables by mistake. If you want to reuse a variable, you need to 
explicitly say so by setting the variable scope’s <code>reuse</code> attribute to <code>True</code> (in which case you don’t have to specify the shape or the initializer):</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">variable_scope</code><code class="p">(</code><code class="s2">"relu"</code><code class="p">,</code> <code class="n">reuse</code><code class="o">=</code><code class="bp">True</code><code class="p">):</code>
    <code class="n">threshold</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">get_variable</code><code class="p">(</code><code class="s2">"threshold"</code><code class="p">)</code></pre>

<p>This code will fetch the existing <code>"relu/threshold"</code> variable, or raise an exception if it does not exist or if it was not created using <code>get_variable()</code>. Alternatively, you can set the <code>reuse</code> attribute to <code>True</code> inside the block by calling the <a data-type="indexterm" data-primary="reuse_variables()" id="idm140583002860176"></a>scope’s <code>reuse_variables()</code> method:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">variable_scope</code><code class="p">(</code><code class="s2">"relu"</code><code class="p">)</code> <code class="k">as</code> <code class="n">scope</code><code class="p">:</code>
    <code class="n">scope</code><code class="o">.</code><code class="n">reuse_variables</code><code class="p">()</code>
    <code class="n">threshold</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">get_variable</code><code class="p">(</code><code class="s2">"threshold"</code><code class="p">)</code></pre>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>Once <code>reuse</code> is set to <code>True</code>, it cannot be set back to <code>False</code> within the block. Moreover, if you define other variable scopes inside this one, they will automatically inherit <code>reuse=True</code>. Lastly, only variables created by <code>get_variable()</code> can be reused this way.</p>
</div>

<p>Now you have all the pieces you need to make the <code>relu()</code> function access the <code>threshold</code> variable without having to pass it as a parameter:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">def</code> <code class="nf">relu</code><code class="p">(</code><code class="n">X</code><code class="p">):</code>
    <code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">variable_scope</code><code class="p">(</code><code class="s2">"relu"</code><code class="p">,</code> <code class="n">reuse</code><code class="o">=</code><code class="bp">True</code><code class="p">):</code>
        <code class="n">threshold</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">get_variable</code><code class="p">(</code><code class="s2">"threshold"</code><code class="p">)</code>  <code class="c1"># reuse existing variable</code>
        <code class="p">[</code><code class="o">...</code><code class="p">]</code>
        <code class="k">return</code> <code class="n">tf</code><code class="o">.</code><code class="n">maximum</code><code class="p">(</code><code class="n">z</code><code class="p">,</code> <code class="n">threshold</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"max"</code><code class="p">)</code>

<code class="n">X</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">placeholder</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">,</code> <code class="n">shape</code><code class="o">=</code><code class="p">(</code><code class="bp">None</code><code class="p">,</code> <code class="n">n_features</code><code class="p">),</code> <code class="n">name</code><code class="o">=</code><code class="s2">"X"</code><code class="p">)</code>
<code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">variable_scope</code><code class="p">(</code><code class="s2">"relu"</code><code class="p">):</code>  <code class="c1"># create the variable</code>
    <code class="n">threshold</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">get_variable</code><code class="p">(</code><code class="s2">"threshold"</code><code class="p">,</code> <code class="n">shape</code><code class="o">=</code><code class="p">(),</code>
                                <code class="n">initializer</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">constant_initializer</code><code class="p">(</code><code class="mf">0.0</code><code class="p">))</code>
<code class="n">relus</code> <code class="o">=</code> <code class="p">[</code><code class="n">relu</code><code class="p">(</code><code class="n">X</code><code class="p">)</code> <code class="k">for</code> <code class="n">relu_index</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="mi">5</code><code class="p">)]</code>
<code class="n">output</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">add_n</code><code class="p">(</code><code class="n">relus</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"output"</code><code class="p">)</code></pre>

<p>This <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.add_n()" id="tfaddnch9part2"></a>code first defines the <code>relu()</code> function, then creates the <code>relu/threshold</code> variable (as a scalar that will later be initialized to <code>0.0</code>) and builds five ReLUs by calling the <code>relu()</code> function. The <code>relu()</code> function reuses the <code>relu/threshold</code> variable, and creates the other ReLU nodes.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Variables created using <code>get_variable()</code> are always named using the name of <a data-type="indexterm" data-primary="variable_scope()" data-startref="varscopechap9" id="idm140583002505568"></a>their <code>variable_scope</code> as a prefix (e.g., <code>"relu/threshold"</code>), but for all other nodes (including variables created with <code>tf.Variable()</code>)
 the variable scope acts like a new name scope. In particular, if a name
 scope with an identical name was already created, then a suffix is 
added to make the name unique. For example, all nodes created in the 
preceding code (except the <code>threshold</code> variable) have a name <a data-type="indexterm" data-primary="get_variable()" data-startref="gv9" id="idm140583002502624"></a>prefixed with <code>"relu_1/"</code> to <code>"relu_5/"</code>, as shown in <a data-type="xref" href="#tensorboard_shared_variable_screenshot">Figure&nbsp;9-8</a>.</p>
</div>

<figure><div id="tensorboard_shared_variable_screenshot" class="figure">
<img src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_0908.png" alt="mlst 0908" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_0908.png" width="1440" height="348">
<h6><span class="label">Figure 9-8. </span>Five ReLUs sharing the threshold variable</h6>
</div></figure>

<p>It is somewhat unfortunate that the <code>threshold</code> variable must be defined outside the <code>relu()</code> function, where all the rest of the ReLU code resides. To fix this, the following code creates the <code>threshold</code> variable within the <code>relu()</code> function upon the first call, then reuses it in subsequent calls. Now the <code>relu()</code> function does not have to worry about name scopes or variable sharing: it just calls <code>get_variable()</code>, which will create or reuse the <code>threshold</code> variable (it does not need to know which is the case). The rest of the code calls <code>relu()</code> five times, making sure to set <code>reuse=False</code> on the first call, and <code>reuse=True</code> for the other <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.get_variable()" data-startref="tfgetvarch9" id="idm140583002492864"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.constant_initializer()" data-startref="tfconstantinitch9" id="idm140583002491584"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.maximum()" data-startref="tfmaxch9" id="idm140583002490304"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.variable_scope()" data-startref="tfcvarscopecha9" id="idm140583002489088"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.add_n()" data-startref="tfaddnch9part2" id="idm140583002487872"></a>calls.</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">def</code> <code class="nf">relu</code><code class="p">(</code><code class="n">X</code><code class="p">):</code>
    <code class="n">threshold</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">get_variable</code><code class="p">(</code><code class="s2">"threshold"</code><code class="p">,</code> <code class="n">shape</code><code class="o">=</code><code class="p">(),</code>
                                <code class="n">initializer</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">constant_initializer</code><code class="p">(</code><code class="mf">0.0</code><code class="p">))</code>
    <code class="p">[</code><code class="o">...</code><code class="p">]</code>
    <code class="k">return</code> <code class="n">tf</code><code class="o">.</code><code class="n">maximum</code><code class="p">(</code><code class="n">z</code><code class="p">,</code> <code class="n">threshold</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"max"</code><code class="p">)</code>

<code class="n">X</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">placeholder</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">,</code> <code class="n">shape</code><code class="o">=</code><code class="p">(</code><code class="bp">None</code><code class="p">,</code> <code class="n">n_features</code><code class="p">),</code> <code class="n">name</code><code class="o">=</code><code class="s2">"X"</code><code class="p">)</code>
<code class="n">relus</code> <code class="o">=</code> <code class="p">[]</code>
<code class="k">for</code> <code class="n">relu_index</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="mi">5</code><code class="p">):</code>
    <code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">variable_scope</code><code class="p">(</code><code class="s2">"relu"</code><code class="p">,</code> <code class="n">reuse</code><code class="o">=</code><code class="p">(</code><code class="n">relu_index</code> <code class="o">&gt;=</code> <code class="mi">1</code><code class="p">))</code> <code class="k">as</code> <code class="n">scope</code><code class="p">:</code>
        <code class="n">relus</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">relu</code><code class="p">(</code><code class="n">X</code><code class="p">))</code>
<code class="n">output</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">add_n</code><code class="p">(</code><code class="n">relus</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"output"</code><code class="p">)</code></pre>

<p>The resulting graph is slightly different than before, since the shared variable lives within the first ReLU (see <a data-type="xref" href="#tensorboard_shared_variable_v2_screenshot">Figure&nbsp;9-9</a>).</p>

<figure><div id="tensorboard_shared_variable_v2_screenshot" class="figure">
<img src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_0909.png" alt="mlst 0909" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_0909.png" width="1440" height="266">
<h6><span class="label">Figure 9-9. </span>Five ReLUs sharing the threshold variable</h6>
</div></figure>

<p>This concludes this introduction to TensorFlow. We will discuss more 
advanced topics as we go through the following chapters, in particular 
many operations related to deep neural networks, convolutional neural 
networks, and recurrent neural networks as well as how to scale up with 
TensorFlow using multithreading, queues, multiple GPUs, and <a data-type="indexterm" data-primary="TensorFlow" data-secondary="sharing variables" data-startref="tf9sv" id="idm140583002411376"></a><a data-type="indexterm" data-primary="variables, sharing" data-startref="vs9" id="idm140583002410128"></a><a data-type="indexterm" data-primary="threshold  variable" data-startref="tv9" id="idm140583002409184"></a>multiple servers.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Exercises"><div class="sect1" id="idm140583002975360">
<h1>Exercises</h1>
<ol>
<li>
<p>What are the main benefits of creating a computation graph rather 
than directly executing the computations? What are the main drawbacks?</p>
</li>
<li>
<p>Is the statement <code>a_val</code> <code>=</code> <code>a.eval(session=sess)</code> equivalent to <code>a_val</code> <code>=</code> <code>sess.run(a)</code>?</p>
</li>
<li>
<p>Is the statement <code>a_val, b_val</code> <code>=</code> <code>a.eval(session=sess), b.eval(session=sess)</code> equivalent to <code>a_val, b_val</code> <code>=</code> <code>sess.run([a, b])</code>?</p>
</li>
<li>
<p>Can you run two graphs in the same session?</p>
</li>
<li>
<p>If you create a graph <code>g</code> containing a variable <code>w</code>, then start two threads and open a session in each thread, both using the same graph <code>g</code>, will each session have its own copy of the variable <code>w</code> or will it be shared?</p>
</li>
<li>
<p>When is a variable initialized? When is it destroyed?</p>
</li>
<li>
<p>What is the difference between a placeholder and a variable?</p>
</li>
<li>
<p>What happens when you run the graph to evaluate an operation that 
depends on a placeholder but you don’t feed its value? What happens if 
the operation does not depend on the placeholder?</p>
</li>
<li>
<p>When you run a graph, can you feed the output value of any operation, or just the value of placeholders?</p>
</li>
<li>
<p>How can you set a variable to any value you want (during the execution phase)?</p>
</li>
<li>
<p>How many times does reverse-mode autodiff need to traverse the graph 
in order to compute the gradients of the cost function with regards to 
10 variables? What about forward-mode autodiff? And symbolic 
differentiation?</p>
</li>
<li>
<p>Implement Logistic Regression with Mini-batch Gradient Descent using 
TensorFlow. Train it and evaluate it on the moons dataset (introduced in
 <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch05.html#svm_chapter">Chapter&nbsp;5</a>). Try adding all the bells and whistles:</p>

<ul>
<li>
<p>Define the graph within a <code>logistic_regression()</code> function that can be reused easily.</p>
</li>
<li>
<p>Save checkpoints using a <code>Saver</code> at regular intervals during training, and save the final model at the end of training.</p>
</li>
<li>
<p>Restore the last checkpoint upon startup if training was interrupted.</p>
</li>
<li>
<p>Define the graph using name scopes so the graph looks good in TensorBoard.</p>
</li>
<li>
<p>Add summaries to visualize the learning curves in TensorBoard.</p>
</li>
<li>
<p>Try tweaking some hyperparameters such as the learning rate or the mini-batch size and look at the shape of the learning curve.</p>
</li>
</ul>
</li>

</ol>

<p>Solutions to these exercises are available <a data-type="indexterm" data-primary="TensorFlow" data-startref="t9" id="idm140583002302320"></a>in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app01.html#solutions_appendix">Appendix&nbsp;A</a>.</p>
</div></section>







<div data-type="footnotes"><p data-type="footnote" id="idm140583006206368"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch09.html#idm140583006206368-marker" class="totri-footnote">1</a></sup> TensorFlow is not limited to neural networks or even Machine Learning; you could run quantum physics simulations if you wanted.</p><p data-type="footnote" id="idm140583006201856"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch09.html#idm140583006201856-marker" class="totri-footnote">2</a></sup> Not to be confused with the TFLearn library, which is an independent project.</p><p data-type="footnote" id="idm140583006120656"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch09.html#idm140583006120656-marker" class="totri-footnote">3</a></sup> In distributed TensorFlow, variable values are stored on the servers instead of the session, as we will see in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch12.html#distributed_chapter">Chapter&nbsp;12</a>.</p><p data-type="footnote" id="idm140583005420832"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch09.html#idm140583005420832-marker" class="totri-footnote">4</a></sup> Note that <code>housing.target</code> is a 1D array, but we need to reshape it to a column vector to compute <code>theta</code>. Recall that NumPy’s <code>reshape()</code>
 function accepts –1 (meaning “unspecified”) for one of the dimensions: 
that dimension will be computed based on the array’s length and the 
remaining dimensions.</p><p data-type="footnote" id="idm140583002712640"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch09.html#idm140583002712640-marker" class="totri-footnote">5</a></sup> Creating a <code>ReLU</code> class is arguably the cleanest option, but it is rather heavyweight.</p></div></div></section><div class="annotator-outer annotator-viewer viewer annotator-hide">
  <ul class="annotator-widget annotator-listing"></ul>
</div><div class="annotator-modal-wrapper annotator-editor-modal annotator-editor annotator-hide">
	<div class="annotator-outer editor">
		<h2 class="title">Highlight</h2>
		<form class="annotator-widget">
			<ul class="annotator-listing">
			<li class="annotator-item"><textarea id="annotator-field-9" placeholder="Add a note using markdown (optional)" class="js-editor" maxlength="750"></textarea></li></ul>
			<div class="annotator-controls">
				<a class="link-to-markdown" href="https://daringfireball.net/projects/markdown/basics" target="_blank">?</a>
				<ul>
					<li class="delete annotator-hide"><a href="#delete" class="annotator-delete-note button positive">Delete Note</a></li>
					<li class="save"><a href="#save" class="annotator-save annotator-focus button positive">Save Note</a></li>
					<li class="cancel"><a href="#cancel" class="annotator-cancel button">Cancel</a></li>
				</ul>
			</div>
		</form>
	</div>
</div><div class="annotator-modal-wrapper annotator-delete-confirm-modal" style="display: none;">
  <div class="annotator-outer">
    <h2 class="title">Highlight</h2>
      <a class="js-close-delete-confirm annotator-cancel close" href="#close">Close</a>
      <div class="annotator-widget">
         <div class="delete-confirm">
            Are you sure you want to permanently delete this note?
         </div>
         <div class="annotator-controls">
            <a href="#cancel" class="annotator-cancel button js-cancel-delete-confirm">No, I changed my mind</a>
            <a href="#delete" class="annotator-delete button positive js-delete-confirm">Yes, delete it</a>
         </div>
       </div>
   </div>
</div><div class="annotator-adder" style="display: none;">
	<ul class="adders ">
		
		<li class="copy"><a href="#">Copy</a></li>
		
		<li class="add-highlight"><a href="#">Add Highlight</a></li>
		<li class="add-note"><a href="#">
			
				Add Note
			
		</a></li>
		
	</ul>
</div></div></div>



  <div class="t-sbo-prev sbo-prev sbo-nav-bottom">
  
    
      
        <a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/part02.html" class="prev nav-link">
      
          <span aria-hidden="true" class="pagination-label t-prev-label">Prev</span>
          <span class="visuallyhidden">Previous Chapter</span>
          <div class="pagination-title t-prev-title">II. Neural Networks and Deep Learning</div>
        </a>
    
  
  </div>

  <div class="t-sbo-next sbo-next sbo-nav-bottom">
  
    
      
        <a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html" class="next nav-link">
      
          <span aria-hidden="true" class="pagination-label t-next-label">Next</span>
          <span class="visuallyhidden">Next Chapter</span>
          <div class="pagination-title t-next-title">10. Introduction to Artificial Neural Networks</div>
        </a>
    
  
  </div>

</section>
  </div>
<section class="sbo-saved-archives"></section>



          
          
  




    
    
      <div id="js-subscribe-nag" class="subscribe-nag clearfix trial-panel t-subscribe-nag collapsed slideUp">
        
        
          
          
            <p class="usage-data">Find answers on the fly, or master something new. Subscribe today. <a href="https://www.safaribooksonline.com/subscribe/" class="ga-active-trial-subscribe-nag">See pricing options.</a></p>
          

          
        
        

      </div>

    
    



        
      </div>
      




  <footer class="pagefoot t-pagefoot" style="padding-bottom: 69px;">
    <a href="#" class="icon-up" style="display: none;"><div class="visuallyhidden">Back to top</div></a>
    <ul class="js-footer-nav">
      
        <li><a class="t-recommendations-footer" href="https://www.safaribooksonline.com/r/">Recommended</a></li>
      
      <li>
      
      <a class="t-queue-footer" href="https://www.safaribooksonline.com/s/">Queue</a>
      
      </li>
      
        <li><a class="t-recent-footer" href="https://www.safaribooksonline.com/history/">History</a></li>
        <li><a class="t-topics-footer" href="https://www.safaribooksonline.com/topics?q=*&amp;limit=21">Topics</a></li>
      
      
        <li><a class="t-tutorials-footer" href="https://www.safaribooksonline.com/tutorials/">Tutorials</a></li>
      
      <li><a class="t-settings-footer js-settings" href="https://www.safaribooksonline.com/u/">Settings</a></li>
      <li class="full-support"><a href="https://www.safaribooksonline.com/public/support">Support</a></li>
      <li><a href="https://www.safaribooksonline.com/apps/">Get the App</a></li>
      <li><a href="https://www.safaribooksonline.com/accounts/logout/">Sign Out</a></li>
    </ul>
    <span class="copyright">© 2017 <a href="https://www.safaribooksonline.com/" target="_blank">Safari</a>.</span>
    <a href="https://www.safaribooksonline.com/terms/">Terms of Service</a> /
    <a href="https://www.safaribooksonline.com/privacy/">Privacy Policy</a>
  </footer>

<script type="text/javascript">window.NREUM||(NREUM={});NREUM.info={"agent":"","errorBeacon":"bam.nr-data.net","licenseKey":"510f1a6865","queueTime":0,"beacon":"bam.nr-data.net","transactionName":"YgdaZ0NSW0cEB0RdWltNfkZfUEFdCgofXFBHDVYdR1pQQxZeRl1QQj1aWkU=","applicationID":"3275661","applicationTime":811}</script>


    

    <script src="7.%20Ensemble%20Learning%20and%20Random%20Forests%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/a_005.js" charset="utf-8"></script><script type="text/javascript" id="">!function(b,e,f,g,a,c,d){b.fbq||(a=b.fbq=function(){a.callMethod?a.callMethod.apply(a,arguments):a.queue.push(arguments)},b._fbq||(b._fbq=a),a.push=a,a.loaded=!0,a.version="2.0",a.queue=[],c=e.createElement(f),c.async=!0,c.src=g,d=e.getElementsByTagName(f)[0],d.parentNode.insertBefore(c,d))}(window,document,"script","https://connect.facebook.net/en_US/fbevents.js");fbq("init","1732687426968531");fbq("track","PageView");</script>
<noscript><img height="1" width="1" style="display:none" src="https://www.facebook.com/tr?id=1732687426968531&amp;ev=PageView&amp;noscript=1"></noscript><div style="width:0px; height:0px; display:none; visibility:hidden;" id="batBeacon0.31551976328735265"><img style="width:0px; height:0px; display:none; visibility:hidden;" id="batBeacon0.7746668699298912" alt="" src="7.%20Ensemble%20Learning%20and%20Random%20Forests%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/0.txt" width="0" height="0"></div>
    <script src="7.%20Ensemble%20Learning%20and%20Random%20Forests%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/a_004.js" charset="utf-8"></script>
  

<div class="annotator-notice"></div><div class="font-flyout" style="top: 200px; left: 1257px;"><div class="font-controls-panel">
	<div class="nightmodes">
		<ul>
			<li class="day"><a href="#" id="day-mode" title="Day Mode">
				<i class="fa fa-sun-o"></i>
				<span>Day Mode</span></a></li>
			<li class="cloudy"><a href="#" id="cloudy-mode" title="Cloudy Mode">
				<i class="fa fa-cloud"></i>
				<span>Cloud Mode</span>
			</a></li>
			<li class="night"><a href="#" id="night-mode" title="Night Mode">
				<i class="fa fa-moon-o"></i>
				<span>Night Mode</span>
			</a></li>
		</ul>
	</div>

	<div class="font-resizer resizer">
		<div class="draggable-containment-wrapper">
			<i class="fa fa-font left"></i>
			<span class="filler" style="width: 50%;"></span>
			<div id="js-font-size-draggable" class="draggable ui-widget-content ui-draggable ui-draggable-handle" style="position: relative; left: 80px;"></div>
			<i class="fa fa-font right"></i>
		</div>
	</div>

	<div class="column-resizer resizer">
		<div class="draggable-containment-wrapper">
			<i class="fa fa-compress left"></i>
			<span class="filler" style="width: 50%;"></span>
			<div id="js-column-size-draggable" class="draggable ui-widget-content ui-draggable ui-draggable-handle" style="position: relative; left: 80px;"></div>
			<i class="fa fa-expand right"></i>
		</div>
	</div>

	<a id="reset" class="button" href="#">Reset</a>
</div>
</div><script src="7.%20Ensemble%20Learning%20and%20Random%20Forests%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/a.js" type="text/javascript"></script><script src="7.%20Ensemble%20Learning%20and%20Random%20Forests%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/a" type="text/javascript"></script><img src="7.%20Ensemble%20Learning%20and%20Random%20Forests%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/seg.gif" alt="" style="display: none;" width="1" height="1" border="0"></body></html>