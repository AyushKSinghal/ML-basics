<!--[if IE]><![endif]-->
<!DOCTYPE html>
<!--[if IE 8]><html class="no-js ie8 oldie" lang="en" prefix="og: http://ogp.me/ns/# og:book: http://ogp.me/ns/book# og:video: http://ogp.me/ns/video#"

    
        itemscope itemtype="http://schema.org/Book http://schema.org/ItemPage"" data-login-url="/accounts/login/"
data-offline-url="/"
data-url="/library/view/hands-on-machine-learning/9781491962282/ch03.html"
data-csrf-cookie="csrfsafari"
data-highlight-privacy=""


  data-user-id="2309833"
  data-user-uuid="2d2acfb7-1cff-4dc7-9037-8ffbac19b02e"
  data-username="ayushksinghal"
  data-account-type="Trial"
  
  data-activated-trial-date="12/02/2017"


  data-archive="9781491962282"
  data-publishers="O&#39;Reilly Media, Inc."



  data-htmlfile-name="ch03.html"
  data-epub-title="Hands-On Machine Learning with Scikit-Learn and TensorFlow" data-debug=0 data-testing=0><![endif]-->
<!--[if gt IE 8]><!-->
<html class="js flexbox flexboxlegacy no-touch no-websqldatabase indexeddb history csscolumns csstransforms localstorage sessionstorage applicationcache svg inlinesvg no-zoom gr__safaribooksonline_com" prefix="og: http://ogp.me/ns/# og:book: http://ogp.me/ns/book# og:video: http://ogp.me/ns/video#" itemscope="" itemtype="http://schema.org/Book http://schema.org/ItemPage" "="" data-login-url="/accounts/login/" data-offline-url="/" data-url="/library/view/hands-on-machine-learning/9781491962282/ch03.html" data-csrf-cookie="csrfsafari" data-highlight-privacy="" data-user-id="2309833" data-user-uuid="2d2acfb7-1cff-4dc7-9037-8ffbac19b02e" data-username="ayushksinghal" data-account-type="Trial" data-activated-trial-date="12/02/2017" data-archive="9781491962282" data-publishers="O'Reilly Media, Inc." data-htmlfile-name="ch03.html" data-epub-title="Hands-On Machine Learning with Scikit-Learn and TensorFlow" data-debug="0" data-testing="0" style="" data-ember-extension="1" lang="en"><!--<![endif]--><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="author" content="Safari Books Online"><meta name="format-detection" content="telephone=no"><meta http-equiv="cleartype" content="on"><meta name="HandheldFriendly" content="True"><meta name="MobileOptimized" content="320"><meta name="apple-itunes-app" content="app-id=881697395, app-argument=safaridetail://9781491962282"><meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, maximum-scale=1.0"><meta property="twitter:account_id" content="4503599627559754"><script type="text/javascript" src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/510f1a6865.js"></script><script src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/nr-spa-1044.js"></script><script type="text/javascript" async="" src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/linkid.js"></script><script src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/1732687426968531.js" async=""></script><script async="" src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/fbevents.js"></script><script type="text/javascript" async="" src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/bat.js"></script><script type="text/javascript" async="" src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/conversion_async.js"></script><script type="text/javascript" async="" src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/insight.js"></script><script type="text/javascript" async="" src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/conversion_async.js"></script><script async="" src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/gtm.js"></script><script async="" src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/analytics.js"></script><script type="text/javascript">(window.NREUM||(NREUM={})).loader_config={xpid:"VQQDUVVVGwACU1RUAQA="};window.NREUM||(NREUM={}),__nr_require=function(t,e,n){function r(n){if(!e[n]){var o=e[n]={exports:{}};t[n][0].call(o.exports,function(e){var o=t[n][1][e];return r(o||e)},o,o.exports)}return e[n].exports}if("function"==typeof __nr_require)return __nr_require;for(var o=0;o<n.length;o++)r(n[o]);return r}({1:[function(t,e,n){function r(t){try{c.console&&console.log(t)}catch(e){}}var o,i=t("ee"),a=t(19),c={};try{o=localStorage.getItem("__nr_flags").split(","),console&&"function"==typeof console.log&&(c.console=!0,o.indexOf("dev")!==-1&&(c.dev=!0),o.indexOf("nr_dev")!==-1&&(c.nrDev=!0))}catch(s){}c.nrDev&&i.on("internal-error",function(t){r(t.stack)}),c.dev&&i.on("fn-err",function(t,e,n){r(n.stack)}),c.dev&&(r("NR AGENT IN DEVELOPMENT MODE"),r("flags: "+a(c,function(t,e){return t}).join(", ")))},{}],2:[function(t,e,n){function r(t,e,n,r,o){try{d?d-=1:i("err",[o||new UncaughtException(t,e,n)])}catch(c){try{i("ierr",[c,s.now(),!0])}catch(u){}}return"function"==typeof f&&f.apply(this,a(arguments))}function UncaughtException(t,e,n){this.message=t||"Uncaught error with no additional information",this.sourceURL=e,this.line=n}function o(t){i("err",[t,s.now()])}var i=t("handle"),a=t(20),c=t("ee"),s=t("loader"),f=window.onerror,u=!1,d=0;s.features.err=!0,t(1),window.onerror=r;try{throw new Error}catch(p){"stack"in p&&(t(12),t(11),"addEventListener"in window&&t(6),s.xhrWrappable&&t(13),u=!0)}c.on("fn-start",function(t,e,n){u&&(d+=1)}),c.on("fn-err",function(t,e,n){u&&(this.thrown=!0,o(n))}),c.on("fn-end",function(){u&&!this.thrown&&d>0&&(d-=1)}),c.on("internal-error",function(t){i("ierr",[t,s.now(),!0])})},{}],3:[function(t,e,n){t("loader").features.ins=!0},{}],4:[function(t,e,n){function r(){C++,M=y.hash,this[u]=b.now()}function o(){C--,y.hash!==M&&i(0,!0);var t=b.now();this[l]=~~this[l]+t-this[u],this[d]=t}function i(t,e){E.emit("newURL",[""+y,e])}function a(t,e){t.on(e,function(){this[e]=b.now()})}var c="-start",s="-end",f="-body",u="fn"+c,d="fn"+s,p="cb"+c,h="cb"+s,l="jsTime",m="fetch",v="addEventListener",w=window,y=w.location,b=t("loader");if(w[v]&&b.xhrWrappable){var g=t(9),x=t(10),E=t(8),O=t(6),R=t(12),P=t(7),T=t(13),S=t("ee"),N=S.get("tracer");t(14),b.features.spa=!0;var M,j=w[v],C=0;S.on(u,r),S.on(p,r),S.on(d,o),S.on(h,o),S.buffer([u,d,"xhr-done","xhr-resolved"]),O.buffer([u]),R.buffer(["setTimeout"+s,"clearTimeout"+c,u]),T.buffer([u,"new-xhr","send-xhr"+c]),P.buffer([m+c,m+"-done",m+f+c,m+f+s]),E.buffer(["newURL"]),g.buffer([u]),x.buffer(["propagate",p,h,"executor-err","resolve"+c]),N.buffer([u,"no-"+u]),a(T,"send-xhr"+c),a(S,"xhr-resolved"),a(S,"xhr-done"),a(P,m+c),a(P,m+"-done"),E.on("pushState-end",i),E.on("replaceState-end",i),j("hashchange",i,!0),j("load",i,!0),j("popstate",function(){i(0,C>1)},!0)}},{}],5:[function(t,e,n){function r(t){}if(window.performance&&window.performance.timing&&window.performance.getEntriesByType){var o=t("ee"),i=t("handle"),a=t(12),c=t(11),s="learResourceTimings",f="addEventListener",u="resourcetimingbufferfull",d="bstResource",p="resource",h="-start",l="-end",m="fn"+h,v="fn"+l,w="bstTimer",y="pushState",b=t("loader");b.features.stn=!0,t(8);var g=NREUM.o.EV;o.on(m,function(t,e){var n=t[0];n instanceof g&&(this.bstStart=b.now())}),o.on(v,function(t,e){var n=t[0];n instanceof g&&i("bst",[n,e,this.bstStart,b.now()])}),a.on(m,function(t,e,n){this.bstStart=b.now(),this.bstType=n}),a.on(v,function(t,e){i(w,[e,this.bstStart,b.now(),this.bstType])}),c.on(m,function(){this.bstStart=b.now()}),c.on(v,function(t,e){i(w,[e,this.bstStart,b.now(),"requestAnimationFrame"])}),o.on(y+h,function(t){this.time=b.now(),this.startPath=location.pathname+location.hash}),o.on(y+l,function(t){i("bstHist",[location.pathname+location.hash,this.startPath,this.time])}),f in window.performance&&(window.performance["c"+s]?window.performance[f](u,function(t){i(d,[window.performance.getEntriesByType(p)]),window.performance["c"+s]()},!1):window.performance[f]("webkit"+u,function(t){i(d,[window.performance.getEntriesByType(p)]),window.performance["webkitC"+s]()},!1)),document[f]("scroll",r,{passive:!0}),document[f]("keypress",r,!1),document[f]("click",r,!1)}},{}],6:[function(t,e,n){function r(t){for(var e=t;e&&!e.hasOwnProperty(u);)e=Object.getPrototypeOf(e);e&&o(e)}function o(t){c.inPlace(t,[u,d],"-",i)}function i(t,e){return t[1]}var a=t("ee").get("events"),c=t(22)(a,!0),s=t("gos"),f=XMLHttpRequest,u="addEventListener",d="removeEventListener";e.exports=a,"getPrototypeOf"in Object?(r(document),r(window),r(f.prototype)):f.prototype.hasOwnProperty(u)&&(o(window),o(f.prototype)),a.on(u+"-start",function(t,e){var n=t[1],r=s(n,"nr@wrapped",function(){function t(){if("function"==typeof n.handleEvent)return n.handleEvent.apply(n,arguments)}var e={object:t,"function":n}[typeof n];return e?c(e,"fn-",null,e.name||"anonymous"):n});this.wrapped=t[1]=r}),a.on(d+"-start",function(t){t[1]=this.wrapped||t[1]})},{}],7:[function(t,e,n){function r(t,e,n){var r=t[e];"function"==typeof r&&(t[e]=function(){var t=r.apply(this,arguments);return o.emit(n+"start",arguments,t),t.then(function(e){return o.emit(n+"end",[null,e],t),e},function(e){throw o.emit(n+"end",[e],t),e})})}var o=t("ee").get("fetch"),i=t(19);e.exports=o;var a=window,c="fetch-",s=c+"body-",f=["arrayBuffer","blob","json","text","formData"],u=a.Request,d=a.Response,p=a.fetch,h="prototype";u&&d&&p&&(i(f,function(t,e){r(u[h],e,s),r(d[h],e,s)}),r(a,"fetch",c),o.on(c+"end",function(t,e){var n=this;e?e.clone().arrayBuffer().then(function(t){n.rxSize=t.byteLength,o.emit(c+"done",[null,e],n)}):o.emit(c+"done",[t],n)}))},{}],8:[function(t,e,n){var r=t("ee").get("history"),o=t(22)(r);e.exports=r,o.inPlace(window.history,["pushState","replaceState"],"-")},{}],9:[function(t,e,n){var r=t("ee").get("mutation"),o=t(22)(r),i=NREUM.o.MO;e.exports=r,i&&(window.MutationObserver=function(t){return this instanceof i?new i(o(t,"fn-")):i.apply(this,arguments)},MutationObserver.prototype=i.prototype)},{}],10:[function(t,e,n){function r(t){var e=a.context(),n=c(t,"executor-",e),r=new f(n);return a.context(r).getCtx=function(){return e},a.emit("new-promise",[r,e],e),r}function o(t,e){return e}var i=t(22),a=t("ee").get("promise"),c=i(a),s=t(19),f=NREUM.o.PR;e.exports=a,f&&(window.Promise=r,["all","race"].forEach(function(t){var e=f[t];f[t]=function(n){function r(t){return function(){a.emit("propagate",[null,!o],i),o=o||!t}}var o=!1;s(n,function(e,n){Promise.resolve(n).then(r("all"===t),r(!1))});var i=e.apply(f,arguments),c=f.resolve(i);return c}}),["resolve","reject"].forEach(function(t){var e=f[t];f[t]=function(t){var n=e.apply(f,arguments);return t!==n&&a.emit("propagate",[t,!0],n),n}}),f.prototype["catch"]=function(t){return this.then(null,t)},f.prototype=Object.create(f.prototype,{constructor:{value:r}}),s(Object.getOwnPropertyNames(f),function(t,e){try{r[e]=f[e]}catch(n){}}),a.on("executor-start",function(t){t[0]=c(t[0],"resolve-",this),t[1]=c(t[1],"resolve-",this)}),a.on("executor-err",function(t,e,n){t[1](n)}),c.inPlace(f.prototype,["then"],"then-",o),a.on("then-start",function(t,e){this.promise=e,t[0]=c(t[0],"cb-",this),t[1]=c(t[1],"cb-",this)}),a.on("then-end",function(t,e,n){this.nextPromise=n;var r=this.promise;a.emit("propagate",[r,!0],n)}),a.on("cb-end",function(t,e,n){a.emit("propagate",[n,!0],this.nextPromise)}),a.on("propagate",function(t,e,n){this.getCtx&&!e||(this.getCtx=function(){if(t instanceof Promise)var e=a.context(t);return e&&e.getCtx?e.getCtx():this})}),r.toString=function(){return""+f})},{}],11:[function(t,e,n){var r=t("ee").get("raf"),o=t(22)(r),i="equestAnimationFrame";e.exports=r,o.inPlace(window,["r"+i,"mozR"+i,"webkitR"+i,"msR"+i],"raf-"),r.on("raf-start",function(t){t[0]=o(t[0],"fn-")})},{}],12:[function(t,e,n){function r(t,e,n){t[0]=a(t[0],"fn-",null,n)}function o(t,e,n){this.method=n,this.timerDuration=isNaN(t[1])?0:+t[1],t[0]=a(t[0],"fn-",this,n)}var i=t("ee").get("timer"),a=t(22)(i),c="setTimeout",s="setInterval",f="clearTimeout",u="-start",d="-";e.exports=i,a.inPlace(window,[c,"setImmediate"],c+d),a.inPlace(window,[s],s+d),a.inPlace(window,[f,"clearImmediate"],f+d),i.on(s+u,r),i.on(c+u,o)},{}],13:[function(t,e,n){function r(t,e){d.inPlace(e,["onreadystatechange"],"fn-",c)}function o(){var t=this,e=u.context(t);t.readyState>3&&!e.resolved&&(e.resolved=!0,u.emit("xhr-resolved",[],t)),d.inPlace(t,y,"fn-",c)}function i(t){b.push(t),l&&(x?x.then(a):v?v(a):(E=-E,O.data=E))}function a(){for(var t=0;t<b.length;t++)r([],b[t]);b.length&&(b=[])}function c(t,e){return e}function s(t,e){for(var n in t)e[n]=t[n];return e}t(6);var f=t("ee"),u=f.get("xhr"),d=t(22)(u),p=NREUM.o,h=p.XHR,l=p.MO,m=p.PR,v=p.SI,w="readystatechange",y=["onload","onerror","onabort","onloadstart","onloadend","onprogress","ontimeout"],b=[];e.exports=u;var g=window.XMLHttpRequest=function(t){var e=new h(t);try{u.emit("new-xhr",[e],e),e.addEventListener(w,o,!1)}catch(n){try{u.emit("internal-error",[n])}catch(r){}}return e};if(s(h,g),g.prototype=h.prototype,d.inPlace(g.prototype,["open","send"],"-xhr-",c),u.on("send-xhr-start",function(t,e){r(t,e),i(e)}),u.on("open-xhr-start",r),l){var x=m&&m.resolve();if(!v&&!m){var E=1,O=document.createTextNode(E);new l(a).observe(O,{characterData:!0})}}else f.on("fn-end",function(t){t[0]&&t[0].type===w||a()})},{}],14:[function(t,e,n){function r(t){var e=this.params,n=this.metrics;if(!this.ended){this.ended=!0;for(var r=0;r<d;r++)t.removeEventListener(u[r],this.listener,!1);if(!e.aborted){if(n.duration=a.now()-this.startTime,4===t.readyState){e.status=t.status;var i=o(t,this.lastSize);if(i&&(n.rxSize=i),this.sameOrigin){var s=t.getResponseHeader("X-NewRelic-App-Data");s&&(e.cat=s.split(", ").pop())}}else e.status=0;n.cbTime=this.cbTime,f.emit("xhr-done",[t],t),c("xhr",[e,n,this.startTime])}}}function o(t,e){var n=t.responseType;if("json"===n&&null!==e)return e;var r="arraybuffer"===n||"blob"===n||"json"===n?t.response:t.responseText;return l(r)}function i(t,e){var n=s(e),r=t.params;r.host=n.hostname+":"+n.port,r.pathname=n.pathname,t.sameOrigin=n.sameOrigin}var a=t("loader");if(a.xhrWrappable){var c=t("handle"),s=t(15),f=t("ee"),u=["load","error","abort","timeout"],d=u.length,p=t("id"),h=t(18),l=t(17),m=window.XMLHttpRequest;a.features.xhr=!0,t(13),f.on("new-xhr",function(t){var e=this;e.totalCbs=0,e.called=0,e.cbTime=0,e.end=r,e.ended=!1,e.xhrGuids={},e.lastSize=null,h&&(h>34||h<10)||window.opera||t.addEventListener("progress",function(t){e.lastSize=t.loaded},!1)}),f.on("open-xhr-start",function(t){this.params={method:t[0]},i(this,t[1]),this.metrics={}}),f.on("open-xhr-end",function(t,e){"loader_config"in NREUM&&"xpid"in NREUM.loader_config&&this.sameOrigin&&e.setRequestHeader("X-NewRelic-ID",NREUM.loader_config.xpid)}),f.on("send-xhr-start",function(t,e){var n=this.metrics,r=t[0],o=this;if(n&&r){var i=l(r);i&&(n.txSize=i)}this.startTime=a.now(),this.listener=function(t){try{"abort"===t.type&&(o.params.aborted=!0),("load"!==t.type||o.called===o.totalCbs&&(o.onloadCalled||"function"!=typeof e.onload))&&o.end(e)}catch(n){try{f.emit("internal-error",[n])}catch(r){}}};for(var c=0;c<d;c++)e.addEventListener(u[c],this.listener,!1)}),f.on("xhr-cb-time",function(t,e,n){this.cbTime+=t,e?this.onloadCalled=!0:this.called+=1,this.called!==this.totalCbs||!this.onloadCalled&&"function"==typeof n.onload||this.end(n)}),f.on("xhr-load-added",function(t,e){var n=""+p(t)+!!e;this.xhrGuids&&!this.xhrGuids[n]&&(this.xhrGuids[n]=!0,this.totalCbs+=1)}),f.on("xhr-load-removed",function(t,e){var n=""+p(t)+!!e;this.xhrGuids&&this.xhrGuids[n]&&(delete this.xhrGuids[n],this.totalCbs-=1)}),f.on("addEventListener-end",function(t,e){e instanceof m&&"load"===t[0]&&f.emit("xhr-load-added",[t[1],t[2]],e)}),f.on("removeEventListener-end",function(t,e){e instanceof m&&"load"===t[0]&&f.emit("xhr-load-removed",[t[1],t[2]],e)}),f.on("fn-start",function(t,e,n){e instanceof m&&("onload"===n&&(this.onload=!0),("load"===(t[0]&&t[0].type)||this.onload)&&(this.xhrCbStart=a.now()))}),f.on("fn-end",function(t,e){this.xhrCbStart&&f.emit("xhr-cb-time",[a.now()-this.xhrCbStart,this.onload,e],e)})}},{}],15:[function(t,e,n){e.exports=function(t){var e=document.createElement("a"),n=window.location,r={};e.href=t,r.port=e.port;var o=e.href.split("://");!r.port&&o[1]&&(r.port=o[1].split("/")[0].split("@").pop().split(":")[1]),r.port&&"0"!==r.port||(r.port="https"===o[0]?"443":"80"),r.hostname=e.hostname||n.hostname,r.pathname=e.pathname,r.protocol=o[0],"/"!==r.pathname.charAt(0)&&(r.pathname="/"+r.pathname);var i=!e.protocol||":"===e.protocol||e.protocol===n.protocol,a=e.hostname===document.domain&&e.port===n.port;return r.sameOrigin=i&&(!e.hostname||a),r}},{}],16:[function(t,e,n){function r(){}function o(t,e,n){return function(){return i(t,[f.now()].concat(c(arguments)),e?null:this,n),e?void 0:this}}var i=t("handle"),a=t(19),c=t(20),s=t("ee").get("tracer"),f=t("loader"),u=NREUM;"undefined"==typeof window.newrelic&&(newrelic=u);var d=["setPageViewName","setCustomAttribute","setErrorHandler","finished","addToTrace","inlineHit","addRelease"],p="api-",h=p+"ixn-";a(d,function(t,e){u[e]=o(p+e,!0,"api")}),u.addPageAction=o(p+"addPageAction",!0),u.setCurrentRouteName=o(p+"routeName",!0),e.exports=newrelic,u.interaction=function(){return(new r).get()};var l=r.prototype={createTracer:function(t,e){var n={},r=this,o="function"==typeof e;return i(h+"tracer",[f.now(),t,n],r),function(){if(s.emit((o?"":"no-")+"fn-start",[f.now(),r,o],n),o)try{return e.apply(this,arguments)}finally{s.emit("fn-end",[f.now()],n)}}}};a("setName,setAttribute,save,ignore,onEnd,getContext,end,get".split(","),function(t,e){l[e]=o(h+e)}),newrelic.noticeError=function(t){"string"==typeof t&&(t=new Error(t)),i("err",[t,f.now()])}},{}],17:[function(t,e,n){e.exports=function(t){if("string"==typeof t&&t.length)return t.length;if("object"==typeof t){if("undefined"!=typeof ArrayBuffer&&t instanceof ArrayBuffer&&t.byteLength)return t.byteLength;if("undefined"!=typeof Blob&&t instanceof Blob&&t.size)return t.size;if(!("undefined"!=typeof FormData&&t instanceof FormData))try{return JSON.stringify(t).length}catch(e){return}}}},{}],18:[function(t,e,n){var r=0,o=navigator.userAgent.match(/Firefox[\/\s](\d+\.\d+)/);o&&(r=+o[1]),e.exports=r},{}],19:[function(t,e,n){function r(t,e){var n=[],r="",i=0;for(r in t)o.call(t,r)&&(n[i]=e(r,t[r]),i+=1);return n}var o=Object.prototype.hasOwnProperty;e.exports=r},{}],20:[function(t,e,n){function r(t,e,n){e||(e=0),"undefined"==typeof n&&(n=t?t.length:0);for(var r=-1,o=n-e||0,i=Array(o<0?0:o);++r<o;)i[r]=t[e+r];return i}e.exports=r},{}],21:[function(t,e,n){e.exports={exists:"undefined"!=typeof window.performance&&window.performance.timing&&"undefined"!=typeof window.performance.timing.navigationStart}},{}],22:[function(t,e,n){function r(t){return!(t&&t instanceof Function&&t.apply&&!t[a])}var o=t("ee"),i=t(20),a="nr@original",c=Object.prototype.hasOwnProperty,s=!1;e.exports=function(t,e){function n(t,e,n,o){function nrWrapper(){var r,a,c,s;try{a=this,r=i(arguments),c="function"==typeof n?n(r,a):n||{}}catch(f){p([f,"",[r,a,o],c])}u(e+"start",[r,a,o],c);try{return s=t.apply(a,r)}catch(d){throw u(e+"err",[r,a,d],c),d}finally{u(e+"end",[r,a,s],c)}}return r(t)?t:(e||(e=""),nrWrapper[a]=t,d(t,nrWrapper),nrWrapper)}function f(t,e,o,i){o||(o="");var a,c,s,f="-"===o.charAt(0);for(s=0;s<e.length;s++)c=e[s],a=t[c],r(a)||(t[c]=n(a,f?c+o:o,i,c))}function u(n,r,o){if(!s||e){var i=s;s=!0;try{t.emit(n,r,o,e)}catch(a){p([a,n,r,o])}s=i}}function d(t,e){if(Object.defineProperty&&Object.keys)try{var n=Object.keys(t);return n.forEach(function(n){Object.defineProperty(e,n,{get:function(){return t[n]},set:function(e){return t[n]=e,e}})}),e}catch(r){p([r])}for(var o in t)c.call(t,o)&&(e[o]=t[o]);return e}function p(e){try{t.emit("internal-error",e)}catch(n){}}return t||(t=o),n.inPlace=f,n.flag=a,n}},{}],ee:[function(t,e,n){function r(){}function o(t){function e(t){return t&&t instanceof r?t:t?s(t,c,i):i()}function n(n,r,o,i){if(!p.aborted||i){t&&t(n,r,o);for(var a=e(o),c=l(n),s=c.length,f=0;f<s;f++)c[f].apply(a,r);var d=u[y[n]];return d&&d.push([b,n,r,a]),a}}function h(t,e){w[t]=l(t).concat(e)}function l(t){return w[t]||[]}function m(t){return d[t]=d[t]||o(n)}function v(t,e){f(t,function(t,n){e=e||"feature",y[n]=e,e in u||(u[e]=[])})}var w={},y={},b={on:h,emit:n,get:m,listeners:l,context:e,buffer:v,abort:a,aborted:!1};return b}function i(){return new r}function a(){(u.api||u.feature)&&(p.aborted=!0,u=p.backlog={})}var c="nr@context",s=t("gos"),f=t(19),u={},d={},p=e.exports=o();p.backlog=u},{}],gos:[function(t,e,n){function r(t,e,n){if(o.call(t,e))return t[e];var r=n();if(Object.defineProperty&&Object.keys)try{return Object.defineProperty(t,e,{value:r,writable:!0,enumerable:!1}),r}catch(i){}return t[e]=r,r}var o=Object.prototype.hasOwnProperty;e.exports=r},{}],handle:[function(t,e,n){function r(t,e,n,r){o.buffer([t],r),o.emit(t,e,n)}var o=t("ee").get("handle");e.exports=r,r.ee=o},{}],id:[function(t,e,n){function r(t){var e=typeof t;return!t||"object"!==e&&"function"!==e?-1:t===window?0:a(t,i,function(){return o++})}var o=1,i="nr@id",a=t("gos");e.exports=r},{}],loader:[function(t,e,n){function r(){if(!x++){var t=g.info=NREUM.info,e=p.getElementsByTagName("script")[0];if(setTimeout(u.abort,3e4),!(t&&t.licenseKey&&t.applicationID&&e))return u.abort();f(y,function(e,n){t[e]||(t[e]=n)}),s("mark",["onload",a()+g.offset],null,"api");var n=p.createElement("script");n.src="https://"+t.agent,e.parentNode.insertBefore(n,e)}}function o(){"complete"===p.readyState&&i()}function i(){s("mark",["domContent",a()+g.offset],null,"api")}function a(){return E.exists&&performance.now?Math.round(performance.now()):(c=Math.max((new Date).getTime(),c))-g.offset}var c=(new Date).getTime(),s=t("handle"),f=t(19),u=t("ee"),d=window,p=d.document,h="addEventListener",l="attachEvent",m=d.XMLHttpRequest,v=m&&m.prototype;NREUM.o={ST:setTimeout,SI:d.setImmediate,CT:clearTimeout,XHR:m,REQ:d.Request,EV:d.Event,PR:d.Promise,MO:d.MutationObserver};var w=""+location,y={beacon:"bam.nr-data.net",errorBeacon:"bam.nr-data.net",agent:"js-agent.newrelic.com/nr-spa-1044.min.js"},b=m&&v&&v[h]&&!/CriOS/.test(navigator.userAgent),g=e.exports={offset:c,now:a,origin:w,features:{},xhrWrappable:b};t(16),p[h]?(p[h]("DOMContentLoaded",i,!1),d[h]("load",r,!1)):(p[l]("onreadystatechange",o),d[l]("onload",r)),s("mark",["firstbyte",c],null,"api");var x=0,E=t(21)},{}]},{},["loader",2,14,5,3,4]);</script><link rel="apple-touch-icon" href="https://www.safaribooksonline.com/static/images/apple-touch-icon.8cc2fd27400e.png"><link rel="shortcut icon" href="https://www.safaribooksonline.com/favicon.ico" type="image/x-icon"><link href="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/css.css" rel="stylesheet" type="text/css"><title>5. Support Vector Machines - Hands-On Machine Learning with Scikit-Learn and TensorFlow</title><link rel="stylesheet" href="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/d6ec1592ffb3.css" type="text/css"><link rel="stylesheet" type="text/css" href="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/annotator.css"><link rel="stylesheet" href="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/font-awesome.css"><style type="text/css" title="ibis-book">@charset "utf-8";#sbo-rt-content html,#sbo-rt-content div,#sbo-rt-content div,#sbo-rt-content span,#sbo-rt-content applet,#sbo-rt-content object,#sbo-rt-content iframe,#sbo-rt-content h1,#sbo-rt-content h2,#sbo-rt-content h3,#sbo-rt-content h4,#sbo-rt-content h5,#sbo-rt-content h6,#sbo-rt-content p,#sbo-rt-content blockquote,#sbo-rt-content pre,#sbo-rt-content a,#sbo-rt-content abbr,#sbo-rt-content acronym,#sbo-rt-content address,#sbo-rt-content big,#sbo-rt-content cite,#sbo-rt-content code,#sbo-rt-content del,#sbo-rt-content dfn,#sbo-rt-content em,#sbo-rt-content img,#sbo-rt-content ins,#sbo-rt-content kbd,#sbo-rt-content q,#sbo-rt-content s,#sbo-rt-content samp,#sbo-rt-content small,#sbo-rt-content strike,#sbo-rt-content strong,#sbo-rt-content sub,#sbo-rt-content sup,#sbo-rt-content tt,#sbo-rt-content var,#sbo-rt-content b,#sbo-rt-content u,#sbo-rt-content i,#sbo-rt-content center,#sbo-rt-content dl,#sbo-rt-content dt,#sbo-rt-content dd,#sbo-rt-content ol,#sbo-rt-content ul,#sbo-rt-content li,#sbo-rt-content fieldset,#sbo-rt-content form,#sbo-rt-content label,#sbo-rt-content legend,#sbo-rt-content table,#sbo-rt-content caption,#sbo-rt-content tdiv,#sbo-rt-content tfoot,#sbo-rt-content thead,#sbo-rt-content tr,#sbo-rt-content th,#sbo-rt-content td,#sbo-rt-content article,#sbo-rt-content aside,#sbo-rt-content canvas,#sbo-rt-content details,#sbo-rt-content embed,#sbo-rt-content figure,#sbo-rt-content figcaption,#sbo-rt-content footer,#sbo-rt-content header,#sbo-rt-content hgroup,#sbo-rt-content menu,#sbo-rt-content nav,#sbo-rt-content output,#sbo-rt-content ruby,#sbo-rt-content section,#sbo-rt-content summary,#sbo-rt-content time,#sbo-rt-content mark,#sbo-rt-content audio,#sbo-rt-content video{margin:0;padding:0;border:0;font-size:100%;font:inherit;vertical-align:baseline}#sbo-rt-content article,#sbo-rt-content aside,#sbo-rt-content details,#sbo-rt-content figcaption,#sbo-rt-content figure,#sbo-rt-content footer,#sbo-rt-content header,#sbo-rt-content hgroup,#sbo-rt-content menu,#sbo-rt-content nav,#sbo-rt-content section{display:block}#sbo-rt-content div{line-height:1}#sbo-rt-content ol,#sbo-rt-content ul{list-style:none}#sbo-rt-content blockquote,#sbo-rt-content q{quotes:none}#sbo-rt-content blockquote:before,#sbo-rt-content blockquote:after,#sbo-rt-content q:before,#sbo-rt-content q:after{content:none}#sbo-rt-content table{border-collapse:collapse;border-spacing:0}@page{margin:5px !important}#sbo-rt-content p{margin:10px 0 0;line-height:125%;text-align:left}#sbo-rt-content p.byline{text-align:left;margin:-33px auto 35px;font-style:italic;font-weight:bold}#sbo-rt-content div.preface p+p.byline{margin:1em 0 0}#sbo-rt-content div.preface p.byline+p.byline{margin:0}#sbo-rt-content div.sect1>p.byline{margin:-.25em 0 1em}#sbo-rt-content div.sect1>p.byline+p.byline{margin-top:-1em}#sbo-rt-content em{font-style:italic;font-family:inherit}#sbo-rt-content em strong,#sbo-rt-content strong em{font-weight:bold;font-style:italic;font-family:inherit}#sbo-rt-content strong,#sbo-rt-content span.bold{font-weight:bold}#sbo-rt-content em.replaceable{font-style:italic}#sbo-rt-content strong.userinput{font-weight:bold;font-style:normal}#sbo-rt-content span.bolditalic{font-weight:bold;font-style:italic}#sbo-rt-content a.ulink,#sbo-rt-content a.xref,#sbo-rt-content a.email,#sbo-rt-content a.link,#sbo-rt-content a{text-decoration:none;color:#8e0012}#sbo-rt-content span.lineannotation{font-style:italic;color:#a62a2a;font-family:serif}#sbo-rt-content span.underline{text-decoration:underline}#sbo-rt-content span.strikethrough{text-decoration:line-through}#sbo-rt-content span.smallcaps{font-variant:small-caps}#sbo-rt-content span.cursor{background:#000;color:#fff}#sbo-rt-content span.smaller{font-size:75%}#sbo-rt-content .boxedtext,#sbo-rt-content .keycap{border-style:solid;border-width:1px;border-color:#000;padding:1px}#sbo-rt-content span.gray50{color:#7F7F7F;}#sbo-rt-content h1,#sbo-rt-content div.toc-title,#sbo-rt-content h2,#sbo-rt-content h3,#sbo-rt-content h4,#sbo-rt-content h5{-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;font-weight:bold;text-align:left;page-break-after:avoid !important;font-family:sans-serif,"DejaVuSans"}#sbo-rt-content div.toc-title{font-size:1.5em;margin-top:20px !important;margin-bottom:30px !important}#sbo-rt-content section[data-type="sect1"] h1{font-size:1.3em;color:#8e0012;margin:40px 0 8px 0}#sbo-rt-content section[data-type="sect2"] h2{font-size:1.1em;margin:30px 0 8px 0 !important}#sbo-rt-content section[data-type="sect3"] h3{font-size:1em;color:#555;margin:20px 0 8px 0 !important}#sbo-rt-content section[data-type="sect4"] h4{font-size:1em;font-weight:normal;font-style:italic;margin:15px 0 6px 0 !important}#sbo-rt-content section[data-type="chapter"]>div>h1,#sbo-rt-content section[data-type="preface"]>div>h1,#sbo-rt-content section[data-type="appendix"]>div>h1,#sbo-rt-content section[data-type="glossary"]>div>h1,#sbo-rt-content section[data-type="bibliography"]>div>h1,#sbo-rt-content section[data-type="index"]>div>h1{font-size:2em;line-height:1;margin-bottom:50px;color:#000;padding-bottom:10px;border-bottom:1px solid #000}#sbo-rt-content span.label,#sbo-rt-content span.keep-together{font-size:inherit;font-weight:inherit}#sbo-rt-content div[data-type="part"] h1{font-size:2em;text-align:center;margin-top:0 !important;margin-bottom:50px;padding:50px 0 10px 0;border-bottom:1px solid #000}#sbo-rt-content img.width-ninety{width:90%}#sbo-rt-content img{max-width:95%;margin:0 auto;padding:0}#sbo-rt-content div.figure{background-color:transparent;text-align:center !important;margin:15px 0 15px 0 !important;page-break-inside:avoid}#sbo-rt-content figure{margin:15px 0 15px 0 !important;page-break-inside:avoid}#sbo-rt-content div.figure h6{font-size:90%;text-align:center;font-weight:normal;font-style:italic;font-family:serif !important;color:#000;padding-top:10px !important;page-break-before:avoid;page-break-after:avoid}#sbo-rt-content div.informalfigure{text-align:center !important;padding:5px 0 !important}#sbo-rt-content div.sidebar{margin:15px 0 10px 0 !important;border:1px solid #DCDCDC;background-color:#F7F7F7;padding:15px !important;page-break-inside:avoid}#sbo-rt-content aside[data-type="sidebar"]{margin:15px 0 10px 0 !important;page-break-inside:avoid}#sbo-rt-content div.sidebar-title,#sbo-rt-content aside[data-type="sidebar"] h5{font-weight:bold;font-size:1em;font-family:sans-serif;text-transform:uppercase;letter-spacing:1px;text-align:center;margin:4px 0 6px 0 !important;page-break-inside:avoid}#sbo-rt-content div.sidebar ol,#sbo-rt-content div.sidebar ul,#sbo-rt-content aside[data-type="sidebar"] ol,#sbo-rt-content aside[data-type="sidebar"] ul{margin-left:1.25em !important}#sbo-rt-content div.sidebar div.figure p.title,#sbo-rt-content aside[data-type="sidebar"] figcaption,#sbo-rt-content div.sidebar div.informalfigure div.caption{font-size:90%;text-align:center;font-weight:normal;font-style:italic;font-family:serif !important;color:#000;padding:5px !important;page-break-before:avoid;page-break-after:avoid}#sbo-rt-content div.sidebar div.tip,#sbo-rt-content div.sidebar div[data-type="tip"],#sbo-rt-content div.sidebar div.note,#sbo-rt-content div.sidebar div[data-type="note"],#sbo-rt-content div.sidebar div.warning,#sbo-rt-content div.sidebar div[data-type="warning"],#sbo-rt-content div.sidebar div[data-type="caution"],#sbo-rt-content div.sidebar div[data-type="important"]{margin:20px auto 20px auto !important;font-size:90%;width:85%}#sbo-rt-content aside[data-type="sidebar"] p.byline{font-size:90%;font-weight:bold;font-style:italic;text-align:center;text-indent:0;margin:5px auto 6px;page-break-after:avoid}#sbo-rt-content pre{white-space:pre-wrap;font-family:"Ubuntu Mono",monospace;margin:25px 0 25px 20px;font-size:85%;display:block;-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;overflow-wrap:break-word}#sbo-rt-content div.note pre.programlisting,#sbo-rt-content div.tip pre.programlisting,#sbo-rt-content div.warning pre.programlisting,#sbo-rt-content div.caution pre.programlisting,#sbo-rt-content div.important pre.programlisting{margin-bottom:0}#sbo-rt-content code{font-family:"Ubuntu Mono",monospace;-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;overflow-wrap:break-word}#sbo-rt-content code strong em,#sbo-rt-content code em strong,#sbo-rt-content pre em strong,#sbo-rt-content pre strong em,#sbo-rt-content strong code em code,#sbo-rt-content em code strong code,#sbo-rt-content span.bolditalic code{font-weight:bold;font-style:italic;font-family:"Ubuntu Mono BoldItal",monospace}#sbo-rt-content code em,#sbo-rt-content em code,#sbo-rt-content pre em,#sbo-rt-content em.replaceable{font-family:"Ubuntu Mono Ital",monospace;font-style:italic}#sbo-rt-content code strong,#sbo-rt-content strong code,#sbo-rt-content pre strong,#sbo-rt-content strong.userinput{font-family:"Ubuntu Mono Bold",monospace;font-weight:bold}#sbo-rt-content div[data-type="example"]{margin:10px 0 15px 0 !important}#sbo-rt-content div[data-type="example"] h1,#sbo-rt-content div[data-type="example"] h2,#sbo-rt-content div[data-type="example"] h3,#sbo-rt-content div[data-type="example"] h4,#sbo-rt-content div[data-type="example"] h5,#sbo-rt-content div[data-type="example"] h6{font-style:italic;font-weight:normal;text-align:left !important;text-transform:none !important;font-family:serif !important;margin:10px 0 5px 0 !important;border-bottom:1px solid #000}#sbo-rt-content li pre.example{padding:10px 0 !important}#sbo-rt-content div[data-type="example"] pre[data-type="programlisting"],#sbo-rt-content div[data-type="example"] pre[data-type="screen"]{margin:0}#sbo-rt-content section[data-type="titlepage"]>div>h1{font-size:2em;margin:50px 0 10px 0 !important;line-height:1;text-align:center}#sbo-rt-content section[data-type="titlepage"] h2,#sbo-rt-content section[data-type="titlepage"] p.subtitle,#sbo-rt-content section[data-type="titlepage"] p[data-type="subtitle"]{font-size:1.3em;font-weight:normal;text-align:center;margin-top:.5em;color:#555}#sbo-rt-content section[data-type="titlepage"]>div>h2[data-type="author"],#sbo-rt-content section[data-type="titlepage"] p.author{font-size:1.3em;font-family:serif !important;font-weight:bold;margin:50px 0 !important;text-align:center}#sbo-rt-content section[data-type="titlepage"] p.edition{text-align:center;text-transform:uppercase;margin-top:2em}#sbo-rt-content section[data-type="titlepage"]{text-align:center}#sbo-rt-content section[data-type="titlepage"]:after{content:url(css_assets/titlepage_footer_ebook.png);margin:0 auto;max-width:80%}#sbo-rt-content div.book div.titlepage div.publishername{margin-top:60%;margin-bottom:20px;text-align:center;font-size:1.25em}#sbo-rt-content div.book div.titlepage div.locations p{margin:0;text-align:center}#sbo-rt-content div.book div.titlepage div.locations p.cities{font-size:80%;text-align:center;margin-top:5px}#sbo-rt-content section.preface[title="Dedication"]>div.titlepage h2.title{text-align:center;text-transform:uppercase;font-size:1.5em;margin-top:50px;margin-bottom:50px}#sbo-rt-content ul.stafflist{margin:15px 0 15px 20px !important}#sbo-rt-content ul.stafflist li{list-style-type:none;padding:5px 0}#sbo-rt-content ul.printings li{list-style-type:none}#sbo-rt-content section.preface[title="Dedication"] p{font-style:italic;text-align:center}#sbo-rt-content div.colophon h1.title{font-size:1.3em;margin:0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon h2.subtitle{margin:0 !important;color:#000;font-family:serif !important;font-size:1em;font-weight:normal}#sbo-rt-content div.colophon div.author h3.author{font-size:1.1em;font-family:serif !important;margin:10px 0 0 !important;font-weight:normal}#sbo-rt-content div.colophon div.editor h4,#sbo-rt-content div.colophon div.editor h3.editor{color:#000;font-size:.8em;margin:15px 0 0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon div.editor h3.editor{font-size:.8em;margin:0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon div.publisher{margin-top:10px}#sbo-rt-content div.colophon div.publisher p,#sbo-rt-content div.colophon div.publisher span.publishername{margin:0;font-size:.8em}#sbo-rt-content div.legalnotice p,#sbo-rt-content div.timestamp p{font-size:.8em}#sbo-rt-content div.timestamp p{margin-top:10px}#sbo-rt-content div.colophon[title="About the Author"] h1.title,#sbo-rt-content div.colophon[title="Colophon"] h1.title{font-size:1.5em;margin:0 !important;font-family:sans-serif !important}#sbo-rt-content section.chapter div.titlepage div.author{margin:10px 0 10px 0}#sbo-rt-content section.chapter div.titlepage div.author div.affiliation{font-style:italic}#sbo-rt-content div.attribution{margin:5px 0 0 50px !important}#sbo-rt-content h3.author span.orgname{display:none}#sbo-rt-content div.epigraph{margin:10px 0 10px 20px !important;page-break-inside:avoid;font-size:90%}#sbo-rt-content div.epigraph p{font-style:italic}#sbo-rt-content blockquote,#sbo-rt-content div.blockquote{margin:10px !important;page-break-inside:avoid;font-size:95%}#sbo-rt-content blockquote p,#sbo-rt-content div.blockquote p{font-style:italic;margin:.75em 0 0 !important}#sbo-rt-content blockquote div.attribution,#sbo-rt-content blockquote p[data-type="attribution"]{margin:5px 0 10px 30px !important;text-align:right;width:80%}#sbo-rt-content blockquote div.attribution p,#sbo-rt-content blockquote p[data-type="attribution"]{font-style:normal;margin-top:5px}#sbo-rt-content blockquote div.attribution p:before,#sbo-rt-content blockquote p[data-type="attribution"]:before{font-style:normal;content:"—";-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none}#sbo-rt-content p.right{text-align:right;margin:0}#sbo-rt-content div[data-type="footnotes"]{border-top:1px solid black;margin-top:1.5em}#sbo-rt-content sub,#sbo-rt-content sup{font-size:75%;line-height:0;position:relative}#sbo-rt-content sup{top:-.5em}#sbo-rt-content sub{bottom:-.25em}#sbo-rt-content div.refentry p.refname{font-size:1em;font-family:sans-serif,"DejaVuSans";font-weight:bold;margin-bottom:5px;overflow:auto;width:100%}#sbo-rt-content div.refentry{width:100%;display:block;margin-top:2em}#sbo-rt-content div.refsynopsisdiv{display:block;clear:both}#sbo-rt-content div.refentry header{page-break-inside:avoid !important;display:block;break-inside:avoid !important;padding-top:0;border-bottom:1px solid #000}#sbo-rt-content div.refsect1 h6{font-size:.9em;font-family:sans-serif,"DejaVuSans";font-weight:bold}#sbo-rt-content div.refsect1{margin-top:3em}#sbo-rt-content dt{padding-top:10px !important;padding-bottom:0 !important}#sbo-rt-content dd{margin-left:1.5em !important;margin-bottom:.25em}#sbo-rt-content dd ol,#sbo-rt-content dd ul{padding-left:1em}#sbo-rt-content dd li{margin-top:0;margin-bottom:0}#sbo-rt-content dd,#sbo-rt-content li{text-align:left}#sbo-rt-content ul,#sbo-rt-content ul>li,#sbo-rt-content ol ul,#sbo-rt-content ol ul>li,#sbo-rt-content ul ol ul,#sbo-rt-content ul ol ul>li{list-style-type:disc}#sbo-rt-content ul ul,#sbo-rt-content ul ul>li{list-style-type:square}#sbo-rt-content ul ul ul,#sbo-rt-content ul ul ul>li{list-style-type:circle}#sbo-rt-content ol,#sbo-rt-content ol>li,#sbo-rt-content ol ul ol,#sbo-rt-content ol ul ol>li,#sbo-rt-content ul ol,#sbo-rt-content ul ol>li{list-style-type:decimal}#sbo-rt-content ol ol,#sbo-rt-content ol ol>li{list-style-type:lower-alpha}#sbo-rt-content ol ol ol,#sbo-rt-content ol ol ol>li{list-style-type:lower-roman}#sbo-rt-content ol,#sbo-rt-content ul{list-style-position:outside;margin:15px 0 15px 1.25em;padding-left:2.25em}#sbo-rt-content ol li,#sbo-rt-content ul li{margin:.5em 0 .65em;line-height:125%}#sbo-rt-content div.orderedlistalpha{list-style-type:upper-alpha}#sbo-rt-content table.simplelist,#sbo-rt-content ul.simplelist{margin:15px 0 15px 20px !important}#sbo-rt-content ul.simplelist li{list-style-type:none;padding:5px 0}#sbo-rt-content table.simplelist td{border:none}#sbo-rt-content table.simplelist tr{border-bottom:none}#sbo-rt-content table.simplelist tr:nth-of-type(even){background-color:transparent}#sbo-rt-content dl.calloutlist p:first-child{margin-top:-25px !important}#sbo-rt-content dl.calloutlist dd{padding-left:0;margin-top:-25px}#sbo-rt-content dl.calloutlist img,#sbo-rt-content a.co img{padding:0}#sbo-rt-content div.toc ol{margin-top:8px !important;margin-bottom:8px !important;margin-left:0 !important;padding-left:0 !important}#sbo-rt-content div.toc ol ol{margin-left:30px !important;padding-left:0 !important}#sbo-rt-content div.toc ol li{list-style-type:none}#sbo-rt-content div.toc a{color:#8e0012}#sbo-rt-content div.toc ol a{font-size:1em;font-weight:bold}#sbo-rt-content div.toc ol>li>ol a{font-weight:bold;font-size:1em}#sbo-rt-content div.toc ol>li>ol>li>ol a{text-decoration:none;font-weight:normal;font-size:1em}#sbo-rt-content div.tip,#sbo-rt-content div[data-type="tip"],#sbo-rt-content div.note,#sbo-rt-content div[data-type="note"],#sbo-rt-content div.warning,#sbo-rt-content div[data-type="warning"],#sbo-rt-content div[data-type="caution"],#sbo-rt-content div[data-type="important"]{margin:30px !important;font-size:90%;padding:10px 8px 20px 8px !important;page-break-inside:avoid}#sbo-rt-content div.tip ol,#sbo-rt-content div.tip ul,#sbo-rt-content div[data-type="tip"] ol,#sbo-rt-content div[data-type="tip"] ul,#sbo-rt-content div.note ol,#sbo-rt-content div.note ul,#sbo-rt-content div[data-type="note"] ol,#sbo-rt-content div[data-type="note"] ul,#sbo-rt-content div.warning ol,#sbo-rt-content div.warning ul,#sbo-rt-content div[data-type="warning"] ol,#sbo-rt-content div[data-type="warning"] ul,#sbo-rt-content div[data-type="caution"] ol,#sbo-rt-content div[data-type="caution"] ul,#sbo-rt-content div[data-type="important"] ol,#sbo-rt-content div[data-type="important"] ul{margin-left:1.5em !important}#sbo-rt-content div.tip,#sbo-rt-content div[data-type="tip"],#sbo-rt-content div.note,#sbo-rt-content div[data-type="note"]{border:1px solid #BEBEBE;background-color:transparent}#sbo-rt-content div.warning,#sbo-rt-content div[data-type="warning"],#sbo-rt-content div[data-type="caution"],#sbo-rt-content div[data-type="important"]{border:1px solid #BC8F8F}#sbo-rt-content div.tip h3,#sbo-rt-content div[data-type="tip"] h6,#sbo-rt-content div[data-type="tip"] h1,#sbo-rt-content div.note h3,#sbo-rt-content div[data-type="note"] h6,#sbo-rt-content div[data-type="note"] h1,#sbo-rt-content div.warning h3,#sbo-rt-content div[data-type="warning"] h6,#sbo-rt-content div[data-type="warning"] h1,#sbo-rt-content div[data-type="caution"] h6,#sbo-rt-content div[data-type="caution"] h1,#sbo-rt-content div[data-type="important"] h1,#sbo-rt-content div[data-type="important"] h6{font-weight:bold;font-size:110%;font-family:sans-serif !important;text-transform:uppercase;letter-spacing:1px;text-align:center;margin:4px 0 6px !important}#sbo-rt-content div.tip h3,#sbo-rt-content div[data-type="tip"] h6,#sbo-rt-content div.note h3,#sbo-rt-content div[data-type="note"] h6,#sbo-rt-content div[data-type="tip"] h1,#sbo-rt-content div[data-type="note"] h1{color:#737373}#sbo-rt-content div.warning h3,#sbo-rt-content div[data-type="warning"] h6,#sbo-rt-content div[data-type="caution"] h6,#sbo-rt-content div[data-type="important"] h6,#sbo-rt-content div[data-type="warning"] h1,#sbo-rt-content div[data-type="caution"] h1,#sbo-rt-content div[data-type="important"] h1{color:#C67171}#sbo-rt-content div.sect1[title="Safari® Books Online"] div.note,#sbo-rt-content div.safarienabled{background-color:transparent;margin:8px 0 0 !important;border:0 solid #BEBEBE;font-size:100%;padding:0 !important;page-break-inside:avoid}#sbo-rt-content div.sect1[title="Safari® Books Online"] div.note h3,#sbo-rt-content div.safarienabled h6{display:none}#sbo-rt-content div.table,#sbo-rt-content table{margin:15px 0 30px 0 !important;max-width:95%;border:none !important;background:none;display:table !important}#sbo-rt-content div.table,#sbo-rt-content div.informaltable,#sbo-rt-content table{page-break-inside:avoid}#sbo-rt-content tr,#sbo-rt-content tr td{border-bottom:1px solid #c3c3c3}#sbo-rt-content thead td,#sbo-rt-content thead th{border-bottom:#9d9d9d 1px solid !important;border-top:#9d9d9d 1px solid !important}#sbo-rt-content tr:nth-of-type(even){background-color:#f1f6fc}#sbo-rt-content thead{font-family:sans-serif;font-weight:bold}#sbo-rt-content td,#sbo-rt-content th{display:table-cell;padding:.3em;text-align:left;vertical-align:middle;font-size:80%}#sbo-rt-content div.informaltable table{margin:10px auto !important}#sbo-rt-content div.informaltable table tr{border-bottom:none}#sbo-rt-content div.informaltable table tr:nth-of-type(even){background-color:transparent}#sbo-rt-content div.informaltable td,#sbo-rt-content div.informaltable th{border:#9d9d9d 1px solid}#sbo-rt-content div.table-title,#sbo-rt-content table caption{font-weight:normal;font-style:italic;font-family:serif;font-size:1em;margin:10px 0 10px 0 !important;padding:0;page-break-after:avoid;text-align:left !important}#sbo-rt-content table code{font-size:smaller}#sbo-rt-content div.equation,#sbo-rt-content div[data-type="equation"]{margin:10px 0 15px 0 !important}#sbo-rt-content div.equation-title,#sbo-rt-content div[data-type="equation"] h5{font-style:italic;font-weight:normal;font-family:serif !important;font-size:90%;margin:20px 0 10px 0 !important;page-break-after:avoid}#sbo-rt-content div.equation-contents{margin-left:20px}#sbo-rt-content span.inlinemediaobject{height:.85em;display:inline-block;margin-bottom:.2em}#sbo-rt-content span.inlinemediaobject img{margin:0;height:.85em}#sbo-rt-content div.informalequation{margin:20px 0 20px 20px;width:75%}#sbo-rt-content div.informalequation img{width:75%}#sbo-rt-content div.index{text-indent:0}#sbo-rt-content div.index li{line-height:140%}#sbo-rt-content div.index a.indexterm{color:#8e0012}#sbo-rt-content div.index ul,#sbo-rt-content div[data-type="index"] ul{list-style-type:none;padding-left:0;margin-left:0}#sbo-rt-content div.index ul li{padding-left:0;margin-left:0}#sbo-rt-content div.index ul li ul li{margin-left:1em}#sbo-rt-content code.boolean,#sbo-rt-content .navy{color:rgb(0,0,128);}#sbo-rt-content code.character,#sbo-rt-content .olive{color:rgb(128,128,0);}#sbo-rt-content code.comment,#sbo-rt-content .blue{color:rgb(0,0,255);}#sbo-rt-content code.conditional,#sbo-rt-content .limegreen{color:rgb(50,205,50);}#sbo-rt-content code.constant,#sbo-rt-content .darkorange{color:rgb(255,140,0);}#sbo-rt-content code.debug,#sbo-rt-content .darkred{color:rgb(139,0,0);}#sbo-rt-content code.define,#sbo-rt-content .darkgoldenrod,#sbo-rt-content .gold{color:rgb(184,134,11);}#sbo-rt-content code.delimiter,#sbo-rt-content .dimgray{color:rgb(105,105,105);}#sbo-rt-content code.error,#sbo-rt-content .red{color:rgb(255,0,0);}#sbo-rt-content code.exception,#sbo-rt-content .salmon{color:rgb(250,128,11);}#sbo-rt-content code.float,#sbo-rt-content .steelblue{color:rgb(70,130,180);}#sbo-rt-content pre code.function,#sbo-rt-content .green{color:rgb(0,128,0);}#sbo-rt-content code.identifier,#sbo-rt-content .royalblue{color:rgb(65,105,225);}#sbo-rt-content code.ignore,#sbo-rt-content .gray{color:rgb(128,128,128);}#sbo-rt-content code.include,#sbo-rt-content .purple{color:rgb(128,0,128);}#sbo-rt-content code.keyword,#sbo-rt-content .sienna{color:rgb(160,82,45);}#sbo-rt-content code.label,#sbo-rt-content .deeppink{color:rgb(255,20,147);}#sbo-rt-content code.macro,#sbo-rt-content .orangered{color:rgb(255,69,0);}#sbo-rt-content code.number,#sbo-rt-content .brown{color:rgb(165,42,42);}#sbo-rt-content code.operator,#sbo-rt-content .black{color:#000;}#sbo-rt-content code.preCondit,#sbo-rt-content .teal{color:rgb(0,128,128);}#sbo-rt-content code.preProc,#sbo-rt-content .fuschia{color:rgb(255,0,255);}#sbo-rt-content code.repeat,#sbo-rt-content .indigo{color:rgb(75,0,130);}#sbo-rt-content code.special,#sbo-rt-content .saddlebrown{color:rgb(139,69,19);}#sbo-rt-content code.specialchar,#sbo-rt-content .magenta{color:rgb(255,0,255);}#sbo-rt-content code.specialcomment,#sbo-rt-content .seagreen{color:rgb(46,139,87);}#sbo-rt-content code.statement,#sbo-rt-content .forestgreen{color:rgb(34,139,34);}#sbo-rt-content code.storageclass,#sbo-rt-content .plum{color:rgb(221,160,221);}#sbo-rt-content code.string,#sbo-rt-content .darkred{color:rgb(139,0,0);}#sbo-rt-content code.structure,#sbo-rt-content .chocolate{color:rgb(210,106,30);}#sbo-rt-content code.tag,#sbo-rt-content .darkcyan{color:rgb(0,139,139);}#sbo-rt-content code.todo,#sbo-rt-content .black{color:#000;}#sbo-rt-content code.type,#sbo-rt-content .mediumslateblue{color:rgb(123,104,238);}#sbo-rt-content code.typedef,#sbo-rt-content .darkgreen{color:rgb(0,100,0);}#sbo-rt-content code.underlined{text-decoration:underline;}#sbo-rt-content pre code.hll{background-color:#ffc}#sbo-rt-content pre code.c{color:#09F;font-style:italic}#sbo-rt-content pre code.err{color:#A00}#sbo-rt-content pre code.k{color:#069;font-weight:bold}#sbo-rt-content pre code.o{color:#555}#sbo-rt-content pre code.cm{color:#35586C;font-style:italic}#sbo-rt-content pre code.cp{color:#099}#sbo-rt-content pre code.c1{color:#35586C;font-style:italic}#sbo-rt-content pre code.cs{color:#35586C;font-weight:bold;font-style:italic}#sbo-rt-content pre code.gd{background-color:#FCC}#sbo-rt-content pre code.ge{font-style:italic}#sbo-rt-content pre code.gr{color:#F00}#sbo-rt-content pre code.gh{color:#030;font-weight:bold}#sbo-rt-content pre code.gi{background-color:#CFC}#sbo-rt-content pre code.go{color:#000}#sbo-rt-content pre code.gp{color:#009;font-weight:bold}#sbo-rt-content pre code.gs{font-weight:bold}#sbo-rt-content pre code.gu{color:#030;font-weight:bold}#sbo-rt-content pre code.gt{color:#9C6}#sbo-rt-content pre code.kc{color:#069;font-weight:bold}#sbo-rt-content pre code.kd{color:#069;font-weight:bold}#sbo-rt-content pre code.kn{color:#069;font-weight:bold}#sbo-rt-content pre code.kp{color:#069}#sbo-rt-content pre code.kr{color:#069;font-weight:bold}#sbo-rt-content pre code.kt{color:#078;font-weight:bold}#sbo-rt-content pre code.m{color:#F60}#sbo-rt-content pre code.s{color:#C30}#sbo-rt-content pre code.na{color:#309}#sbo-rt-content pre code.nb{color:#366}#sbo-rt-content pre code.nc{color:#0A8;font-weight:bold}#sbo-rt-content pre code.no{color:#360}#sbo-rt-content pre code.nd{color:#99F}#sbo-rt-content pre code.ni{color:#999;font-weight:bold}#sbo-rt-content pre code.ne{color:#C00;font-weight:bold}#sbo-rt-content pre code.nf{color:#C0F}#sbo-rt-content pre code.nl{color:#99F}#sbo-rt-content pre code.nn{color:#0CF;font-weight:bold}#sbo-rt-content pre code.nt{color:#309;font-weight:bold}#sbo-rt-content pre code.nv{color:#033}#sbo-rt-content pre code.ow{color:#000;font-weight:bold}#sbo-rt-content pre code.w{color:#bbb}#sbo-rt-content pre code.mf{color:#F60}#sbo-rt-content pre code.mh{color:#F60}#sbo-rt-content pre code.mi{color:#F60}#sbo-rt-content pre code.mo{color:#F60}#sbo-rt-content pre code.sb{color:#C30}#sbo-rt-content pre code.sc{color:#C30}#sbo-rt-content pre code.sd{color:#C30;font-style:italic}#sbo-rt-content pre code.s2{color:#C30}#sbo-rt-content pre code.se{color:#C30;font-weight:bold}#sbo-rt-content pre code.sh{color:#C30}#sbo-rt-content pre code.si{color:#A00}#sbo-rt-content pre code.sx{color:#C30}#sbo-rt-content pre code.sr{color:#3AA}#sbo-rt-content pre code.s1{color:#C30}#sbo-rt-content pre code.ss{color:#A60}#sbo-rt-content pre code.bp{color:#366}#sbo-rt-content pre code.vc{color:#033}#sbo-rt-content pre code.vg{color:#033}#sbo-rt-content pre code.vi{color:#033}#sbo-rt-content pre code.il{color:#F60}#sbo-rt-content pre code.g{color:#050}#sbo-rt-content pre code.l{color:#C60}#sbo-rt-content pre code.l{color:#F90}#sbo-rt-content pre code.n{color:#008}#sbo-rt-content pre code.nx{color:#008}#sbo-rt-content pre code.py{color:#96F}#sbo-rt-content pre code.p{color:#000}#sbo-rt-content pre code.x{color:#F06}#sbo-rt-content div.blockquote_sampler_toc{width:95%;margin:5px 5px 5px 10px !important}#sbo-rt-content div{font-family:serif;text-align:left}#sbo-rt-content .gray-background,#sbo-rt-content .reverse-video{background:#2E2E2E;color:#FFF}#sbo-rt-content .light-gray-background{background:#A0A0A0}#sbo-rt-content .preserve-whitespace{white-space:pre-wrap}#sbo-rt-content span.gray{color:#4C4C4C}#sbo-rt-content div[data-type="equation"].fifty-percent img{width:50%}</style><script> // <![CDATA[
    var g = {
      position_cache: {
        
          "chapter": "/api/v1/book/9781491962282/chapter/ch03.html",
          "book_id": "9781491962282",
          "chapter_uri": "ch03.html",
          "position": 1.94296272015,
          "user_uuid": "2d2acfb7-1cff-4dc7-9037-8ffbac19b02e",
          "next_chapter_uri": "/library/view/hands-on-machine-learning/9781491962282/ch04.html"
        
      },
      title: "Hands\u002DOn Machine Learning with Scikit\u002DLearn and TensorFlow",
      author_list: "Aurélien Géron",
      format: "book",
      source: "application/epub+zip",
      is_system_book: true,
      is_public: false,
      loaded_from_server: true,
      allow_scripts: false,
      has_mathml: false,
      show_ios_app_teaser: false
    };
    // ]]></script><script src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/modernizr.js"></script><script>
    
      
        

        

        
          
            window.PUBLIC_ANNOTATIONS = true;
          
        

      

      
        window.MOBILE_PUBLIC_ANNOTATIONS = false;
      

    

    
      window.PRIVACY_CONTROL_OVERRIDE = false;
    

    
      window.PRIVACY_CONTROL_SWITCH = true;
    

    
      window.PUBLISHER_PAGES = true;
    

      window.SBO = {
        "constants": {
          "SITB_ENDPOINT": "https://www.safaribooksonline.com/api/v2/sitb/",
          "SEARCH_SELECT_ENDPOINT": "https://www.safaribooksonline.com/api/v2/search/select/",
          "ENABLE_ONLINE_TRAINING": true
        }
      };
  </script><link rel="canonical" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch03.html"><meta name="description" content=" Chapter 3. Classification In Chapter&nbsp;1 we mentioned that the most common supervised learning tasks are regression (predicting values) and classification (predicting classes). In Chapter&nbsp;2 we explored a regression ... "><meta property="og:title" content="3. Classification"><meta itemprop="isPartOf" content="/library/view/hands-on-machine-learning/9781491962282/"><meta itemprop="name" content="3. Classification"><meta property="og:url" itemprop="url" content="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch03.html"><meta property="og:site_name" content="Safari"><meta property="og:image" itemprop="thumbnailUrl" content="https://www.safaribooksonline.com/library/cover/9781491962282/"><meta property="og:description" itemprop="description" content=" Chapter 3. Classification In Chapter&nbsp;1 we mentioned that the most common supervised learning tasks are regression (predicting values) and classification (predicting classes). In Chapter&nbsp;2 we explored a regression ... "><meta itemprop="inLanguage" content="en"><meta itemprop="publisher" content="O'Reilly Media, Inc."><meta property="og:type" content="book"><meta property="og:book:isbn" itemprop="isbn" content="9781491962299"><meta property="og:book:author" itemprop="author" content="Aurélien Géron"><meta property="og:book:tag" itemprop="about" content="Core Programming"><meta property="og:book:tag" itemprop="about" content="Engineering"><meta property="og:book:tag" itemprop="about" content="Python"><meta name="twitter:card" content="summary"><meta name="twitter:site" content="@safari"><style type="text/css" id="font-styles" data-template="#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-size: &lt;%= font_size %&gt; !important; }"></style><style type="text/css" id="font-family" data-template="#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-family: &lt;%= font_family %&gt; !important; }"></style><style type="text/css" id="column-width" data-template="#sbo-rt-content { max-width: &lt;%= column_width %&gt;% !important; margin: 0 auto !important; }"></style><noscript><meta http-equiv="refresh" content="0; url=/library/no-js/" /></noscript><script type="text/javascript">
  (function(i,s,o,g,r,a,m) {
    i['GoogleAnalyticsObject']=r;
    i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();
    a=s.createElement(o),m=s.getElementsByTagName(o)[0];
    a.async=1;
    a.src=g;
    m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  var matches = document.cookie.match(/BrowserCookie\s*=\s*([a-f0-9\-]{36})/),
      user_uuid = null;

  if (matches && matches.length === 2) {
    user_uuid = matches[1];
  }


  ga('create', 'UA-39299553-7', {'userId': '2d2acfb7-1cff-4dc7-9037-8ffbac19b02e' });



  
    ga('set', 'dimension1', 'Trial');
  


ga('set', 'dimension6', user_uuid);


  ga('set', 'dimension2', '2d2acfb7-1cff-4dc7-9037-8ffbac19b02e');
  






//enable enhanced link tracking
ga('require', 'linkid', 'linkid.js');

// reading interface will track pageviews itself
if (document.location.pathname.indexOf("/library/view") !== 0) {
  ga('send', 'pageview');
}
</script><script>
    (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    '//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-5P4V6Z');
  </script><script defer="defer" src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/vendor.js"></script><script defer="defer" src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/reader.js"></script><script async="" src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/MathJax.js"></script><style id="annotator-dynamic-style">.annotator-adder, .annotator-outer, .annotator-notice {
  z-index: 100019;
}
.annotator-filter {
  z-index: 100009;
}</style><script src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/a_002.js"></script><script src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/a_003.js"></script></head>


<body class="reading sidenav nav-collapsed  scalefonts subscribe-panel library" data-gr-c-s-loaded="true">

    
  
  <noscript> 
    <iframe src="//www.googletagmanager.com/ns.html?id=GTM-5P4V6Z"
            height="0" width="0"
            style="display:none;visibility:hidden">
    </iframe>
  </noscript>
  



    
      <div class="hide working" role="status">
        <div class="working-image"></div>
      </div>
      <div class="sbo-site-nav">
        





<a href="#container" class="skip">Skip to content</a><header class="topbar t-topbar"><nav role="navigation" class="js-site-nav"><ul class="topnav"><li class="t-logo"><a href="https://www.safaribooksonline.com/home/" class="l0 None safari-home nav-icn js-keyboard-nav-home"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width="20" height="20" version="1.1" fill="#4A3C31"><desc>Safari Home Icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M4 9.9L4 9.9 4 18 16 18 16 9.9 10 4 4 9.9ZM2.6 8.1L2.6 8.1 8.7 1.9 10 0.5 11.3 1.9 17.4 8.1 18 8.7 18 9.5 18 18.1 18 20 16.1 20 3.9 20 2 20 2 18.1 2 9.5 2 8.7 2.6 8.1Z"></path><rect x="10" y="12" width="3" height="7"></rect><rect transform="translate(18.121320, 10.121320) rotate(-315.000000) translate(-18.121320, -10.121320) " x="16.1" y="9.1" width="4" height="2"></rect><rect transform="translate(2.121320, 10.121320) scale(-1, 1) rotate(-315.000000) translate(-2.121320, -10.121320) " x="0.1" y="9.1" width="4" height="2"></rect></g></svg><span>Safari Home</span></a></li><li><a href="https://www.safaribooksonline.com/r/" class="t-recommendations-nav l0 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>recommendations icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M50 25C50 18.2 44.9 12.5 38.3 11.7 37.5 5.1 31.8 0 25 0 18.2 0 12.5 5.1 11.7 11.7 5.1 12.5 0 18.2 0 25 0 31.8 5.1 37.5 11.7 38.3 12.5 44.9 18.2 50 25 50 31.8 50 37.5 44.9 38.3 38.3 44.9 37.5 50 31.8 50 25ZM25 3.1C29.7 3.1 33.6 6.9 34.4 11.8 30.4 12.4 26.9 15.1 25 18.8 23.1 15.1 19.6 12.4 15.6 11.8 16.4 6.9 20.3 3.1 25 3.1ZM34.4 15.6C33.6 19.3 30.7 22.2 27.1 22.9 27.8 19.2 30.7 16.3 34.4 15.6ZM22.9 22.9C19.2 22.2 16.3 19.3 15.6 15.6 19.3 16.3 22.2 19.2 22.9 22.9ZM3.1 25C3.1 20.3 6.9 16.4 11.8 15.6 12.4 19.6 15.1 23.1 18.8 25 15.1 26.9 12.4 30.4 11.8 34.4 6.9 33.6 3.1 29.7 3.1 25ZM22.9 27.1C22.2 30.7 19.3 33.6 15.6 34.4 16.3 30.7 19.2 27.8 22.9 27.1ZM25 46.9C20.3 46.9 16.4 43.1 15.6 38.2 19.6 37.6 23.1 34.9 25 31.3 26.9 34.9 30.4 37.6 34.4 38.2 33.6 43.1 29.7 46.9 25 46.9ZM27.1 27.1C30.7 27.8 33.6 30.7 34.4 34.4 30.7 33.6 27.8 30.7 27.1 27.1ZM38.2 34.4C37.6 30.4 34.9 26.9 31.3 25 34.9 23.1 37.6 19.6 38.2 15.6 43.1 16.4 46.9 20.3 46.9 25 46.9 29.7 43.1 33.6 38.2 34.4Z"></path></g></svg><span>Recommended</span></a></li><li><a href="https://www.safaribooksonline.com/s/" class="t-queue-nav l0 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>queue icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M25 29.2C25.4 29.2 25.8 29.1 26.1 28.9L48.7 16.8C49.5 16.4 50 15.5 50 14.6 50 13.7 49.5 12.8 48.7 12.4L26.1 0.3C25.4-0.1 24.6-0.1 23.9 0.3L1.3 12.4C0.5 12.8 0 13.7 0 14.6 0 15.5 0.5 16.4 1.3 16.8L23.9 28.9C24.2 29.1 24.6 29.2 25 29.2ZM7.3 14.6L25 5.2 42.7 14.6 25 24 7.3 14.6ZM48.7 22.4L47.7 21.9 25 34.2 2.3 21.9 1.3 22.4C0.5 22.9 0 23.7 0 24.7 0 25.6 0.5 26.5 1.3 26.9L23.9 39.3C24.2 39.5 24.6 39.6 25 39.6 25.4 39.6 25.8 39.5 26.1 39.3L48.7 26.9C49.5 26.5 50 25.6 50 24.7 50 23.7 49.5 22.9 48.7 22.4ZM48.7 32.8L47.7 32.3 25 44.6 2.3 32.3 1.3 32.8C0.5 33.3 0 34.1 0 35.1 0 36 0.5 36.9 1.3 37.3L23.9 49.7C24.2 49.9 24.6 50 25 50 25.4 50 25.8 49.9 26.1 49.7L48.7 37.3C49.5 36.9 50 36 50 35.1 50 34.1 49.5 33.3 48.7 32.8Z"></path></g></svg><span>
                  Queue
              </span></a></li><li class="search"><a href="#" class="t-search-nav trigger nav-icn l0" data-dropdown-selector=".searchbox"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>search icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M31.3 0C20.9 0 12.5 8.4 12.5 18.8 12.5 22.5 13.6 25.9 15.4 28.8L1.2 42.9C-0.4 44.5-0.4 47.2 1.2 48.8 2 49.6 3.1 50 4.2 50 5.2 50 6.3 49.6 7.1 48.8L21.2 34.6C24.1 36.5 27.5 37.5 31.3 37.5 41.6 37.5 50 29.1 50 18.8 50 8.4 41.6 0 31.3 0ZM31.3 31.3C24.4 31.3 18.8 25.6 18.8 18.8 18.8 11.9 24.4 6.3 31.3 6.3 38.1 6.3 43.8 11.9 43.8 18.8 43.8 25.6 38.1 31.3 31.3 31.3Z"></path></g></svg><span>Search</span></a></li><li class="usermenu dropdown"><a href="#" class="trigger l0 nav-icn nav-dropdown"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width="20" height="20" version="1.1" fill="#4A3C31"><desc>navigation arrow</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M0.1 12.5L9.7 3.1C9.8 3 9.9 3 10 3 10.1 3 10.2 3 10.3 3.1L19.9 12.5C20 12.5 20 12.6 20 12.8 20 12.9 20 13 19.9 13L17 15.9C16.9 16 16.8 16 16.7 16 16.5 16 16.4 16 16.4 15.9L10 9.7 3.6 15.9C3.6 16 3.5 16 3.3 16 3.2 16 3.1 16 3 15.9L0.1 13C0 12.9 0 12.8 0 12.7 0 12.7 0 12.6 0.1 12.5Z"></path></g></svg><span>Expand Nav</span></a><div class="drop-content"><ul><li><a href="https://www.safaribooksonline.com/history/" class="t-recent-nav l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>recent items icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M25 0C11.2 0 0 11.2 0 25 0 38.8 11.2 50 25 50 38.8 50 50 38.8 50 25 50 11.2 38.8 0 25 0ZM6.3 25C6.3 14.6 14.6 6.3 25 6.3 35.4 6.3 43.8 14.6 43.8 25 43.8 35.4 35.4 43.8 25 43.8 14.6 43.8 6.3 35.4 6.3 25ZM31.8 31.5C32.5 30.5 32.4 29.2 31.6 28.3L27.1 23.8 27.1 12.8C27.1 11.5 26.2 10.4 25 10.4 23.9 10.4 22.9 11.5 22.9 12.8L22.9 25.7 28.8 31.7C29.2 32.1 29.7 32.3 30.2 32.3 30.8 32.3 31.3 32 31.8 31.5Z"></path></g></svg><span>History</span></a></li><li><a href="https://www.safaribooksonline.com/topics" class="t-topics-link l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 55" width="20" height="20" version="1.1" fill="#4A3C31"><desc>topics icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M25 55L50 41.262 50 13.762 25 0 0 13.762 0 41.262 25 55ZM8.333 37.032L8.333 17.968 25 8.462 41.667 17.968 41.667 37.032 25 46.538 8.333 37.032Z"></path></g></svg><span>Topics</span></a></li><li><a href="https://www.safaribooksonline.com/tutorials/" class="l1 nav-icn t-tutorials-nav js-toggle-menu-item None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width="20" height="20" version="1.1" fill="#4A3C31"><desc>tutorials icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M15.8 18.2C15.8 18.2 15.9 18.2 16 18.2 16.1 18.2 16.2 18.2 16.4 18.2 16.5 18.2 16.7 18.1 16.9 18 17 17.9 17.1 17.8 17.2 17.7 17.3 17.6 17.4 17.5 17.4 17.4 17.5 17.2 17.6 16.9 17.6 16.7 17.6 16.6 17.6 16.5 17.6 16.4 17.5 16.2 17.5 16.1 17.4 15.9 17.3 15.8 17.2 15.6 17 15.5 16.8 15.3 16.6 15.3 16.4 15.2 16.2 15.2 16 15.2 15.8 15.2 15.7 15.2 15.5 15.3 15.3 15.4 15.2 15.4 15.1 15.5 15 15.7 14.9 15.8 14.8 15.9 14.7 16 14.7 16.1 14.6 16.3 14.6 16.4 14.6 16.5 14.6 16.6 14.6 16.6 14.6 16.7 14.6 16.9 14.6 17 14.6 17.1 14.7 17.3 14.7 17.4 14.8 17.6 15 17.7 15.1 17.9 15.2 18 15.3 18 15.5 18.1 15.5 18.1 15.6 18.2 15.7 18.2 15.7 18.2 15.7 18.2 15.8 18.2L15.8 18.2ZM9.4 11.5C9.5 11.5 9.5 11.5 9.6 11.5 9.7 11.5 9.9 11.5 10 11.5 10.2 11.5 10.3 11.4 10.5 11.3 10.6 11.2 10.8 11.1 10.9 11 10.9 10.9 11 10.8 11.1 10.7 11.2 10.5 11.2 10.2 11.2 10 11.2 9.9 11.2 9.8 11.2 9.7 11.2 9.5 11.1 9.4 11 9.2 10.9 9.1 10.8 8.9 10.6 8.8 10.5 8.7 10.3 8.6 10 8.5 9.9 8.5 9.7 8.5 9.5 8.5 9.3 8.5 9.1 8.6 9 8.7 8.8 8.7 8.7 8.8 8.6 9 8.5 9.1 8.4 9.2 8.4 9.3 8.2 9.5 8.2 9.8 8.2 10 8.2 10.1 8.2 10.2 8.2 10.3 8.2 10.5 8.3 10.6 8.4 10.7 8.5 10.9 8.6 11.1 8.7 11.2 8.9 11.3 9 11.4 9.1 11.4 9.2 11.4 9.3 11.5 9.3 11.5 9.3 11.5 9.4 11.5 9.4 11.5L9.4 11.5ZM3 4.8C3.1 4.8 3.1 4.8 3.2 4.8 3.4 4.8 3.5 4.8 3.7 4.8 3.8 4.8 4 4.7 4.1 4.6 4.3 4.5 4.4 4.4 4.5 4.3 4.6 4.2 4.6 4.1 4.7 4 4.8 3.8 4.8 3.5 4.8 3.3 4.8 3.1 4.8 3 4.8 2.9 4.7 2.8 4.7 2.6 4.6 2.5 4.5 2.3 4.4 2.2 4.2 2.1 4 1.9 3.8 1.9 3.6 1.8 3.5 1.8 3.3 1.8 3.1 1.8 2.9 1.8 2.7 1.9 2.6 2 2.4 2.1 2.3 2.2 2.2 2.3 2.1 2.4 2 2.5 2 2.6 1.8 2.8 1.8 3 1.8 3.3 1.8 3.4 1.8 3.5 1.8 3.6 1.8 3.8 1.9 3.9 2 4 2.1 4.2 2.2 4.4 2.4 4.5 2.5 4.6 2.6 4.7 2.7 4.7 2.8 4.7 2.9 4.8 2.9 4.8 3 4.8 3 4.8 3 4.8L3 4.8ZM13.1 15.2C13.2 15.1 13.2 15.1 13.2 15.1 13.3 14.9 13.4 14.7 13.6 14.5 13.8 14.2 14.1 14 14.4 13.8 14.7 13.6 15.1 13.5 15.5 13.4 15.9 13.4 16.3 13.4 16.7 13.5 17.2 13.5 17.6 13.7 17.9 13.9 18.2 14.1 18.5 14.4 18.7 14.7 18.9 15 19.1 15.3 19.2 15.6 19.3 15.9 19.4 16.1 19.4 16.4 19.4 17 19.3 17.5 19.1 18.1 19 18.3 18.9 18.5 18.7 18.7 18.5 19 18.3 19.2 18 19.4 17.7 19.6 17.3 19.8 16.9 19.9 16.6 20 16.3 20 16 20 15.8 20 15.6 20 15.4 19.9 15.4 19.9 15.4 19.9 15.4 19.9 15.2 19.9 15 19.8 14.9 19.8 14.8 19.7 14.7 19.7 14.6 19.7 14.4 19.6 14.3 19.5 14.1 19.3 13.7 19.1 13.4 18.7 13.2 18.4 13.1 18.1 12.9 17.8 12.9 17.5 12.8 17.3 12.8 17.1 12.8 16.9L3.5 14.9C3.3 14.9 3.1 14.8 3 14.8 2.7 14.7 2.4 14.5 2.1 14.3 1.7 14 1.4 13.7 1.2 13.3 1 13 0.9 12.6 0.8 12.3 0.7 12 0.7 11.7 0.7 11.4 0.7 11 0.8 10.5 1 10.1 1.1 9.8 1.3 9.5 1.6 9.2 1.8 8.9 2.1 8.7 2.4 8.5 2.8 8.3 3.2 8.1 3.6 8.1 3.9 8 4.2 8 4.5 8 4.6 8 4.8 8 4.9 8.1L6.8 8.5C6.8 8.4 6.8 8.4 6.8 8.4 6.9 8.2 7.1 8 7.2 7.8 7.5 7.5 7.7 7.3 8 7.1 8.4 6.9 8.7 6.8 9.1 6.7 9.5 6.7 10 6.7 10.4 6.8 10.8 6.8 11.2 7 11.5 7.2 11.8 7.5 12.1 7.7 12.4 8 12.6 8.3 12.7 8.6 12.8 8.9 12.9 9.2 13 9.4 13 9.7 13 9.7 13 9.8 13 9.8 13.6 9.9 14.2 10.1 14.9 10.2 15 10.2 15 10.2 15.1 10.2 15.3 10.2 15.4 10.2 15.6 10.2 15.8 10.1 16 10 16.2 9.9 16.4 9.8 16.5 9.6 16.6 9.5 16.8 9.2 16.9 8.8 16.9 8.5 16.9 8.3 16.9 8.2 16.8 8 16.8 7.8 16.7 7.7 16.6 7.5 16.5 7.3 16.3 7.2 16.2 7.1 16 7 15.9 6.9 15.8 6.9 15.7 6.9 15.6 6.8 15.5 6.8L6.2 4.8C6.2 5 6 5.2 5.9 5.3 5.7 5.6 5.5 5.8 5.3 6 4.9 6.2 4.5 6.4 4.1 6.5 3.8 6.6 3.5 6.6 3.2 6.6 3 6.6 2.8 6.6 2.7 6.6 2.6 6.6 2.6 6.5 2.6 6.5 2.5 6.5 2.3 6.5 2.1 6.4 1.8 6.3 1.6 6.1 1.3 6 1 5.7 0.7 5.4 0.5 5 0.3 4.7 0.2 4.4 0.1 4.1 0 3.8 0 3.6 0 3.3 0 2.8 0.1 2.2 0.4 1.7 0.5 1.5 0.7 1.3 0.8 1.1 1.1 0.8 1.3 0.6 1.6 0.5 2 0.3 2.3 0.1 2.7 0.1 3.1 0 3.6 0 4 0.1 4.4 0.2 4.8 0.3 5.1 0.5 5.5 0.8 5.7 1 6 1.3 6.2 1.6 6.3 1.9 6.4 2.3 6.5 2.5 6.6 2.7 6.6 3 6.6 3 6.6 3.1 6.6 3.1 9.7 3.8 12.8 4.4 15.9 5.1 16.1 5.1 16.2 5.2 16.4 5.2 16.7 5.3 16.9 5.5 17.2 5.6 17.5 5.9 17.8 6.2 18.1 6.5 18.3 6.8 18.4 7.2 18.6 7.5 18.6 7.9 18.7 8.2 18.7 8.6 18.7 9 18.6 9.4 18.4 9.8 18.3 10.1 18.2 10.3 18 10.6 17.8 10.9 17.5 11.1 17.3 11.3 16.9 11.6 16.5 11.8 16 11.9 15.7 12 15.3 12 15 12 14.8 12 14.7 12 14.5 11.9 13.9 11.8 13.3 11.7 12.6 11.5 12.5 11.7 12.4 11.9 12.3 12 12.1 12.3 11.9 12.5 11.7 12.7 11.3 12.9 10.9 13.1 10.5 13.2 10.2 13.3 9.9 13.3 9.6 13.3 9.4 13.3 9.2 13.3 9 13.2 9 13.2 9 13.2 9 13.2 8.8 13.2 8.7 13.2 8.5 13.1 8.2 13 8 12.8 7.7 12.6 7.4 12.4 7.1 12 6.8 11.7 6.7 11.4 6.6 11.1 6.5 10.8 6.4 10.6 6.4 10.4 6.4 10.2 5.8 10.1 5.2 9.9 4.5 9.8 4.4 9.8 4.4 9.8 4.3 9.8 4.1 9.8 4 9.8 3.8 9.8 3.6 9.9 3.4 10 3.2 10.1 3 10.2 2.9 10.4 2.8 10.5 2.6 10.8 2.5 11.1 2.5 11.5 2.5 11.6 2.5 11.8 2.6 12 2.6 12.1 2.7 12.3 2.8 12.5 2.9 12.6 3.1 12.8 3.2 12.9 3.3 13 3.5 13.1 3.6 13.1 3.7 13.1 3.8 13.2 3.9 13.2L13.1 15.2 13.1 15.2Z"></path></g></svg><span>Tutorials</span></a></li><li class="nav-offers flyout-parent"><a href="#" class="l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>offers icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M35.9 20.6L27 15.5C26.1 15 24.7 15 23.7 15.5L14.9 20.6C13.9 21.1 13.2 22.4 13.2 23.4L13.2 41.4C13.2 42.4 13.9 43.7 14.9 44.2L23.3 49C24.2 49.5 25.6 49.5 26.6 49L35.9 43.6C36.8 43.1 37.6 41.8 37.6 40.8L37.6 23.4C37.6 22.4 36.8 21.1 35.9 20.6L35.9 20.6ZM40 8.2C39.1 7.6 37.6 7.6 36.7 8.2L30.2 11.9C29.3 12.4 29.3 13.2 30.2 13.8L39.1 18.8C40 19.4 40.7 20.6 40.7 21.7L40.7 39C40.7 40.1 41.4 40.5 42.4 40L48.2 36.6C49.1 36.1 49.8 34.9 49.8 33.8L49.8 15.6C49.8 14.6 49.1 13.3 48.2 12.8L40 8.2 40 8.2ZM27 10.1L33.6 6.4C34.5 5.9 34.5 5 33.6 4.5L26.6 0.5C25.6 0 24.2 0 23.3 0.5L16.7 4.2C15.8 4.7 15.8 5.6 16.7 6.1L23.7 10.1C24.7 10.6 26.1 10.6 27 10.1ZM10.1 21.7C10.1 20.6 10.8 19.4 11.7 18.8L20.6 13.8C21.5 13.2 21.5 12.4 20.6 11.9L13.6 7.9C12.7 7.4 11.2 7.4 10.3 7.9L1.6 12.8C0.7 13.3 0 14.6 0 15.6L0 33.8C0 34.9 0.7 36.1 1.6 36.6L8.4 40.5C9.3 41 10.1 40.6 10.1 39.6L10.1 21.7 10.1 21.7Z"></path></g></svg><span>Offers &amp; Deals</span></a><ul class="flyout"><li><a href="https://www.safaribooksonline.com/oreilly-newsletters/" class="l2 nav-icn"><span>Newsletters</span></a></li></ul></li><li class="nav-highlights"><a href="https://www.safaribooksonline.com/u/0011N00001APXw3QAH/" class="t-highlights-nav l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 35" width="20" height="20" version="1.1" fill="#4A3C31"><desc>highlights icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M13.325 18.071L8.036 18.071C8.036 11.335 12.36 7.146 22.5 5.594L22.5 0C6.37 1.113 0 10.632 0 22.113 0 29.406 3.477 35 10.403 35 15.545 35 19.578 31.485 19.578 26.184 19.578 21.556 17.211 18.891 13.325 18.071L13.325 18.071ZM40.825 18.071L35.565 18.071C35.565 11.335 39.86 7.146 50 5.594L50 0C33.899 1.113 27.5 10.632 27.5 22.113 27.5 29.406 30.977 35 37.932 35 43.045 35 47.078 31.485 47.078 26.184 47.078 21.556 44.74 18.891 40.825 18.071L40.825 18.071Z"></path></g></svg><span>Highlights</span></a></li><li><a href="https://www.safaribooksonline.com/u/" class="t-settings-nav l1 js-settings nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 53" width="20" height="20" version="1.1" fill="#4A3C31"><desc>settings icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M44.6 29.6C44.7 28.6 44.8 27.5 44.8 26.5 44.8 25.5 44.7 24.4 44.6 23.4L49.6 19C50 18.8 50.1 18.3 49.9 17.9 48.9 14.7 47.1 11.7 44.9 9.1 44.6 8.8 44.2 8.7 43.8 8.8L37.4 11.1C35.8 9.8 34 8.7 32.1 8L30.9 1.4C30.8 0.9 30.4 0.6 30 0.5 26.7-0.2 23.3-0.2 20 0.5 19.6 0.6 19.2 0.9 19.1 1.4L17.9 8C16 8.7 14.1 9.8 12.6 11.1L6.2 8.8C5.8 8.7 5.4 8.8 5.1 9.1 2.9 11.7 1.1 14.7 0.1 17.9 -0.1 18.3 0 18.8 0.4 19L5.4 23.4C5.3 24.4 5.2 25.5 5.2 26.5 5.2 27.5 5.3 28.6 5.4 29.6L0.4 34C0 34.2-0.1 34.7 0.1 35.1 1.1 38.3 2.9 41.4 5.1 43.9 5.4 44.2 5.8 44.4 6.2 44.2L12.6 42C14.1 43.2 16 44.3 17.9 45L19.1 51.7C19.2 52.1 19.6 52.5 20 52.5 21.6 52.8 23.3 53 25 53 26.7 53 28.4 52.8 30 52.5 30.4 52.5 30.8 52.1 30.9 51.7L32.1 45C34 44.3 35.8 43.2 37.4 42L43.8 44.2C44.2 44.4 44.6 44.2 44.9 43.9 47.1 41.4 48.9 38.3 49.9 35.1 50.1 34.7 50 34.2 49.6 34L44.6 29.6ZM25 36.4C19.6 36.4 15.2 32 15.2 26.5 15.2 21 19.6 16.6 25 16.6 30.4 16.6 34.8 21 34.8 26.5 34.8 32 30.4 36.4 25 36.4Z"></path></g></svg><span>Settings</span></a></li><li><a href="https://www.safaribooksonline.com/public/support" class="l1 no-icon">Support</a></li><li><a href="https://www.safaribooksonline.com/accounts/logout/" class="l1 no-icon">Sign Out</a></li></ul><ul class="profile"><li><a href="https://www.safaribooksonline.com/u/" class="l2 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 53" width="20" height="20" version="1.1" fill="#4A3C31"><desc>settings icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M44.6 29.6C44.7 28.6 44.8 27.5 44.8 26.5 44.8 25.5 44.7 24.4 44.6 23.4L49.6 19C50 18.8 50.1 18.3 49.9 17.9 48.9 14.7 47.1 11.7 44.9 9.1 44.6 8.8 44.2 8.7 43.8 8.8L37.4 11.1C35.8 9.8 34 8.7 32.1 8L30.9 1.4C30.8 0.9 30.4 0.6 30 0.5 26.7-0.2 23.3-0.2 20 0.5 19.6 0.6 19.2 0.9 19.1 1.4L17.9 8C16 8.7 14.1 9.8 12.6 11.1L6.2 8.8C5.8 8.7 5.4 8.8 5.1 9.1 2.9 11.7 1.1 14.7 0.1 17.9 -0.1 18.3 0 18.8 0.4 19L5.4 23.4C5.3 24.4 5.2 25.5 5.2 26.5 5.2 27.5 5.3 28.6 5.4 29.6L0.4 34C0 34.2-0.1 34.7 0.1 35.1 1.1 38.3 2.9 41.4 5.1 43.9 5.4 44.2 5.8 44.4 6.2 44.2L12.6 42C14.1 43.2 16 44.3 17.9 45L19.1 51.7C19.2 52.1 19.6 52.5 20 52.5 21.6 52.8 23.3 53 25 53 26.7 53 28.4 52.8 30 52.5 30.4 52.5 30.8 52.1 30.9 51.7L32.1 45C34 44.3 35.8 43.2 37.4 42L43.8 44.2C44.2 44.4 44.6 44.2 44.9 43.9 47.1 41.4 48.9 38.3 49.9 35.1 50.1 34.7 50 34.2 49.6 34L44.6 29.6ZM25 36.4C19.6 36.4 15.2 32 15.2 26.5 15.2 21 19.6 16.6 25 16.6 30.4 16.6 34.8 21 34.8 26.5 34.8 32 30.4 36.4 25 36.4Z"></path></g></svg><span>Settings</span></a><span class="l2 t-nag-notification" id="nav-nag"><strong class="trial-green">10</strong> days left in your trial.
  
  

  
    
      

<a class="" href="https://www.safaribooksonline.com/subscribe/">Subscribe</a>.


    
  

  

</span></li><li><a href="https://www.safaribooksonline.com/public/support" class="l2">Support</a></li><li><a href="https://www.safaribooksonline.com/accounts/logout/" class="l2">Sign Out</a></li></ul></div></li></ul></nav></header>


      </div>
      <div id="container" class="application" style="height: auto;">
        
          <div class="nav-container clearfix">
            


            
            
          </div>

          

  <div class="js-toc">
    
      <div class="sbo-reading-menu sbo-menu-top"><section class="sbo-toc-container toc-menu"><a href="#" class="sbo-toc-thumb"><span class="sbo-title ss-list"><h1><div class="visuallyhidden">Table of Contents for </div>
      
      Hands-On Machine Learning with Scikit-Learn and TensorFlow
      
    </h1></span></a><div class="toc-contents"></div></section></div>

    

    <div class="interface-controls interface-controls-top">
      <ul class="interface-control-btns js-bitlist js-reader">
        <li class="js-search-in-archive search-in-archive t-search-in-archive"><a href="#" title="Search in archive" class="js-search-controls search-controls"><span class="icon">Search in book...</span></a><form class="search-archive-bar js-search-form"><input name="query" placeholder="Search inside this book..." autocomplete="off" type="search"></form><div class="search-archive-results"><div class="js-sitb-results-region"></div></div></li><li class="queue-control"><button type="button" class="rec-fav ss-queue js-queue js-current-chapter-queue" data-queue-endpoint="/api/v1/book/9781491962282/chapter/ch05.html" data-for-analytics="9781491962282:ch05.html" aria-label="Add to Queue"><span>Add to Queue</span></button></li><li class="js-font-control-panel font-control-activator"><a href="#" data-push-state="false" id="font-controls" title="Change font size" aria-label="Change font size"><span class="icon">Toggle Font Controls</span></a></li><li class="dropdown sharing-controls"><a href="#" class="trigger" data-push-state="false" title="Share" aria-label="Share"><i class="fa fa-share"></i></a><ul class="social-sharing dropdown-menu"><li><a class="twitter share-button t-twitter" target="_blank" aria-label="Share this section on Twitter" title="Share this section on Twitter" href="https://twitter.com/share?url=https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch03.html&amp;text=Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow&amp;via=safari"><span>Twitter</span></a></li><li><a class="facebook share-button t-facebook" target="_blank" aria-label="Share this section on Facebook" title="Share this section on Facebook" href="https://www.facebook.com/sharer/sharer.php?u=https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch03.html"><span>Facebook</span></a></li><li><a class="googleplus share-button t-googleplus" target="_blank" aria-label="Share this secton on Google Plus" title="Share this secton on Google Plus" href="https://plus.google.com/share?url=https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch03.html"><span>Google Plus</span></a></li><li><a class="email share-button t-email" aria-label="Share this section via email" title="Share this section via email" href="mailto:?subject=Safari:%203.%20Classification&amp;body=https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch03.html%0D%0Afrom%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow%0D%0A"><span>Email</span></a></li></ul></li>
      </ul>
    </div>

    <section role="document">
	  <div class="t-sbo-prev sbo-prev sbo-nav-top">
  
    
      
        <a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch04.html" class="prev nav-link">
      
          <span aria-hidden="true" class="pagination-label t-prev-label">Prev</span>
          <span class="visuallyhidden">Previous Chapter</span>
          <div class="pagination-title t-prev-title">4. Training Models</div>
        </a>
    
  
  </div>

  <div class="t-sbo-next sbo-next sbo-nav-top">
  
    
      
        <a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch06.html" class="next nav-link">
      
          <span aria-hidden="true" class="pagination-label t-next-label">Next</span>
          <span class="visuallyhidden">Next Chapter</span>
          <div class="pagination-title t-next-title">6. Decision Trees</div>
        </a>
    
  
  </div>



<div id="sbo-rt-content"><div class="annotator-wrapper"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 5. Support Vector Machines"><div class="chapter" id="svm_chapter">
<h1><span class="label">Chapter 5. </span>Support Vector Machines</h1>


<p>A <em>Support Vector Machine</em> (SVM) is <a data-type="indexterm" data-primary="Support Vector Machines (SVMs)" id="svm5"></a>a
 very powerful and versatile Machine Learning model, capable of 
performing linear or nonlinear classification, regression, and even 
outlier detection. It is one of the most popular models in Machine 
Learning, and anyone interested in Machine Learning should have it in 
their toolbox. SVMs are particularly well suited for classification of 
complex but small- or medium-sized datasets.</p>

<p>This chapter will explain the core concepts of SVMs, how to use them, and how they work.</p>






<section data-type="sect1" data-pdf-bookmark="Linear SVM Classification"><div class="sect1" id="idm140583012787824">
<h1>Linear SVM Classification</h1>

<p>The <a data-type="indexterm" data-primary="Support Vector Machines (SVMs)" data-secondary="linear classification" id="svm5lc"></a><a data-type="indexterm" data-primary="linear SVM classification" id="lsvmc5"></a><a data-type="indexterm" data-primary="linear models" data-secondary="SVM" id="lm5svm"></a>fundamental idea behind SVMs is best explained with some pictures. <a data-type="xref" href="#large_margin_classification_plot">Figure&nbsp;5-1</a> shows part of the iris dataset that was introduced at the end of <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch04.html#linear_models_chapter">Chapter&nbsp;4</a>. The two classes can clearly be separated easily with a straight line (they are <em>linearly separable</em>).
 The left plot shows the decision boundaries of three possible linear 
classifiers. The model whose decision boundary is represented by the 
dashed line is so bad that it does not even separate the classes 
properly. The other two models work perfectly on this training set, but 
their decision boundaries come so close to the instances that these 
models will probably not perform as well on new instances. In contrast, 
the solid line in the plot on the right represents the decision boundary
 of an SVM classifier; this line not only separates the two classes but 
also stays as far away from the closest training instances as possible. 
You can think of an SVM classifier as fitting the widest possible street
 (represented by the parallel dashed lines) between the classes. This is
 <a data-type="indexterm" data-primary="large margin classification" id="lmc5"></a>called <em>large margin classification</em>.</p>

<figure><div id="large_margin_classification_plot" class="figure">
<img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/mlst_0501.png" alt="mlst 0501" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_0501.png" width="3600" height="810">
<h6><span class="label">Figure 5-1. </span>Large margin classification</h6>
</div></figure>

<p>Notice that adding more training instances “off the street” will not 
affect the decision boundary at all: it is fully determined (or 
“supported”) by the instances located on the edge of the street. These 
instances are called <a data-type="indexterm" data-primary="support vectors" id="idm140583012775600"></a>the <em>support vectors</em> (they are circled in <a data-type="xref" href="#large_margin_classification_plot">Figure&nbsp;5-1</a>).</p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>SVMs are <a data-type="indexterm" data-primary="large margin classification" data-startref="lmc5" id="idm140583012772416"></a>sensitive to the feature scales, as you can see in <a data-type="xref" href="#sensitivity_to_feature_scales_plot">Figure&nbsp;5-2</a>:
 on the left plot, the vertical scale is much larger than the horizontal
 scale, so the widest possible street is close to horizontal. After 
feature scaling (e.g., using Scikit-Learn’s <code>StandardScaler</code>), <a data-type="indexterm" data-primary="Scikit-Learn" data-secondary="sklearn.preprocessing.StandardScaler" id="idm140583012769856"></a>the decision boundary looks much better (on the right plot).</p>
</div>

<figure><div id="sensitivity_to_feature_scales_plot" class="figure">
<img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/mlst_0502.png" alt="mlst 0502" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_0502.png" width="1440" height="359">
<h6><span class="label">Figure 5-2. </span>Sensitivity to feature scales</h6>
</div></figure>








<section data-type="sect2" data-pdf-bookmark="Soft Margin Classification"><div class="sect2" id="idm140583012766496">
<h2>Soft Margin Classification</h2>

<p>If we <a data-type="indexterm" data-primary="soft margin classification" id="smc5"></a>strictly impose that all instances be off the street and on the right side, this is called <em>hard margin classification</em>. <a data-type="indexterm" data-primary="hard margin classification" id="hmc5"></a>There
 are two main issues with hard margin classification. First, it only 
works if the data is linearly separable, and second it is quite 
sensitive to outliers. <a data-type="xref" href="#sensitivity_to_outliers_plot">Figure&nbsp;5-3</a>
 shows the iris dataset with just one additional outlier: on the left, 
it is impossible to find a hard margin, and on the right the decision 
boundary ends up very different from the one we saw in <a data-type="xref" href="#large_margin_classification_plot">Figure&nbsp;5-1</a> without the outlier, and it will probably not generalize as well.</p>

<figure><div id="sensitivity_to_outliers_plot" class="figure">
<img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/mlst_0503.png" alt="mlst 0503" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_0503.png" width="1440" height="295">
<h6><span class="label">Figure 5-3. </span>Hard margin sensitivity to outliers</h6>
</div></figure>

<p>To avoid these issues <a data-type="indexterm" data-primary="hard margin classification" data-startref="hmc5" id="idm140583012757504"></a>it
 is preferable to use a more flexible model. The objective is to find a 
good balance between keeping the street as large as possible and 
limiting the <em>margin violations</em> <a data-type="indexterm" data-primary="margin violations" id="idm140583012755744"></a>(i.e., instances that end up in the middle of the street or even on the wrong side). This is called <em>soft margin classification</em>.</p>

<p>In Scikit-Learn’s SVM classes, you can control this balance using the <code>C</code> hyperparameter: a smaller <code>C</code> value leads to a wider street but more margin violations. <a data-type="xref" href="#regularization_plot">Figure&nbsp;5-4</a>
 shows the decision boundaries and margins of two soft margin SVM 
classifiers on a nonlinearly separable dataset. On the left, using a 
high <code>C</code> value the classifier makes fewer margin violations but ends up with a smaller margin. On the right, using a low <code>C</code>
 value the margin is much larger, but many instances end up on the 
street. However, it seems likely that the second classifier will 
generalize better: in fact even on this training set it makes fewer 
prediction errors, since most of the margin violations are actually on 
the correct side of the decision boundary.</p>

<figure><div id="regularization_plot" class="figure">
<img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/mlst_0504.png" alt="mlst 0504" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_0504.png" width="3600" height="960">
<h6><span class="label">Figure 5-4. </span>Fewer margin violations versus large margin</h6>
</div></figure>
<div data-type="tip"><h6>Tip</h6>
<p>If your SVM model is <a data-type="indexterm" data-primary="overfitting" id="idm140583012747808"></a>overfitting, you can try regularizing it by reducing <code>C</code>.</p>
</div>

<p>The following Scikit-Learn code loads the iris dataset, scales the features, and then trains a linear SVM model <a data-type="indexterm" data-primary="Scikit-Learn" data-secondary="sklearn.svm.LinearSVC" id="sklsvmlsvcch5"></a>(using the <code>LinearSVC</code> class with <em>C</em> = 1 and the <em>hinge loss</em> function, described shortly) to detect Iris-Virginica flowers. The resulting model is represented on <a data-type="indexterm" data-primary="Scikit-Learn" data-secondary="sklearn.preprocessing.StandardScaler" id="sklpssch5"></a><a data-type="indexterm" data-primary="Scikit-Learn" data-secondary="sklearn.pipeline.Pipeline" id="sklpipepipech5"></a><a data-type="indexterm" data-primary="Scikit-Learn" data-secondary="sklearn.datasets.load_iris()" id="idm140583012740288"></a>the right of <a data-type="xref" href="#regularization_plot">Figure&nbsp;5-4</a>.</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">import</code> <code class="nn">numpy</code> <code class="kn">as</code> <code class="nn">np</code>
<code class="kn">from</code> <code class="nn">sklearn</code> <code class="kn">import</code> <code class="n">datasets</code>
<code class="kn">from</code> <code class="nn">sklearn.pipeline</code> <code class="kn">import</code> <code class="n">Pipeline</code>
<code class="kn">from</code> <code class="nn">sklearn.preprocessing</code> <code class="kn">import</code> <code class="n">StandardScaler</code>
<code class="kn">from</code> <code class="nn">sklearn.svm</code> <code class="kn">import</code> <code class="n">LinearSVC</code>

<code class="n">iris</code> <code class="o">=</code> <code class="n">datasets</code><code class="o">.</code><code class="n">load_iris</code><code class="p">()</code>
<code class="n">X</code> <code class="o">=</code> <code class="n">iris</code><code class="p">[</code><code class="s2">"data"</code><code class="p">][:,</code> <code class="p">(</code><code class="mi">2</code><code class="p">,</code> <code class="mi">3</code><code class="p">)]</code>  <code class="c1"># petal length, petal width</code>
<code class="n">y</code> <code class="o">=</code> <code class="p">(</code><code class="n">iris</code><code class="p">[</code><code class="s2">"target"</code><code class="p">]</code> <code class="o">==</code> <code class="mi">2</code><code class="p">)</code><code class="o">.</code><code class="n">astype</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">float64</code><code class="p">)</code>  <code class="c1"># Iris-Virginica</code>

<code class="n">svm_clf</code> <code class="o">=</code> <code class="n">Pipeline</code><code class="p">([</code>
        <code class="p">(</code><code class="s2">"scaler"</code><code class="p">,</code> <code class="n">StandardScaler</code><code class="p">()),</code>
        <code class="p">(</code><code class="s2">"linear_svc"</code><code class="p">,</code> <code class="n">LinearSVC</code><code class="p">(</code><code class="n">C</code><code class="o">=</code><code class="mi">1</code><code class="p">,</code> <code class="n">loss</code><code class="o">=</code><code class="s2">"hinge"</code><code class="p">)),</code>
    <code class="p">])</code>

<code class="n">svm_clf</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">y</code><code class="p">)</code></pre>

<p>Then, as usual, you can use the model to make predictions:</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">svm_clf</code><code class="o">.</code><code class="n">predict</code><code class="p">([[</code><code class="mf">5.5</code><code class="p">,</code> <code class="mf">1.7</code><code class="p">]])</code>
<code class="go">array([ 1.])</code></pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Unlike Logistic Regression classifiers, SVM classifiers do not output probabilities for each class.</p>
</div>

<p>Alternatively, <a data-type="indexterm" data-primary="Scikit-Learn" data-secondary="sklearn.svm.SVC" id="idm140583012340992"></a>you could use the <code>SVC</code> class, using <code>SVC(kernel="linear", C=1)</code>, but it is much slower, especially with large training sets, so it is not recommended. Another option is to use the <code>SGDClassifier</code> class, with <code>SGDClassifier(loss="hinge", alpha=1/(m*C))</code>. This applies regular <a data-type="indexterm" data-primary="Stochastic Gradient Descent (SGD)" id="idm140583012338064"></a><a data-type="indexterm" data-primary="Gradient Descent (GD)" data-secondary="Stochastic GD" id="idm140583012337392"></a>Stochastic Gradient Descent (see <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch04.html#linear_models_chapter">Chapter&nbsp;4</a>) to train a linear SVM classifier. It does not converge as fast as the <code>LinearSVC</code>
 class, but it can be useful to handle huge datasets that do not fit in 
memory (out-of-core training), or to handle online classification tasks.</p>
<div data-type="tip"><h6>Tip</h6>
<p>The <code>LinearSVC</code> class regularizes the bias term, so you 
should center the training set first by subtracting its mean. This is 
automatic if you scale the data using the <code>StandardScaler</code>. Moreover, make sure you set the <code>loss</code> hyperparameter to <code>"hinge"</code>, as it is not the default value. Finally, for better performance you should set the <code>dual</code> hyperparameter to <code>False</code>, unless there are more features than training instances (we will discuss duality later in the <a data-type="indexterm" data-primary="soft margin classification" data-startref="smc5" id="idm140583012326096"></a><a data-type="indexterm" data-primary="Support Vector Machines (SVMs)" data-secondary="linear classification" data-startref="svm5lc" id="idm140583012325152"></a><a data-type="indexterm" data-primary="linear models" data-secondary="SVM" data-startref="lm5svm" id="idm140583012323968"></a><a data-type="indexterm" data-primary="linear SVM classification" data-startref="lsvmc5" id="idm140583012322752"></a>chapter).</p>
</div>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Nonlinear SVM Classification"><div class="sect1" id="idm140583012765872">
<h1>Nonlinear SVM Classification</h1>

<p>Although <a data-type="indexterm" data-primary="Support Vector Machines (SVMs)" data-secondary="nonlinear classification" id="svm5nc"></a><a data-type="indexterm" data-primary="nonlinear SVM classification" id="nsvmc5"></a>linear
 SVM classifiers are efficient and work surprisingly well in many cases,
 many datasets are not even close to being linearly separable. One 
approach to handling nonlinear datasets is to add more features, such as
 <a data-type="indexterm" data-primary="nonlinear SVM classification" data-secondary="with polynomial features" data-secondary-sortas="polynomial features" id="nsvmc5wpf"></a><a data-type="indexterm" data-primary="polynomial features, adding" id="pf5"></a>polynomial features (as you did in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch04.html#linear_models_chapter">Chapter&nbsp;4</a>); in some cases this can result in a linearly separable dataset. Consider the left plot in <a data-type="xref" href="#higher_dimensions_plot">Figure&nbsp;5-5</a>: it represents a simple dataset with just one feature <em>x</em><sub>1</sub>. This dataset is not linearly separable, as you can see. But if you add a second feature <em>x</em><sub>2</sub> = (<em>x</em><sub>1</sub>)<sup>2</sup>, the resulting 2D dataset is perfectly linearly separable.</p>

<figure><div id="higher_dimensions_plot" class="figure">
<img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/mlst_0505.png" alt="mlst 0505" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_0505.png" width="1440" height="540">
<h6><span class="label">Figure 5-5. </span>Adding features to make a dataset linearly separable</h6>
</div></figure>

<p>To implement this idea using <a data-type="indexterm" data-primary="Scikit-Learn" data-secondary="sklearn.svm.LinearSVC" data-startref="sklsvmlsvcch5" id="idm140583012626128"></a>  <a data-type="indexterm" data-primary="Scikit-Learn" data-secondary="sklearn.preprocessing.PolynomialFeatures" id="idm140583012624752"></a><a data-type="indexterm" data-primary="Scikit-Learn" data-secondary="Pipeline constructor" id="idm140583012623680"></a><a data-type="indexterm" data-primary="Scikit-Learn" data-secondary="sklearn.datasets.make_moons()" id="idm140583012622736"></a><a data-type="indexterm" data-primary="Scikit-Learn" data-secondary="sklearn.pipeline.Pipeline" data-startref="sklpipepipech5" id="idm140583012621776"></a>Scikit-Learn, you can create a <code>Pipeline</code> containing a <code>PolynomialFeatures</code> transformer (discussed in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch04.html#polynomial_regression">“Polynomial Regression”</a>), followed by a <code>StandardScaler</code> and a <code>LinearSVC</code>. Let’s test this on the moons dataset (see <a data-type="xref" href="#moons_polynomial_svc_plot">Figure&nbsp;5-6</a>):</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">sklearn.datasets</code> <code class="kn">import</code> <code class="n">make_moons</code>
<code class="kn">from</code> <code class="nn">sklearn.pipeline</code> <code class="kn">import</code> <code class="n">Pipeline</code>
<code class="kn">from</code> <code class="nn">sklearn.preprocessing</code> <code class="kn">import</code> <code class="n">PolynomialFeatures</code>

<code class="n">polynomial_svm_clf</code> <code class="o">=</code> <code class="n">Pipeline</code><code class="p">([</code>
        <code class="p">(</code><code class="s2">"poly_features"</code><code class="p">,</code> <code class="n">PolynomialFeatures</code><code class="p">(</code><code class="n">degree</code><code class="o">=</code><code class="mi">3</code><code class="p">)),</code>
        <code class="p">(</code><code class="s2">"scaler"</code><code class="p">,</code> <code class="n">StandardScaler</code><code class="p">()),</code>
        <code class="p">(</code><code class="s2">"svm_clf"</code><code class="p">,</code> <code class="n">LinearSVC</code><code class="p">(</code><code class="n">C</code><code class="o">=</code><code class="mi">10</code><code class="p">,</code> <code class="n">loss</code><code class="o">=</code><code class="s2">"hinge"</code><code class="p">))</code>
    <code class="p">])</code>

<code class="n">polynomial_svm_clf</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">y</code><code class="p">)</code></pre>

<figure><div id="moons_polynomial_svc_plot" class="figure">
<img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/mlst_0506.png" alt="mlst 0506" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_0506.png" width="1440" height="939">
<h6><span class="label">Figure 5-6. </span>Linear SVM classifier using polynomial features</h6>
</div></figure>








<section data-type="sect2" data-pdf-bookmark="Polynomial Kernel"><div class="sect2" id="idm140583010076160">
<h2>Polynomial Kernel</h2>

<p>Adding <a data-type="indexterm" data-primary="nonlinear SVM classification" data-secondary="with polynomial features" data-secondary-sortas="polynomial features" data-startref="nsvmc5wpf" id="idm140583010074624"></a><a data-type="indexterm" data-primary="polynomial features, adding" data-startref="pf5" id="idm140583010073136"></a><a data-type="indexterm" data-primary="nonlinear SVM classification" data-secondary="polynomial kernel" id="nsvmc5pk"></a><a data-type="indexterm" data-primary="polynomial kernel" id="pk5"></a><a data-type="indexterm" data-primary="kernel trick" id="idm140583010070048"></a><a data-type="indexterm" data-primary="kernels" id="k5"></a>polynomial
 features is simple to implement and can work great with all sorts of 
Machine Learning algorithms (not just SVMs), but at a low polynomial 
degree it cannot deal with very complex datasets, and with a high 
polynomial degree it creates a huge number of features, making the model
 too slow.</p>

<p>Fortunately, when using SVMs you can apply an almost miraculous mathematical technique called the <em>kernel trick</em>
 (it is explained in a moment). It makes it possible to get the same 
result as if you added many polynomial features, even with very 
high-degree polynomials, without actually having to add them. So there 
is no combinatorial explosion of the number of features since you don’t 
actually add any features. This trick is implemented by the <code>SVC</code> class. <a data-type="indexterm" data-primary="Scikit-Learn" data-secondary="sklearn.svm.SVC" id="idm140583010066304"></a>Let’s test it on the moons dataset:</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">sklearn.svm</code> <code class="kn">import</code> <code class="n">SVC</code>
<code class="n">poly_kernel_svm_clf</code> <code class="o">=</code> <code class="n">Pipeline</code><code class="p">([</code>
        <code class="p">(</code><code class="s2">"scaler"</code><code class="p">,</code> <code class="n">StandardScaler</code><code class="p">()),</code>
        <code class="p">(</code><code class="s2">"svm_clf"</code><code class="p">,</code> <code class="n">SVC</code><code class="p">(</code><code class="n">kernel</code><code class="o">=</code><code class="s2">"poly"</code><code class="p">,</code> <code class="n">degree</code><code class="o">=</code><code class="mi">3</code><code class="p">,</code> <code class="n">coef0</code><code class="o">=</code><code class="mi">1</code><code class="p">,</code> <code class="n">C</code><code class="o">=</code><code class="mi">5</code><code class="p">))</code>
    <code class="p">])</code>
<code class="n">poly_kernel_svm_clf</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">y</code><code class="p">)</code></pre>

<p>This code <a data-type="indexterm" data-primary="Scikit-Learn" data-secondary="sklearn.preprocessing.StandardScaler" data-startref="sklpssch5" id="idm140583012552128"></a>trains an SVM classifier using a 3<sup>rd</sup>-degree polynomial kernel. It is represented on the left of <a data-type="xref" href="#moons_kernelized_polynomial_svc_plot">Figure&nbsp;5-7</a>. On the right is another SVM classifier using a 10<sup>th</sup>-degree
 polynomial kernel. Obviously, if your model is overfitting, you might 
want to reduce the polynomial degree. Conversely, if it is underfitting,
 you can try increasing it. The hyperparameter <code>coef0</code> controls how much the model is influenced by high-degree polynomials versus low-degree polynomials.</p>

<figure><div id="moons_kernelized_polynomial_svc_plot" class="figure">
<img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/mlst_0507.png" alt="mlst 0507" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_0507.png" width="1440" height="496">
<h6><span class="label">Figure 5-7. </span>SVM classifiers with a polynomial kernel</h6>
</div></figure>
<div data-type="tip"><h6>Tip</h6>
<p>A common approach to find the right <a data-type="indexterm" data-primary="hyperparameters" id="idm140583012510816"></a>hyperparameter values is to use grid <a data-type="indexterm" data-primary="grid search" id="idm140583012509984"></a>search (see <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch02.html#project_chapter">Chapter&nbsp;2</a>).
 It is often faster to first do a very coarse grid search, then a finer 
grid search around the best values found. Having a good sense of what 
each hyperparameter actually does can also help you search in the right 
part of the <a data-type="indexterm" data-primary="nonlinear SVM classification" data-secondary="polynomial kernel" data-startref="nsvmc5pk" id="idm140583012508112"></a><a data-type="indexterm" data-primary="polynomial kernel" data-startref="pk5" id="idm140583012506832"></a>hyperparameter space.</p>
</div>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Adding Similarity Features"><div class="sect2" id="idm140583012505504">
<h2>Adding Similarity Features</h2>

<p>Another <a data-type="indexterm" data-primary="nonlinear SVM classification" data-secondary="similarity features, adding" id="nsvmc5sfa"></a><a data-type="indexterm" data-primary="similarity function" id="sf5"></a>technique to tackle nonlinear problems is to add features computed using a <em>similarity function</em> that measures how much each instance resembles a particular <em>landmark</em>. <a data-type="indexterm" data-primary="landmarks" id="l5"></a>For example, let’s take the one-dimensional dataset discussed earlier and add two landmarks to it at <em>x</em><sub>1</sub> = –2 and <em>x</em><sub>1</sub> = 1 (see the left plot in <a data-type="xref" href="#kernel_method_plot">Figure&nbsp;5-8</a>). Next, let’s define the similarity function to be the <a data-type="indexterm" data-primary="Radial Basis Function (RBF)" id="idm140583012496960"></a><a data-type="indexterm" data-primary="Gaussian RBF" id="idm140583012496224"></a>Gaussian <em>Radial Basis Function</em> (<em>RBF</em>) with <em>γ</em> = 0.3 (see <a data-type="xref" href="#grbf_function">Equation 5-1</a>).</p>
<div id="grbf_function" data-type="equation"><h5><span class="label">Equation 5-1. </span>Gaussian RBF</h5><img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_47.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_47.png" width="782" height="81">
</div>

<p>It is a bell-shaped function varying from 0 (very far away from the 
landmark) to 1 (at the landmark). Now we are ready to compute the new 
features. For example, let’s look at the instance <em>x</em><sub>1</sub> = –1: it is located at a distance of 1 from the first landmark, and 2 from the second landmark. Therefore its new features are <em>x</em><sub>2</sub> = exp (–0.3 × 1<sup>2</sup>) ≈ 0.74 and <em>x</em><sub>3</sub> = exp (–0.3 × 2<sup>2</sup>) ≈ 0.30. The plot on the right of <a data-type="xref" href="#kernel_method_plot">Figure&nbsp;5-8</a> shows the transformed dataset (dropping the original features). As you can see, it is now linearly <span class="keep-together">separable</span>.</p>

<figure><div id="kernel_method_plot" class="figure">
<img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/mlst_0508.png" alt="mlst 0508" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_0508.png" width="1440" height="500">
<h6><span class="label">Figure 5-8. </span>Similarity features using the Gaussian RBF</h6>
</div></figure>

<p>You may wonder how to select the landmarks. The simplest approach is 
to create a landmark at the location of each and every instance in the 
dataset. This creates many dimensions and thus increases the chances 
that the transformed training set will be linearly separable. The 
downside is that a training set with <em>m</em> instances and <em>n</em> features gets transformed into a training set with <em>m</em> instances and <em>m</em>
 features (assuming you drop the original features). If your training 
set is very large, you end up with an equally large number of <a data-type="indexterm" data-primary="landmarks" data-startref="l5" id="idm140583012481440"></a><a data-type="indexterm" data-primary="nonlinear SVM classification" data-secondary="similarity features, adding" data-startref="nsvmc5sfa" id="idm140583012480464"></a><a data-type="indexterm" data-primary="similarity function" data-startref="sf5" id="idm140583012479264"></a>features.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Gaussian RBF Kernel"><div class="sect2" id="idm140583012478192">
<h2>Gaussian RBF Kernel</h2>

<p>Just <a data-type="indexterm" data-primary="nonlinear SVM classification" data-secondary="Gaussian RBF kernel" id="nsvm5grbf"></a><a data-type="indexterm" data-primary="Gaussian RBF kernel" id="grbfk5"></a>like
 the polynomial features method, the similarity features method can be 
useful with any Machine Learning algorithm, but it may be 
computationally expensive to compute all the additional features, 
especially on large training sets. However, once again the <a data-type="indexterm" data-primary="kernel trick" id="idm140583012473808"></a>kernel
 trick does its SVM magic: it makes it possible to obtain a similar 
result as if you had added many similarity features, without actually 
having to add them. Let’s try the Gaussian RBF kernel using <a data-type="indexterm" data-primary="Scikit-Learn" data-secondary="sklearn.svm.SVC" id="sklsvmsvcch5"></a><a data-type="indexterm" data-primary="Scikit-Learn" data-secondary="sklearn.preprocessing.StandardScaler" id="idm140583010041808"></a>the <code>SVC</code> class:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">rbf_kernel_svm_clf</code> <code class="o">=</code> <code class="n">Pipeline</code><code class="p">([</code>
        <code class="p">(</code><code class="s2">"scaler"</code><code class="p">,</code> <code class="n">StandardScaler</code><code class="p">()),</code>
        <code class="p">(</code><code class="s2">"svm_clf"</code><code class="p">,</code> <code class="n">SVC</code><code class="p">(</code><code class="n">kernel</code><code class="o">=</code><code class="s2">"rbf"</code><code class="p">,</code> <code class="n">gamma</code><code class="o">=</code><code class="mi">5</code><code class="p">,</code> <code class="n">C</code><code class="o">=</code><code class="mf">0.001</code><code class="p">))</code>
    <code class="p">])</code>
<code class="n">rbf_kernel_svm_clf</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">y</code><code class="p">)</code></pre>

<p>This model is represented on the bottom left of <a data-type="xref" href="#moons_rbf_svc_plot">Figure&nbsp;5-9</a>. The other plots show models trained with different values of hyperparameters <code>gamma</code> (<em>γ</em>) and <em>C</em>. Increasing <code>gamma</code> makes the bell-shape curve narrower (see the left plot of <a data-type="xref" href="#kernel_method_plot">Figure&nbsp;5-8</a>),
 and as a result each instance’s range of influence is smaller: the 
decision boundary ends up being more irregular, wiggling around 
individual instances. Conversely, a small <code>gamma</code> <a data-type="indexterm" data-primary="gamma value" id="idm140583010012064"></a>value
 makes the bell-shaped curve wider, so instances have a larger range of 
influence, and the decision boundary ends up smoother. So <em>γ</em> acts like a regularization hyperparameter: if your model is <a data-type="indexterm" data-primary="overfitting" id="idm140583010010624"></a>overfitting, you should reduce it, and if it is <a data-type="indexterm" data-primary="underfitting" id="idm140583010009792"></a>underfitting, you should increase it (similar to the <code>C</code> hyperparameter).</p>

<figure><div id="moons_rbf_svc_plot" class="figure">
<img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/mlst_0509.png" alt="mlst 0509" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_0509.png" width="1440" height="903">
<h6><span class="label">Figure 5-9. </span>SVM classifiers using an RBF kernel</h6>
</div></figure>

<p>Other kernels exist but are used much more rarely. For example, some kernels are specialized for specific data structures. <em>String kernels</em> <a data-type="indexterm" data-primary="string kernels" id="idm140583010005632"></a>are sometimes used when classifying text documents or DNA sequences (e.g., using the <em>string subsequence kernel</em> or kernels based on <a data-type="indexterm" data-primary="Levenshtein distance" id="idm140583010004384"></a>the <em>Levenshtein distance</em>).</p>
<div data-type="tip"><h6>Tip</h6>
<p>With so many kernels to choose from, how can you decide which one to 
use? As a rule of thumb, you should always try the linear kernel first 
(remember that <code>LinearSVC</code> <a data-type="indexterm" data-primary="Scikit-Learn" data-secondary="sklearn.svm.LinearSVC" id="sklsvmlsvcch5part2"></a>is much faster than <code>SVC(kernel="linear")</code>),
 especially if the training set is very large or if it has plenty of 
features. If the training set is not too large, you should try the 
Gaussian RBF kernel as well; it works well in most cases. Then if you 
have spare time and computing power, you can also experiment with a few 
other kernels using cross-validation and grid search, especially if 
there are kernels specialized for your training set’s data <a data-type="indexterm" data-primary="nonlinear SVM classification" data-secondary="Gaussian RBF kernel" data-startref="nsvm5grbf" id="idm140583009999152"></a><a data-type="indexterm" data-primary="Gaussian RBF kernel" data-startref="grbfk5" id="idm140583009997936"></a><a data-type="indexterm" data-primary="kernels" data-startref="k5" id="idm140583009996992"></a>structure.</p>
</div>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Computational Complexity"><div class="sect2" id="idm140583009995792">
<h2>Computational Complexity</h2>

<p>The<a data-type="indexterm" data-primary="nonlinear SVM classification" data-secondary="computational complexity" id="idm140583009994032"></a><a data-type="indexterm" data-primary="computational complexity" id="idm140583009961280"></a> <code>LinearSVC</code> class is based on the <em>liblinear</em> library, <a data-type="indexterm" data-primary="liblinear library" id="idm140583009959760"></a>which implements an <a href="http://goo.gl/R635CH">optimized algorithm</a> for linear SVMs.<sup><a data-type="noteref" id="idm140583009958208-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch05.html#idm140583009958208" class="totri-footnote">1</a></sup>
 It does not support the kernel trick, but it scales almost linearly 
with the number of training instances and the number of features: its 
training time complexity is roughly <em>O</em>(<em>m</em> × <em>n</em>).</p>

<p>The algorithm takes longer if you require a very high precision. This is controlled by the <a data-type="indexterm" data-primary="tolerance hyperparameter" id="idm140583009955584"></a><a data-type="indexterm" data-primary="hyperparameters" id="idm140583009954864"></a>tolerance hyperparameter <em>ϵ</em> (called <code>tol</code> in Scikit-Learn). In most classification tasks, the default tolerance is fine.</p>

<p>The <code>SVC</code> class is based on <a data-type="indexterm" data-primary="libsvm library" id="idm140583009951984"></a>the <em>libsvm</em> library, which implements <a href="http://goo.gl/a8HkE3">an algorithm</a> that supports the kernel trick.<sup><a data-type="noteref" id="idm140583009949968-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch05.html#idm140583009949968" class="totri-footnote">2</a></sup> The training time complexity is usually between <em>O</em>(<em>m</em><sup>2</sup> × <em>n</em>) and <em>O</em>(<em>m</em><sup>3</sup> × <em>n</em>).
 Unfortunately, this means that it gets dreadfully slow when the number 
of training instances gets large (e.g., hundreds of thousands of 
instances). This algorithm is perfect for complex but small or medium 
training sets. However, it scales well with the number of features, 
especially with <em>sparse features</em> (i.e., when each instance has 
few nonzero features). In this case, the algorithm scales roughly with 
the average number of nonzero features per instance. <a data-type="xref" href="#svm_classification_algorithm_comparison">Table&nbsp;5-1</a> compares <a data-type="indexterm" data-primary="Scikit-Learn" data-secondary="SVM classification classes" id="idm140583009944256"></a>Scikit-Learn’s SVM classification <a data-type="indexterm" data-primary="Support Vector Machines (SVMs)" data-secondary="nonlinear classification" data-startref="svm5nc" id="idm140583009943088"></a><a data-type="indexterm" data-primary="nonlinear SVM classification" data-startref="nsvmc5" id="idm140583009941792"></a>classes.</p>
<table id="svm_classification_algorithm_comparison">
<caption><span class="label">Table 5-1. </span>Comparison of Scikit-Learn classes for SVM <a data-type="indexterm" data-primary="Scikit-Learn" data-secondary="sklearn.svm.LinearSVC" data-startref="sklsvmlsvcch5part2" id="idm140583009940016"></a><a data-type="indexterm" data-primary="Scikit-Learn" data-secondary="sklearn.svm.SVC" data-startref="sklsvmsvcch5" id="idm140583009938768"></a>classification</caption>
<thead>
<tr>
<th>Class</th>
<th>Time complexity</th>
<th>Out-of-core support</th>
<th>Scaling required</th>
<th>Kernel trick</th>
</tr>
</thead>
<tbody>
<tr>
<td><p><code>LinearSVC</code></p></td>
<td><p>O(<em>m</em> × <em>n</em>)</p></td>
<td><p>No</p></td>
<td><p>Yes</p></td>
<td><p>No</p></td>
</tr>
<tr>
<td><p><code>SGDClassifier</code></p></td>
<td><p>O(<em>m</em> × <em>n</em>)</p></td>
<td><p>Yes</p></td>
<td><p>Yes</p></td>
<td><p>No</p></td>
</tr>
<tr>
<td><p><code>SVC</code></p></td>
<td><p>O(<em>m</em>² × <em>n</em>) to O(<em>m</em>³ × <em>n</em>)</p></td>
<td><p>No</p></td>
<td><p>Yes</p></td>
<td><p>Yes</p></td>
</tr>
</tbody>
</table>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="SVM Regression"><div class="sect1" id="idm140583012321120">
<h1>SVM Regression</h1>

<p>As <a data-type="indexterm" data-primary="Support Vector Machines (SVMs)" data-secondary="SVM regression" id="svm5svmr"></a>we
 mentioned earlier, the SVM algorithm is quite versatile: not only does 
it support linear and nonlinear classification, but it also supports 
linear and nonlinear regression. The trick is to reverse the objective: 
instead of trying to fit the largest possible street between two classes
 while limiting margin violations, SVM Regression tries to fit as many 
instances as possible <em>on</em> the street while limiting margin violations (i.e., instances <em>off</em> the street). The width of the street is controlled by a hyperparameter <em>ϵ</em>. <a data-type="xref" href="#svm_regression_plot">Figure&nbsp;5-10</a> shows two linear SVM Regression models trained on some random linear data, one with a large margin (<em>ϵ</em> = 1.5) and the other with a small margin (<em>ϵ</em> = 0.5).</p>

<figure><div id="svm_regression_plot" class="figure">
<img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/mlst_0510.png" alt="mlst 0510" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_0510.png" width="1440" height="610">
<h6><span class="label">Figure 5-10. </span>SVM Regression</h6>
</div></figure>

<p>Adding more training instances within the margin does not affect the model’s predictions; thus, the model is said to <a data-type="indexterm" data-primary="ε-insensitive" id="idm140583009910240"></a><a data-type="indexterm" data-primary="ε-insensitive" data-primary-sortas="epsilon-insensitive" id="idm140583009909536"></a>be <em>ϵ-insensitive</em>.</p>

<p>You can use Scikit-Learn’s <code>LinearSVR</code> class <a data-type="indexterm" data-primary="Scikit-Learn" data-secondary="sklearn.svm.LinearSVR" id="sklsvmlsvrch5"></a>to perform linear SVM Regression. The following code produces the model represented on the left of <a data-type="xref" href="#svm_regression_plot">Figure&nbsp;5-10</a> (the training data should be scaled and centered first):</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">sklearn.svm</code> <code class="kn">import</code> <code class="n">LinearSVR</code>

<code class="n">svm_reg</code> <code class="o">=</code> <code class="n">LinearSVR</code><code class="p">(</code><code class="n">epsilon</code><code class="o">=</code><code class="mf">1.5</code><code class="p">)</code>
<code class="n">svm_reg</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">y</code><code class="p">)</code></pre>

<p>To tackle nonlinear regression tasks, you can use a kernelized SVM model. For example, <a data-type="xref" href="#svm_with_polynomial_kernel_plot">Figure&nbsp;5-11</a> shows SVM Regression on a random quadratic training set, using a 2<sup>nd</sup>-degree polynomial kernel. There is little regularization on the left plot (i.e., a large <code>C</code> value), and much more regularization on the right plot (i.e., a small <code>C</code> value).</p>

<figure><div id="svm_with_polynomial_kernel_plot" class="figure">
<img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/mlst_0511.png" alt="mlst 0511" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_0511.png" width="1440" height="608">
<h6><span class="label">Figure 5-11. </span>SVM regression using a 2<sup>nd</sup>-degree polynomial kernel</h6>
</div></figure>

<p>The following code produces the model represented on the left of <a data-type="xref" href="#svm_with_polynomial_kernel_plot">Figure&nbsp;5-11</a> using Scikit-Learn’s <code>SVR</code> class (which supports the kernel trick). The <code>SVR</code> class is the regression equivalent of the <code>SVC</code> class, and <a data-type="indexterm" data-primary="Scikit-Learn" data-secondary="LinearSVR class" id="idm140583009849008"></a>the <code>LinearSVR</code> class is the regression equivalent of the <code>LinearSVC</code> class. The <code>LinearSVR</code> class scales linearly with the size of the training set (just like the <code>LinearSVC</code> class), while the <code>SVR</code> class gets much too slow when the training set grows <a data-type="indexterm" data-primary="Support Vector Machines (SVMs)" data-secondary="SVM regression" data-startref="svm5svmr" id="idm140583009845664"></a>large <a data-type="indexterm" data-primary="Scikit-Learn" data-secondary="sklearn.svm.SVC" id="idm140583009844224"></a> <a data-type="indexterm" data-primary="Scikit-Learn" data-secondary="sklearn.svm.SVR" id="idm140583009843120"></a> <a data-type="indexterm" data-primary="Scikit-Learn" data-secondary="sklearn.svm.LinearSVC" id="idm140583009842016"></a> <a data-type="indexterm" data-primary="Scikit-Learn" data-secondary="sklearn.svm.LinearSVR" data-startref="sklsvmlsvrch5" id="idm140583009840912"></a>(just like the <code>SVC</code> class).</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">sklearn.svm</code> <code class="kn">import</code> <code class="n">SVR</code>

<code class="n">svm_poly_reg</code> <code class="o">=</code> <code class="n">SVR</code><code class="p">(</code><code class="n">kernel</code><code class="o">=</code><code class="s2">"poly"</code><code class="p">,</code> <code class="n">degree</code><code class="o">=</code><code class="mi">2</code><code class="p">,</code> <code class="n">C</code><code class="o">=</code><code class="mi">100</code><code class="p">,</code> <code class="n">epsilon</code><code class="o">=</code><code class="mf">0.1</code><code class="p">)</code>
<code class="n">svm_poly_reg</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">y</code><code class="p">)</code></pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>SVMs can also be used for outlier detection; see Scikit-Learn’s documentation for more details.</p>
</div>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Under the Hood"><div class="sect1" id="idm140583009918784">
<h1>Under the Hood</h1>

<p>This <a data-type="indexterm" data-primary="Support Vector Machines (SVMs)" data-secondary="mechanics of" id="svm5mo"></a>section
 explains how SVMs make predictions and how their training algorithms 
work, starting with linear SVM classifiers. You can safely skip it and 
go straight to the exercises at the end of this chapter if you are just 
getting started with Machine Learning, and come back later when you want
 to get a deeper understanding of SVMs.</p>

<p>First, a word about notations: in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch04.html#linear_models_chapter">Chapter&nbsp;4</a> we used the convention of putting all the <a data-type="indexterm" data-primary="model parameters" id="idm140583009801120"></a>model parameters in one vector <em>θ</em>, including the bias term <em>θ</em><sub>0</sub> and the input feature weights <em>θ</em><sub>1</sub> to <em>θ</em><sub><em>n</em></sub>, and adding a bias input <em>x</em><sub>0</sub>
 = 1 to all instances. In this chapter, we will use a different 
convention, which is more convenient (and more common) when you are 
dealing with SVMs: the bias term will be called <em>b</em> and the feature weights vector will be called <strong>w</strong>. No bias feature will be added to the input <a data-type="indexterm" data-primary="feature vector" id="idm140583009795936"></a>feature vectors.</p>








<section data-type="sect2" data-pdf-bookmark="Decision Function and Predictions"><div class="sect2" id="idm140583009802000">
<h2>Decision Function and Predictions</h2>

<p>The <a data-type="indexterm" data-primary="Support Vector Machines (SVMs)" data-secondary="decision function and predictions" id="svm5modfap"></a><a data-type="indexterm" data-primary="decision function" id="df5"></a><a data-type="indexterm" data-primary="predictions" id="p5"></a>linear SVM classifier model predicts the class of a new instance <strong>x</strong> by simply computing the decision function <strong>w</strong><sup><em>T</em></sup> · <strong>x</strong> + <em>b</em> = <em>w</em><sub>1</sub> <em>x</em><sub>1</sub> + ⋯ + <em>w</em><sub><em>n</em></sub> <em>x</em><sub><em>n</em></sub> + <em>b</em>: if the result is positive, the predicted class <em>ŷ</em> is the positive class (1), or else it is the negative class (0); see <a data-type="xref" href="#linear_svm_classifier_prediction">Equation 5-2</a>.</p>
<div class="fifty-percent" id="linear_svm_classifier_prediction" data-type="equation"><h5><span class="label">Equation 5-2. </span>Linear SVM classifier prediction</h5><img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_48.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_48.png" width="640" height="158">
</div>

<p><a data-type="xref" href="#iris_3D_plot">Figure&nbsp;5-12</a> shows the decision function that corresponds to the model on the right of <a data-type="xref" href="#regularization_plot">Figure&nbsp;5-4</a>:
 it is a two-dimensional plane since this dataset has two features 
(petal width and petal length). The decision boundary is the set of 
points where the decision function is equal to 0: it is the intersection
 of two planes, which is a straight line (represented by the thick solid
 line).<sup><a data-type="noteref" id="idm140583009779104-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch05.html#idm140583009779104" class="totri-footnote">3</a></sup></p>

<figure><div id="iris_3D_plot" class="figure">
<img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/mlst_0512.png" alt="mlst 0512" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_0512.png" width="1440" height="778">
<h6><span class="label">Figure 5-12. </span>Decision function for the iris dataset</h6>
</div></figure>

<p>The dashed lines represent the points where the decision function is 
equal to 1 or –1: they are parallel and at equal distance to the 
decision boundary, forming a margin around it. Training a linear SVM 
classifier means finding the value of <strong>w</strong> and <em>b</em> that make this margin as wide as possible while avoiding margin violations (hard margin) or <a data-type="indexterm" data-primary="Support Vector Machines (SVMs)" data-secondary="decision function and predictions" data-startref="svm5modfap" id="idm140583009772224"></a><a data-type="indexterm" data-primary="decision function" data-startref="df5" id="idm140583009770896"></a><a data-type="indexterm" data-primary="predictions" data-startref="p5" id="idm140583009769952"></a>limiting them (soft margin).</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Training Objective"><div class="sect2" id="idm140583009768752">
<h2>Training Objective</h2>

<p>Consider <a data-type="indexterm" data-primary="Support Vector Machines (SVMs)" data-secondary="training objective" id="svm5moto"></a><a data-type="indexterm" data-primary="training objectives" id="to5"></a>the slope of the decision function: it is equal to the norm of the weight vector, ∥ <strong>w</strong>
 ∥. If we divide this slope by 2, the points where the decision function
 is equal to ±1 are going to be twice as far away from the decision 
boundary. In other words, dividing the slope by 2 will multiply the 
margin by 2. Perhaps this is easier to visualize in 2D in <a data-type="xref" href="#small_w_large_margin_plot">Figure&nbsp;5-13</a>. The smaller the weight vector <strong>w</strong>, the larger the margin.</p>

<figure><div id="small_w_large_margin_plot" class="figure">
<img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/mlst_0513.png" alt="mlst 0513" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_0513.png" width="1440" height="352">
<h6><span class="label">Figure 5-13. </span>A smaller weight vector results in a larger margin</h6>
</div></figure>

<p>So we want to minimize ∥ <strong>w</strong> ∥ to get a large margin. 
However, if we also want to avoid any margin violation (hard margin), 
then we need the decision function to be greater than 1 for all positive
 training instances, and lower than –1 for negative training instances. 
If we define <em>t</em><sup><em>(i)</em></sup> =  –1 for negative instances (if <em>y</em><sup><em>(i)</em></sup> = 0) and <em>t</em><sup><em>(i)</em></sup> = 1 for positive instances (if <em>y</em><sup><em>(i)</em></sup> = 1), then we can express this constraint as <em>t</em><sup><em>(i)</em></sup>(<strong>w</strong><sup><em>T</em></sup> · <strong>x</strong><sup><em>(i)</em></sup> + <em>b</em>) ≥ 1 for all instances.</p>

<p>We can therefore express the hard margin linear SVM classifier objective as the <em>constrained optimization</em> <a data-type="indexterm" data-primary="constrained optimization" id="idm140583009729856"></a>problem in <a data-type="xref" href="#hard_margin_objective">Equation 5-3</a>.</p>
<div id="hard_margin_objective" data-type="equation"><h5><span class="label">Equation 5-3. </span>Hard margin linear SVM classifier objective</h5><img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_49.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_49.png" width="1383" height="206">
</div>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>We are minimizing <img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_50.png" alt="one-half" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_50.png" width="12" height="30"><strong>w</strong><sup><em>T</em></sup> · <strong>w</strong>, which is equal to <img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_51.png" alt="one-half" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_51.png" width="12" height="30">∥ <strong>w</strong> ∥<sup>2</sup>, rather than minimizing ∥ <strong>w</strong> ∥. This is because it will give the same result (since the values of <strong>w</strong> and <em>b</em> that minimize a value also minimize half of its square), but <img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_52.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_52.png" width="12" height="30">∥ <strong>w</strong> ∥<sup>2</sup> has a nice and simple derivative (it is just <strong>w</strong>) while ∥ <strong>w</strong> ∥ is not differentiable at <strong>w</strong> = <strong>0</strong>. Optimization algorithms work much better on differentiable functions.</p>
</div>

<p>To get the soft margin objective, we need to introduce <a data-type="indexterm" data-primary="slack variable" id="idm140583009716496"></a>a <em>slack variable</em> <em>ζ</em><sup><em>(i)</em></sup> ≥ 0 for each instance:<sup><a data-type="noteref" id="idm140583009714032-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch05.html#idm140583009714032" class="totri-footnote">4</a></sup> <em>ζ</em><sup><em>(i)</em></sup> measures how much the i<sup>th</sup>
 instance is allowed to violate the margin. We now have two conflicting 
objectives: making the slack variables as small as possible to reduce 
the margin violations, and making <img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_53.png" alt="one-half" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_53.png" width="12" height="30"><strong>w</strong><sup><em>T</em></sup> · <strong>w</strong> as small as possible to increase the margin. This is where the <code>C</code> hyperparameter comes in: it allows us to define the tradeoff between these two objectives. This gives us the constrained <a data-type="indexterm" data-primary="Support Vector Machines (SVMs)" data-secondary="training objective" data-startref="svm5moto" id="idm140583009708352"></a><a data-type="indexterm" data-primary="training objectives" data-startref="to5" id="idm140583009707040"></a>optimization problem in <a data-type="xref" href="#soft_margin_objective">Equation 5-4</a>.</p>
<div id="soft_margin_objective" data-type="equation"><h5><span class="label">Equation 5-4. </span>Soft margin linear SVM classifier objective</h5><img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_54.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_54.png" width="1938" height="261">
</div>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Quadratic Programming"><div class="sect2" id="quadratic_programming_paragraph">
<h2>Quadratic Programming</h2>

<p>The <a data-type="indexterm" data-primary="Support Vector Machines (SVMs)" data-secondary="Quadratic Programming (QP) problems" id="svm5moqpp"></a><a data-type="indexterm" data-primary="Quadratic Programming (QP) Problems" id="qpp5"></a>hard
 margin and soft margin problems are both convex quadratic optimization 
problems with linear constraints. Such problems are known as <em>Quadratic Programming</em>
 (QP) problems. Many off-the-shelf solvers are available to solve QP 
problems using a variety of techniques that are outside the scope of 
this book.<sup><a data-type="noteref" id="idm140583009698768-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch05.html#idm140583009698768" class="totri-footnote">5</a></sup> The general problem formulation is given by <a data-type="xref" href="#quadratic_programming_problem_formulation">Equation 5-5</a>.</p>
<div id="quadratic_programming_problem_formulation" data-type="equation"><h5><span class="label">Equation 5-5. </span>Quadratic Programming problem</h5><img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_55.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_55.png" width="2034" height="648">
</div>

<p>Note that the expression <strong>A</strong> · <strong>p</strong> ≤ <strong>b</strong> actually defines <em>n</em><sub><em>c</em></sub> constraints: <strong>p</strong><sup><em>T</em></sup> · <strong>a</strong><sup><em>(i)</em></sup> ≤ <em>b</em><sup><em>(i)</em></sup> for <em>i</em> = 1, 2, ⋯, <em>n</em><sub><em>c</em></sub>, where <strong>a</strong><sup><em>(i)</em></sup> is the vector containing the elements of the i<sup>th</sup> row of <strong>A</strong> and <em>b</em><sup><em>(i)</em></sup> is the i<sup>th</sup> element of <strong>b</strong>.</p>

<p>You can easily verify that if you set the QP <a data-type="indexterm" data-primary="model parameters" id="idm140583009683264"></a>parameters in the following way, you get the hard margin linear SVM classifier objective:</p>

<ul>
<li>
<p><em>n</em><sub><em>p</em></sub> = <em>n</em> + 1, where <em>n</em> is the number of features (the +1 is for the bias term).</p>
</li>
<li>
<p><em>n</em><sub><em>c</em></sub> = <em>m</em>, where <em>m</em> is the number of training instances.</p>
</li>
<li>
<p><strong>H</strong> is the <em>n</em><sub><em>p</em></sub> × <em>n</em><sub><em>p</em></sub> <a data-type="indexterm" data-primary="identity matrix" id="idm140583009649152"></a>identity matrix, except with a zero in the top-left cell (to ignore the bias term).</p>
</li>
<li>
<p><strong>f</strong> = <strong>0</strong>, an <em>n</em><sub><em>p</em></sub>-dimensional vector full of 0s.</p>
</li>
<li>
<p><strong>b</strong> = <strong>1</strong>, an <em>n</em><sub><em>c</em></sub>-dimensional vector full of 1s.</p>
</li>
<li>
<p><strong>a</strong><sup><em>(i)</em></sup> = –<em>t</em><sup><em>(i)</em></sup> <img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_56.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_56.png" width="17" height="22"> <sup><em>(i)</em></sup>, where <img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_57.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_57.png" width="17" height="22"> <sup><em>(i)</em></sup> is equal to <strong>x</strong><sup><em>(i)</em></sup> with an extra bias feature <img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_58.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_58.png" width="17" height="22"> <sub>0</sub> = 1.</p>
</li>
</ul>

<p>So one way to train a hard margin linear SVM classifier is just to 
use an off-the-shelf QP solver by passing it the preceding parameters. 
The resulting vector <strong>p</strong> will contain the bias term <em>b</em> = <em>p</em><sub>0</sub> and the feature weights <em>w</em><sub><em>i</em></sub> = <em>p</em><sub><em>i</em></sub> for <em>i</em> = 1, 2, ⋯, <em>m</em>. Similarly, you can use a QP solver to solve the soft margin problem (see the exercises at the end of the chapter).</p>

<p>However, to use the kernel trick we are going to look at a different constrained optimization <a data-type="indexterm" data-primary="Support Vector Machines (SVMs)" data-secondary="Quadratic Programming (QP) problems" data-startref="svm5moqpp" id="idm140583009630992"></a><a data-type="indexterm" data-primary="Quadratic Programming (QP) Problems" data-startref="qpp5" id="idm140583009629712"></a>problem.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="The Dual Problem"><div class="sect2" id="idm140583009628496">
<h2>The Dual Problem</h2>

<p>Given <a data-type="indexterm" data-primary="Support Vector Machines (SVMs)" data-secondary="the dual problem" id="idm140583009626768"></a>a constrained optimization problem, known as <a data-type="indexterm" data-primary="primal problem" id="idm140583009625632"></a>the <em>primal problem</em>, it is possible to express a different but closely related problem, called <a data-type="indexterm" data-primary="dual problem" id="idm140583009624384"></a>its <em>dual problem</em>.
 The solution to the dual problem typically gives a lower bound to the 
solution of the primal problem, but under some conditions it can even 
have the same solutions as the primal problem. Luckily, the SVM problem 
happens to meet these conditions,<sup><a data-type="noteref" id="idm140583009622880-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch05.html#idm140583009622880" class="totri-footnote">6</a></sup> so you can choose to solve the primal problem or the dual problem; both will have the same solution. <a data-type="xref" href="#svm_dual_form">Equation 5-6</a>
 shows the dual form of the linear SVM objective (if you are interested 
in knowing how to derive the dual problem from the primal problem, see <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app03.html#svm_dual_problem_appendix">Appendix&nbsp;C</a>).</p>
<div id="svm_dual_form" data-type="equation"><h5><span class="label">Equation 5-6. </span>Dual form of the linear SVM objective</h5><img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_59.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_59.png" width="1436" height="334">
</div>

<p>Once you find the vector <img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_60.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_60.png" width="14" height="23"> that minimizes this equation (using a QP solver), you can compute <img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_61.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_61.png" width="19" height="23"> and <img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_62.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_62.png" width="11" height="24"> that minimize the primal problem by using <a data-type="xref" href="#from_alpha_to_w_and_b">Equation 5-7</a>.</p>
<div class="fifty-percent" id="from_alpha_to_w_and_b" data-type="equation"><h5><span class="label">Equation 5-7. </span>From the dual solution to the primal solution</h5><img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_63.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_63.png" width="626" height="403">
  </div>

<p>The dual problem is faster to solve than the primal when the number 
of training instances is smaller than the number of features. More 
importantly, it makes the kernel trick possible, while the primal does 
not. So what is this <a data-type="indexterm" data-primary="kernel trick" id="kt5"></a>kernel trick anyway?</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Kernelized SVM"><div class="sect2" id="idm140583009611824">
<h2>Kernelized SVM</h2>

<p>Suppose <a data-type="indexterm" data-primary="Support Vector Machines (SVMs)" data-secondary="kernelized SVM" id="svm5moksvm"></a><a data-type="indexterm" data-primary="kernelized SVM" id="ksvm5"></a>you want to apply a 2<sup>nd</sup>-degree
 polynomial transformation to a two-dimensional training set (such as 
the moons training set), then train a linear SVM classifier on the 
transformed training set. <a data-type="xref" href="#example_second_degree_polynomial_mapping">Equation 5-8</a> shows the 2<sup>nd</sup>-degree polynomial mapping function <em>ϕ</em> that you want to apply.</p>
<div class="fifty-percent" id="example_second_degree_polynomial_mapping" data-type="equation"><h5><span class="label">Equation 5-8. </span>Second-degree polynomial mapping</h5><img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_64.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_64.png" width="667" height="277">
</div>

<p>Notice that the transformed vector is three-dimensional instead of 
two-dimensional. Now let’s look at what happens to a couple of 
two-dimensional vectors, <strong>a</strong> and <strong>b</strong>, if we apply this 2<sup>nd</sup>-degree polynomial mapping and then compute the dot product of the transformed vectors (See <a data-type="xref" href="#kernel_trick_for_second_degree_polynomial_mapping">Equation 5-9</a>).</p>
<div class="pagebreak-before less_space" id="kernel_trick_for_second_degree_polynomial_mapping" data-type="equation"><h5><span class="label">Equation 5-9. </span>Kernel trick for a 2<sup>nd</sup>-degree polynomial mapping</h5>
<img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_65.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_65.png" width="1744" height="467">
</div>

<p>How about that? The dot product of the transformed vectors is equal to the square of the dot product of the original vectors: <em>ϕ</em>(<strong>a</strong>)<sup><em>T</em></sup> · <em>ϕ</em>(<strong>b</strong>) = (<strong>a</strong><sup><em>T</em></sup> · <strong>b</strong>)<sup>2</sup>.</p>

<p>Now here is the key insight: if you apply the transformation <em>ϕ</em> to all training instances, then the dual problem (see <a data-type="xref" href="#svm_dual_form">Equation 5-6</a>) will contain the dot product <em>ϕ</em>(<strong>x</strong><sup><em>(i)</em></sup>)<sup><em>T</em></sup> · <em>ϕ</em>(<strong>x</strong><sup><em>(j)</em></sup>). But if <em>ϕ</em> is the 2<sup>nd</sup>-degree polynomial transformation defined in <a data-type="xref" href="#example_second_degree_polynomial_mapping">Equation 5-8</a>, then you can replace this dot product of transformed vectors simply by <img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_66.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_66.png" width="93" height="27">. So you don’t actually need to transform the training instances at all: just replace the dot product by its square in <a data-type="xref" href="#svm_dual_form">Equation 5-6</a>.
 The result will be strictly the same as if you went through the trouble
 of actually transforming the training set then fitting a linear SVM 
algorithm, but this trick makes the whole process much more 
computationally efficient. This is the essence of the kernel trick.</p>

<p>The function <em>K</em>(<strong>a</strong>, <strong>b</strong>) = (<strong>a</strong><sup><em>T</em></sup> · <strong>b</strong>)<sup>2</sup> is called a 2<sup>nd</sup>-degree <em>polynomial kernel</em>. <a data-type="indexterm" data-primary="polynomial kernel" id="idm140583009579920"></a>In Machine Learning, a <em>kernel</em> is a function capable of computing the dot product <em>ϕ</em>(<strong>a</strong>)<sup><em>T</em></sup> · <em>ϕ</em>(<strong>b</strong>) based only on the original vectors <strong>a</strong> and <strong>b</strong>, without having to compute (or even to know about) the transformation <em>ϕ</em>. <a data-type="xref" href="#common_kernels">Equation 5-10</a> lists some of the most commonly used kernels.</p>
<div id="common_kernels" data-type="equation"><h5><span class="label">Equation 5-10. </span>Common kernels</h5>
<img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_67.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_67.png" width="1265" height="374">
</div>
<aside data-type="sidebar" epub:type="sidebar" class="pagebreak-before less_space"><div class="sidebar" id="idm140583009572256">
<h5>Mercer’s Theorem</h5>
<p>According <a data-type="indexterm" data-primary="Mercer's theorem" id="idm140583009570640"></a>to <em>Mercer’s theorem</em>, if a function <em>K</em>(<strong>a</strong>, <strong>b</strong>) respects a few mathematical conditions called <em>Mercer’s conditions</em> (<em>K</em> must be continuous, symmetric in its arguments so <em>K</em>(<strong>a</strong>, <strong>b</strong>) = <em>K</em>(<strong>b</strong>, <strong>a</strong>), etc.), then there exists a function <em>ϕ</em> that maps <strong>a</strong> and <strong>b</strong> into another space (possibly with much higher dimensions) such that <em>K</em>(<strong>a</strong>, <strong>b</strong>) = <em>ϕ</em>(<strong>a</strong>)<sup><em>T</em></sup> · <em>ϕ</em>(<strong>b</strong>). So you can use <em>K</em> as a kernel since you know <em>ϕ</em> exists, even if you don’t know what <em>ϕ</em> is. In the case of the <a data-type="indexterm" data-primary="Gaussian RBF kernel" id="idm140583009557120"></a>Gaussian RBF kernel, it can be shown that <em>ϕ</em>
 actually maps each training instance to an infinite-dimensional space, 
so it’s a good thing you don’t need to actually perform the mapping!</p>

<p>Note that some frequently used kernels (such as the Sigmoid kernel) 
don’t respect all of Mercer’s conditions, yet they generally work well 
in practice.</p>
</div></aside>

<p>There is still one loose end we must tie. <a data-type="xref" href="#from_alpha_to_w_and_b">Equation 5-7</a>
 shows how to go from the dual solution to the primal solution in the 
case of a linear SVM classifier, but if you apply the kernel trick you 
end up with equations that include <em>ϕ</em>(<em>x</em><sup><em>(i)</em></sup>). In fact, <img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_68.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_68.png" width="19" height="23"> must have the same number of dimensions as <em>ϕ</em>(<em>x</em><sup><em>(i)</em></sup>), which may be huge or even infinite, so you can’t compute it. But how can you make predictions without knowing <img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_69.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_69.png" width="19" height="23">? Well, the good news is that you can plug in the formula for <img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_70.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_70.png" width="19" height="23"> from <a data-type="xref" href="#from_alpha_to_w_and_b">Equation 5-7</a> into the decision function for a new instance <strong>x</strong><sup><em>(n)</em></sup>,
 and you get an equation with only dot products between input vectors. 
This makes it possible to use the kernel trick, once again (<a data-type="xref" href="#making_predictions_with_a_kernelized_svm">Equation 5-11</a>).</p>
<div id="making_predictions_with_a_kernelized_svm" data-type="equation"><h5><span class="label">Equation 5-11. </span>Making predictions with a kernelized SVM</h5><img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_71.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_71.png" width="1647" height="596">
</div>

<p>Note that since <em>α</em><sup><em>(i)</em></sup> ≠ 0 only for support vectors, making predictions involves computing the dot product of the new input vector <strong>x</strong><sup><em>(n)</em></sup> with only the support vectors, not all the training instances. Of course, you also need to compute the bias term <img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_72.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_72.png" width="11" height="24">, using the same trick (<a data-type="xref" href="#bias_term_using_the_kernel_trick">Equation 5-12</a>).</p>
<div class="pagebreak-before less_space" id="bias_term_using_the_kernel_trick" data-type="equation"><h5><span class="label">Equation 5-12. </span>Computing the bias term using the kernel trick</h5>
<img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_73.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_73.png" width="1967" height="651">
</div>

<p>If you are starting to get a headache, it’s perfectly normal: it’s an unfortunate side effects of the <a data-type="indexterm" data-primary="Support Vector Machines (SVMs)" data-secondary="kernelized SVM" data-startref="svm5moksvm" id="idm140583009538624"></a><a data-type="indexterm" data-primary="kernelized SVM" data-startref="ksvm5" id="idm140583009537360"></a><a data-type="indexterm" data-primary="kernel trick" data-startref="kt5" id="idm140583009536416"></a>kernel trick.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Online SVMs"><div class="sect2" id="idm140583009611200">
<h2>Online SVMs</h2>

<p>Before <a data-type="indexterm" data-primary="Support Vector Machines (SVMs)" data-secondary="online SVMs" id="svm5osvm"></a><a data-type="indexterm" data-primary="online SVMs" id="osvm5"></a>concluding
 this chapter, let’s take a quick look at online SVM classifiers (recall
 that online learning means learning incrementally, typically as new 
instances arrive).</p>

<p>For linear SVM classifiers, one method is to use <a data-type="indexterm" data-primary="Gradient Descent (GD)" id="idm140583009530880"></a>Gradient Descent (e.g., using <code>SGDClassifier</code>) to minimize the cost function in <a data-type="xref" href="#linear_svm_classifier_cost_function">Equation 5-13</a>, which is derived from the primal problem. Unfortunately it converges much more slowly than the methods based on QP.</p>
<div id="linear_svm_classifier_cost_function" data-type="equation"><h5><span class="label">Equation 5-13. </span>Linear SVM classifier cost function</h5><img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_74.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_74.png" width="1474" height="152"></div>

<p>The first sum in the cost function will push the model to have a small weight vector <strong>w</strong>,
 leading to a larger margin. The second sum computes the total of all 
margin violations. An instance’s margin violation is equal to 0 if it is
 located off the street and on the correct side, or else it is 
proportional to the distance to the correct side of the street. 
Minimizing this term ensures that the model makes the margin violations 
as small and as few as possible</p>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="hinge_loss_function">
<h5>Hinge Loss</h5>
<p>The function <em>max</em>(0, 1 – <em>t</em>) is called <a data-type="indexterm" data-primary="hinge loss function" id="idm140583009522944"></a>the <em>hinge loss</em> function (represented below). It is equal to 0 when <em>t</em> ≥ 1. Its derivative (slope) is equal to –1 if <em>t</em> &lt; 1 and 0 if <em>t</em> &gt; 1. It is not differentiable at <em>t</em> = 1, but just like for Lasso Regression (see <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch04.html#lasso_regression">“Lasso Regression”</a>) you can still use Gradient Descent using <a data-type="indexterm" data-primary="subderivatives" id="idm140583009518880"></a>any <em>subderivative</em> at <em>t</em> = 1 (i.e., any value between –1 and 0).</p>

<figure class="smallersixty"><div class="figure">
<img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/mlst_05in01.png" alt="mlst 05in01" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_05in01.png" width="1402" height="738">
<h6></h6>
</div></figure>
</div></aside>

<p>It is also possible to implement online kernelized SVMs—for example, using <a href="http://goo.gl/JEqVui">“Incremental and Decremental SVM Learning”</a><sup><a data-type="noteref" id="idm140583009514240-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch05.html#idm140583009514240" class="totri-footnote">7</a></sup> or <a href="https://goo.gl/hsoUHA">“Fast Kernel Classifiers with Online and Active Learning.”</a><sup><a data-type="noteref" id="idm140583009512912-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch05.html#idm140583009512912" class="totri-footnote">8</a></sup>
 However, these are implemented in Matlab and C++. For large-scale 
nonlinear problems, you may want to consider using neural networks 
instead <a data-type="indexterm" data-primary="Support Vector Machines (SVMs)" data-secondary="mechanics of" data-startref="svm5mo" id="idm140583009511888"></a><a data-type="indexterm" data-primary="Support Vector Machines (SVMs)" data-secondary="SVM regression" data-startref="svm5svmr" id="idm140583009510656"></a><a data-type="indexterm" data-primary="Support Vector Machines (SVMs)" data-secondary="online SVMs" data-startref="svm5osvm" id="idm140583009509424"></a><a data-type="indexterm" data-primary="online SVMs" data-startref="osvm5" id="idm140583009508192"></a>(see <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/part02.html#neural_nets_part">Part&nbsp;II</a>).</p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Exercises"><div class="sect1" id="idm140583009506288">
<h1>Exercises</h1>
<ol>
<li>
<p>What is the fundamental idea behind Support Vector Machines?</p>
</li>
<li>
<p>What is a support vector?</p>
</li>
<li>
<p>Why is it important to scale the inputs when using SVMs?</p>
</li>
<li>
<p>Can an SVM classifier output a confidence score when it classifies an instance? What about a probability?</p>
</li>
<li>
<p>Should you use the primal or the dual form of the SVM problem to 
train a model on a training set with millions of instances and hundreds 
of features?</p>
</li>
<li>
<p>Say you trained an SVM classifier with an RBF kernel. It seems to underfit the training set: should you increase or decrease <em>γ</em> (<code>gamma</code>)? What about <code>C</code>?</p>
</li>
<li>
<p>How should you set the QP parameters (<strong>H</strong>, <strong>f</strong>, <strong>A</strong>, and <strong>b</strong>) to solve the soft margin linear SVM classifier problem using an off-the-shelf QP solver?</p>
</li>
<li>
<p>Train a <code>LinearSVC</code> on a linearly separable dataset. Then train an <code>SVC</code> and a <code>SGDClassifier</code> on the same dataset. <a data-type="indexterm" data-primary="Scikit-Learn" data-secondary="sklearn.svm.SVC" id="idm140583009492224"></a> <a data-type="indexterm" data-primary="Scikit-Learn" data-secondary="sklearn.svm.LinearSVC" id="idm140583009491088"></a>See if you can get them to produce roughly the same model.</p>
</li>
<li>
<p>Train an SVM classifier on the MNIST dataset. Since SVM classifiers are binary classifiers, you will need to use <a data-type="indexterm" data-primary="one-versus-all  (OvA)  strategy" id="idm140583009489104"></a>one-versus-all
 to classify all 10 digits. You may want to tune the hyperparameters 
using small validation sets to speed up the process. What accuracy can 
you reach?</p>
</li>
<li>
<p>Train an SVM regressor on the California housing <a data-type="indexterm" data-primary="Support Vector Machines (SVMs)" data-startref="svm5" id="idm140583009487200"></a>dataset.</p>
</li>

</ol>

<p>Solutions to these exercises are available in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app01.html#solutions_appendix">Appendix&nbsp;A</a>.</p>
</div></section>







<div data-type="footnotes"><p data-type="footnote" id="idm140583009958208"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch05.html#idm140583009958208-marker" class="totri-footnote">1</a></sup> “A Dual Coordinate Descent Method for Large-scale Linear SVM,” Lin et al. (2008).</p><p data-type="footnote" id="idm140583009949968"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch05.html#idm140583009949968-marker" class="totri-footnote">2</a></sup> “Sequential Minimal Optimization (SMO),” J. Platt (1998).</p><p data-type="footnote" id="idm140583009779104"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch05.html#idm140583009779104-marker" class="totri-footnote">3</a></sup> More generally, when there are <em>n</em> features, the decision function is an <em>n</em>-dimensional <em>hyperplane</em>, <a data-type="indexterm" data-primary="hyperplane" id="idm140583009776960"></a>and the decision boundary is an (<em>n</em> – 1)-dimensional hyperplane.</p><p data-type="footnote" id="idm140583009714032"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch05.html#idm140583009714032-marker" class="totri-footnote">4</a></sup> Zeta (<em>ζ</em>) is the 6<sup>th</sup> letter of the Greek alphabet.</p><p data-type="footnote" id="idm140583009698768"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch05.html#idm140583009698768-marker" class="totri-footnote">5</a></sup> To learn more about Quadratic Programming, you can start by reading Stephen Boyd and Lieven Vandenberghe, <a href="http://goo.gl/FGXuLw"><em>Convex Optimization</em></a> (Cambridge, UK: Cambridge University Press, 2004) or watch Richard Brown’s <a href="http://goo.gl/rTo3Af">series of video lectures</a>.</p><p data-type="footnote" id="idm140583009622880"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch05.html#idm140583009622880-marker" class="totri-footnote">6</a></sup> The objective function is convex, and the inequality constraints are continuously differentiable and convex functions.</p><p data-type="footnote" id="idm140583009514240"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch05.html#idm140583009514240-marker" class="totri-footnote">7</a></sup> “Incremental and Decremental Support Vector Machine Learning,” G. Cauwenberghs, T. Poggio (2001).</p><p data-type="footnote" id="idm140583009512912"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch05.html#idm140583009512912-marker" class="totri-footnote">8</a></sup> “Fast Kernel Classifiers with Online and Active Learning,“ A. Bordes, S. Ertekin, J. Weston, L. Bottou (2005).</p></div></div></section><div class="annotator-outer annotator-viewer viewer annotator-hide">
  <ul class="annotator-widget annotator-listing"></ul>
</div><div class="annotator-modal-wrapper annotator-editor-modal annotator-editor annotator-hide">
	<div class="annotator-outer editor">
		<h2 class="title">Highlight</h2>
		<form class="annotator-widget">
			<ul class="annotator-listing">
			<li class="annotator-item"><textarea id="annotator-field-4" placeholder="Add a note using markdown (optional)" class="js-editor" maxlength="750"></textarea></li></ul>
			<div class="annotator-controls">
				<a class="link-to-markdown" href="https://daringfireball.net/projects/markdown/basics" target="_blank">?</a>
				<ul>
					<li class="delete annotator-hide"><a href="#delete" class="annotator-delete-note button positive">Delete Note</a></li>
					<li class="save"><a href="#save" class="annotator-save annotator-focus button positive">Save Note</a></li>
					<li class="cancel"><a href="#cancel" class="annotator-cancel button">Cancel</a></li>
				</ul>
			</div>
		</form>
	</div>
</div><div class="annotator-modal-wrapper annotator-delete-confirm-modal" style="display: none;">
  <div class="annotator-outer">
    <h2 class="title">Highlight</h2>
      <a class="js-close-delete-confirm annotator-cancel close" href="#close">Close</a>
      <div class="annotator-widget">
         <div class="delete-confirm">
            Are you sure you want to permanently delete this note?
         </div>
         <div class="annotator-controls">
            <a href="#cancel" class="annotator-cancel button js-cancel-delete-confirm">No, I changed my mind</a>
            <a href="#delete" class="annotator-delete button positive js-delete-confirm">Yes, delete it</a>
         </div>
       </div>
   </div>
</div><div class="annotator-adder" style="display: none;">
	<ul class="adders ">
		
		<li class="copy"><a href="#">Copy</a></li>
		
		<li class="add-highlight"><a href="#">Add Highlight</a></li>
		<li class="add-note"><a href="#">
			
				Add Note
			
		</a></li>
		
	</ul>
</div></div></div>



  <div class="t-sbo-prev sbo-prev sbo-nav-bottom">
  
    
      
        <a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch04.html" class="prev nav-link">
      
          <span aria-hidden="true" class="pagination-label t-prev-label">Prev</span>
          <span class="visuallyhidden">Previous Chapter</span>
          <div class="pagination-title t-prev-title">4. Training Models</div>
        </a>
    
  
  </div>

  <div class="t-sbo-next sbo-next sbo-nav-bottom">
  
    
      
        <a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch06.html" class="next nav-link">
      
          <span aria-hidden="true" class="pagination-label t-next-label">Next</span>
          <span class="visuallyhidden">Next Chapter</span>
          <div class="pagination-title t-next-title">6. Decision Trees</div>
        </a>
    
  
  </div>

</section>
  </div>
<section class="sbo-saved-archives"></section>



          
          
  




    
    
      <div id="js-subscribe-nag" class="subscribe-nag clearfix trial-panel t-subscribe-nag collapsed slideUp">
        
        
          
          
            <p class="usage-data">Find answers on the fly, or master something new. Subscribe today. <a href="https://www.safaribooksonline.com/subscribe/" class="ga-active-trial-subscribe-nag">See pricing options.</a></p>
          

          
        
        

      </div>

    
    



        
      </div>
      




  <footer class="pagefoot t-pagefoot" style="padding-bottom: 69px;">
    <a href="#" class="icon-up" style="display: none;"><div class="visuallyhidden">Back to top</div></a>
    <ul class="js-footer-nav">
      
        <li><a class="t-recommendations-footer" href="https://www.safaribooksonline.com/r/">Recommended</a></li>
      
      <li>
      
      <a class="t-queue-footer" href="https://www.safaribooksonline.com/s/">Queue</a>
      
      </li>
      
        <li><a class="t-recent-footer" href="https://www.safaribooksonline.com/history/">History</a></li>
        <li><a class="t-topics-footer" href="https://www.safaribooksonline.com/topics?q=*&amp;limit=21">Topics</a></li>
      
      
        <li><a class="t-tutorials-footer" href="https://www.safaribooksonline.com/tutorials/">Tutorials</a></li>
      
      <li><a class="t-settings-footer js-settings" href="https://www.safaribooksonline.com/u/">Settings</a></li>
      <li class="full-support"><a href="https://www.safaribooksonline.com/public/support">Support</a></li>
      <li><a href="https://www.safaribooksonline.com/apps/">Get the App</a></li>
      <li><a href="https://www.safaribooksonline.com/accounts/logout/">Sign Out</a></li>
    </ul>
    <span class="copyright">© 2017 <a href="https://www.safaribooksonline.com/" target="_blank">Safari</a>.</span>
    <a href="https://www.safaribooksonline.com/terms/">Terms of Service</a> /
    <a href="https://www.safaribooksonline.com/privacy/">Privacy Policy</a>
  </footer>

<script type="text/javascript">window.NREUM||(NREUM={});NREUM.info={"agent":"","errorBeacon":"bam.nr-data.net","licenseKey":"510f1a6865","queueTime":0,"beacon":"bam.nr-data.net","transactionName":"YgdaZ0NSW0cEB0RdWltNfkZfUEFdCgofXFBHDVYdR1pQQxZeRl1QQj1aWkU=","applicationID":"3275661","applicationTime":811}</script>


    

    <script src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/a_005.js" charset="utf-8"></script><script type="text/javascript" id="">!function(b,e,f,g,a,c,d){b.fbq||(a=b.fbq=function(){a.callMethod?a.callMethod.apply(a,arguments):a.queue.push(arguments)},b._fbq||(b._fbq=a),a.push=a,a.loaded=!0,a.version="2.0",a.queue=[],c=e.createElement(f),c.async=!0,c.src=g,d=e.getElementsByTagName(f)[0],d.parentNode.insertBefore(c,d))}(window,document,"script","https://connect.facebook.net/en_US/fbevents.js");fbq("init","1732687426968531");fbq("track","PageView");</script>
<noscript><img height="1" width="1" style="display:none" src="https://www.facebook.com/tr?id=1732687426968531&amp;ev=PageView&amp;noscript=1"></noscript><div style="width:0px; height:0px; display:none; visibility:hidden;" id="batBeacon0.31551976328735265"><img style="width:0px; height:0px; display:none; visibility:hidden;" id="batBeacon0.7746668699298912" alt="" src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/0.txt" width="0" height="0"></div>
    <script src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/a_004.js" charset="utf-8"></script>
  

<div class="annotator-notice"></div><div class="font-flyout" style="top: 200px; left: 1257px;"><div class="font-controls-panel">
	<div class="nightmodes">
		<ul>
			<li class="day"><a href="#" id="day-mode" title="Day Mode">
				<i class="fa fa-sun-o"></i>
				<span>Day Mode</span></a></li>
			<li class="cloudy"><a href="#" id="cloudy-mode" title="Cloudy Mode">
				<i class="fa fa-cloud"></i>
				<span>Cloud Mode</span>
			</a></li>
			<li class="night"><a href="#" id="night-mode" title="Night Mode">
				<i class="fa fa-moon-o"></i>
				<span>Night Mode</span>
			</a></li>
		</ul>
	</div>

	<div class="font-resizer resizer">
		<div class="draggable-containment-wrapper">
			<i class="fa fa-font left"></i>
			<span class="filler" style="width: 50%;"></span>
			<div id="js-font-size-draggable" class="draggable ui-widget-content ui-draggable ui-draggable-handle" style="position: relative; left: 80px;"></div>
			<i class="fa fa-font right"></i>
		</div>
	</div>

	<div class="column-resizer resizer">
		<div class="draggable-containment-wrapper">
			<i class="fa fa-compress left"></i>
			<span class="filler" style="width: 50%;"></span>
			<div id="js-column-size-draggable" class="draggable ui-widget-content ui-draggable ui-draggable-handle" style="position: relative; left: 80px;"></div>
			<i class="fa fa-expand right"></i>
		</div>
	</div>

	<a id="reset" class="button" href="#">Reset</a>
</div>
</div><script src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/a.js" type="text/javascript"></script><script src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/a" type="text/javascript"></script><img src="5.%20Support%20Vector%20Machines%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/seg.gif" alt="" style="display: none;" width="1" height="1" border="0"></body></html>