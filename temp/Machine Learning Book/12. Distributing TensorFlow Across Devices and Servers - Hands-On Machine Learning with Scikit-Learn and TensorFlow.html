<!--[if IE]><![endif]-->
<!DOCTYPE html>
<!--[if IE 8]><html class="no-js ie8 oldie" lang="en" prefix="og: http://ogp.me/ns/# og:book: http://ogp.me/ns/book# og:video: http://ogp.me/ns/video#"

    
        itemscope itemtype="http://schema.org/Book http://schema.org/ItemPage"" data-login-url="/accounts/login/"
data-offline-url="/"
data-url="/library/view/hands-on-machine-learning/9781491962282/ch10.html"
data-csrf-cookie="csrfsafari"
data-highlight-privacy="private"


  data-user-id="2309833"
  data-user-uuid="2d2acfb7-1cff-4dc7-9037-8ffbac19b02e"
  data-username="ayushksinghal"
  data-account-type="Trial"
  
  data-activated-trial-date="12/02/2017"


  data-archive="9781491962282"
  data-publishers="O&#39;Reilly Media, Inc."



  data-htmlfile-name="ch10.html"
  data-epub-title="Hands-On Machine Learning with Scikit-Learn and TensorFlow" data-debug=0 data-testing=0><![endif]-->
<!--[if gt IE 8]><!-->
<html class="js flexbox flexboxlegacy no-touch no-websqldatabase indexeddb history csscolumns csstransforms localstorage sessionstorage applicationcache svg inlinesvg no-zoom gr__safaribooksonline_com" prefix="og: http://ogp.me/ns/# og:book: http://ogp.me/ns/book# og:video: http://ogp.me/ns/video#" itemscope="" itemtype="http://schema.org/Book http://schema.org/ItemPage" "="" data-login-url="/accounts/login/" data-offline-url="/" data-url="/library/view/hands-on-machine-learning/9781491962282/ch10.html" data-csrf-cookie="csrfsafari" data-highlight-privacy="private" data-user-id="2309833" data-user-uuid="2d2acfb7-1cff-4dc7-9037-8ffbac19b02e" data-username="ayushksinghal" data-account-type="Trial" data-activated-trial-date="12/02/2017" data-archive="9781491962282" data-publishers="O'Reilly Media, Inc." data-htmlfile-name="ch10.html" data-epub-title="Hands-On Machine Learning with Scikit-Learn and TensorFlow" data-debug="0" data-testing="0" style="" data-ember-extension="1" lang="en"><!--<![endif]--><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="author" content="Safari Books Online"><meta name="format-detection" content="telephone=no"><meta http-equiv="cleartype" content="on"><meta name="HandheldFriendly" content="True"><meta name="MobileOptimized" content="320"><meta name="apple-itunes-app" content="app-id=881697395, app-argument=safaridetail://9781491962282"><meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, maximum-scale=1.0"><meta property="twitter:account_id" content="4503599627559754"><script type="text/javascript" src="12.%20Distributing%20TensorFlow%20Across%20Devices%20and%20Servers%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/510f1a6865.js"></script><script src="12.%20Distributing%20TensorFlow%20Across%20Devices%20and%20Servers%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/nr-spa-1044.js"></script><script type="text/javascript" async="" src="12.%20Distributing%20TensorFlow%20Across%20Devices%20and%20Servers%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/linkid.js"></script><script src="12.%20Distributing%20TensorFlow%20Across%20Devices%20and%20Servers%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/1732687426968531.js" async=""></script><script async="" src="12.%20Distributing%20TensorFlow%20Across%20Devices%20and%20Servers%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/fbevents.js"></script><script type="text/javascript" async="" src="12.%20Distributing%20TensorFlow%20Across%20Devices%20and%20Servers%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/bat.js"></script><script type="text/javascript" async="" src="12.%20Distributing%20TensorFlow%20Across%20Devices%20and%20Servers%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/conversion_async.js"></script><script type="text/javascript" async="" src="12.%20Distributing%20TensorFlow%20Across%20Devices%20and%20Servers%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/insight.js"></script><script type="text/javascript" async="" src="12.%20Distributing%20TensorFlow%20Across%20Devices%20and%20Servers%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/conversion_async.js"></script><script async="" src="12.%20Distributing%20TensorFlow%20Across%20Devices%20and%20Servers%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/gtm.js"></script><script async="" src="12.%20Distributing%20TensorFlow%20Across%20Devices%20and%20Servers%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/analytics.js"></script><script type="text/javascript">(window.NREUM||(NREUM={})).loader_config={xpid:"VQQDUVVVGwACU1RUAQA="};window.NREUM||(NREUM={}),__nr_require=function(t,e,n){function r(n){if(!e[n]){var o=e[n]={exports:{}};t[n][0].call(o.exports,function(e){var o=t[n][1][e];return r(o||e)},o,o.exports)}return e[n].exports}if("function"==typeof __nr_require)return __nr_require;for(var o=0;o<n.length;o++)r(n[o]);return r}({1:[function(t,e,n){function r(t){try{c.console&&console.log(t)}catch(e){}}var o,i=t("ee"),a=t(19),c={};try{o=localStorage.getItem("__nr_flags").split(","),console&&"function"==typeof console.log&&(c.console=!0,o.indexOf("dev")!==-1&&(c.dev=!0),o.indexOf("nr_dev")!==-1&&(c.nrDev=!0))}catch(s){}c.nrDev&&i.on("internal-error",function(t){r(t.stack)}),c.dev&&i.on("fn-err",function(t,e,n){r(n.stack)}),c.dev&&(r("NR AGENT IN DEVELOPMENT MODE"),r("flags: "+a(c,function(t,e){return t}).join(", ")))},{}],2:[function(t,e,n){function r(t,e,n,r,o){try{d?d-=1:i("err",[o||new UncaughtException(t,e,n)])}catch(c){try{i("ierr",[c,s.now(),!0])}catch(u){}}return"function"==typeof f&&f.apply(this,a(arguments))}function UncaughtException(t,e,n){this.message=t||"Uncaught error with no additional information",this.sourceURL=e,this.line=n}function o(t){i("err",[t,s.now()])}var i=t("handle"),a=t(20),c=t("ee"),s=t("loader"),f=window.onerror,u=!1,d=0;s.features.err=!0,t(1),window.onerror=r;try{throw new Error}catch(p){"stack"in p&&(t(12),t(11),"addEventListener"in window&&t(6),s.xhrWrappable&&t(13),u=!0)}c.on("fn-start",function(t,e,n){u&&(d+=1)}),c.on("fn-err",function(t,e,n){u&&(this.thrown=!0,o(n))}),c.on("fn-end",function(){u&&!this.thrown&&d>0&&(d-=1)}),c.on("internal-error",function(t){i("ierr",[t,s.now(),!0])})},{}],3:[function(t,e,n){t("loader").features.ins=!0},{}],4:[function(t,e,n){function r(){C++,M=y.hash,this[u]=b.now()}function o(){C--,y.hash!==M&&i(0,!0);var t=b.now();this[l]=~~this[l]+t-this[u],this[d]=t}function i(t,e){E.emit("newURL",[""+y,e])}function a(t,e){t.on(e,function(){this[e]=b.now()})}var c="-start",s="-end",f="-body",u="fn"+c,d="fn"+s,p="cb"+c,h="cb"+s,l="jsTime",m="fetch",v="addEventListener",w=window,y=w.location,b=t("loader");if(w[v]&&b.xhrWrappable){var g=t(9),x=t(10),E=t(8),O=t(6),R=t(12),P=t(7),T=t(13),S=t("ee"),N=S.get("tracer");t(14),b.features.spa=!0;var M,j=w[v],C=0;S.on(u,r),S.on(p,r),S.on(d,o),S.on(h,o),S.buffer([u,d,"xhr-done","xhr-resolved"]),O.buffer([u]),R.buffer(["setTimeout"+s,"clearTimeout"+c,u]),T.buffer([u,"new-xhr","send-xhr"+c]),P.buffer([m+c,m+"-done",m+f+c,m+f+s]),E.buffer(["newURL"]),g.buffer([u]),x.buffer(["propagate",p,h,"executor-err","resolve"+c]),N.buffer([u,"no-"+u]),a(T,"send-xhr"+c),a(S,"xhr-resolved"),a(S,"xhr-done"),a(P,m+c),a(P,m+"-done"),E.on("pushState-end",i),E.on("replaceState-end",i),j("hashchange",i,!0),j("load",i,!0),j("popstate",function(){i(0,C>1)},!0)}},{}],5:[function(t,e,n){function r(t){}if(window.performance&&window.performance.timing&&window.performance.getEntriesByType){var o=t("ee"),i=t("handle"),a=t(12),c=t(11),s="learResourceTimings",f="addEventListener",u="resourcetimingbufferfull",d="bstResource",p="resource",h="-start",l="-end",m="fn"+h,v="fn"+l,w="bstTimer",y="pushState",b=t("loader");b.features.stn=!0,t(8);var g=NREUM.o.EV;o.on(m,function(t,e){var n=t[0];n instanceof g&&(this.bstStart=b.now())}),o.on(v,function(t,e){var n=t[0];n instanceof g&&i("bst",[n,e,this.bstStart,b.now()])}),a.on(m,function(t,e,n){this.bstStart=b.now(),this.bstType=n}),a.on(v,function(t,e){i(w,[e,this.bstStart,b.now(),this.bstType])}),c.on(m,function(){this.bstStart=b.now()}),c.on(v,function(t,e){i(w,[e,this.bstStart,b.now(),"requestAnimationFrame"])}),o.on(y+h,function(t){this.time=b.now(),this.startPath=location.pathname+location.hash}),o.on(y+l,function(t){i("bstHist",[location.pathname+location.hash,this.startPath,this.time])}),f in window.performance&&(window.performance["c"+s]?window.performance[f](u,function(t){i(d,[window.performance.getEntriesByType(p)]),window.performance["c"+s]()},!1):window.performance[f]("webkit"+u,function(t){i(d,[window.performance.getEntriesByType(p)]),window.performance["webkitC"+s]()},!1)),document[f]("scroll",r,{passive:!0}),document[f]("keypress",r,!1),document[f]("click",r,!1)}},{}],6:[function(t,e,n){function r(t){for(var e=t;e&&!e.hasOwnProperty(u);)e=Object.getPrototypeOf(e);e&&o(e)}function o(t){c.inPlace(t,[u,d],"-",i)}function i(t,e){return t[1]}var a=t("ee").get("events"),c=t(22)(a,!0),s=t("gos"),f=XMLHttpRequest,u="addEventListener",d="removeEventListener";e.exports=a,"getPrototypeOf"in Object?(r(document),r(window),r(f.prototype)):f.prototype.hasOwnProperty(u)&&(o(window),o(f.prototype)),a.on(u+"-start",function(t,e){var n=t[1],r=s(n,"nr@wrapped",function(){function t(){if("function"==typeof n.handleEvent)return n.handleEvent.apply(n,arguments)}var e={object:t,"function":n}[typeof n];return e?c(e,"fn-",null,e.name||"anonymous"):n});this.wrapped=t[1]=r}),a.on(d+"-start",function(t){t[1]=this.wrapped||t[1]})},{}],7:[function(t,e,n){function r(t,e,n){var r=t[e];"function"==typeof r&&(t[e]=function(){var t=r.apply(this,arguments);return o.emit(n+"start",arguments,t),t.then(function(e){return o.emit(n+"end",[null,e],t),e},function(e){throw o.emit(n+"end",[e],t),e})})}var o=t("ee").get("fetch"),i=t(19);e.exports=o;var a=window,c="fetch-",s=c+"body-",f=["arrayBuffer","blob","json","text","formData"],u=a.Request,d=a.Response,p=a.fetch,h="prototype";u&&d&&p&&(i(f,function(t,e){r(u[h],e,s),r(d[h],e,s)}),r(a,"fetch",c),o.on(c+"end",function(t,e){var n=this;e?e.clone().arrayBuffer().then(function(t){n.rxSize=t.byteLength,o.emit(c+"done",[null,e],n)}):o.emit(c+"done",[t],n)}))},{}],8:[function(t,e,n){var r=t("ee").get("history"),o=t(22)(r);e.exports=r,o.inPlace(window.history,["pushState","replaceState"],"-")},{}],9:[function(t,e,n){var r=t("ee").get("mutation"),o=t(22)(r),i=NREUM.o.MO;e.exports=r,i&&(window.MutationObserver=function(t){return this instanceof i?new i(o(t,"fn-")):i.apply(this,arguments)},MutationObserver.prototype=i.prototype)},{}],10:[function(t,e,n){function r(t){var e=a.context(),n=c(t,"executor-",e),r=new f(n);return a.context(r).getCtx=function(){return e},a.emit("new-promise",[r,e],e),r}function o(t,e){return e}var i=t(22),a=t("ee").get("promise"),c=i(a),s=t(19),f=NREUM.o.PR;e.exports=a,f&&(window.Promise=r,["all","race"].forEach(function(t){var e=f[t];f[t]=function(n){function r(t){return function(){a.emit("propagate",[null,!o],i),o=o||!t}}var o=!1;s(n,function(e,n){Promise.resolve(n).then(r("all"===t),r(!1))});var i=e.apply(f,arguments),c=f.resolve(i);return c}}),["resolve","reject"].forEach(function(t){var e=f[t];f[t]=function(t){var n=e.apply(f,arguments);return t!==n&&a.emit("propagate",[t,!0],n),n}}),f.prototype["catch"]=function(t){return this.then(null,t)},f.prototype=Object.create(f.prototype,{constructor:{value:r}}),s(Object.getOwnPropertyNames(f),function(t,e){try{r[e]=f[e]}catch(n){}}),a.on("executor-start",function(t){t[0]=c(t[0],"resolve-",this),t[1]=c(t[1],"resolve-",this)}),a.on("executor-err",function(t,e,n){t[1](n)}),c.inPlace(f.prototype,["then"],"then-",o),a.on("then-start",function(t,e){this.promise=e,t[0]=c(t[0],"cb-",this),t[1]=c(t[1],"cb-",this)}),a.on("then-end",function(t,e,n){this.nextPromise=n;var r=this.promise;a.emit("propagate",[r,!0],n)}),a.on("cb-end",function(t,e,n){a.emit("propagate",[n,!0],this.nextPromise)}),a.on("propagate",function(t,e,n){this.getCtx&&!e||(this.getCtx=function(){if(t instanceof Promise)var e=a.context(t);return e&&e.getCtx?e.getCtx():this})}),r.toString=function(){return""+f})},{}],11:[function(t,e,n){var r=t("ee").get("raf"),o=t(22)(r),i="equestAnimationFrame";e.exports=r,o.inPlace(window,["r"+i,"mozR"+i,"webkitR"+i,"msR"+i],"raf-"),r.on("raf-start",function(t){t[0]=o(t[0],"fn-")})},{}],12:[function(t,e,n){function r(t,e,n){t[0]=a(t[0],"fn-",null,n)}function o(t,e,n){this.method=n,this.timerDuration=isNaN(t[1])?0:+t[1],t[0]=a(t[0],"fn-",this,n)}var i=t("ee").get("timer"),a=t(22)(i),c="setTimeout",s="setInterval",f="clearTimeout",u="-start",d="-";e.exports=i,a.inPlace(window,[c,"setImmediate"],c+d),a.inPlace(window,[s],s+d),a.inPlace(window,[f,"clearImmediate"],f+d),i.on(s+u,r),i.on(c+u,o)},{}],13:[function(t,e,n){function r(t,e){d.inPlace(e,["onreadystatechange"],"fn-",c)}function o(){var t=this,e=u.context(t);t.readyState>3&&!e.resolved&&(e.resolved=!0,u.emit("xhr-resolved",[],t)),d.inPlace(t,y,"fn-",c)}function i(t){b.push(t),l&&(x?x.then(a):v?v(a):(E=-E,O.data=E))}function a(){for(var t=0;t<b.length;t++)r([],b[t]);b.length&&(b=[])}function c(t,e){return e}function s(t,e){for(var n in t)e[n]=t[n];return e}t(6);var f=t("ee"),u=f.get("xhr"),d=t(22)(u),p=NREUM.o,h=p.XHR,l=p.MO,m=p.PR,v=p.SI,w="readystatechange",y=["onload","onerror","onabort","onloadstart","onloadend","onprogress","ontimeout"],b=[];e.exports=u;var g=window.XMLHttpRequest=function(t){var e=new h(t);try{u.emit("new-xhr",[e],e),e.addEventListener(w,o,!1)}catch(n){try{u.emit("internal-error",[n])}catch(r){}}return e};if(s(h,g),g.prototype=h.prototype,d.inPlace(g.prototype,["open","send"],"-xhr-",c),u.on("send-xhr-start",function(t,e){r(t,e),i(e)}),u.on("open-xhr-start",r),l){var x=m&&m.resolve();if(!v&&!m){var E=1,O=document.createTextNode(E);new l(a).observe(O,{characterData:!0})}}else f.on("fn-end",function(t){t[0]&&t[0].type===w||a()})},{}],14:[function(t,e,n){function r(t){var e=this.params,n=this.metrics;if(!this.ended){this.ended=!0;for(var r=0;r<d;r++)t.removeEventListener(u[r],this.listener,!1);if(!e.aborted){if(n.duration=a.now()-this.startTime,4===t.readyState){e.status=t.status;var i=o(t,this.lastSize);if(i&&(n.rxSize=i),this.sameOrigin){var s=t.getResponseHeader("X-NewRelic-App-Data");s&&(e.cat=s.split(", ").pop())}}else e.status=0;n.cbTime=this.cbTime,f.emit("xhr-done",[t],t),c("xhr",[e,n,this.startTime])}}}function o(t,e){var n=t.responseType;if("json"===n&&null!==e)return e;var r="arraybuffer"===n||"blob"===n||"json"===n?t.response:t.responseText;return l(r)}function i(t,e){var n=s(e),r=t.params;r.host=n.hostname+":"+n.port,r.pathname=n.pathname,t.sameOrigin=n.sameOrigin}var a=t("loader");if(a.xhrWrappable){var c=t("handle"),s=t(15),f=t("ee"),u=["load","error","abort","timeout"],d=u.length,p=t("id"),h=t(18),l=t(17),m=window.XMLHttpRequest;a.features.xhr=!0,t(13),f.on("new-xhr",function(t){var e=this;e.totalCbs=0,e.called=0,e.cbTime=0,e.end=r,e.ended=!1,e.xhrGuids={},e.lastSize=null,h&&(h>34||h<10)||window.opera||t.addEventListener("progress",function(t){e.lastSize=t.loaded},!1)}),f.on("open-xhr-start",function(t){this.params={method:t[0]},i(this,t[1]),this.metrics={}}),f.on("open-xhr-end",function(t,e){"loader_config"in NREUM&&"xpid"in NREUM.loader_config&&this.sameOrigin&&e.setRequestHeader("X-NewRelic-ID",NREUM.loader_config.xpid)}),f.on("send-xhr-start",function(t,e){var n=this.metrics,r=t[0],o=this;if(n&&r){var i=l(r);i&&(n.txSize=i)}this.startTime=a.now(),this.listener=function(t){try{"abort"===t.type&&(o.params.aborted=!0),("load"!==t.type||o.called===o.totalCbs&&(o.onloadCalled||"function"!=typeof e.onload))&&o.end(e)}catch(n){try{f.emit("internal-error",[n])}catch(r){}}};for(var c=0;c<d;c++)e.addEventListener(u[c],this.listener,!1)}),f.on("xhr-cb-time",function(t,e,n){this.cbTime+=t,e?this.onloadCalled=!0:this.called+=1,this.called!==this.totalCbs||!this.onloadCalled&&"function"==typeof n.onload||this.end(n)}),f.on("xhr-load-added",function(t,e){var n=""+p(t)+!!e;this.xhrGuids&&!this.xhrGuids[n]&&(this.xhrGuids[n]=!0,this.totalCbs+=1)}),f.on("xhr-load-removed",function(t,e){var n=""+p(t)+!!e;this.xhrGuids&&this.xhrGuids[n]&&(delete this.xhrGuids[n],this.totalCbs-=1)}),f.on("addEventListener-end",function(t,e){e instanceof m&&"load"===t[0]&&f.emit("xhr-load-added",[t[1],t[2]],e)}),f.on("removeEventListener-end",function(t,e){e instanceof m&&"load"===t[0]&&f.emit("xhr-load-removed",[t[1],t[2]],e)}),f.on("fn-start",function(t,e,n){e instanceof m&&("onload"===n&&(this.onload=!0),("load"===(t[0]&&t[0].type)||this.onload)&&(this.xhrCbStart=a.now()))}),f.on("fn-end",function(t,e){this.xhrCbStart&&f.emit("xhr-cb-time",[a.now()-this.xhrCbStart,this.onload,e],e)})}},{}],15:[function(t,e,n){e.exports=function(t){var e=document.createElement("a"),n=window.location,r={};e.href=t,r.port=e.port;var o=e.href.split("://");!r.port&&o[1]&&(r.port=o[1].split("/")[0].split("@").pop().split(":")[1]),r.port&&"0"!==r.port||(r.port="https"===o[0]?"443":"80"),r.hostname=e.hostname||n.hostname,r.pathname=e.pathname,r.protocol=o[0],"/"!==r.pathname.charAt(0)&&(r.pathname="/"+r.pathname);var i=!e.protocol||":"===e.protocol||e.protocol===n.protocol,a=e.hostname===document.domain&&e.port===n.port;return r.sameOrigin=i&&(!e.hostname||a),r}},{}],16:[function(t,e,n){function r(){}function o(t,e,n){return function(){return i(t,[f.now()].concat(c(arguments)),e?null:this,n),e?void 0:this}}var i=t("handle"),a=t(19),c=t(20),s=t("ee").get("tracer"),f=t("loader"),u=NREUM;"undefined"==typeof window.newrelic&&(newrelic=u);var d=["setPageViewName","setCustomAttribute","setErrorHandler","finished","addToTrace","inlineHit","addRelease"],p="api-",h=p+"ixn-";a(d,function(t,e){u[e]=o(p+e,!0,"api")}),u.addPageAction=o(p+"addPageAction",!0),u.setCurrentRouteName=o(p+"routeName",!0),e.exports=newrelic,u.interaction=function(){return(new r).get()};var l=r.prototype={createTracer:function(t,e){var n={},r=this,o="function"==typeof e;return i(h+"tracer",[f.now(),t,n],r),function(){if(s.emit((o?"":"no-")+"fn-start",[f.now(),r,o],n),o)try{return e.apply(this,arguments)}finally{s.emit("fn-end",[f.now()],n)}}}};a("setName,setAttribute,save,ignore,onEnd,getContext,end,get".split(","),function(t,e){l[e]=o(h+e)}),newrelic.noticeError=function(t){"string"==typeof t&&(t=new Error(t)),i("err",[t,f.now()])}},{}],17:[function(t,e,n){e.exports=function(t){if("string"==typeof t&&t.length)return t.length;if("object"==typeof t){if("undefined"!=typeof ArrayBuffer&&t instanceof ArrayBuffer&&t.byteLength)return t.byteLength;if("undefined"!=typeof Blob&&t instanceof Blob&&t.size)return t.size;if(!("undefined"!=typeof FormData&&t instanceof FormData))try{return JSON.stringify(t).length}catch(e){return}}}},{}],18:[function(t,e,n){var r=0,o=navigator.userAgent.match(/Firefox[\/\s](\d+\.\d+)/);o&&(r=+o[1]),e.exports=r},{}],19:[function(t,e,n){function r(t,e){var n=[],r="",i=0;for(r in t)o.call(t,r)&&(n[i]=e(r,t[r]),i+=1);return n}var o=Object.prototype.hasOwnProperty;e.exports=r},{}],20:[function(t,e,n){function r(t,e,n){e||(e=0),"undefined"==typeof n&&(n=t?t.length:0);for(var r=-1,o=n-e||0,i=Array(o<0?0:o);++r<o;)i[r]=t[e+r];return i}e.exports=r},{}],21:[function(t,e,n){e.exports={exists:"undefined"!=typeof window.performance&&window.performance.timing&&"undefined"!=typeof window.performance.timing.navigationStart}},{}],22:[function(t,e,n){function r(t){return!(t&&t instanceof Function&&t.apply&&!t[a])}var o=t("ee"),i=t(20),a="nr@original",c=Object.prototype.hasOwnProperty,s=!1;e.exports=function(t,e){function n(t,e,n,o){function nrWrapper(){var r,a,c,s;try{a=this,r=i(arguments),c="function"==typeof n?n(r,a):n||{}}catch(f){p([f,"",[r,a,o],c])}u(e+"start",[r,a,o],c);try{return s=t.apply(a,r)}catch(d){throw u(e+"err",[r,a,d],c),d}finally{u(e+"end",[r,a,s],c)}}return r(t)?t:(e||(e=""),nrWrapper[a]=t,d(t,nrWrapper),nrWrapper)}function f(t,e,o,i){o||(o="");var a,c,s,f="-"===o.charAt(0);for(s=0;s<e.length;s++)c=e[s],a=t[c],r(a)||(t[c]=n(a,f?c+o:o,i,c))}function u(n,r,o){if(!s||e){var i=s;s=!0;try{t.emit(n,r,o,e)}catch(a){p([a,n,r,o])}s=i}}function d(t,e){if(Object.defineProperty&&Object.keys)try{var n=Object.keys(t);return n.forEach(function(n){Object.defineProperty(e,n,{get:function(){return t[n]},set:function(e){return t[n]=e,e}})}),e}catch(r){p([r])}for(var o in t)c.call(t,o)&&(e[o]=t[o]);return e}function p(e){try{t.emit("internal-error",e)}catch(n){}}return t||(t=o),n.inPlace=f,n.flag=a,n}},{}],ee:[function(t,e,n){function r(){}function o(t){function e(t){return t&&t instanceof r?t:t?s(t,c,i):i()}function n(n,r,o,i){if(!p.aborted||i){t&&t(n,r,o);for(var a=e(o),c=l(n),s=c.length,f=0;f<s;f++)c[f].apply(a,r);var d=u[y[n]];return d&&d.push([b,n,r,a]),a}}function h(t,e){w[t]=l(t).concat(e)}function l(t){return w[t]||[]}function m(t){return d[t]=d[t]||o(n)}function v(t,e){f(t,function(t,n){e=e||"feature",y[n]=e,e in u||(u[e]=[])})}var w={},y={},b={on:h,emit:n,get:m,listeners:l,context:e,buffer:v,abort:a,aborted:!1};return b}function i(){return new r}function a(){(u.api||u.feature)&&(p.aborted=!0,u=p.backlog={})}var c="nr@context",s=t("gos"),f=t(19),u={},d={},p=e.exports=o();p.backlog=u},{}],gos:[function(t,e,n){function r(t,e,n){if(o.call(t,e))return t[e];var r=n();if(Object.defineProperty&&Object.keys)try{return Object.defineProperty(t,e,{value:r,writable:!0,enumerable:!1}),r}catch(i){}return t[e]=r,r}var o=Object.prototype.hasOwnProperty;e.exports=r},{}],handle:[function(t,e,n){function r(t,e,n,r){o.buffer([t],r),o.emit(t,e,n)}var o=t("ee").get("handle");e.exports=r,r.ee=o},{}],id:[function(t,e,n){function r(t){var e=typeof t;return!t||"object"!==e&&"function"!==e?-1:t===window?0:a(t,i,function(){return o++})}var o=1,i="nr@id",a=t("gos");e.exports=r},{}],loader:[function(t,e,n){function r(){if(!x++){var t=g.info=NREUM.info,e=p.getElementsByTagName("script")[0];if(setTimeout(u.abort,3e4),!(t&&t.licenseKey&&t.applicationID&&e))return u.abort();f(y,function(e,n){t[e]||(t[e]=n)}),s("mark",["onload",a()+g.offset],null,"api");var n=p.createElement("script");n.src="https://"+t.agent,e.parentNode.insertBefore(n,e)}}function o(){"complete"===p.readyState&&i()}function i(){s("mark",["domContent",a()+g.offset],null,"api")}function a(){return E.exists&&performance.now?Math.round(performance.now()):(c=Math.max((new Date).getTime(),c))-g.offset}var c=(new Date).getTime(),s=t("handle"),f=t(19),u=t("ee"),d=window,p=d.document,h="addEventListener",l="attachEvent",m=d.XMLHttpRequest,v=m&&m.prototype;NREUM.o={ST:setTimeout,SI:d.setImmediate,CT:clearTimeout,XHR:m,REQ:d.Request,EV:d.Event,PR:d.Promise,MO:d.MutationObserver};var w=""+location,y={beacon:"bam.nr-data.net",errorBeacon:"bam.nr-data.net",agent:"js-agent.newrelic.com/nr-spa-1044.min.js"},b=m&&v&&v[h]&&!/CriOS/.test(navigator.userAgent),g=e.exports={offset:c,now:a,origin:w,features:{},xhrWrappable:b};t(16),p[h]?(p[h]("DOMContentLoaded",i,!1),d[h]("load",r,!1)):(p[l]("onreadystatechange",o),d[l]("onload",r)),s("mark",["firstbyte",c],null,"api");var x=0,E=t(21)},{}]},{},["loader",2,14,5,3,4]);</script><link rel="apple-touch-icon" href="https://www.safaribooksonline.com/static/images/apple-touch-icon.8cc2fd27400e.png"><link rel="shortcut icon" href="https://www.safaribooksonline.com/favicon.ico" type="image/x-icon"><link href="12.%20Distributing%20TensorFlow%20Across%20Devices%20and%20Servers%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/css.css" rel="stylesheet" type="text/css"><title>14. Recurrent Neural Networks - Hands-On Machine Learning with Scikit-Learn and TensorFlow</title><link rel="stylesheet" href="12.%20Distributing%20TensorFlow%20Across%20Devices%20and%20Servers%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/d6ec1592ffb3.css" type="text/css"><link rel="stylesheet" type="text/css" href="12.%20Distributing%20TensorFlow%20Across%20Devices%20and%20Servers%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/annotator.css"><link rel="stylesheet" href="12.%20Distributing%20TensorFlow%20Across%20Devices%20and%20Servers%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/font-awesome.css"><style type="text/css" title="ibis-book">@charset "utf-8";#sbo-rt-content html,#sbo-rt-content div,#sbo-rt-content div,#sbo-rt-content span,#sbo-rt-content applet,#sbo-rt-content object,#sbo-rt-content iframe,#sbo-rt-content h1,#sbo-rt-content h2,#sbo-rt-content h3,#sbo-rt-content h4,#sbo-rt-content h5,#sbo-rt-content h6,#sbo-rt-content p,#sbo-rt-content blockquote,#sbo-rt-content pre,#sbo-rt-content a,#sbo-rt-content abbr,#sbo-rt-content acronym,#sbo-rt-content address,#sbo-rt-content big,#sbo-rt-content cite,#sbo-rt-content code,#sbo-rt-content del,#sbo-rt-content dfn,#sbo-rt-content em,#sbo-rt-content img,#sbo-rt-content ins,#sbo-rt-content kbd,#sbo-rt-content q,#sbo-rt-content s,#sbo-rt-content samp,#sbo-rt-content small,#sbo-rt-content strike,#sbo-rt-content strong,#sbo-rt-content sub,#sbo-rt-content sup,#sbo-rt-content tt,#sbo-rt-content var,#sbo-rt-content b,#sbo-rt-content u,#sbo-rt-content i,#sbo-rt-content center,#sbo-rt-content dl,#sbo-rt-content dt,#sbo-rt-content dd,#sbo-rt-content ol,#sbo-rt-content ul,#sbo-rt-content li,#sbo-rt-content fieldset,#sbo-rt-content form,#sbo-rt-content label,#sbo-rt-content legend,#sbo-rt-content table,#sbo-rt-content caption,#sbo-rt-content tdiv,#sbo-rt-content tfoot,#sbo-rt-content thead,#sbo-rt-content tr,#sbo-rt-content th,#sbo-rt-content td,#sbo-rt-content article,#sbo-rt-content aside,#sbo-rt-content canvas,#sbo-rt-content details,#sbo-rt-content embed,#sbo-rt-content figure,#sbo-rt-content figcaption,#sbo-rt-content footer,#sbo-rt-content header,#sbo-rt-content hgroup,#sbo-rt-content menu,#sbo-rt-content nav,#sbo-rt-content output,#sbo-rt-content ruby,#sbo-rt-content section,#sbo-rt-content summary,#sbo-rt-content time,#sbo-rt-content mark,#sbo-rt-content audio,#sbo-rt-content video{margin:0;padding:0;border:0;font-size:100%;font:inherit;vertical-align:baseline}#sbo-rt-content article,#sbo-rt-content aside,#sbo-rt-content details,#sbo-rt-content figcaption,#sbo-rt-content figure,#sbo-rt-content footer,#sbo-rt-content header,#sbo-rt-content hgroup,#sbo-rt-content menu,#sbo-rt-content nav,#sbo-rt-content section{display:block}#sbo-rt-content div{line-height:1}#sbo-rt-content ol,#sbo-rt-content ul{list-style:none}#sbo-rt-content blockquote,#sbo-rt-content q{quotes:none}#sbo-rt-content blockquote:before,#sbo-rt-content blockquote:after,#sbo-rt-content q:before,#sbo-rt-content q:after{content:none}#sbo-rt-content table{border-collapse:collapse;border-spacing:0}@page{margin:5px !important}#sbo-rt-content p{margin:10px 0 0;line-height:125%;text-align:left}#sbo-rt-content p.byline{text-align:left;margin:-33px auto 35px;font-style:italic;font-weight:bold}#sbo-rt-content div.preface p+p.byline{margin:1em 0 0}#sbo-rt-content div.preface p.byline+p.byline{margin:0}#sbo-rt-content div.sect1>p.byline{margin:-.25em 0 1em}#sbo-rt-content div.sect1>p.byline+p.byline{margin-top:-1em}#sbo-rt-content em{font-style:italic;font-family:inherit}#sbo-rt-content em strong,#sbo-rt-content strong em{font-weight:bold;font-style:italic;font-family:inherit}#sbo-rt-content strong,#sbo-rt-content span.bold{font-weight:bold}#sbo-rt-content em.replaceable{font-style:italic}#sbo-rt-content strong.userinput{font-weight:bold;font-style:normal}#sbo-rt-content span.bolditalic{font-weight:bold;font-style:italic}#sbo-rt-content a.ulink,#sbo-rt-content a.xref,#sbo-rt-content a.email,#sbo-rt-content a.link,#sbo-rt-content a{text-decoration:none;color:#8e0012}#sbo-rt-content span.lineannotation{font-style:italic;color:#a62a2a;font-family:serif}#sbo-rt-content span.underline{text-decoration:underline}#sbo-rt-content span.strikethrough{text-decoration:line-through}#sbo-rt-content span.smallcaps{font-variant:small-caps}#sbo-rt-content span.cursor{background:#000;color:#fff}#sbo-rt-content span.smaller{font-size:75%}#sbo-rt-content .boxedtext,#sbo-rt-content .keycap{border-style:solid;border-width:1px;border-color:#000;padding:1px}#sbo-rt-content span.gray50{color:#7F7F7F;}#sbo-rt-content h1,#sbo-rt-content div.toc-title,#sbo-rt-content h2,#sbo-rt-content h3,#sbo-rt-content h4,#sbo-rt-content h5{-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;font-weight:bold;text-align:left;page-break-after:avoid !important;font-family:sans-serif,"DejaVuSans"}#sbo-rt-content div.toc-title{font-size:1.5em;margin-top:20px !important;margin-bottom:30px !important}#sbo-rt-content section[data-type="sect1"] h1{font-size:1.3em;color:#8e0012;margin:40px 0 8px 0}#sbo-rt-content section[data-type="sect2"] h2{font-size:1.1em;margin:30px 0 8px 0 !important}#sbo-rt-content section[data-type="sect3"] h3{font-size:1em;color:#555;margin:20px 0 8px 0 !important}#sbo-rt-content section[data-type="sect4"] h4{font-size:1em;font-weight:normal;font-style:italic;margin:15px 0 6px 0 !important}#sbo-rt-content section[data-type="chapter"]>div>h1,#sbo-rt-content section[data-type="preface"]>div>h1,#sbo-rt-content section[data-type="appendix"]>div>h1,#sbo-rt-content section[data-type="glossary"]>div>h1,#sbo-rt-content section[data-type="bibliography"]>div>h1,#sbo-rt-content section[data-type="index"]>div>h1{font-size:2em;line-height:1;margin-bottom:50px;color:#000;padding-bottom:10px;border-bottom:1px solid #000}#sbo-rt-content span.label,#sbo-rt-content span.keep-together{font-size:inherit;font-weight:inherit}#sbo-rt-content div[data-type="part"] h1{font-size:2em;text-align:center;margin-top:0 !important;margin-bottom:50px;padding:50px 0 10px 0;border-bottom:1px solid #000}#sbo-rt-content img.width-ninety{width:90%}#sbo-rt-content img{max-width:95%;margin:0 auto;padding:0}#sbo-rt-content div.figure{background-color:transparent;text-align:center !important;margin:15px 0 15px 0 !important;page-break-inside:avoid}#sbo-rt-content figure{margin:15px 0 15px 0 !important;page-break-inside:avoid}#sbo-rt-content div.figure h6{font-size:90%;text-align:center;font-weight:normal;font-style:italic;font-family:serif !important;color:#000;padding-top:10px !important;page-break-before:avoid;page-break-after:avoid}#sbo-rt-content div.informalfigure{text-align:center !important;padding:5px 0 !important}#sbo-rt-content div.sidebar{margin:15px 0 10px 0 !important;border:1px solid #DCDCDC;background-color:#F7F7F7;padding:15px !important;page-break-inside:avoid}#sbo-rt-content aside[data-type="sidebar"]{margin:15px 0 10px 0 !important;page-break-inside:avoid}#sbo-rt-content div.sidebar-title,#sbo-rt-content aside[data-type="sidebar"] h5{font-weight:bold;font-size:1em;font-family:sans-serif;text-transform:uppercase;letter-spacing:1px;text-align:center;margin:4px 0 6px 0 !important;page-break-inside:avoid}#sbo-rt-content div.sidebar ol,#sbo-rt-content div.sidebar ul,#sbo-rt-content aside[data-type="sidebar"] ol,#sbo-rt-content aside[data-type="sidebar"] ul{margin-left:1.25em !important}#sbo-rt-content div.sidebar div.figure p.title,#sbo-rt-content aside[data-type="sidebar"] figcaption,#sbo-rt-content div.sidebar div.informalfigure div.caption{font-size:90%;text-align:center;font-weight:normal;font-style:italic;font-family:serif !important;color:#000;padding:5px !important;page-break-before:avoid;page-break-after:avoid}#sbo-rt-content div.sidebar div.tip,#sbo-rt-content div.sidebar div[data-type="tip"],#sbo-rt-content div.sidebar div.note,#sbo-rt-content div.sidebar div[data-type="note"],#sbo-rt-content div.sidebar div.warning,#sbo-rt-content div.sidebar div[data-type="warning"],#sbo-rt-content div.sidebar div[data-type="caution"],#sbo-rt-content div.sidebar div[data-type="important"]{margin:20px auto 20px auto !important;font-size:90%;width:85%}#sbo-rt-content aside[data-type="sidebar"] p.byline{font-size:90%;font-weight:bold;font-style:italic;text-align:center;text-indent:0;margin:5px auto 6px;page-break-after:avoid}#sbo-rt-content pre{white-space:pre-wrap;font-family:"Ubuntu Mono",monospace;margin:25px 0 25px 20px;font-size:85%;display:block;-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;overflow-wrap:break-word}#sbo-rt-content div.note pre.programlisting,#sbo-rt-content div.tip pre.programlisting,#sbo-rt-content div.warning pre.programlisting,#sbo-rt-content div.caution pre.programlisting,#sbo-rt-content div.important pre.programlisting{margin-bottom:0}#sbo-rt-content code{font-family:"Ubuntu Mono",monospace;-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;overflow-wrap:break-word}#sbo-rt-content code strong em,#sbo-rt-content code em strong,#sbo-rt-content pre em strong,#sbo-rt-content pre strong em,#sbo-rt-content strong code em code,#sbo-rt-content em code strong code,#sbo-rt-content span.bolditalic code{font-weight:bold;font-style:italic;font-family:"Ubuntu Mono BoldItal",monospace}#sbo-rt-content code em,#sbo-rt-content em code,#sbo-rt-content pre em,#sbo-rt-content em.replaceable{font-family:"Ubuntu Mono Ital",monospace;font-style:italic}#sbo-rt-content code strong,#sbo-rt-content strong code,#sbo-rt-content pre strong,#sbo-rt-content strong.userinput{font-family:"Ubuntu Mono Bold",monospace;font-weight:bold}#sbo-rt-content div[data-type="example"]{margin:10px 0 15px 0 !important}#sbo-rt-content div[data-type="example"] h1,#sbo-rt-content div[data-type="example"] h2,#sbo-rt-content div[data-type="example"] h3,#sbo-rt-content div[data-type="example"] h4,#sbo-rt-content div[data-type="example"] h5,#sbo-rt-content div[data-type="example"] h6{font-style:italic;font-weight:normal;text-align:left !important;text-transform:none !important;font-family:serif !important;margin:10px 0 5px 0 !important;border-bottom:1px solid #000}#sbo-rt-content li pre.example{padding:10px 0 !important}#sbo-rt-content div[data-type="example"] pre[data-type="programlisting"],#sbo-rt-content div[data-type="example"] pre[data-type="screen"]{margin:0}#sbo-rt-content section[data-type="titlepage"]>div>h1{font-size:2em;margin:50px 0 10px 0 !important;line-height:1;text-align:center}#sbo-rt-content section[data-type="titlepage"] h2,#sbo-rt-content section[data-type="titlepage"] p.subtitle,#sbo-rt-content section[data-type="titlepage"] p[data-type="subtitle"]{font-size:1.3em;font-weight:normal;text-align:center;margin-top:.5em;color:#555}#sbo-rt-content section[data-type="titlepage"]>div>h2[data-type="author"],#sbo-rt-content section[data-type="titlepage"] p.author{font-size:1.3em;font-family:serif !important;font-weight:bold;margin:50px 0 !important;text-align:center}#sbo-rt-content section[data-type="titlepage"] p.edition{text-align:center;text-transform:uppercase;margin-top:2em}#sbo-rt-content section[data-type="titlepage"]{text-align:center}#sbo-rt-content section[data-type="titlepage"]:after{content:url(css_assets/titlepage_footer_ebook.png);margin:0 auto;max-width:80%}#sbo-rt-content div.book div.titlepage div.publishername{margin-top:60%;margin-bottom:20px;text-align:center;font-size:1.25em}#sbo-rt-content div.book div.titlepage div.locations p{margin:0;text-align:center}#sbo-rt-content div.book div.titlepage div.locations p.cities{font-size:80%;text-align:center;margin-top:5px}#sbo-rt-content section.preface[title="Dedication"]>div.titlepage h2.title{text-align:center;text-transform:uppercase;font-size:1.5em;margin-top:50px;margin-bottom:50px}#sbo-rt-content ul.stafflist{margin:15px 0 15px 20px !important}#sbo-rt-content ul.stafflist li{list-style-type:none;padding:5px 0}#sbo-rt-content ul.printings li{list-style-type:none}#sbo-rt-content section.preface[title="Dedication"] p{font-style:italic;text-align:center}#sbo-rt-content div.colophon h1.title{font-size:1.3em;margin:0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon h2.subtitle{margin:0 !important;color:#000;font-family:serif !important;font-size:1em;font-weight:normal}#sbo-rt-content div.colophon div.author h3.author{font-size:1.1em;font-family:serif !important;margin:10px 0 0 !important;font-weight:normal}#sbo-rt-content div.colophon div.editor h4,#sbo-rt-content div.colophon div.editor h3.editor{color:#000;font-size:.8em;margin:15px 0 0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon div.editor h3.editor{font-size:.8em;margin:0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon div.publisher{margin-top:10px}#sbo-rt-content div.colophon div.publisher p,#sbo-rt-content div.colophon div.publisher span.publishername{margin:0;font-size:.8em}#sbo-rt-content div.legalnotice p,#sbo-rt-content div.timestamp p{font-size:.8em}#sbo-rt-content div.timestamp p{margin-top:10px}#sbo-rt-content div.colophon[title="About the Author"] h1.title,#sbo-rt-content div.colophon[title="Colophon"] h1.title{font-size:1.5em;margin:0 !important;font-family:sans-serif !important}#sbo-rt-content section.chapter div.titlepage div.author{margin:10px 0 10px 0}#sbo-rt-content section.chapter div.titlepage div.author div.affiliation{font-style:italic}#sbo-rt-content div.attribution{margin:5px 0 0 50px !important}#sbo-rt-content h3.author span.orgname{display:none}#sbo-rt-content div.epigraph{margin:10px 0 10px 20px !important;page-break-inside:avoid;font-size:90%}#sbo-rt-content div.epigraph p{font-style:italic}#sbo-rt-content blockquote,#sbo-rt-content div.blockquote{margin:10px !important;page-break-inside:avoid;font-size:95%}#sbo-rt-content blockquote p,#sbo-rt-content div.blockquote p{font-style:italic;margin:.75em 0 0 !important}#sbo-rt-content blockquote div.attribution,#sbo-rt-content blockquote p[data-type="attribution"]{margin:5px 0 10px 30px !important;text-align:right;width:80%}#sbo-rt-content blockquote div.attribution p,#sbo-rt-content blockquote p[data-type="attribution"]{font-style:normal;margin-top:5px}#sbo-rt-content blockquote div.attribution p:before,#sbo-rt-content blockquote p[data-type="attribution"]:before{font-style:normal;content:"—";-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none}#sbo-rt-content p.right{text-align:right;margin:0}#sbo-rt-content div[data-type="footnotes"]{border-top:1px solid black;margin-top:1.5em}#sbo-rt-content sub,#sbo-rt-content sup{font-size:75%;line-height:0;position:relative}#sbo-rt-content sup{top:-.5em}#sbo-rt-content sub{bottom:-.25em}#sbo-rt-content div.refentry p.refname{font-size:1em;font-family:sans-serif,"DejaVuSans";font-weight:bold;margin-bottom:5px;overflow:auto;width:100%}#sbo-rt-content div.refentry{width:100%;display:block;margin-top:2em}#sbo-rt-content div.refsynopsisdiv{display:block;clear:both}#sbo-rt-content div.refentry header{page-break-inside:avoid !important;display:block;break-inside:avoid !important;padding-top:0;border-bottom:1px solid #000}#sbo-rt-content div.refsect1 h6{font-size:.9em;font-family:sans-serif,"DejaVuSans";font-weight:bold}#sbo-rt-content div.refsect1{margin-top:3em}#sbo-rt-content dt{padding-top:10px !important;padding-bottom:0 !important}#sbo-rt-content dd{margin-left:1.5em !important;margin-bottom:.25em}#sbo-rt-content dd ol,#sbo-rt-content dd ul{padding-left:1em}#sbo-rt-content dd li{margin-top:0;margin-bottom:0}#sbo-rt-content dd,#sbo-rt-content li{text-align:left}#sbo-rt-content ul,#sbo-rt-content ul>li,#sbo-rt-content ol ul,#sbo-rt-content ol ul>li,#sbo-rt-content ul ol ul,#sbo-rt-content ul ol ul>li{list-style-type:disc}#sbo-rt-content ul ul,#sbo-rt-content ul ul>li{list-style-type:square}#sbo-rt-content ul ul ul,#sbo-rt-content ul ul ul>li{list-style-type:circle}#sbo-rt-content ol,#sbo-rt-content ol>li,#sbo-rt-content ol ul ol,#sbo-rt-content ol ul ol>li,#sbo-rt-content ul ol,#sbo-rt-content ul ol>li{list-style-type:decimal}#sbo-rt-content ol ol,#sbo-rt-content ol ol>li{list-style-type:lower-alpha}#sbo-rt-content ol ol ol,#sbo-rt-content ol ol ol>li{list-style-type:lower-roman}#sbo-rt-content ol,#sbo-rt-content ul{list-style-position:outside;margin:15px 0 15px 1.25em;padding-left:2.25em}#sbo-rt-content ol li,#sbo-rt-content ul li{margin:.5em 0 .65em;line-height:125%}#sbo-rt-content div.orderedlistalpha{list-style-type:upper-alpha}#sbo-rt-content table.simplelist,#sbo-rt-content ul.simplelist{margin:15px 0 15px 20px !important}#sbo-rt-content ul.simplelist li{list-style-type:none;padding:5px 0}#sbo-rt-content table.simplelist td{border:none}#sbo-rt-content table.simplelist tr{border-bottom:none}#sbo-rt-content table.simplelist tr:nth-of-type(even){background-color:transparent}#sbo-rt-content dl.calloutlist p:first-child{margin-top:-25px !important}#sbo-rt-content dl.calloutlist dd{padding-left:0;margin-top:-25px}#sbo-rt-content dl.calloutlist img,#sbo-rt-content a.co img{padding:0}#sbo-rt-content div.toc ol{margin-top:8px !important;margin-bottom:8px !important;margin-left:0 !important;padding-left:0 !important}#sbo-rt-content div.toc ol ol{margin-left:30px !important;padding-left:0 !important}#sbo-rt-content div.toc ol li{list-style-type:none}#sbo-rt-content div.toc a{color:#8e0012}#sbo-rt-content div.toc ol a{font-size:1em;font-weight:bold}#sbo-rt-content div.toc ol>li>ol a{font-weight:bold;font-size:1em}#sbo-rt-content div.toc ol>li>ol>li>ol a{text-decoration:none;font-weight:normal;font-size:1em}#sbo-rt-content div.tip,#sbo-rt-content div[data-type="tip"],#sbo-rt-content div.note,#sbo-rt-content div[data-type="note"],#sbo-rt-content div.warning,#sbo-rt-content div[data-type="warning"],#sbo-rt-content div[data-type="caution"],#sbo-rt-content div[data-type="important"]{margin:30px !important;font-size:90%;padding:10px 8px 20px 8px !important;page-break-inside:avoid}#sbo-rt-content div.tip ol,#sbo-rt-content div.tip ul,#sbo-rt-content div[data-type="tip"] ol,#sbo-rt-content div[data-type="tip"] ul,#sbo-rt-content div.note ol,#sbo-rt-content div.note ul,#sbo-rt-content div[data-type="note"] ol,#sbo-rt-content div[data-type="note"] ul,#sbo-rt-content div.warning ol,#sbo-rt-content div.warning ul,#sbo-rt-content div[data-type="warning"] ol,#sbo-rt-content div[data-type="warning"] ul,#sbo-rt-content div[data-type="caution"] ol,#sbo-rt-content div[data-type="caution"] ul,#sbo-rt-content div[data-type="important"] ol,#sbo-rt-content div[data-type="important"] ul{margin-left:1.5em !important}#sbo-rt-content div.tip,#sbo-rt-content div[data-type="tip"],#sbo-rt-content div.note,#sbo-rt-content div[data-type="note"]{border:1px solid #BEBEBE;background-color:transparent}#sbo-rt-content div.warning,#sbo-rt-content div[data-type="warning"],#sbo-rt-content div[data-type="caution"],#sbo-rt-content div[data-type="important"]{border:1px solid #BC8F8F}#sbo-rt-content div.tip h3,#sbo-rt-content div[data-type="tip"] h6,#sbo-rt-content div[data-type="tip"] h1,#sbo-rt-content div.note h3,#sbo-rt-content div[data-type="note"] h6,#sbo-rt-content div[data-type="note"] h1,#sbo-rt-content div.warning h3,#sbo-rt-content div[data-type="warning"] h6,#sbo-rt-content div[data-type="warning"] h1,#sbo-rt-content div[data-type="caution"] h6,#sbo-rt-content div[data-type="caution"] h1,#sbo-rt-content div[data-type="important"] h1,#sbo-rt-content div[data-type="important"] h6{font-weight:bold;font-size:110%;font-family:sans-serif !important;text-transform:uppercase;letter-spacing:1px;text-align:center;margin:4px 0 6px !important}#sbo-rt-content div.tip h3,#sbo-rt-content div[data-type="tip"] h6,#sbo-rt-content div.note h3,#sbo-rt-content div[data-type="note"] h6,#sbo-rt-content div[data-type="tip"] h1,#sbo-rt-content div[data-type="note"] h1{color:#737373}#sbo-rt-content div.warning h3,#sbo-rt-content div[data-type="warning"] h6,#sbo-rt-content div[data-type="caution"] h6,#sbo-rt-content div[data-type="important"] h6,#sbo-rt-content div[data-type="warning"] h1,#sbo-rt-content div[data-type="caution"] h1,#sbo-rt-content div[data-type="important"] h1{color:#C67171}#sbo-rt-content div.sect1[title="Safari® Books Online"] div.note,#sbo-rt-content div.safarienabled{background-color:transparent;margin:8px 0 0 !important;border:0 solid #BEBEBE;font-size:100%;padding:0 !important;page-break-inside:avoid}#sbo-rt-content div.sect1[title="Safari® Books Online"] div.note h3,#sbo-rt-content div.safarienabled h6{display:none}#sbo-rt-content div.table,#sbo-rt-content table{margin:15px 0 30px 0 !important;max-width:95%;border:none !important;background:none;display:table !important}#sbo-rt-content div.table,#sbo-rt-content div.informaltable,#sbo-rt-content table{page-break-inside:avoid}#sbo-rt-content tr,#sbo-rt-content tr td{border-bottom:1px solid #c3c3c3}#sbo-rt-content thead td,#sbo-rt-content thead th{border-bottom:#9d9d9d 1px solid !important;border-top:#9d9d9d 1px solid !important}#sbo-rt-content tr:nth-of-type(even){background-color:#f1f6fc}#sbo-rt-content thead{font-family:sans-serif;font-weight:bold}#sbo-rt-content td,#sbo-rt-content th{display:table-cell;padding:.3em;text-align:left;vertical-align:middle;font-size:80%}#sbo-rt-content div.informaltable table{margin:10px auto !important}#sbo-rt-content div.informaltable table tr{border-bottom:none}#sbo-rt-content div.informaltable table tr:nth-of-type(even){background-color:transparent}#sbo-rt-content div.informaltable td,#sbo-rt-content div.informaltable th{border:#9d9d9d 1px solid}#sbo-rt-content div.table-title,#sbo-rt-content table caption{font-weight:normal;font-style:italic;font-family:serif;font-size:1em;margin:10px 0 10px 0 !important;padding:0;page-break-after:avoid;text-align:left !important}#sbo-rt-content table code{font-size:smaller}#sbo-rt-content div.equation,#sbo-rt-content div[data-type="equation"]{margin:10px 0 15px 0 !important}#sbo-rt-content div.equation-title,#sbo-rt-content div[data-type="equation"] h5{font-style:italic;font-weight:normal;font-family:serif !important;font-size:90%;margin:20px 0 10px 0 !important;page-break-after:avoid}#sbo-rt-content div.equation-contents{margin-left:20px}#sbo-rt-content span.inlinemediaobject{height:.85em;display:inline-block;margin-bottom:.2em}#sbo-rt-content span.inlinemediaobject img{margin:0;height:.85em}#sbo-rt-content div.informalequation{margin:20px 0 20px 20px;width:75%}#sbo-rt-content div.informalequation img{width:75%}#sbo-rt-content div.index{text-indent:0}#sbo-rt-content div.index li{line-height:140%}#sbo-rt-content div.index a.indexterm{color:#8e0012}#sbo-rt-content div.index ul,#sbo-rt-content div[data-type="index"] ul{list-style-type:none;padding-left:0;margin-left:0}#sbo-rt-content div.index ul li{padding-left:0;margin-left:0}#sbo-rt-content div.index ul li ul li{margin-left:1em}#sbo-rt-content code.boolean,#sbo-rt-content .navy{color:rgb(0,0,128);}#sbo-rt-content code.character,#sbo-rt-content .olive{color:rgb(128,128,0);}#sbo-rt-content code.comment,#sbo-rt-content .blue{color:rgb(0,0,255);}#sbo-rt-content code.conditional,#sbo-rt-content .limegreen{color:rgb(50,205,50);}#sbo-rt-content code.constant,#sbo-rt-content .darkorange{color:rgb(255,140,0);}#sbo-rt-content code.debug,#sbo-rt-content .darkred{color:rgb(139,0,0);}#sbo-rt-content code.define,#sbo-rt-content .darkgoldenrod,#sbo-rt-content .gold{color:rgb(184,134,11);}#sbo-rt-content code.delimiter,#sbo-rt-content .dimgray{color:rgb(105,105,105);}#sbo-rt-content code.error,#sbo-rt-content .red{color:rgb(255,0,0);}#sbo-rt-content code.exception,#sbo-rt-content .salmon{color:rgb(250,128,11);}#sbo-rt-content code.float,#sbo-rt-content .steelblue{color:rgb(70,130,180);}#sbo-rt-content pre code.function,#sbo-rt-content .green{color:rgb(0,128,0);}#sbo-rt-content code.identifier,#sbo-rt-content .royalblue{color:rgb(65,105,225);}#sbo-rt-content code.ignore,#sbo-rt-content .gray{color:rgb(128,128,128);}#sbo-rt-content code.include,#sbo-rt-content .purple{color:rgb(128,0,128);}#sbo-rt-content code.keyword,#sbo-rt-content .sienna{color:rgb(160,82,45);}#sbo-rt-content code.label,#sbo-rt-content .deeppink{color:rgb(255,20,147);}#sbo-rt-content code.macro,#sbo-rt-content .orangered{color:rgb(255,69,0);}#sbo-rt-content code.number,#sbo-rt-content .brown{color:rgb(165,42,42);}#sbo-rt-content code.operator,#sbo-rt-content .black{color:#000;}#sbo-rt-content code.preCondit,#sbo-rt-content .teal{color:rgb(0,128,128);}#sbo-rt-content code.preProc,#sbo-rt-content .fuschia{color:rgb(255,0,255);}#sbo-rt-content code.repeat,#sbo-rt-content .indigo{color:rgb(75,0,130);}#sbo-rt-content code.special,#sbo-rt-content .saddlebrown{color:rgb(139,69,19);}#sbo-rt-content code.specialchar,#sbo-rt-content .magenta{color:rgb(255,0,255);}#sbo-rt-content code.specialcomment,#sbo-rt-content .seagreen{color:rgb(46,139,87);}#sbo-rt-content code.statement,#sbo-rt-content .forestgreen{color:rgb(34,139,34);}#sbo-rt-content code.storageclass,#sbo-rt-content .plum{color:rgb(221,160,221);}#sbo-rt-content code.string,#sbo-rt-content .darkred{color:rgb(139,0,0);}#sbo-rt-content code.structure,#sbo-rt-content .chocolate{color:rgb(210,106,30);}#sbo-rt-content code.tag,#sbo-rt-content .darkcyan{color:rgb(0,139,139);}#sbo-rt-content code.todo,#sbo-rt-content .black{color:#000;}#sbo-rt-content code.type,#sbo-rt-content .mediumslateblue{color:rgb(123,104,238);}#sbo-rt-content code.typedef,#sbo-rt-content .darkgreen{color:rgb(0,100,0);}#sbo-rt-content code.underlined{text-decoration:underline;}#sbo-rt-content pre code.hll{background-color:#ffc}#sbo-rt-content pre code.c{color:#09F;font-style:italic}#sbo-rt-content pre code.err{color:#A00}#sbo-rt-content pre code.k{color:#069;font-weight:bold}#sbo-rt-content pre code.o{color:#555}#sbo-rt-content pre code.cm{color:#35586C;font-style:italic}#sbo-rt-content pre code.cp{color:#099}#sbo-rt-content pre code.c1{color:#35586C;font-style:italic}#sbo-rt-content pre code.cs{color:#35586C;font-weight:bold;font-style:italic}#sbo-rt-content pre code.gd{background-color:#FCC}#sbo-rt-content pre code.ge{font-style:italic}#sbo-rt-content pre code.gr{color:#F00}#sbo-rt-content pre code.gh{color:#030;font-weight:bold}#sbo-rt-content pre code.gi{background-color:#CFC}#sbo-rt-content pre code.go{color:#000}#sbo-rt-content pre code.gp{color:#009;font-weight:bold}#sbo-rt-content pre code.gs{font-weight:bold}#sbo-rt-content pre code.gu{color:#030;font-weight:bold}#sbo-rt-content pre code.gt{color:#9C6}#sbo-rt-content pre code.kc{color:#069;font-weight:bold}#sbo-rt-content pre code.kd{color:#069;font-weight:bold}#sbo-rt-content pre code.kn{color:#069;font-weight:bold}#sbo-rt-content pre code.kp{color:#069}#sbo-rt-content pre code.kr{color:#069;font-weight:bold}#sbo-rt-content pre code.kt{color:#078;font-weight:bold}#sbo-rt-content pre code.m{color:#F60}#sbo-rt-content pre code.s{color:#C30}#sbo-rt-content pre code.na{color:#309}#sbo-rt-content pre code.nb{color:#366}#sbo-rt-content pre code.nc{color:#0A8;font-weight:bold}#sbo-rt-content pre code.no{color:#360}#sbo-rt-content pre code.nd{color:#99F}#sbo-rt-content pre code.ni{color:#999;font-weight:bold}#sbo-rt-content pre code.ne{color:#C00;font-weight:bold}#sbo-rt-content pre code.nf{color:#C0F}#sbo-rt-content pre code.nl{color:#99F}#sbo-rt-content pre code.nn{color:#0CF;font-weight:bold}#sbo-rt-content pre code.nt{color:#309;font-weight:bold}#sbo-rt-content pre code.nv{color:#033}#sbo-rt-content pre code.ow{color:#000;font-weight:bold}#sbo-rt-content pre code.w{color:#bbb}#sbo-rt-content pre code.mf{color:#F60}#sbo-rt-content pre code.mh{color:#F60}#sbo-rt-content pre code.mi{color:#F60}#sbo-rt-content pre code.mo{color:#F60}#sbo-rt-content pre code.sb{color:#C30}#sbo-rt-content pre code.sc{color:#C30}#sbo-rt-content pre code.sd{color:#C30;font-style:italic}#sbo-rt-content pre code.s2{color:#C30}#sbo-rt-content pre code.se{color:#C30;font-weight:bold}#sbo-rt-content pre code.sh{color:#C30}#sbo-rt-content pre code.si{color:#A00}#sbo-rt-content pre code.sx{color:#C30}#sbo-rt-content pre code.sr{color:#3AA}#sbo-rt-content pre code.s1{color:#C30}#sbo-rt-content pre code.ss{color:#A60}#sbo-rt-content pre code.bp{color:#366}#sbo-rt-content pre code.vc{color:#033}#sbo-rt-content pre code.vg{color:#033}#sbo-rt-content pre code.vi{color:#033}#sbo-rt-content pre code.il{color:#F60}#sbo-rt-content pre code.g{color:#050}#sbo-rt-content pre code.l{color:#C60}#sbo-rt-content pre code.l{color:#F90}#sbo-rt-content pre code.n{color:#008}#sbo-rt-content pre code.nx{color:#008}#sbo-rt-content pre code.py{color:#96F}#sbo-rt-content pre code.p{color:#000}#sbo-rt-content pre code.x{color:#F06}#sbo-rt-content div.blockquote_sampler_toc{width:95%;margin:5px 5px 5px 10px !important}#sbo-rt-content div{font-family:serif;text-align:left}#sbo-rt-content .gray-background,#sbo-rt-content .reverse-video{background:#2E2E2E;color:#FFF}#sbo-rt-content .light-gray-background{background:#A0A0A0}#sbo-rt-content .preserve-whitespace{white-space:pre-wrap}#sbo-rt-content span.gray{color:#4C4C4C}#sbo-rt-content div[data-type="equation"].fifty-percent img{width:50%}</style><script> // <![CDATA[
    var g = {
      position_cache: {
        
          "chapter": "/api/v1/book/9781491962282/chapter/ch10.html",
          "book_id": "9781491962282",
          "chapter_uri": "ch10.html",
          "position": 2.55275831017,
          "user_uuid": "2d2acfb7-1cff-4dc7-9037-8ffbac19b02e",
          "next_chapter_uri": "/library/view/hands-on-machine-learning/9781491962282/ch11.html"
        
      },
      title: "Hands\u002DOn Machine Learning with Scikit\u002DLearn and TensorFlow",
      author_list: "Aurélien Géron",
      format: "book",
      source: "application/epub+zip",
      is_system_book: true,
      is_public: false,
      loaded_from_server: true,
      allow_scripts: false,
      has_mathml: false,
      show_ios_app_teaser: false
    };
    // ]]></script><script src="12.%20Distributing%20TensorFlow%20Across%20Devices%20and%20Servers%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/modernizr.js"></script><script>
    
      
        

        

        
          
            window.PUBLIC_ANNOTATIONS = true;
          
        

      

      
        window.MOBILE_PUBLIC_ANNOTATIONS = false;
      

    

    
      window.PRIVACY_CONTROL_OVERRIDE = false;
    

    
      window.PRIVACY_CONTROL_SWITCH = true;
    

    
      window.PUBLISHER_PAGES = true;
    

      window.SBO = {
        "constants": {
          "SITB_ENDPOINT": "https://www.safaribooksonline.com/api/v2/sitb/",
          "SEARCH_SELECT_ENDPOINT": "https://www.safaribooksonline.com/api/v2/search/select/",
          "ENABLE_ONLINE_TRAINING": true
        }
      };
  </script><link rel="canonical" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html"><meta name="description" content=" Chapter 10. Introduction to Artificial Neural Networks Birds inspired us to fly, burdock plants inspired velcro, and nature has inspired many other inventions. It seems only logical, then, to look ... "><meta property="og:title" content="10. Introduction to Artificial Neural Networks"><meta itemprop="isPartOf" content="/library/view/hands-on-machine-learning/9781491962282/"><meta itemprop="name" content="10. Introduction to Artificial Neural Networks"><meta property="og:url" itemprop="url" content="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html"><meta property="og:site_name" content="Safari"><meta property="og:image" itemprop="thumbnailUrl" content="https://www.safaribooksonline.com/library/cover/9781491962282/"><meta property="og:description" itemprop="description" content=" Chapter 10. Introduction to Artificial Neural Networks Birds inspired us to fly, burdock plants inspired velcro, and nature has inspired many other inventions. It seems only logical, then, to look ... "><meta itemprop="inLanguage" content="en"><meta itemprop="publisher" content="O'Reilly Media, Inc."><meta property="og:type" content="book"><meta property="og:book:isbn" itemprop="isbn" content="9781491962299"><meta property="og:book:author" itemprop="author" content="Aurélien Géron"><meta property="og:book:tag" itemprop="about" content="Core Programming"><meta property="og:book:tag" itemprop="about" content="Engineering"><meta property="og:book:tag" itemprop="about" content="Python"><meta name="twitter:card" content="summary"><meta name="twitter:site" content="@safari"><style type="text/css" id="font-styles" data-template="#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-size: &lt;%= font_size %&gt; !important; }"></style><style type="text/css" id="font-family" data-template="#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-family: &lt;%= font_family %&gt; !important; }"></style><style type="text/css" id="column-width" data-template="#sbo-rt-content { max-width: &lt;%= column_width %&gt;% !important; margin: 0 auto !important; }"></style><noscript><meta http-equiv="refresh" content="0; url=/library/no-js/" /></noscript><script type="text/javascript">
  (function(i,s,o,g,r,a,m) {
    i['GoogleAnalyticsObject']=r;
    i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();
    a=s.createElement(o),m=s.getElementsByTagName(o)[0];
    a.async=1;
    a.src=g;
    m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  var matches = document.cookie.match(/BrowserCookie\s*=\s*([a-f0-9\-]{36})/),
      user_uuid = null;

  if (matches && matches.length === 2) {
    user_uuid = matches[1];
  }


  ga('create', 'UA-39299553-7', {'userId': '2d2acfb7-1cff-4dc7-9037-8ffbac19b02e' });



  
    ga('set', 'dimension1', 'Trial');
  


ga('set', 'dimension6', user_uuid);


  ga('set', 'dimension2', '2d2acfb7-1cff-4dc7-9037-8ffbac19b02e');
  






//enable enhanced link tracking
ga('require', 'linkid', 'linkid.js');

// reading interface will track pageviews itself
if (document.location.pathname.indexOf("/library/view") !== 0) {
  ga('send', 'pageview');
}
</script><script>
    (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    '//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-5P4V6Z');
  </script><script defer="defer" src="12.%20Distributing%20TensorFlow%20Across%20Devices%20and%20Servers%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/vendor.js"></script><script defer="defer" src="12.%20Distributing%20TensorFlow%20Across%20Devices%20and%20Servers%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/reader.js"></script><script async="" src="12.%20Distributing%20TensorFlow%20Across%20Devices%20and%20Servers%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/MathJax.js"></script><style id="annotator-dynamic-style">.annotator-adder, .annotator-outer, .annotator-notice {
  z-index: 100019;
}
.annotator-filter {
  z-index: 100009;
}</style><script src="12.%20Distributing%20TensorFlow%20Across%20Devices%20and%20Servers%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/a_003.js"></script><script src="12.%20Distributing%20TensorFlow%20Across%20Devices%20and%20Servers%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/a_002.js"></script></head>


<body class="reading sidenav nav-collapsed  scalefonts subscribe-panel library" data-gr-c-s-loaded="true">

    
  
  <noscript> 
    <iframe src="//www.googletagmanager.com/ns.html?id=GTM-5P4V6Z"
            height="0" width="0"
            style="display:none;visibility:hidden">
    </iframe>
  </noscript>
  



    
      <div class="working hide" role="status">
        <div class="working-image"></div>
      </div>
      <div class="sbo-site-nav">
        





<a href="#container" class="skip">Skip to content</a><header class="topbar t-topbar"><nav role="navigation" class="js-site-nav"><ul class="topnav"><li class="t-logo"><a href="https://www.safaribooksonline.com/home/" class="l0 None safari-home nav-icn js-keyboard-nav-home"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width="20" height="20" version="1.1" fill="#4A3C31"><desc>Safari Home Icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M4 9.9L4 9.9 4 18 16 18 16 9.9 10 4 4 9.9ZM2.6 8.1L2.6 8.1 8.7 1.9 10 0.5 11.3 1.9 17.4 8.1 18 8.7 18 9.5 18 18.1 18 20 16.1 20 3.9 20 2 20 2 18.1 2 9.5 2 8.7 2.6 8.1Z"></path><rect x="10" y="12" width="3" height="7"></rect><rect transform="translate(18.121320, 10.121320) rotate(-315.000000) translate(-18.121320, -10.121320) " x="16.1" y="9.1" width="4" height="2"></rect><rect transform="translate(2.121320, 10.121320) scale(-1, 1) rotate(-315.000000) translate(-2.121320, -10.121320) " x="0.1" y="9.1" width="4" height="2"></rect></g></svg><span>Safari Home</span></a></li><li><a href="https://www.safaribooksonline.com/r/" class="t-recommendations-nav l0 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>recommendations icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M50 25C50 18.2 44.9 12.5 38.3 11.7 37.5 5.1 31.8 0 25 0 18.2 0 12.5 5.1 11.7 11.7 5.1 12.5 0 18.2 0 25 0 31.8 5.1 37.5 11.7 38.3 12.5 44.9 18.2 50 25 50 31.8 50 37.5 44.9 38.3 38.3 44.9 37.5 50 31.8 50 25ZM25 3.1C29.7 3.1 33.6 6.9 34.4 11.8 30.4 12.4 26.9 15.1 25 18.8 23.1 15.1 19.6 12.4 15.6 11.8 16.4 6.9 20.3 3.1 25 3.1ZM34.4 15.6C33.6 19.3 30.7 22.2 27.1 22.9 27.8 19.2 30.7 16.3 34.4 15.6ZM22.9 22.9C19.2 22.2 16.3 19.3 15.6 15.6 19.3 16.3 22.2 19.2 22.9 22.9ZM3.1 25C3.1 20.3 6.9 16.4 11.8 15.6 12.4 19.6 15.1 23.1 18.8 25 15.1 26.9 12.4 30.4 11.8 34.4 6.9 33.6 3.1 29.7 3.1 25ZM22.9 27.1C22.2 30.7 19.3 33.6 15.6 34.4 16.3 30.7 19.2 27.8 22.9 27.1ZM25 46.9C20.3 46.9 16.4 43.1 15.6 38.2 19.6 37.6 23.1 34.9 25 31.3 26.9 34.9 30.4 37.6 34.4 38.2 33.6 43.1 29.7 46.9 25 46.9ZM27.1 27.1C30.7 27.8 33.6 30.7 34.4 34.4 30.7 33.6 27.8 30.7 27.1 27.1ZM38.2 34.4C37.6 30.4 34.9 26.9 31.3 25 34.9 23.1 37.6 19.6 38.2 15.6 43.1 16.4 46.9 20.3 46.9 25 46.9 29.7 43.1 33.6 38.2 34.4Z"></path></g></svg><span>Recommended</span></a></li><li><a href="https://www.safaribooksonline.com/s/" class="t-queue-nav l0 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>queue icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M25 29.2C25.4 29.2 25.8 29.1 26.1 28.9L48.7 16.8C49.5 16.4 50 15.5 50 14.6 50 13.7 49.5 12.8 48.7 12.4L26.1 0.3C25.4-0.1 24.6-0.1 23.9 0.3L1.3 12.4C0.5 12.8 0 13.7 0 14.6 0 15.5 0.5 16.4 1.3 16.8L23.9 28.9C24.2 29.1 24.6 29.2 25 29.2ZM7.3 14.6L25 5.2 42.7 14.6 25 24 7.3 14.6ZM48.7 22.4L47.7 21.9 25 34.2 2.3 21.9 1.3 22.4C0.5 22.9 0 23.7 0 24.7 0 25.6 0.5 26.5 1.3 26.9L23.9 39.3C24.2 39.5 24.6 39.6 25 39.6 25.4 39.6 25.8 39.5 26.1 39.3L48.7 26.9C49.5 26.5 50 25.6 50 24.7 50 23.7 49.5 22.9 48.7 22.4ZM48.7 32.8L47.7 32.3 25 44.6 2.3 32.3 1.3 32.8C0.5 33.3 0 34.1 0 35.1 0 36 0.5 36.9 1.3 37.3L23.9 49.7C24.2 49.9 24.6 50 25 50 25.4 50 25.8 49.9 26.1 49.7L48.7 37.3C49.5 36.9 50 36 50 35.1 50 34.1 49.5 33.3 48.7 32.8Z"></path></g></svg><span>
                  Queue
              </span></a></li><li class="search"><a href="#" class="t-search-nav trigger nav-icn l0" data-dropdown-selector=".searchbox"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>search icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M31.3 0C20.9 0 12.5 8.4 12.5 18.8 12.5 22.5 13.6 25.9 15.4 28.8L1.2 42.9C-0.4 44.5-0.4 47.2 1.2 48.8 2 49.6 3.1 50 4.2 50 5.2 50 6.3 49.6 7.1 48.8L21.2 34.6C24.1 36.5 27.5 37.5 31.3 37.5 41.6 37.5 50 29.1 50 18.8 50 8.4 41.6 0 31.3 0ZM31.3 31.3C24.4 31.3 18.8 25.6 18.8 18.8 18.8 11.9 24.4 6.3 31.3 6.3 38.1 6.3 43.8 11.9 43.8 18.8 43.8 25.6 38.1 31.3 31.3 31.3Z"></path></g></svg><span>Search</span></a></li><li class="usermenu dropdown"><a href="#" class="trigger l0 nav-icn nav-dropdown"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width="20" height="20" version="1.1" fill="#4A3C31"><desc>navigation arrow</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M0.1 12.5L9.7 3.1C9.8 3 9.9 3 10 3 10.1 3 10.2 3 10.3 3.1L19.9 12.5C20 12.5 20 12.6 20 12.8 20 12.9 20 13 19.9 13L17 15.9C16.9 16 16.8 16 16.7 16 16.5 16 16.4 16 16.4 15.9L10 9.7 3.6 15.9C3.6 16 3.5 16 3.3 16 3.2 16 3.1 16 3 15.9L0.1 13C0 12.9 0 12.8 0 12.7 0 12.7 0 12.6 0.1 12.5Z"></path></g></svg><span>Expand Nav</span></a><div class="drop-content"><ul><li><a href="https://www.safaribooksonline.com/history/" class="t-recent-nav l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>recent items icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M25 0C11.2 0 0 11.2 0 25 0 38.8 11.2 50 25 50 38.8 50 50 38.8 50 25 50 11.2 38.8 0 25 0ZM6.3 25C6.3 14.6 14.6 6.3 25 6.3 35.4 6.3 43.8 14.6 43.8 25 43.8 35.4 35.4 43.8 25 43.8 14.6 43.8 6.3 35.4 6.3 25ZM31.8 31.5C32.5 30.5 32.4 29.2 31.6 28.3L27.1 23.8 27.1 12.8C27.1 11.5 26.2 10.4 25 10.4 23.9 10.4 22.9 11.5 22.9 12.8L22.9 25.7 28.8 31.7C29.2 32.1 29.7 32.3 30.2 32.3 30.8 32.3 31.3 32 31.8 31.5Z"></path></g></svg><span>History</span></a></li><li><a href="https://www.safaribooksonline.com/topics" class="t-topics-link l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 55" width="20" height="20" version="1.1" fill="#4A3C31"><desc>topics icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M25 55L50 41.262 50 13.762 25 0 0 13.762 0 41.262 25 55ZM8.333 37.032L8.333 17.968 25 8.462 41.667 17.968 41.667 37.032 25 46.538 8.333 37.032Z"></path></g></svg><span>Topics</span></a></li><li><a href="https://www.safaribooksonline.com/tutorials/" class="l1 nav-icn t-tutorials-nav js-toggle-menu-item None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width="20" height="20" version="1.1" fill="#4A3C31"><desc>tutorials icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M15.8 18.2C15.8 18.2 15.9 18.2 16 18.2 16.1 18.2 16.2 18.2 16.4 18.2 16.5 18.2 16.7 18.1 16.9 18 17 17.9 17.1 17.8 17.2 17.7 17.3 17.6 17.4 17.5 17.4 17.4 17.5 17.2 17.6 16.9 17.6 16.7 17.6 16.6 17.6 16.5 17.6 16.4 17.5 16.2 17.5 16.1 17.4 15.9 17.3 15.8 17.2 15.6 17 15.5 16.8 15.3 16.6 15.3 16.4 15.2 16.2 15.2 16 15.2 15.8 15.2 15.7 15.2 15.5 15.3 15.3 15.4 15.2 15.4 15.1 15.5 15 15.7 14.9 15.8 14.8 15.9 14.7 16 14.7 16.1 14.6 16.3 14.6 16.4 14.6 16.5 14.6 16.6 14.6 16.6 14.6 16.7 14.6 16.9 14.6 17 14.6 17.1 14.7 17.3 14.7 17.4 14.8 17.6 15 17.7 15.1 17.9 15.2 18 15.3 18 15.5 18.1 15.5 18.1 15.6 18.2 15.7 18.2 15.7 18.2 15.7 18.2 15.8 18.2L15.8 18.2ZM9.4 11.5C9.5 11.5 9.5 11.5 9.6 11.5 9.7 11.5 9.9 11.5 10 11.5 10.2 11.5 10.3 11.4 10.5 11.3 10.6 11.2 10.8 11.1 10.9 11 10.9 10.9 11 10.8 11.1 10.7 11.2 10.5 11.2 10.2 11.2 10 11.2 9.9 11.2 9.8 11.2 9.7 11.2 9.5 11.1 9.4 11 9.2 10.9 9.1 10.8 8.9 10.6 8.8 10.5 8.7 10.3 8.6 10 8.5 9.9 8.5 9.7 8.5 9.5 8.5 9.3 8.5 9.1 8.6 9 8.7 8.8 8.7 8.7 8.8 8.6 9 8.5 9.1 8.4 9.2 8.4 9.3 8.2 9.5 8.2 9.8 8.2 10 8.2 10.1 8.2 10.2 8.2 10.3 8.2 10.5 8.3 10.6 8.4 10.7 8.5 10.9 8.6 11.1 8.7 11.2 8.9 11.3 9 11.4 9.1 11.4 9.2 11.4 9.3 11.5 9.3 11.5 9.3 11.5 9.4 11.5 9.4 11.5L9.4 11.5ZM3 4.8C3.1 4.8 3.1 4.8 3.2 4.8 3.4 4.8 3.5 4.8 3.7 4.8 3.8 4.8 4 4.7 4.1 4.6 4.3 4.5 4.4 4.4 4.5 4.3 4.6 4.2 4.6 4.1 4.7 4 4.8 3.8 4.8 3.5 4.8 3.3 4.8 3.1 4.8 3 4.8 2.9 4.7 2.8 4.7 2.6 4.6 2.5 4.5 2.3 4.4 2.2 4.2 2.1 4 1.9 3.8 1.9 3.6 1.8 3.5 1.8 3.3 1.8 3.1 1.8 2.9 1.8 2.7 1.9 2.6 2 2.4 2.1 2.3 2.2 2.2 2.3 2.1 2.4 2 2.5 2 2.6 1.8 2.8 1.8 3 1.8 3.3 1.8 3.4 1.8 3.5 1.8 3.6 1.8 3.8 1.9 3.9 2 4 2.1 4.2 2.2 4.4 2.4 4.5 2.5 4.6 2.6 4.7 2.7 4.7 2.8 4.7 2.9 4.8 2.9 4.8 3 4.8 3 4.8 3 4.8L3 4.8ZM13.1 15.2C13.2 15.1 13.2 15.1 13.2 15.1 13.3 14.9 13.4 14.7 13.6 14.5 13.8 14.2 14.1 14 14.4 13.8 14.7 13.6 15.1 13.5 15.5 13.4 15.9 13.4 16.3 13.4 16.7 13.5 17.2 13.5 17.6 13.7 17.9 13.9 18.2 14.1 18.5 14.4 18.7 14.7 18.9 15 19.1 15.3 19.2 15.6 19.3 15.9 19.4 16.1 19.4 16.4 19.4 17 19.3 17.5 19.1 18.1 19 18.3 18.9 18.5 18.7 18.7 18.5 19 18.3 19.2 18 19.4 17.7 19.6 17.3 19.8 16.9 19.9 16.6 20 16.3 20 16 20 15.8 20 15.6 20 15.4 19.9 15.4 19.9 15.4 19.9 15.4 19.9 15.2 19.9 15 19.8 14.9 19.8 14.8 19.7 14.7 19.7 14.6 19.7 14.4 19.6 14.3 19.5 14.1 19.3 13.7 19.1 13.4 18.7 13.2 18.4 13.1 18.1 12.9 17.8 12.9 17.5 12.8 17.3 12.8 17.1 12.8 16.9L3.5 14.9C3.3 14.9 3.1 14.8 3 14.8 2.7 14.7 2.4 14.5 2.1 14.3 1.7 14 1.4 13.7 1.2 13.3 1 13 0.9 12.6 0.8 12.3 0.7 12 0.7 11.7 0.7 11.4 0.7 11 0.8 10.5 1 10.1 1.1 9.8 1.3 9.5 1.6 9.2 1.8 8.9 2.1 8.7 2.4 8.5 2.8 8.3 3.2 8.1 3.6 8.1 3.9 8 4.2 8 4.5 8 4.6 8 4.8 8 4.9 8.1L6.8 8.5C6.8 8.4 6.8 8.4 6.8 8.4 6.9 8.2 7.1 8 7.2 7.8 7.5 7.5 7.7 7.3 8 7.1 8.4 6.9 8.7 6.8 9.1 6.7 9.5 6.7 10 6.7 10.4 6.8 10.8 6.8 11.2 7 11.5 7.2 11.8 7.5 12.1 7.7 12.4 8 12.6 8.3 12.7 8.6 12.8 8.9 12.9 9.2 13 9.4 13 9.7 13 9.7 13 9.8 13 9.8 13.6 9.9 14.2 10.1 14.9 10.2 15 10.2 15 10.2 15.1 10.2 15.3 10.2 15.4 10.2 15.6 10.2 15.8 10.1 16 10 16.2 9.9 16.4 9.8 16.5 9.6 16.6 9.5 16.8 9.2 16.9 8.8 16.9 8.5 16.9 8.3 16.9 8.2 16.8 8 16.8 7.8 16.7 7.7 16.6 7.5 16.5 7.3 16.3 7.2 16.2 7.1 16 7 15.9 6.9 15.8 6.9 15.7 6.9 15.6 6.8 15.5 6.8L6.2 4.8C6.2 5 6 5.2 5.9 5.3 5.7 5.6 5.5 5.8 5.3 6 4.9 6.2 4.5 6.4 4.1 6.5 3.8 6.6 3.5 6.6 3.2 6.6 3 6.6 2.8 6.6 2.7 6.6 2.6 6.6 2.6 6.5 2.6 6.5 2.5 6.5 2.3 6.5 2.1 6.4 1.8 6.3 1.6 6.1 1.3 6 1 5.7 0.7 5.4 0.5 5 0.3 4.7 0.2 4.4 0.1 4.1 0 3.8 0 3.6 0 3.3 0 2.8 0.1 2.2 0.4 1.7 0.5 1.5 0.7 1.3 0.8 1.1 1.1 0.8 1.3 0.6 1.6 0.5 2 0.3 2.3 0.1 2.7 0.1 3.1 0 3.6 0 4 0.1 4.4 0.2 4.8 0.3 5.1 0.5 5.5 0.8 5.7 1 6 1.3 6.2 1.6 6.3 1.9 6.4 2.3 6.5 2.5 6.6 2.7 6.6 3 6.6 3 6.6 3.1 6.6 3.1 9.7 3.8 12.8 4.4 15.9 5.1 16.1 5.1 16.2 5.2 16.4 5.2 16.7 5.3 16.9 5.5 17.2 5.6 17.5 5.9 17.8 6.2 18.1 6.5 18.3 6.8 18.4 7.2 18.6 7.5 18.6 7.9 18.7 8.2 18.7 8.6 18.7 9 18.6 9.4 18.4 9.8 18.3 10.1 18.2 10.3 18 10.6 17.8 10.9 17.5 11.1 17.3 11.3 16.9 11.6 16.5 11.8 16 11.9 15.7 12 15.3 12 15 12 14.8 12 14.7 12 14.5 11.9 13.9 11.8 13.3 11.7 12.6 11.5 12.5 11.7 12.4 11.9 12.3 12 12.1 12.3 11.9 12.5 11.7 12.7 11.3 12.9 10.9 13.1 10.5 13.2 10.2 13.3 9.9 13.3 9.6 13.3 9.4 13.3 9.2 13.3 9 13.2 9 13.2 9 13.2 9 13.2 8.8 13.2 8.7 13.2 8.5 13.1 8.2 13 8 12.8 7.7 12.6 7.4 12.4 7.1 12 6.8 11.7 6.7 11.4 6.6 11.1 6.5 10.8 6.4 10.6 6.4 10.4 6.4 10.2 5.8 10.1 5.2 9.9 4.5 9.8 4.4 9.8 4.4 9.8 4.3 9.8 4.1 9.8 4 9.8 3.8 9.8 3.6 9.9 3.4 10 3.2 10.1 3 10.2 2.9 10.4 2.8 10.5 2.6 10.8 2.5 11.1 2.5 11.5 2.5 11.6 2.5 11.8 2.6 12 2.6 12.1 2.7 12.3 2.8 12.5 2.9 12.6 3.1 12.8 3.2 12.9 3.3 13 3.5 13.1 3.6 13.1 3.7 13.1 3.8 13.2 3.9 13.2L13.1 15.2 13.1 15.2Z"></path></g></svg><span>Tutorials</span></a></li><li class="nav-offers flyout-parent"><a href="#" class="l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>offers icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M35.9 20.6L27 15.5C26.1 15 24.7 15 23.7 15.5L14.9 20.6C13.9 21.1 13.2 22.4 13.2 23.4L13.2 41.4C13.2 42.4 13.9 43.7 14.9 44.2L23.3 49C24.2 49.5 25.6 49.5 26.6 49L35.9 43.6C36.8 43.1 37.6 41.8 37.6 40.8L37.6 23.4C37.6 22.4 36.8 21.1 35.9 20.6L35.9 20.6ZM40 8.2C39.1 7.6 37.6 7.6 36.7 8.2L30.2 11.9C29.3 12.4 29.3 13.2 30.2 13.8L39.1 18.8C40 19.4 40.7 20.6 40.7 21.7L40.7 39C40.7 40.1 41.4 40.5 42.4 40L48.2 36.6C49.1 36.1 49.8 34.9 49.8 33.8L49.8 15.6C49.8 14.6 49.1 13.3 48.2 12.8L40 8.2 40 8.2ZM27 10.1L33.6 6.4C34.5 5.9 34.5 5 33.6 4.5L26.6 0.5C25.6 0 24.2 0 23.3 0.5L16.7 4.2C15.8 4.7 15.8 5.6 16.7 6.1L23.7 10.1C24.7 10.6 26.1 10.6 27 10.1ZM10.1 21.7C10.1 20.6 10.8 19.4 11.7 18.8L20.6 13.8C21.5 13.2 21.5 12.4 20.6 11.9L13.6 7.9C12.7 7.4 11.2 7.4 10.3 7.9L1.6 12.8C0.7 13.3 0 14.6 0 15.6L0 33.8C0 34.9 0.7 36.1 1.6 36.6L8.4 40.5C9.3 41 10.1 40.6 10.1 39.6L10.1 21.7 10.1 21.7Z"></path></g></svg><span>Offers &amp; Deals</span></a><ul class="flyout"><li><a href="https://www.safaribooksonline.com/oreilly-newsletters/" class="l2 nav-icn"><span>Newsletters</span></a></li></ul></li><li class="nav-highlights"><a href="https://www.safaribooksonline.com/u/0011N00001APXw3QAH/" class="t-highlights-nav l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 35" width="20" height="20" version="1.1" fill="#4A3C31"><desc>highlights icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M13.325 18.071L8.036 18.071C8.036 11.335 12.36 7.146 22.5 5.594L22.5 0C6.37 1.113 0 10.632 0 22.113 0 29.406 3.477 35 10.403 35 15.545 35 19.578 31.485 19.578 26.184 19.578 21.556 17.211 18.891 13.325 18.071L13.325 18.071ZM40.825 18.071L35.565 18.071C35.565 11.335 39.86 7.146 50 5.594L50 0C33.899 1.113 27.5 10.632 27.5 22.113 27.5 29.406 30.977 35 37.932 35 43.045 35 47.078 31.485 47.078 26.184 47.078 21.556 44.74 18.891 40.825 18.071L40.825 18.071Z"></path></g></svg><span>Highlights</span></a></li><li><a href="https://www.safaribooksonline.com/u/" class="t-settings-nav l1 js-settings nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 53" width="20" height="20" version="1.1" fill="#4A3C31"><desc>settings icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M44.6 29.6C44.7 28.6 44.8 27.5 44.8 26.5 44.8 25.5 44.7 24.4 44.6 23.4L49.6 19C50 18.8 50.1 18.3 49.9 17.9 48.9 14.7 47.1 11.7 44.9 9.1 44.6 8.8 44.2 8.7 43.8 8.8L37.4 11.1C35.8 9.8 34 8.7 32.1 8L30.9 1.4C30.8 0.9 30.4 0.6 30 0.5 26.7-0.2 23.3-0.2 20 0.5 19.6 0.6 19.2 0.9 19.1 1.4L17.9 8C16 8.7 14.1 9.8 12.6 11.1L6.2 8.8C5.8 8.7 5.4 8.8 5.1 9.1 2.9 11.7 1.1 14.7 0.1 17.9 -0.1 18.3 0 18.8 0.4 19L5.4 23.4C5.3 24.4 5.2 25.5 5.2 26.5 5.2 27.5 5.3 28.6 5.4 29.6L0.4 34C0 34.2-0.1 34.7 0.1 35.1 1.1 38.3 2.9 41.4 5.1 43.9 5.4 44.2 5.8 44.4 6.2 44.2L12.6 42C14.1 43.2 16 44.3 17.9 45L19.1 51.7C19.2 52.1 19.6 52.5 20 52.5 21.6 52.8 23.3 53 25 53 26.7 53 28.4 52.8 30 52.5 30.4 52.5 30.8 52.1 30.9 51.7L32.1 45C34 44.3 35.8 43.2 37.4 42L43.8 44.2C44.2 44.4 44.6 44.2 44.9 43.9 47.1 41.4 48.9 38.3 49.9 35.1 50.1 34.7 50 34.2 49.6 34L44.6 29.6ZM25 36.4C19.6 36.4 15.2 32 15.2 26.5 15.2 21 19.6 16.6 25 16.6 30.4 16.6 34.8 21 34.8 26.5 34.8 32 30.4 36.4 25 36.4Z"></path></g></svg><span>Settings</span></a></li><li><a href="https://www.safaribooksonline.com/public/support" class="l1 no-icon">Support</a></li><li><a href="https://www.safaribooksonline.com/accounts/logout/" class="l1 no-icon">Sign Out</a></li></ul><ul class="profile"><li><a href="https://www.safaribooksonline.com/u/" class="l2 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 53" width="20" height="20" version="1.1" fill="#4A3C31"><desc>settings icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M44.6 29.6C44.7 28.6 44.8 27.5 44.8 26.5 44.8 25.5 44.7 24.4 44.6 23.4L49.6 19C50 18.8 50.1 18.3 49.9 17.9 48.9 14.7 47.1 11.7 44.9 9.1 44.6 8.8 44.2 8.7 43.8 8.8L37.4 11.1C35.8 9.8 34 8.7 32.1 8L30.9 1.4C30.8 0.9 30.4 0.6 30 0.5 26.7-0.2 23.3-0.2 20 0.5 19.6 0.6 19.2 0.9 19.1 1.4L17.9 8C16 8.7 14.1 9.8 12.6 11.1L6.2 8.8C5.8 8.7 5.4 8.8 5.1 9.1 2.9 11.7 1.1 14.7 0.1 17.9 -0.1 18.3 0 18.8 0.4 19L5.4 23.4C5.3 24.4 5.2 25.5 5.2 26.5 5.2 27.5 5.3 28.6 5.4 29.6L0.4 34C0 34.2-0.1 34.7 0.1 35.1 1.1 38.3 2.9 41.4 5.1 43.9 5.4 44.2 5.8 44.4 6.2 44.2L12.6 42C14.1 43.2 16 44.3 17.9 45L19.1 51.7C19.2 52.1 19.6 52.5 20 52.5 21.6 52.8 23.3 53 25 53 26.7 53 28.4 52.8 30 52.5 30.4 52.5 30.8 52.1 30.9 51.7L32.1 45C34 44.3 35.8 43.2 37.4 42L43.8 44.2C44.2 44.4 44.6 44.2 44.9 43.9 47.1 41.4 48.9 38.3 49.9 35.1 50.1 34.7 50 34.2 49.6 34L44.6 29.6ZM25 36.4C19.6 36.4 15.2 32 15.2 26.5 15.2 21 19.6 16.6 25 16.6 30.4 16.6 34.8 21 34.8 26.5 34.8 32 30.4 36.4 25 36.4Z"></path></g></svg><span>Settings</span></a><span class="l2 t-nag-notification" id="nav-nag"><strong class="trial-green">10</strong> days left in your trial.
  
  

  
    
      

<a class="" href="https://www.safaribooksonline.com/subscribe/">Subscribe</a>.


    
  

  

</span></li><li><a href="https://www.safaribooksonline.com/public/support" class="l2">Support</a></li><li><a href="https://www.safaribooksonline.com/accounts/logout/" class="l2">Sign Out</a></li></ul></div></li></ul></nav></header>


      </div>
      <div id="container" class="application" style="height: auto;">
        
          <div class="nav-container clearfix">
            


            
            
          </div>

          

  <div class="js-toc">
    
      <div class="sbo-reading-menu sbo-menu-top"><section class="sbo-toc-container toc-menu"><a href="#" class="sbo-toc-thumb"><span class="sbo-title ss-list"><h1><div class="visuallyhidden">Table of Contents for </div>
      
      Hands-On Machine Learning with Scikit-Learn and TensorFlow
      
    </h1></span></a><div class="toc-contents" style="max-height: 0px;">
  <div class="sbo-toc ">
    <button type="button" class="sbo-toc-thumb close"><div class="visuallyhidden">Close</div></button>
      <section class="ios-app-teaser">
        <ul>
            <li><a class="js-toc-link toc-link" href="https://itunes.apple.com/gb/app/safari-queue-library-over/id881697395?mt=8" role="button">Install App</a></li>
            <li><a class="js-toc-link toc-link" href="safaridetail://9781491962282" role="button">Open in App</a></li>
        </ul>
      </section>
      <div class="sbo-book-meta">
        
        <span class="cover">
         <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/">
          <img src="12.%20Distributing%20TensorFlow%20Across%20Devices%20and%20Servers%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/a.jpg" alt="Cover image for Hands-On Machine Learning with Scikit-Learn and TensorFlow" width="140" height="184">
        </a>
        </span>
        <span class="title">
          
            
                <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/publisher/oreilly-media-inc/">
                  <img src="12.%20Distributing%20TensorFlow%20Across%20Devices%20and%20Servers%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/ORM_logo_box_rgb.png" class="publisher-logo video" alt="publisher logo">
                </a>
            
          

          <a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/">Hands-On Machine Learning with Scikit-Learn and TensorFlow</a>
        </span>
        
        <span class="authors">by Aurélien Géron</span>
        

        
        <span class="publishers t-publishers">Published by
          <!-- Show publisher page link if publisher pages switch is on -->
          
            <a class="t-publisher-link toc-link js-toc-link" href="https://www.safaribooksonline.com/library/publisher/oreilly-media-inc/">
              O'Reilly Media, Inc.</a>, 2017
          
        </span>
        

    

    </div>
  <ol class="tocList">
    
    
    
     

     <li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/preface01.html#idm140583011384384">
        Preface 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/part01.html#fundamentals_part">
        I. The Fundamentals of Machine Learning 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch01.html#landscape_chapter">
        1. The Machine Learning Landscape 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch02.html#project_chapter">
        2. End-to-End Machine Learning Project 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch03.html#classification_chapter">
        3. Classification 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch04.html#linear_models_chapter">
        4. Training Models 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch05.html#svm_chapter">
        5. Support Vector Machines 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch06.html#trees_chapter">
        6. Decision Trees 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch07.html#ensembles_chapter">
        7. Ensemble Learning and Random Forests 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch08.html#dim_reduction_chapter">
        8. Dimensionality Reduction 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/part02.html#neural_nets_part">
        II. Neural Networks and Deep Learning 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch09.html#tensorflow_chapter">
        9. Up and Running with TensorFlow 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html#ann_chapter">
        10. Introduction to Artificial Neural Networks 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#deep_chapter">
        11. Training Deep Neural Nets 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch12.html#distributed_chapter">
        12. Distributing TensorFlow Across Devices and Servers 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch13.html#cnn_chapter">
        13. Convolutional Neural Networks 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1 currently-reading">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch14.html#rnn_chapter">
        14. Recurrent Neural Networks 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch15.html#autoencoders_chapter">
        15. Autoencoders 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch16.html#rl_chapter">
        16. Reinforcement Learning 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app01.html#solutions_appendix">
        A. Exercise Solutions 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app02.html#project_checklist_appendix">
        B. Machine Learning Project Checklist 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app03.html#svm_dual_problem_appendix">
        C. SVM Dual Problem 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app04.html#autodiff_appendix">
        D. Autodiff 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app05.html#other_ann_appendix">
        E. Other Popular ANN Architectures 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ix01.html#idm140582977822192">
        Index 
       </a>
      
        
      
   </li></ol>
 </div>



</div></section></div>

    

    <div class="interface-controls interface-controls-top">
      <ul class="interface-control-btns js-bitlist js-reader">
        <li class="js-search-in-archive search-in-archive t-search-in-archive"><a href="#" title="Search in archive" class="js-search-controls search-controls"><span class="icon">Search in book...</span></a><form class="search-archive-bar js-search-form"><input name="query" placeholder="Search inside this book..." autocomplete="off" type="search"></form><div class="search-archive-results"><div class="js-sitb-results-region"></div></div></li><li class="queue-control"><button type="button" class="rec-fav ss-queue js-queue js-current-chapter-queue" data-queue-endpoint="/api/v1/book/9781491962282/chapter/ch14.html" data-for-analytics="9781491962282:ch14.html" aria-label="Add to Queue"><span>Add to Queue</span></button></li><li class="js-font-control-panel font-control-activator"><a href="#" data-push-state="false" id="font-controls" title="Change font size" aria-label="Change font size"><span class="icon">Toggle Font Controls</span></a></li><li class="dropdown sharing-controls"><a href="#" class="trigger" data-push-state="false" title="Share" aria-label="Share"><i class="fa fa-share"></i></a><ul class="social-sharing dropdown-menu"><li class=""><a class="twitter share-button t-twitter" target="_blank" aria-label="Share this section on Twitter" title="Share this section on Twitter" href="https://twitter.com/share?url=https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html&amp;text=Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow&amp;via=safari"><span>Twitter</span></a></li><li class=""><a class="facebook share-button t-facebook" target="_blank" aria-label="Share this section on Facebook" title="Share this section on Facebook" href="https://www.facebook.com/sharer/sharer.php?u=https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html"><span>Facebook</span></a></li><li class=""><a class="googleplus share-button t-googleplus" target="_blank" aria-label="Share this secton on Google Plus" title="Share this secton on Google Plus" href="https://plus.google.com/share?url=https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html"><span>Google Plus</span></a></li><li class=""><a class="email share-button t-email" aria-label="Share this section via email" title="Share this section via email" href="mailto:?subject=Safari:%2010.%20Introduction%20to%20Artificial%20Neural%20Networks&amp;body=https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html%0D%0Afrom%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow%0D%0A"><span>Email</span></a></li></ul></li>
      </ul>
    </div>

    <section role="document">
	  <div class="t-sbo-prev sbo-prev sbo-nav-top">
  
    
      
        <a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch13.html" class="prev nav-link">
      
          <span aria-hidden="true" class="pagination-label t-prev-label">Prev</span>
          <span class="visuallyhidden">Previous Chapter</span>
          <div class="pagination-title t-prev-title">13. Convolutional Neural Networks</div>
        </a>
    
  
  </div>

  <div class="t-sbo-next sbo-next sbo-nav-top">
  
    
      
        <a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch15.html" class="next nav-link">
      
          <span aria-hidden="true" class="pagination-label t-next-label">Next</span>
          <span class="visuallyhidden">Next Chapter</span>
          <div class="pagination-title t-next-title">15. Autoencoders</div>
        </a>
    
  
  </div>



<div id="sbo-rt-content"><div class="annotator-wrapper"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 14. Recurrent Neural Networks"><div class="chapter" id="rnn_chapter">
<h1><span class="label">Chapter 14. </span>Recurrent Neural Networks</h1>


<p>The <a data-type="indexterm" data-primary="recurrent neural networks (RNNs)" id="rnn14"></a>batter
 hits the ball. You immediately start running, anticipating the ball’s 
trajectory. You track it and adapt your movements, and finally catch it 
(under a thunder of applause). Predicting the future is what you do all 
the time, whether you are finishing a friend’s sentence or anticipating 
the smell of coffee at breakfast. In this chapter, we are going to 
discuss <em>recurrent neural networks</em> (RNN), a class of nets that can predict the future (well, up to a point, of course). They can analyze <em>time series</em> <a data-type="indexterm" data-primary="time series data" id="idm140582990847456"></a>data such as stock prices, and tell you when to buy or sell. In <a data-type="indexterm" data-primary="autonomous driving systems" id="idm140582990846592"></a>autonomous driving systems, they can anticipate car trajectories and help avoid accidents. More generally, they can work on <em>sequences</em> <a data-type="indexterm" data-primary="sequences" id="idm140582990845200"></a>of
 arbitrary lengths, rather than on fixed-sized inputs like all the nets 
we have discussed so far. For example, they can take sentences, 
documents, or audio samples as input, making them extremely useful for <a data-type="indexterm" data-primary="natural language processing (NLP)" id="idm140582990844112"></a>natural language processing (NLP) systems such as automatic translation, speech-to-text, or <em>sentiment analysis</em> <a data-type="indexterm" data-primary="sentiment analysis" id="idm140582990842800"></a>(e.g., reading movie reviews and extracting the rater’s feeling about the movie).</p>

<p>Moreover, RNNs’ ability to anticipate also makes them capable of 
surprising creativity. You can ask them to predict which are the most 
likely next notes in a melody, then randomly pick one of these notes and
 play it. Then ask the net for the next most likely notes, play it, and 
repeat the process again and again. Before you know it, your net will 
compose a melody such as <a href="http://goo.gl/IxIL1V">the one</a> produced by Google’s <a href="https://magenta.tensorflow.org/">Magenta project</a>. Similarly, RNNs can <a href="http://goo.gl/onkPNd">generate sentences</a>, <a href="http://goo.gl/Nwx7Kh">image captions</a>, and much more. The result is not exactly Shakespeare or Mozart yet, but who knows what they will produce a few years from now?</p>

<p>In this chapter, we will look at the fundamental concepts underlying 
RNNs, the main problem they face (namely, vanishing/exploding gradients,
 discussed in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#deep_chapter">Chapter&nbsp;11</a>),
 and the solutions widely used to fight it: LSTM and GRU cells. Along 
the way, as always, we will show how to implement RNNs using TensorFlow.
 Finally, we will take a look at the architecture of a machine 
translation system.</p>






<section data-type="sect1" data-pdf-bookmark="Recurrent Neurons"><div class="sect1" id="idm140582990836592">
<h1>Recurrent Neurons</h1>

<p>Up <a data-type="indexterm" data-primary="recurrent neurons" id="rn14"></a>to
 now we have mostly looked at feedforward neural networks, where the 
activations flow only in one direction, from the input layer to the 
output layer (except for a few networks in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app05.html#other_ann_appendix">Appendix&nbsp;E</a>).
 A recurrent neural network looks very much like a feedforward neural 
network, except it also has connections pointing backward. Let’s look at
 the simplest possible RNN, composed of just one neuron receiving 
inputs, producing an output, and sending that output back to itself, as 
shown in <a data-type="xref" href="#simple_rnn_diagram">Figure&nbsp;14-1</a> (left). At each <em>time step</em> <em>t</em> (also called a <em>frame</em>), this <em>recurrent neuron</em> receives the inputs <strong>x</strong><sub>(<em>t</em>)</sub> as well as its own output from the previous time step, <em>y</em><sub>(<em>t</em>–1)</sub>. We can represent this tiny network against the time axis, as shown in <a data-type="xref" href="#simple_rnn_diagram">Figure&nbsp;14-1</a> (right). This is called <em>unrolling the network through time</em>.</p>

<figure class="smallerseventy"><div id="simple_rnn_diagram" class="figure">
<img src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1401.png" alt="mlst 1401" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1401.png" width="1363" height="594">
<h6><span class="label">Figure 14-1. </span>A recurrent neuron (left), unrolled through time (right)</h6>
</div></figure>

<p>You can easily create a layer of recurrent neurons. At each time step <em>t</em>, every neuron receives both the input vector <strong>x</strong><sub>(<em>t</em>)</sub> and the output vector from the previous time step <strong>y</strong><sub>(<em>t</em>–1)</sub>, as shown in <a data-type="xref" href="#rnn_layer_diagram">Figure&nbsp;14-2</a>. Note that both the inputs and outputs are vectors now (when there was just a single neuron, the output was a scalar).</p>

<figure class="smallereighty"><div id="rnn_layer_diagram" class="figure">
<img src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1402.png" alt="mlst 1402" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1402.png" width="1440" height="548">
<h6><span class="label">Figure 14-2. </span>A layer of recurrent neurons (left), unrolled through time (right)</h6>
</div></figure>

<p>Each recurrent neuron has two sets of weights: one for the inputs <strong>x</strong><sub>(<em>t</em>)</sub> and the other for the outputs of the previous time step, <strong>y</strong><sub>(<em>t</em>–1)</sub>. Let’s call these weight vectors <strong>w</strong><sub><em>x</em></sub> and <strong>w</strong><sub><em>y</em></sub>.
 If we consider the whole recurrent layer instead of just one recurrent 
neuron, we can place all the weight vectors in two weight matrices, <strong>W</strong><sub><em>x</em></sub> and <strong>W</strong><sub><em>y</em></sub>. The output vector of the whole recurrent layer can then be computed pretty much as you might expect, as shown in <a data-type="xref" href="#rnn_output_equation">Equation 14-1</a> (<strong>b</strong> is the bias vector and ϕ(·) is the activation function, e.g., ReLU<sup><a data-type="noteref" id="idm140582990809232-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch14.html#idm140582990809232" class="totri-footnote">1</a></sup>).</p>
<div id="rnn_output_equation" data-type="equation"><h5><span class="label">Equation 14-1. </span>Output of a recurrent layer for a single instance</h5>
<img src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_127.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_127.png" width="1038" height="84"></div>

<p>Just like for feedforward neural networks, we can compute a recurrent
 layer’s output in one shot for a whole mini-batch by placing all the 
inputs at time step <em>t</em> in an input matrix <strong>X</strong><sub>(<em>t</em>)</sub> (see <a data-type="xref" href="#rnn_output_vectorized_equation">Equation 14-2</a>).</p>
<div id="rnn_output_vectorized_equation" data-type="equation"><h5><span class="label">Equation 14-2. </span>Outputs of a layer of recurrent neurons for all instances in a mini-batch</h5>
<img src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_128.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_128.png" width="1216" height="246"></div>

<ul>
<li>
<p><strong>Y</strong><sub>(<em>t</em>)</sub> is an <em>m</em> × <em>n</em><sub>neurons</sub> matrix containing the layer’s outputs at time step <em>t</em> for each instance in the mini-batch (<em>m</em> is the number of instances in the mini-batch and <em>n</em><sub>neurons</sub> is the number of neurons).</p>
</li>
<li>
<p><strong>X</strong><sub>(<em>t</em>)</sub> is an <em>m</em> × <em>n</em><sub>inputs</sub> matrix containing the inputs for all instances (<em>n</em><sub>inputs</sub> is the number of input features).</p>
</li>
<li>
<p><strong>W</strong><sub><em>x</em></sub> is an <em>n</em><sub>inputs</sub> × <em>n</em><sub>neurons</sub> matrix containing the connection weights for the inputs of the current time step.</p>
</li>
<li>
<p><strong>W</strong><sub><em>y</em></sub> is an <em>n</em><sub>neurons</sub> × <em>n</em><sub>neurons</sub> matrix containing the connection weights for the outputs of the previous time step.</p>
</li>
<li>
<p><strong>b</strong> is a vector of size <em>n</em><sub>neurons</sub> containing each neuron’s bias term.</p>
</li>
<li>
<p>The weight matrices <strong>W</strong><sub><em>x</em></sub> and <strong>W</strong><sub><em>y</em></sub> are often concatenated vertically into a single weight matrix <strong>W</strong> of shape (<em>n</em><sub>inputs</sub> + <em>n</em><sub>neurons</sub>) × <em>n</em><sub>neurons</sub> (see the second line of <a data-type="xref" href="#rnn_output_vectorized_equation">Equation 14-2</a>).</p>
</li>
<li>
<p>The notation [<strong>X</strong><sub>(<em>t</em>)</sub> <strong>Y</strong><sub>(<em>t</em>–1)</sub>] represents the horizontal concatenation of the matrices <strong>X</strong><sub>(<em>t</em>)</sub> and <strong>Y</strong><sub>(<em>t</em>–1)</sub>.</p>
</li>
</ul>

<p>Notice that <strong>Y</strong><sub>(<em>t</em>)</sub> is a function of <strong>X</strong><sub>(<em>t</em>)</sub> and <strong>Y</strong><sub>(<em>t</em>–1)</sub>, which is a function of <strong>X</strong><sub>(<em>t</em>–1)</sub> and <strong>Y</strong><sub>(<em>t</em>–2)</sub>, which is a function of <strong>X</strong><sub>(<em>t</em>–2)</sub> and <strong>Y</strong><sub>(<em>t</em>–3)</sub>, and so on. This makes <strong>Y</strong><sub>(<em>t</em>)</sub> a function of all the inputs since time <em>t</em> = 0 (that is, <strong>X</strong><sub>(0)</sub>, <strong>X</strong><sub>(1)</sub>, …, <strong>X</strong><sub>(<em>t</em>)</sub>). At the first time step, <em>t</em> = 0, there are no previous outputs, so they are typically assumed to be all zeros.</p>








<section data-type="sect2" data-pdf-bookmark="Memory Cells"><div class="sect2" id="idm140582990769744">
<h2>Memory Cells</h2>

<p>Since <a data-type="indexterm" data-primary="recurrent neurons" data-secondary="memory cells" id="idm140582990755376"></a><a data-type="indexterm" data-primary="memory cells" id="idm140582990754368"></a>the output of a recurrent neuron at time step <em>t</em> is a function of all the inputs from previous time steps, you could say it has a form of <em>memory</em>. A part of a neural network that preserves some state across time steps is called a <em>memory cell</em> (or simply a <em>cell</em>). A single recurrent neuron, or a layer of recurrent neurons, is a very <em>basic cell</em>, but later in this chapter we will look at some more complex and powerful types of cells.</p>

<p>In general a cell’s state at time step <em>t</em>, denoted <strong>h</strong><sub>(<em>t</em>)</sub> (the “h” stands for “hidden”), is a function of some inputs at that time step and its state at the previous time step: <strong>h</strong><sub>(<em>t</em>)</sub> = <em>f</em>(<strong>h</strong><sub>(<em>t</em>–1)</sub>, <strong>x</strong><sub>(<em>t</em>)</sub>). Its output at time step <em>t</em>, denoted <strong>y</strong><sub>(<em>t</em>)</sub>,
 is also a function of the previous state and the current inputs. In the
 case of the basic cells we have discussed so far, the output is simply 
equal to the state, but in more complex cells this is not always the 
case, as shown in <a data-type="xref" href="#hidden_state_diagram">Figure&nbsp;14-3</a>.</p>

<figure class="smallerseventy"><div id="hidden_state_diagram" class="figure">
<img src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1403.png" alt="mlst 1403" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1403.png" width="1095" height="513">
<h6><span class="label">Figure 14-3. </span>A cell’s hidden state and its output may be different</h6>
</div></figure>
</div></section>













<section data-type="sect2" class="pagebreak-before" data-pdf-bookmark="Input and Output Sequences"><div class="sect2" id="idm140582990739824">
<h2>Input and Output Sequences</h2>

<p>An <a data-type="indexterm" data-primary="recurrent neural networks (RNNs)" data-secondary="input and output sequences" id="rnn14iaos"></a>RNN can simultaneously take a sequence of inputs and produce a sequence of outputs (see <a data-type="xref" href="#seq_to_seq_diagram">Figure&nbsp;14-4</a>,
 top-left network). For example, this type of network is useful for 
predicting time series such as stock prices: you feed it the prices over
 the last <em>N</em> days, and it must output the prices shifted by one day into the future (i.e., from <em>N</em> – 1 days ago to tomorrow).</p>

<p>Alternatively, you could feed the network a sequence of inputs, and 
ignore all outputs except for the last one (see the top-right network). 
In other words, this is a sequence-to-vector network. For example, you 
could feed the network a sequence of words corresponding to a movie 
review, and the network would output a sentiment score (e.g., from –1 
[hate] to +1 [love]).</p>

<p>Conversely, you could feed the network a single input at the first 
time step (and zeros for all other time steps), and let it output a 
sequence (see the bottom-left network). This is a vector-to-sequence 
network. For example, the input could be an image, and the output could 
be a caption for that image.</p>

<p>Lastly, you could have a sequence-to-vector network, called <a data-type="indexterm" data-primary="Encoder–Decoder" id="idm140582990732704"></a>an <em>encoder</em>, followed by a vector-to-sequence network, called a <em>decoder</em>
 (see the bottom-right network). For example, this can be used for 
translating a sentence from one language to another. You would feed the 
network a sentence in one language, the encoder would convert this 
sentence into a single vector representation, and then the decoder would
 decode this vector into a sentence in another language. This two-step 
model, called an Encoder–Decoder, works much better than trying to 
translate on the fly with a single sequence-to-sequence RNN (like the 
one represented on the top left), since the last words of a sentence can
 affect the first words of the translation, so you need to wait until 
you have heard the whole sentence before translating it.</p>

<figure><div id="seq_to_seq_diagram" class="figure">
<img src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1404.png" alt="mlst 1404" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1404.png" width="1440" height="965">
<h6><span class="label">Figure 14-4. </span>Seq to seq (top left), seq to vector (top right), vector to seq (bottom left), delayed seq to seq (bottom right)</h6>
</div></figure>

<p>Sounds promising, so let’s <a data-type="indexterm" data-primary="recurrent neural networks (RNNs)" data-secondary="input and output sequences" data-startref="rnn14iaos" id="idm140582990727696"></a><a data-type="indexterm" data-primary="recurrent neurons" data-startref="rn14" id="idm140582990726368"></a>start coding!</p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Basic RNNs in TensorFlow"><div class="sect1" id="idm140582990836000">
<h1>Basic RNNs in TensorFlow</h1>

<p>First, <a data-type="indexterm" data-primary="recurrent neural networks (RNNs)" data-secondary="in TensorFlow" data-secondary-sortas="TensorFlow" id="rnn14it"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="RNNs in" data-seealso="recurrent neural networks (RNNs)" id="tf14rnni"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.random_normal()" id="idm140582990681040"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.zeros()" id="idm140582990680096"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.tanh()" id="idm140582990679152"></a> <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.matmul()" id="idm140582990678080"></a>let’s
 implement a very simple RNN model, without using any of TensorFlow’s 
RNN operations, to better understand what goes on under the hood. We 
will create an RNN composed of a layer of five recurrent neurons (like 
the RNN represented in <a data-type="xref" href="#rnn_layer_diagram">Figure&nbsp;14-2</a>),
 using the tanh activation function. We will assume that the RNN runs 
over only two time steps, taking input vectors of size 3 at each time 
step. The following code builds this RNN, unrolled through two time 
steps:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">n_inputs</code> <code class="o">=</code> <code class="mi">3</code>
<code class="n">n_neurons</code> <code class="o">=</code> <code class="mi">5</code>

<code class="n">X0</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">placeholder</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">,</code> <code class="p">[</code><code class="bp">None</code><code class="p">,</code> <code class="n">n_inputs</code><code class="p">])</code>
<code class="n">X1</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">placeholder</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">,</code> <code class="p">[</code><code class="bp">None</code><code class="p">,</code> <code class="n">n_inputs</code><code class="p">])</code>

<code class="n">Wx</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">Variable</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">random_normal</code><code class="p">(</code><code class="n">shape</code><code class="o">=</code><code class="p">[</code><code class="n">n_inputs</code><code class="p">,</code> <code class="n">n_neurons</code><code class="p">],</code><code class="n">dtype</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">))</code>
<code class="n">Wy</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">Variable</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">random_normal</code><code class="p">(</code><code class="n">shape</code><code class="o">=</code><code class="p">[</code><code class="n">n_neurons</code><code class="p">,</code><code class="n">n_neurons</code><code class="p">],</code><code class="n">dtype</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">))</code>
<code class="n">b</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">Variable</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">zeros</code><code class="p">([</code><code class="mi">1</code><code class="p">,</code> <code class="n">n_neurons</code><code class="p">],</code> <code class="n">dtype</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">))</code>

<code class="n">Y0</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">tanh</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">matmul</code><code class="p">(</code><code class="n">X0</code><code class="p">,</code> <code class="n">Wx</code><code class="p">)</code> <code class="o">+</code> <code class="n">b</code><code class="p">)</code>
<code class="n">Y1</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">tanh</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">matmul</code><code class="p">(</code><code class="n">Y0</code><code class="p">,</code> <code class="n">Wy</code><code class="p">)</code> <code class="o">+</code> <code class="n">tf</code><code class="o">.</code><code class="n">matmul</code><code class="p">(</code><code class="n">X1</code><code class="p">,</code> <code class="n">Wx</code><code class="p">)</code> <code class="o">+</code> <code class="n">b</code><code class="p">)</code>

<code class="n">init</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">global_variables_initializer</code><code class="p">()</code></pre>

<p>This network looks much like a two-layer feedforward neural network, 
with a few twists: first, the same weights and bias terms are shared by 
both layers, and second, we feed inputs at each layer, and we get 
outputs from each layer. To run the model, we need to feed it the inputs
 at both time steps, like so:</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">import</code> <code class="nn">numpy</code> <code class="kn">as</code> <code class="nn">np</code>

<code class="c1"># Mini-batch:        instance 0,instance 1,instance 2,instance 3</code>
<code class="n">X0_batch</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">([[</code><code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">,</code> <code class="mi">2</code><code class="p">],</code> <code class="p">[</code><code class="mi">3</code><code class="p">,</code> <code class="mi">4</code><code class="p">,</code> <code class="mi">5</code><code class="p">],</code> <code class="p">[</code><code class="mi">6</code><code class="p">,</code> <code class="mi">7</code><code class="p">,</code> <code class="mi">8</code><code class="p">],</code> <code class="p">[</code><code class="mi">9</code><code class="p">,</code> <code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">]])</code> <code class="c1"># t = 0</code>
<code class="n">X1_batch</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">([[</code><code class="mi">9</code><code class="p">,</code> <code class="mi">8</code><code class="p">,</code> <code class="mi">7</code><code class="p">],</code> <code class="p">[</code><code class="mi">0</code><code class="p">,</code> <code class="mi">0</code><code class="p">,</code> <code class="mi">0</code><code class="p">],</code> <code class="p">[</code><code class="mi">6</code><code class="p">,</code> <code class="mi">5</code><code class="p">,</code> <code class="mi">4</code><code class="p">],</code> <code class="p">[</code><code class="mi">3</code><code class="p">,</code> <code class="mi">2</code><code class="p">,</code> <code class="mi">1</code><code class="p">]])</code> <code class="c1"># t = 1</code>

<code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">Session</code><code class="p">()</code> <code class="k">as</code> <code class="n">sess</code><code class="p">:</code>
    <code class="n">init</code><code class="o">.</code><code class="n">run</code><code class="p">()</code>
    <code class="n">Y0_val</code><code class="p">,</code> <code class="n">Y1_val</code> <code class="o">=</code> <code class="n">sess</code><code class="o">.</code><code class="n">run</code><code class="p">([</code><code class="n">Y0</code><code class="p">,</code> <code class="n">Y1</code><code class="p">],</code> <code class="n">feed_dict</code><code class="o">=</code><code class="p">{</code><code class="n">X0</code><code class="p">:</code> <code class="n">X0_batch</code><code class="p">,</code> <code class="n">X1</code><code class="p">:</code> <code class="n">X1_batch</code><code class="p">})</code></pre>

<p>This mini-batch contains four instances, each with an input sequence composed of exactly two inputs. At the end, <code>Y0_val</code> and <code>Y1_val</code> contain the outputs of the network at both time steps for all neurons and all instances in the mini-batch:</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="k">print</code><code class="p">(</code><code class="n">Y0_val</code><code class="p">)</code>  <code class="c"># output at t = 0</code>
<code class="go">[[-0.0664006   0.96257669  0.68105787  0.70918542 -0.89821595]  # instance 0</code>
<code class="go"> [ 0.9977755  -0.71978885 -0.99657625  0.9673925  -0.99989718]  # instance 1</code>
<code class="go"> [ 0.99999774 -0.99898815 -0.99999893  0.99677622 -0.99999988]  # instance 2</code>
<code class="go"> [ 1.         -1.         -1.         -0.99818915  0.99950868]] # instance 3</code>
<code class="gp">&gt;&gt;&gt; </code><code class="k">print</code><code class="p">(</code><code class="n">Y1_val</code><code class="p">)</code>  <code class="c"># output at t = 1</code>
<code class="go">[[ 1.         -1.         -1.          0.40200216 -1.        ]  # instance 0</code>
<code class="go"> [-0.12210433  0.62805319  0.96718419 -0.99371207 -0.25839335]  # instance 1</code>
<code class="go"> [ 0.99999827 -0.9999994  -0.9999975  -0.85943311 -0.9999879 ]  # instance 2</code>
<code class="go"> [ 0.99928284 -0.99999815 -0.99990582  0.98579615 -0.92205751]] # instance 3</code></pre>

<p>That wasn’t too hard, but of course if you want to be able to run an 
RNN over 100 time steps, the graph is going to be pretty big. Now let’s 
look at how to create the same model using TensorFlow’s RNN <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.contrib.rnn.static_rnn()" id="tfcrsrch14"></a>operations.</p>








<section data-type="sect2" data-pdf-bookmark="Static Unrolling Through Time"><div class="sect2" id="idm140582990220480">
<h2>Static Unrolling Through Time</h2>

<p>The <code>static_rnn()</code> <a data-type="indexterm" data-primary="static_rnn()" id="rnnf14"></a><a data-type="indexterm" data-primary="recurrent neural networks (RNNs)" data-secondary="in TensorFlow" data-tertiary="static unrolling through time" data-secondary-sortas="TensorFlow" id="rnn14itsutt"></a><a data-type="indexterm" data-primary="static unrolling through time" id="sutt14"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.contrib.rnn.BasicRNNCell" id="tfcrbrcch10"></a>function creates an unrolled RNN network by chaining cells. The following code creates the exact same model as the previous one:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">X0</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">placeholder</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">,</code> <code class="p">[</code><code class="bp">None</code><code class="p">,</code> <code class="n">n_inputs</code><code class="p">])</code>
<code class="n">X1</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">placeholder</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">,</code> <code class="p">[</code><code class="bp">None</code><code class="p">,</code> <code class="n">n_inputs</code><code class="p">])</code>

<code class="n">basic_cell</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">contrib</code><code class="o">.</code><code class="n">rnn</code><code class="o">.</code><code class="n">BasicRNNCell</code><code class="p">(</code><code class="n">num_units</code><code class="o">=</code><code class="n">n_neurons</code><code class="p">)</code>
<code class="n">output_seqs</code><code class="p">,</code> <code class="n">states</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">contrib</code><code class="o">.</code><code class="n">rnn</code><code class="o">.</code><code class="n">static_rnn</code><code class="p">(</code><code class="n">basic_cell</code><code class="p">,</code> <code class="p">[</code><code class="n">X0</code><code class="p">,</code> <code class="n">X1</code><code class="p">],</code>
                                                <code class="n">dtype</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">)</code>
<code class="n">Y0</code><code class="p">,</code> <code class="n">Y1</code> <code class="o">=</code> <code class="n">output_seqs</code></pre>

<p>First we create the input placeholders, as before. Then we create a <code>BasicRNNCell</code>,
 which you can think of as a factory that creates copies of the cell to 
build the unrolled RNN  (one for each time step). Then we call <code>static_rnn()</code>,
 giving it the cell factory and the input tensors, and telling it the 
data type of the inputs (this is used to create the initial state 
matrix, which by default is full of zeros). The <code>static_rnn()</code> function calls the cell factory’s <code>__call__()</code> <a data-type="indexterm" data-primary="__call__()" id="idm140582990427344" contenteditable="false"></a>function
 once per input, creating two copies of the cell (each containing a 
layer of five recurrent neurons), with shared weights and bias terms, 
and it chains them just like we did earlier. The <code>static_rnn()</code>
 function returns two objects. The first is a Python list containing the
 output tensors for each time step. The second is a tensor containing 
the final states of the network. When you are using basic cells, the 
final state is simply equal to the last output.</p>

<p>If there were 50 time steps, it would not be very convenient to have 
to define 50 input placeholders and 50 output tensors. Moreover, at 
execution time you would have to feed each of the 50 placeholders and 
manipulate the 50 outputs. Let’s simplify this. The following code 
builds the same RNN again, but this time it takes a single input 
placeholder of shape <code>[None, n_steps, n_inputs]</code> where the first dimension is the mini-batch size. Then it extracts the list of input sequences for each time step. <code>X_seqs</code> is a Python list of <code>n_steps</code> tensors of shape <code>[None, n_inputs]</code>, where once again the first dimension is the mini-batch size. To do this, we first swap the first two dimensions using the <code>transpose()</code> <a data-type="indexterm" data-primary="transpose()" id="idm140582990152944"></a>function,
 so that the time steps are now the first dimension. Then we extract a 
Python list of tensors along the first dimension (i.e., one tensor per 
time step) using the <code>unstack()</code> <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.unstack()" id="tfunstackcha14"></a><a data-type="indexterm" data-primary="unstack()" id="idm140582990150224"></a>function. The next two lines are the same as before. Finally, we merge all the output tensors into a single tensor using the <code>stack()</code> <a data-type="indexterm" data-primary="stack()" id="idm140582990148896"></a>function, and we swap the first two dimensions to get a final <code>outputs</code> tensor of shape <code>[None, n_steps, n_neurons]</code> (again the first dimension is the mini-batch size).</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">X</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">placeholder</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">,</code> <code class="p">[</code><code class="bp">None</code><code class="p">,</code> <code class="n">n_steps</code><code class="p">,</code> <code class="n">n_inputs</code><code class="p">])</code>
<code class="n">X_seqs</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">unstack</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">transpose</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">perm</code><code class="o">=</code><code class="p">[</code><code class="mi">1</code><code class="p">,</code> <code class="mi">0</code><code class="p">,</code> <code class="mi">2</code><code class="p">]))</code>
<code class="n">basic_cell</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">contrib</code><code class="o">.</code><code class="n">rnn</code><code class="o">.</code><code class="n">BasicRNNCell</code><code class="p">(</code><code class="n">num_units</code><code class="o">=</code><code class="n">n_neurons</code><code class="p">)</code>
<code class="n">output_seqs</code><code class="p">,</code> <code class="n">states</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">contrib</code><code class="o">.</code><code class="n">rnn</code><code class="o">.</code><code class="n">static_rnn</code><code class="p">(</code><code class="n">basic_cell</code><code class="p">,</code> <code class="n">X_seqs</code><code class="p">,</code>
                                                <code class="n">dtype</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">)</code>
<code class="n">outputs</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">transpose</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">stack</code><code class="p">(</code><code class="n">output_seqs</code><code class="p">),</code> <code class="n">perm</code><code class="o">=</code><code class="p">[</code><code class="mi">1</code><code class="p">,</code> <code class="mi">0</code><code class="p">,</code> <code class="mi">2</code><code class="p">])</code></pre>

<p>Now we <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.transpose()" id="idm140582990146224"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.stack()" id="idm140582990145376"></a>can run the network by feeding it a single tensor that contains all the mini-batch sequences:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">X_batch</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">([</code>
         <code class="c1"># t = 0     t = 1</code>
        <code class="p">[[</code><code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">,</code> <code class="mi">2</code><code class="p">],</code> <code class="p">[</code><code class="mi">9</code><code class="p">,</code> <code class="mi">8</code><code class="p">,</code> <code class="mi">7</code><code class="p">]],</code> <code class="c1"># instance 0</code>
        <code class="p">[[</code><code class="mi">3</code><code class="p">,</code> <code class="mi">4</code><code class="p">,</code> <code class="mi">5</code><code class="p">],</code> <code class="p">[</code><code class="mi">0</code><code class="p">,</code> <code class="mi">0</code><code class="p">,</code> <code class="mi">0</code><code class="p">]],</code> <code class="c1"># instance 1</code>
        <code class="p">[[</code><code class="mi">6</code><code class="p">,</code> <code class="mi">7</code><code class="p">,</code> <code class="mi">8</code><code class="p">],</code> <code class="p">[</code><code class="mi">6</code><code class="p">,</code> <code class="mi">5</code><code class="p">,</code> <code class="mi">4</code><code class="p">]],</code> <code class="c1"># instance 2</code>
        <code class="p">[[</code><code class="mi">9</code><code class="p">,</code> <code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">],</code> <code class="p">[</code><code class="mi">3</code><code class="p">,</code> <code class="mi">2</code><code class="p">,</code> <code class="mi">1</code><code class="p">]],</code> <code class="c1"># instance 3</code>
    <code class="p">])</code>

<code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">Session</code><code class="p">()</code> <code class="k">as</code> <code class="n">sess</code><code class="p">:</code>
    <code class="n">init</code><code class="o">.</code><code class="n">run</code><code class="p">()</code>
    <code class="n">outputs_val</code> <code class="o">=</code> <code class="n">outputs</code><code class="o">.</code><code class="n">eval</code><code class="p">(</code><code class="n">feed_dict</code><code class="o">=</code><code class="p">{</code><code class="n">X</code><code class="p">:</code> <code class="n">X_batch</code><code class="p">})</code></pre>

<p>And we get a single <code>outputs_val</code> tensor for all instances, all time steps, and all neurons:</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="k">print</code><code class="p">(</code><code class="n">outputs_val</code><code class="p">)</code>
<code class="go">[[[-0.91279727  0.83698678 -0.89277941  0.80308062 -0.5283336 ]</code>
<code class="go">  [-1.          1.         -0.99794829  0.99985468 -0.99273592]]</code>

<code class="go"> [[-0.99994391  0.99951613 -0.9946925   0.99030769 -0.94413054]</code>
<code class="go">  [ 0.48733309  0.93389565 -0.31362072  0.88573611  0.2424476 ]]</code>

<code class="go"> [[-1.          0.99999875 -0.99975014  0.99956584 -0.99466234]</code>
<code class="go">  [-0.99994856  0.99999434 -0.96058172  0.99784708 -0.9099462 ]]</code>

<code class="go"> [[-0.95972425  0.99951482  0.96938795 -0.969908   -0.67668229]</code>
<code class="go">  [-0.84596014  0.96288228  0.96856463 -0.14777924 -0.9119423 ]]]</code></pre>

<p>However, this approach still builds a graph containing one cell per 
time step. If there were 50 time steps, the graph would look pretty 
ugly. It is a bit like writing a program without ever using loops (e.g.,
 <code>Y0=f(0, X0); Y1=f(Y0, X1); Y2=f(Y1, X2); ...; Y50=f(Y49, X50)</code>). With such as large graph, you may even get out-of-memory (OOM) errors <a data-type="indexterm" data-primary="out-of-memory (OOM) errors" id="idm140582989838496"></a>during
 backpropagation (especially with the limited memory of GPU cards), 
since it must store all tensor values during the forward pass so it can 
use them to compute gradients during the  <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.nn.dynamic_rnn()" id="tfnndrch14"></a>reverse pass.</p>

<p>Fortunately, there is a <a data-type="indexterm" data-primary="static_rnn()" data-startref="rnnf14" id="idm140582989835888"></a><a data-type="indexterm" data-primary="recurrent neural networks (RNNs)" data-secondary="in TensorFlow" data-tertiary="static unrolling through time" data-secondary-sortas="TensorFlow" data-startref="rnn14itsutt" id="idm140582989834912"></a><a data-type="indexterm" data-primary="static unrolling through time" data-startref="sutt14" id="idm140582989833168"></a>better solution: the <code>dynamic_rnn()</code> function.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Dynamic Unrolling Through Time"><div class="sect2" id="idm140582990219888">
<h2>Dynamic Unrolling Through Time</h2>

<p>The <code>dynamic_rnn()</code> <a data-type="indexterm" data-primary="dynamic_rnn()" id="idm140582989820160"></a><a data-type="indexterm" data-primary="recurrent neural networks (RNNs)" data-secondary="in TensorFlow" data-tertiary="dynamic unrolling through time" data-secondary-sortas="TensorFlow" id="idm140582989819424"></a><a data-type="indexterm" data-primary="dynamic unrolling through time" id="idm140582989817952"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.nn.dynamic_rnn()" data-startref="tfnndrch14" id="idm140582989817264"></a> <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.unstack()" data-startref="tfunstackcha14" id="idm140582989815920"></a>function uses a <code>while_loop()</code> <a data-type="indexterm" data-primary="while_loop()" id="idm140582989814128"></a>operation to run over the cell the appropriate number of times, and you can set <code>swap_memory=True</code>
 if you want it to swap the GPU’s memory to the CPU’s memory during 
backpropagation to avoid OOM errors. Conveniently, it also accepts a 
single tensor for all inputs at every time step (shape <code>[None, n_steps, n_inputs]</code>) and it outputs a single tensor for all outputs at every time step (shape <code>[None, n_steps, n_neurons]</code>); there is no need to stack, unstack, or transpose. The following code creates the same RNN as earlier using the <code>dynamic_rnn()</code> function. <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.contrib.rnn.BasicRNNCell" data-startref="tfcrbrcch10" id="idm140582989811312"></a>It’s so much nicer!</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">X</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">placeholder</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">,</code> <code class="p">[</code><code class="bp">None</code><code class="p">,</code> <code class="n">n_steps</code><code class="p">,</code> <code class="n">n_inputs</code><code class="p">])</code>

<code class="n">basic_cell</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">contrib</code><code class="o">.</code><code class="n">rnn</code><code class="o">.</code><code class="n">BasicRNNCell</code><code class="p">(</code><code class="n">num_units</code><code class="o">=</code><code class="n">n_neurons</code><code class="p">)</code>
<code class="n">outputs</code><code class="p">,</code> <code class="n">states</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">dynamic_rnn</code><code class="p">(</code><code class="n">basic_cell</code><code class="p">,</code> <code class="n">X</code><code class="p">,</code> <code class="n">dtype</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">)</code></pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>During backpropagation, the <code>while_loop()</code> operation does 
the appropriate magic: it stores the tensor values for each iteration 
during the forward pass so it can use them to compute gradients during 
the reverse pass.</p>
</div>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Handling Variable Length Input Sequences"><div class="sect2" id="idm140582989757680">
<h2>Handling Variable Length Input Sequences</h2>

<p>So far <a data-type="indexterm" data-primary="recurrent neural networks (RNNs)" data-secondary="in TensorFlow" data-tertiary="variable length input sequences" data-secondary-sortas="TensorFlow" id="idm140582989755792"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.contrib.rnn.static_rnn()" data-startref="tfcrsrch14" id="idm140582989754304"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.int32" id="idm140582989753120"></a>we
 have used only fixed-size input sequences (all exactly two steps long).
 What if the input sequences have variable lengths (e.g., like 
sentences)? In this case you should set the <code>sequence_length</code> <a data-type="indexterm" data-primary="sequence_length" id="seqlench14"></a>argument when calling the <code>dynamic_rnn()</code> (or <code>static_rnn()</code>) function; it must be a 1D tensor indicating the length of the input sequence for each instance. For example:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">seq_length</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">placeholder</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">int32</code><code class="p">,</code> <code class="p">[</code><code class="bp">None</code><code class="p">])</code>

<code class="p">[</code><code class="o">...</code><code class="p">]</code>
<code class="n">outputs</code><code class="p">,</code> <code class="n">states</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">dynamic_rnn</code><code class="p">(</code><code class="n">basic_cell</code><code class="p">,</code> <code class="n">X</code><code class="p">,</code> <code class="n">dtype</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">,</code>
                                    <code class="n">sequence_length</code><code class="o">=</code><code class="n">seq_length</code><code class="p">)</code></pre>

<p>For example, suppose the second input sequence contains only one 
input instead of two. It must be padded with a zero vector in order to 
fit in the input tensor <code>X</code> (because the input tensor’s second dimension is the size of the longest sequence—i.e., 2).</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">X_batch</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">([</code>
        <code class="c1"># step 0     step 1</code>
        <code class="p">[[</code><code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">,</code> <code class="mi">2</code><code class="p">],</code> <code class="p">[</code><code class="mi">9</code><code class="p">,</code> <code class="mi">8</code><code class="p">,</code> <code class="mi">7</code><code class="p">]],</code> <code class="c1"># instance 0</code>
        <code class="p">[[</code><code class="mi">3</code><code class="p">,</code> <code class="mi">4</code><code class="p">,</code> <code class="mi">5</code><code class="p">],</code> <code class="p">[</code><code class="mi">0</code><code class="p">,</code> <code class="mi">0</code><code class="p">,</code> <code class="mi">0</code><code class="p">]],</code> <code class="c1"># instance 1 (padded with a zero vector)</code>
        <code class="p">[[</code><code class="mi">6</code><code class="p">,</code> <code class="mi">7</code><code class="p">,</code> <code class="mi">8</code><code class="p">],</code> <code class="p">[</code><code class="mi">6</code><code class="p">,</code> <code class="mi">5</code><code class="p">,</code> <code class="mi">4</code><code class="p">]],</code> <code class="c1"># instance 2</code>
        <code class="p">[[</code><code class="mi">9</code><code class="p">,</code> <code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">],</code> <code class="p">[</code><code class="mi">3</code><code class="p">,</code> <code class="mi">2</code><code class="p">,</code> <code class="mi">1</code><code class="p">]],</code> <code class="c1"># instance 3</code>
    <code class="p">])</code>
<code class="n">seq_length_batch</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">([</code><code class="mi">2</code><code class="p">,</code> <code class="mi">1</code><code class="p">,</code> <code class="mi">2</code><code class="p">,</code> <code class="mi">2</code><code class="p">])</code></pre>

<p>Of course, you now need to feed values for both placeholders <code>X</code> and <code>seq_length</code>:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">Session</code><code class="p">()</code> <code class="k">as</code> <code class="n">sess</code><code class="p">:</code>
    <code class="n">init</code><code class="o">.</code><code class="n">run</code><code class="p">()</code>
    <code class="n">outputs_val</code><code class="p">,</code> <code class="n">states_val</code> <code class="o">=</code> <code class="n">sess</code><code class="o">.</code><code class="n">run</code><code class="p">(</code>
        <code class="p">[</code><code class="n">outputs</code><code class="p">,</code> <code class="n">states</code><code class="p">],</code> <code class="n">feed_dict</code><code class="o">=</code><code class="p">{</code><code class="n">X</code><code class="p">:</code> <code class="n">X_batch</code><code class="p">,</code> <code class="n">seq_length</code><code class="p">:</code> <code class="n">seq_length_batch</code><code class="p">})</code></pre>

<p>Now the RNN outputs zero vectors for every time step past the input 
sequence length (look at the second instance’s output for the second 
time step):</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="k">print</code><code class="p">(</code><code class="n">outputs_val</code><code class="p">)</code>
<code class="go">[[[-0.68579948 -0.25901747 -0.80249101 -0.18141513 -0.37491536]</code>
<code class="go">  [-0.99996698 -0.94501185  0.98072106 -0.9689762   0.99966913]]  # final state</code>

<code class="go"> [[-0.99099374 -0.64768541 -0.67801034 -0.7415446   0.7719509 ]   # final state</code>
<code class="go">  [ 0.          0.          0.          0.          0.        ]]  # zero vector</code>

<code class="go"> [[-0.99978048 -0.85583007 -0.49696958 -0.93838578  0.98505187]</code>
<code class="go">  [-0.99951065 -0.89148796  0.94170523 -0.38407657  0.97499216]]  # final state</code>

<code class="go"> [[-0.02052618 -0.94588047  0.99935204  0.37283331  0.9998163 ]</code>
<code class="go">  [-0.91052347  0.05769409  0.47446665 -0.44611037  0.89394671]]] # final state</code></pre>

<p>Moreover, the <code>states</code> <a data-type="indexterm" data-primary="states   tensor" id="idm140582989344896"></a>tensor contains the final state of each cell (excluding the zero vectors):</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="k">print</code><code class="p">(</code><code class="n">states_val</code><code class="p">)</code>
<code class="go">[[-0.99996698 -0.94501185  0.98072106 -0.9689762   0.99966913]  # t = 1</code>
<code class="go"> [-0.99099374 -0.64768541 -0.67801034 -0.7415446   0.7719509 ]  # t = 0 !!!</code>
<code class="go"> [-0.99951065 -0.89148796  0.94170523 -0.38407657  0.97499216]  # t = 1</code>
<code class="go"> [-0.91052347  0.05769409  0.47446665 -0.44611037  0.89394671]] # t = 1</code></pre>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Handling Variable-Length Output Sequences"><div class="sect2" id="idm140582989757216">
<h2>Handling Variable-Length Output Sequences</h2>

<p>What if <a data-type="indexterm" data-primary="recurrent neural networks (RNNs)" data-secondary="in TensorFlow" data-tertiary="variable length output sequences" data-secondary-sortas="TensorFlow" id="idm140582989398352"></a>the
 output sequences have variable lengths as well? If you know in advance 
what length each sequence will have (for example if you know that it 
will be the same length as the input sequence), then you can set the <code>sequence_length</code> <a data-type="indexterm" data-primary="sequence_length" data-startref="seqlench14" id="idm140582989396160"></a>parameter
 as described above. Unfortunately, in general this will not be 
possible: for example, the length of a translated sentence is generally 
different from the length of the input sentence. In this case, the most 
common solution is to define a special output called <a data-type="indexterm" data-primary="end-of-sequence (EOS) token" id="idm140582989330160"></a>an <em>end-of-sequence token</em> (EOS token). Any output past the EOS should be ignored (we will discuss this later in this chapter).</p>

<p>Okay, now you know how to build an RNN network (or more precisely an RNN network unrolled through time). <a data-type="indexterm" data-primary="recurrent neural networks (RNNs)" data-secondary="in TensorFlow" data-secondary-sortas="TensorFlow" data-startref="rnn14it" id="idm140582989328448"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="RNNs in" data-seealso="recurrent neural networks (RNNs)" data-startref="tf14rnni" id="idm140582989326960"></a>But how do you train it?</p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Training RNNs"><div class="sect1" id="idm140582990685248">
<h1>Training RNNs</h1>

<p>To <a data-type="indexterm" data-primary="recurrent neural networks (RNNs)" data-secondary="training" id="rnn14t"></a>train an RNN, the trick is to unroll it through time (like we just did) and then simply use regular backpropagation (see <a data-type="xref" href="#bptt_diagram">Figure&nbsp;14-5</a>). This <a data-type="indexterm" data-primary="backpropagation through time (BPTT)" id="idm140582989466512"></a><a data-type="indexterm" data-primary="recurrent neural networks (RNNs)" data-secondary="training" data-tertiary="backpropagation through time (BPTT)" id="idm140582989465792"></a>strategy is called <em>backpropagation through time</em> (BPTT).</p>

<figure class="smallerseventy"><div id="bptt_diagram" class="figure">
<img src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1405.png" alt="mlst 1405" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1405.png" width="1091" height="662">
<h6><span class="label">Figure 14-5. </span>Backpropagation through time</h6>
</div></figure>

<p>Just like in regular backpropagation, there is a first forward pass 
through the unrolled network (represented by the dashed arrows); then 
the output sequence is evaluated using a <a data-type="indexterm" data-primary="cost function" data-secondary="in RNNs" data-secondary-sortas="RNNs" id="idm140582989460752"></a>cost function <img src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_129.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_129.png" width="264" height="28"> (where <em>t</em><sub>min</sub> and <em>t</em><sub>max</sub>
 are the first and last output time steps, not counting the ignored 
outputs), and the gradients of that cost function are propagated 
backward through the unrolled network (represented by the solid arrows);
 and finally the <a data-type="indexterm" data-primary="model parameters" id="idm140582989457136"></a>model
 parameters are updated using the gradients computed during BPTT. Note 
that the gradients flow backward through all the outputs used by the 
cost function, not just through the final output (for example, in <a data-type="xref" href="#bptt_diagram">Figure&nbsp;14-5</a> the cost function is computed using the last three outputs of the network, <strong>Y</strong><sub>(2)</sub>, <strong>Y</strong><sub>(3)</sub>, and <strong>Y</strong><sub>(4)</sub>, so gradients flow through these three outputs, but not through <strong>Y</strong><sub>(0)</sub> and <strong>Y</strong><sub>(1)</sub>). Moreover, since the same parameters <strong>W</strong> and <strong>b</strong> are used at each time step, backpropagation will do the right thing and sum over all time steps.</p>








<section data-type="sect2" data-pdf-bookmark="Training a Sequence Classifier"><div class="sect2" id="idm140582989460960">
<h2>Training a Sequence Classifier</h2>

<p>Let’s <a data-type="indexterm" data-primary="recurrent neural networks (RNNs)" data-secondary="training" data-tertiary="sequence classifiers" id="rnn14tsc"></a>train an RNN to classify MNIST images. A convolutional neural network would be better suited for image classification (see <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch13.html#cnn_chapter">Chapter&nbsp;13</a>),
 but this makes for a simple example that you are already familiar with.
 We will treat each image as a sequence of 28 rows of 28 pixels each 
(since each MNIST image is 28 × 28 pixels). We will use cells of 150 
recurrent neurons, plus a fully connected layer containing 10 neurons 
(one per class) connected to the output of the last time step, followed 
by a softmax layer (see <a data-type="xref" href="#sequence_classifier_diagram">Figure&nbsp;14-6</a>).</p>

<figure class="smallerseventy"><div id="sequence_classifier_diagram" class="figure">
<img src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1406.png" alt="mlst 1406" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1406.png" width="1247" height="733">
<h6><span class="label">Figure 14-6. </span>Sequence classifier</h6>
</div></figure>

<p>The construction phase is quite straightforward; it’s pretty much the same as the MNIST classifier we built in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html#ann_chapter">Chapter&nbsp;10</a> except that an unrolled RNN replaces the hidden layers. Note that the fully connected layer is connected to the <code>states</code> tensor, which contains only the final state of the RNN (i.e., the 28<sup>th</sup> output). Also note that <code>y</code> is a placeholder for <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.int32" id="idm140582989440000"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.contrib.rnn.BasicRNNCell" id="idm140582989438992"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.nn.dynamic_rnn()" id="idm140582989438032"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.nn.sparse_softmax_cross_entropy_with_logits()" id="idm140582989437088"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.reduce_mean()" id="tfredmeanch14"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.train.AdamOptimizer" id="idm140582989434960"></a>the target classes.</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">n_steps</code> <code class="o">=</code> <code class="mi">28</code>
<code class="n">n_inputs</code> <code class="o">=</code> <code class="mi">28</code>
<code class="n">n_neurons</code> <code class="o">=</code> <code class="mi">150</code>
<code class="n">n_outputs</code> <code class="o">=</code> <code class="mi">10</code>

<code class="n">learning_rate</code> <code class="o">=</code> <code class="mf">0.001</code>

<code class="n">X</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">placeholder</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">,</code> <code class="p">[</code><code class="bp">None</code><code class="p">,</code> <code class="n">n_steps</code><code class="p">,</code> <code class="n">n_inputs</code><code class="p">])</code>
<code class="n">y</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">placeholder</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">int32</code><code class="p">,</code> <code class="p">[</code><code class="bp">None</code><code class="p">])</code>

<code class="n">basic_cell</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">contrib</code><code class="o">.</code><code class="n">rnn</code><code class="o">.</code><code class="n">BasicRNNCell</code><code class="p">(</code><code class="n">num_units</code><code class="o">=</code><code class="n">n_neurons</code><code class="p">)</code>
<code class="n">outputs</code><code class="p">,</code> <code class="n">states</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">dynamic_rnn</code><code class="p">(</code><code class="n">basic_cell</code><code class="p">,</code> <code class="n">X</code><code class="p">,</code> <code class="n">dtype</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">)</code>

<code class="n">logits</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">dense</code><code class="p">(</code><code class="n">states</code><code class="p">,</code> <code class="n">n_outputs</code><code class="p">)</code>
<code class="n">xentropy</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">sparse_softmax_cross_entropy_with_logits</code><code class="p">(</code><code class="n">labels</code><code class="o">=</code><code class="n">y</code><code class="p">,</code>
                                                          <code class="n">logits</code><code class="o">=</code><code class="n">logits</code><code class="p">)</code>
<code class="n">loss</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">reduce_mean</code><code class="p">(</code><code class="n">xentropy</code><code class="p">)</code>
<code class="n">optimizer</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">train</code><code class="o">.</code><code class="n">AdamOptimizer</code><code class="p">(</code><code class="n">learning_rate</code><code class="o">=</code><code class="n">learning_rate</code><code class="p">)</code>
<code class="n">training_op</code> <code class="o">=</code> <code class="n">optimizer</code><code class="o">.</code><code class="n">minimize</code><code class="p">(</code><code class="n">loss</code><code class="p">)</code>
<code class="n">correct</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">in_top_k</code><code class="p">(</code><code class="n">logits</code><code class="p">,</code> <code class="n">y</code><code class="p">,</code> <code class="mi">1</code><code class="p">)</code>
<code class="n">accuracy</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">reduce_mean</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">cast</code><code class="p">(</code><code class="n">correct</code><code class="p">,</code> <code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">))</code>

<code class="n">init</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">global_variables_initializer</code><code class="p">()</code></pre>

<p>Now let’s <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.nn.in_top_k()" id="idm140582989432096"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.reduce_mean()" data-startref="tfredmeanch14" id="idm140582989431216"></a> <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.cast()" id="idm140582989182768"></a>load the MNIST data and reshape the test data to <code>[batch_size, n_steps, n_inputs]</code> as is expected by the network. We will take care of reshaping the training data in a moment.</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">tensorflow.examples.tutorials.mnist</code> <code class="kn">import</code> <code class="n">input_data</code>

<code class="n">mnist</code> <code class="o">=</code> <code class="n">input_data</code><code class="o">.</code><code class="n">read_data_sets</code><code class="p">(</code><code class="s2">"/tmp/data/"</code><code class="p">)</code>
<code class="n">X_test</code> <code class="o">=</code> <code class="n">mnist</code><code class="o">.</code><code class="n">test</code><code class="o">.</code><code class="n">images</code><code class="o">.</code><code class="n">reshape</code><code class="p">((</code><code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="n">n_steps</code><code class="p">,</code> <code class="n">n_inputs</code><code class="p">))</code>
<code class="n">y_test</code> <code class="o">=</code> <code class="n">mnist</code><code class="o">.</code><code class="n">test</code><code class="o">.</code><code class="n">labels</code></pre>

<p>Now we are ready to train the RNN. The execution phase is exactly the same as for the MNIST classifier in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html#ann_chapter">Chapter&nbsp;10</a>, except that we reshape each training batch before feeding it to the network.</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">n_epochs</code> <code class="o">=</code> <code class="mi">100</code>
<code class="n">batch_size</code> <code class="o">=</code> <code class="mi">150</code>

<code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">Session</code><code class="p">()</code> <code class="k">as</code> <code class="n">sess</code><code class="p">:</code>
    <code class="n">init</code><code class="o">.</code><code class="n">run</code><code class="p">()</code>
    <code class="k">for</code> <code class="n">epoch</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">n_epochs</code><code class="p">):</code>
        <code class="k">for</code> <code class="n">iteration</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">mnist</code><code class="o">.</code><code class="n">train</code><code class="o">.</code><code class="n">num_examples</code> <code class="o">//</code> <code class="n">batch_size</code><code class="p">):</code>
            <code class="n">X_batch</code><code class="p">,</code> <code class="n">y_batch</code> <code class="o">=</code> <code class="n">mnist</code><code class="o">.</code><code class="n">train</code><code class="o">.</code><code class="n">next_batch</code><code class="p">(</code><code class="n">batch_size</code><code class="p">)</code>
            <code class="n">X_batch</code> <code class="o">=</code> <code class="n">X_batch</code><code class="o">.</code><code class="n">reshape</code><code class="p">((</code><code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="n">n_steps</code><code class="p">,</code> <code class="n">n_inputs</code><code class="p">))</code>
            <code class="n">sess</code><code class="o">.</code><code class="n">run</code><code class="p">(</code><code class="n">training_op</code><code class="p">,</code> <code class="n">feed_dict</code><code class="o">=</code><code class="p">{</code><code class="n">X</code><code class="p">:</code> <code class="n">X_batch</code><code class="p">,</code> <code class="n">y</code><code class="p">:</code> <code class="n">y_batch</code><code class="p">})</code>
        <code class="n">acc_train</code> <code class="o">=</code> <code class="n">accuracy</code><code class="o">.</code><code class="n">eval</code><code class="p">(</code><code class="n">feed_dict</code><code class="o">=</code><code class="p">{</code><code class="n">X</code><code class="p">:</code> <code class="n">X_batch</code><code class="p">,</code> <code class="n">y</code><code class="p">:</code> <code class="n">y_batch</code><code class="p">})</code>
        <code class="n">acc_test</code> <code class="o">=</code> <code class="n">accuracy</code><code class="o">.</code><code class="n">eval</code><code class="p">(</code><code class="n">feed_dict</code><code class="o">=</code><code class="p">{</code><code class="n">X</code><code class="p">:</code> <code class="n">X_test</code><code class="p">,</code> <code class="n">y</code><code class="p">:</code> <code class="n">y_test</code><code class="p">})</code>
        <code class="k">print</code><code class="p">(</code><code class="n">epoch</code><code class="p">,</code> <code class="s2">"Train accuracy:"</code><code class="p">,</code> <code class="n">acc_train</code><code class="p">,</code> <code class="s2">"Test accuracy:"</code><code class="p">,</code> <code class="n">acc_test</code><code class="p">)</code></pre>

<p>The output should look like this:</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="go">0 Train accuracy: 0.94 Test accuracy: 0.9308</code>
<code class="go">1 Train accuracy: 0.933333 Test accuracy: 0.9431</code>
<code class="go">[...]</code>
<code class="go">98 Train accuracy: 0.98 Test accuracy: 0.9794</code>
<code class="go">99 Train accuracy: 1.0 Test accuracy: 0.9804</code></pre>

<p>We get over 98% accuracy—not bad! Plus you would certainly get a 
better result by tuning the hyperparameters, initializing the RNN 
weights using He initialization, training longer, or adding a bit of 
regularization (e.g., dropout).</p>
<div data-type="tip"><h6>Tip</h6>
<p>You <a data-type="indexterm" data-primary="recurrent neural networks (RNNs)" data-secondary="training" data-tertiary="sequence classifiers" data-startref="rnn14tsc" id="idm140582988864896"></a>can specify an initializer for the RNN by wrapping its <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.variable_scope()" id="idm140582988863120"></a> <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.contrib.layers.variance_scaling_initializer()" id="idm140582988862112"></a><span class="keep-together">construction</span> code in a variable scope (e.g., use <code><span class="keep-together">variable_scope</span>("rnn", initializer=variance_scaling_initializer())</code> to use He initialization).</p>
</div>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Training to Predict Time Series"><div class="sect2" id="idm140582989450208">
<h2>Training to Predict Time Series</h2>

<p>Now <a data-type="indexterm" data-primary="recurrent neural networks (RNNs)" data-secondary="training" data-tertiary="time series predictions" id="rnn14ttsp"></a>let’s
 take a look at how to handle time series, such as stock prices, air 
temperature, brain wave patterns, and so on. In this section we will 
train an RNN to predict the next value in a generated time series. Each 
training instance is a randomly selected sequence of 20 consecutive 
values from the time series, and the target sequence is the same as the 
input sequence, except it is shifted by one time step into the future 
(see <a data-type="xref" href="#time_series_plot">Figure&nbsp;14-7</a>).</p>

<figure><div id="time_series_plot" class="figure">
<img src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1407.png" alt="mlst 1407" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1407.png" width="1440" height="494">
<h6><span class="label">Figure 14-7. </span>Time series (left), and a training instance from that series (right)</h6>
</div></figure>

<p>First, let’s create the RNN. It will contain 100 recurrent neurons 
and we will unroll it over 20 time steps since each training instance 
will be 20 inputs long. Each input will contain only one feature (the 
value at that time). The targets <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.nn.dynamic_rnn()" id="idm140582988849520"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.contrib.rnn.BasicRNNCell" id="tfcrbrcch10part2"></a> <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.nn.relu()" id="tfnnreluch14"></a>are also sequences of 20 inputs, each containing a single value. The code is almost the same as earlier:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">n_steps</code> <code class="o">=</code> <code class="mi">20</code>
<code class="n">n_inputs</code> <code class="o">=</code> <code class="mi">1</code>
<code class="n">n_neurons</code> <code class="o">=</code> <code class="mi">100</code>
<code class="n">n_outputs</code> <code class="o">=</code> <code class="mi">1</code>

<code class="n">X</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">placeholder</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">,</code> <code class="p">[</code><code class="bp">None</code><code class="p">,</code> <code class="n">n_steps</code><code class="p">,</code> <code class="n">n_inputs</code><code class="p">])</code>
<code class="n">y</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">placeholder</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">,</code> <code class="p">[</code><code class="bp">None</code><code class="p">,</code> <code class="n">n_steps</code><code class="p">,</code> <code class="n">n_outputs</code><code class="p">])</code>
<code class="n">cell</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">contrib</code><code class="o">.</code><code class="n">rnn</code><code class="o">.</code><code class="n">BasicRNNCell</code><code class="p">(</code><code class="n">num_units</code><code class="o">=</code><code class="n">n_neurons</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">relu</code><code class="p">)</code>
<code class="n">outputs</code><code class="p">,</code> <code class="n">states</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">dynamic_rnn</code><code class="p">(</code><code class="n">cell</code><code class="p">,</code> <code class="n">X</code><code class="p">,</code> <code class="n">dtype</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">)</code></pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>In general you would have more than just one input feature. For 
example, if you were trying to predict stock prices, you would likely 
have many other input features at each time step, such as prices of 
competing stocks, ratings from analysts, or any other feature that might
 help the system make its predictions.</p>
</div>

<p>At each time step we now have an output vector of size 100. But what 
we actually want is a single output value at each time step. The 
simplest solution is to wrap the cell in <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.contrib.rnn.OutputProjectionWrapper" id="tfconrnnoutprojwrapch14"></a><a data-type="indexterm" data-primary="OutputProjectionWrapper" id="opw14"></a>an <code>OutputProjectionWrapper</code>. A <a data-type="indexterm" data-primary="cell wrapper" id="idm140582988729200"></a>cell
 wrapper acts like a normal cell, proxying every method call to an 
underlying cell, but it also adds some functionality. The <code>OutputProjectionWrapper</code>
 adds a fully connected layer of linear neurons (i.e., without any 
activation function) on top of each output (but it does not affect the 
cell state). All these fully connected layers share the same (trainable)
 weights and bias terms. The resulting RNN is represented in <a data-type="xref" href="#output_projection_diagram">Figure&nbsp;14-8</a>.</p>

<figure class="smallerseventy"><div id="output_projection_diagram" class="figure">
<img src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1408.png" alt="mlst 1408" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1408.png" width="1216" height="846">
<h6><span class="label">Figure 14-8. </span>RNN cells using output projections</h6>
</div></figure>

<p>Wrapping a cell is quite easy. <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.contrib.rnn.BasicRNNCell" data-startref="tfcrbrcch10part2" id="idm140582988724224"></a> <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.nn.relu()" data-startref="tfnnreluch14" id="idm140582988722784"></a>Let’s tweak the preceding code by wrapping the <code>BasicRNNCell</code> into an <code>OutputProjectionWrapper</code>:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">cell</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">contrib</code><code class="o">.</code><code class="n">rnn</code><code class="o">.</code><code class="n">OutputProjectionWrapper</code><code class="p">(</code>
    <code class="n">tf</code><code class="o">.</code><code class="n">contrib</code><code class="o">.</code><code class="n">rnn</code><code class="o">.</code><code class="n">BasicRNNCell</code><code class="p">(</code><code class="n">num_units</code><code class="o">=</code><code class="n">n_neurons</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">relu</code><code class="p">),</code>
    <code class="n">output_size</code><code class="o">=</code><code class="n">n_outputs</code><code class="p">)</code></pre>

<p>So far, so good. Now we need to define the <a data-type="indexterm" data-primary="cost function" data-secondary="in RNNs" data-secondary-sortas="RNNs" id="idm140582988630544"></a>cost
 function. We will use the Mean Squared Error (MSE), as we did in 
previous regression tasks. Next we will create an Adam optimizer, the 
training op, and the  <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.square()" id="idm140582988629152"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.train.AdamOptimizer" id="idm140582988628208"></a>variable initialization op, as usual:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">learning_rate</code> <code class="o">=</code> <code class="mf">0.001</code>

<code class="n">loss</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">reduce_mean</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">square</code><code class="p">(</code><code class="n">outputs</code> <code class="o">-</code> <code class="n">y</code><code class="p">))</code>
<code class="n">optimizer</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">train</code><code class="o">.</code><code class="n">AdamOptimizer</code><code class="p">(</code><code class="n">learning_rate</code><code class="o">=</code><code class="n">learning_rate</code><code class="p">)</code>
<code class="n">training_op</code> <code class="o">=</code> <code class="n">optimizer</code><code class="o">.</code><code class="n">minimize</code><code class="p">(</code><code class="n">loss</code><code class="p">)</code>

<code class="n">init</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">global_variables_initializer</code><code class="p">()</code></pre>

<p>Now on to the execution phase:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">n_iterations</code> <code class="o">=</code> <code class="mi">1500</code>
<code class="n">batch_size</code> <code class="o">=</code> <code class="mi">50</code>

<code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">Session</code><code class="p">()</code> <code class="k">as</code> <code class="n">sess</code><code class="p">:</code>
    <code class="n">init</code><code class="o">.</code><code class="n">run</code><code class="p">()</code>
    <code class="k">for</code> <code class="n">iteration</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">n_iterations</code><code class="p">):</code>
        <code class="n">X_batch</code><code class="p">,</code> <code class="n">y_batch</code> <code class="o">=</code> <code class="p">[</code><code class="o">...</code><code class="p">]</code>  <code class="c1"># fetch the next training batch</code>
        <code class="n">sess</code><code class="o">.</code><code class="n">run</code><code class="p">(</code><code class="n">training_op</code><code class="p">,</code> <code class="n">feed_dict</code><code class="o">=</code><code class="p">{</code><code class="n">X</code><code class="p">:</code> <code class="n">X_batch</code><code class="p">,</code> <code class="n">y</code><code class="p">:</code> <code class="n">y_batch</code><code class="p">})</code>
        <code class="k">if</code> <code class="n">iteration</code> <code class="o">%</code> <code class="mi">100</code> <code class="o">==</code> <code class="mi">0</code><code class="p">:</code>
            <code class="n">mse</code> <code class="o">=</code> <code class="n">loss</code><code class="o">.</code><code class="n">eval</code><code class="p">(</code><code class="n">feed_dict</code><code class="o">=</code><code class="p">{</code><code class="n">X</code><code class="p">:</code> <code class="n">X_batch</code><code class="p">,</code> <code class="n">y</code><code class="p">:</code> <code class="n">y_batch</code><code class="p">})</code>
            <code class="k">print</code><code class="p">(</code><code class="n">iteration</code><code class="p">,</code> <code class="s2">"</code><code class="se">\t</code><code class="s2">MSE:"</code><code class="p">,</code> <code class="n">mse</code><code class="p">)</code></pre>

<p>The program’s output should look like this:</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="go">0       MSE: 13.6543</code>
<code class="go">100     MSE: 0.538476</code>
<code class="go">200     MSE: 0.168532</code>
<code class="go">300     MSE: 0.0879579</code>
<code class="go">400     MSE: 0.0633425</code>
<code class="go">[...]</code></pre>

<p>Once the model is trained, you can make predictions:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">X_new</code> <code class="o">=</code> <code class="p">[</code><code class="o">...</code><code class="p">]</code>  <code class="c1"># New sequences</code>
<code class="n">y_pred</code> <code class="o">=</code> <code class="n">sess</code><code class="o">.</code><code class="n">run</code><code class="p">(</code><code class="n">outputs</code><code class="p">,</code> <code class="n">feed_dict</code><code class="o">=</code><code class="p">{</code><code class="n">X</code><code class="p">:</code> <code class="n">X_new</code><code class="p">})</code></pre>

<p><a data-type="xref" href="#time_series_pred_plot">Figure&nbsp;14-9</a> shows the predicted sequence for the instance we looked at earlier (in <a data-type="xref" href="#time_series_plot">Figure&nbsp;14-7</a>), after just 1,000 training iterations.</p>

<p>Although using an <code>OutputProjectionWrapper</code> <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.contrib.rnn.OutputProjectionWrapper" data-startref="tfconrnnoutprojwrapch14" id="idm140582988238720"></a>is
 the simplest solution to reduce the dimensionality of the RNN’s output 
sequences down to just one value per time step (per instance), it is not
 the most efficient. There is a trickier but more efficient solution: 
you can reshape the RNN outputs from <code>[batch_size, n_steps, n_neurons]</code> to <code>[batch_size * n_steps, n_neurons]</code>,
 then apply a single fully connected layer with the appropriate output 
size (in our case just 1), which will result in an output tensor of 
shape <code>[batch_size * n_steps, n_outputs]</code>, and then reshape this tensor to <code>[batch_size, n_steps, n_outputs]</code>. These operations are <a data-type="indexterm" data-primary="OutputProjectionWrapper" data-startref="opw14" id="idm140582988235344"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.contrib.rnn.BasicRNNCell" id="idm140582988234368"></a> <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.nn.relu()" id="idm140582988233232"></a>represented in <a data-type="xref" href="#reshape_reshape_diagram">Figure&nbsp;14-10</a>.</p>

<figure class="smallerseventy"><div id="time_series_pred_plot" class="figure">
<img src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1409.png" alt="mlst 1409" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1409.png" width="1440" height="931">
<h6><span class="label">Figure 14-9. </span>Time series prediction</h6>
</div></figure>

<figure class="smallerninety"><div id="reshape_reshape_diagram" class="figure">
<img src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1410.png" alt="mlst 1410" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1410.png" width="1440" height="1336">
<h6><span class="label">Figure 14-10. </span>Stack all the outputs, apply the projection, <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.unstack()" id="idm140582988272416"></a>then unstack the result</h6>
</div></figure>

<p>To implement this solution, we first revert to a basic cell, without <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.reshape()" id="idm140582988270768"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.nn.dynamic_rnn()" id="idm140582988269792"></a>the <code>OutputProjectionWrapper</code>:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">cell</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">contrib</code><code class="o">.</code><code class="n">rnn</code><code class="o">.</code><code class="n">BasicRNNCell</code><code class="p">(</code><code class="n">num_units</code><code class="o">=</code><code class="n">n_neurons</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">relu</code><code class="p">)</code>
<code class="n">rnn_outputs</code><code class="p">,</code> <code class="n">states</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">dynamic_rnn</code><code class="p">(</code><code class="n">cell</code><code class="p">,</code> <code class="n">X</code><code class="p">,</code> <code class="n">dtype</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">)</code></pre>

<p>Then we stack all the outputs using the <code>reshape()</code> <a data-type="indexterm" data-primary="reshape()" id="idm140582988364560"></a>operation,
 apply the fully connected linear layer (without using any activation 
function; this is just a projection), and finally unstack all the 
outputs, again using <code>reshape()</code>:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">stacked_rnn_outputs</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">reshape</code><code class="p">(</code><code class="n">rnn_outputs</code><code class="p">,</code> <code class="p">[</code><code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="n">n_neurons</code><code class="p">])</code>
<code class="n">stacked_outputs</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">dense</code><code class="p">(</code><code class="n">stacked_rnn_outputs</code><code class="p">,</code> <code class="n">n_outputs</code><code class="p">)</code>
<code class="n">outputs</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">reshape</code><code class="p">(</code><code class="n">stacked_outputs</code><code class="p">,</code> <code class="p">[</code><code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="n">n_steps</code><code class="p">,</code> <code class="n">n_outputs</code><code class="p">])</code></pre>

<p>The rest of the code is the same as earlier. This can provide a 
significant speed boost since there is just one fully connected layer 
instead of one per <a data-type="indexterm" data-primary="recurrent neural networks (RNNs)" data-secondary="training" data-tertiary="time series predictions" data-startref="rnn14ttsp" id="idm140582988207248"></a>time step.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Creative RNN"><div class="sect2" id="idm140582988858368">
<h2>Creative RNN</h2>

<p>Now that we have a <a data-type="indexterm" data-primary="recurrent neural networks (RNNs)" data-secondary="training" data-tertiary="creative sequences" id="idm140582988182352"></a><a data-type="indexterm" data-primary="creative sequences" id="idm140582988181104"></a>model
 that can predict the future, we can use it to generate some creative 
sequences, as explained at the beginning of the chapter. All we need is 
to provide it a seed sequence containing <code>n_steps</code> values 
(e.g., full of zeros), use the model to predict the next value, append 
this predicted value to the sequence, feed the last <code>n_steps</code>
 values to the model to predict the next value, and so on. This process 
generates a new sequence that has some resemblance to the original time 
series (see <a data-type="xref" href="#creative_sequence_plot">Figure&nbsp;14-11</a>).</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">sequence</code> <code class="o">=</code> <code class="p">[</code><code class="mf">0.</code><code class="p">]</code> <code class="o">*</code> <code class="n">n_steps</code>
<code class="k">for</code> <code class="n">iteration</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="mi">300</code><code class="p">):</code>
    <code class="n">X_batch</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">(</code><code class="n">sequence</code><code class="p">[</code><code class="o">-</code><code class="n">n_steps</code><code class="p">:])</code><code class="o">.</code><code class="n">reshape</code><code class="p">(</code><code class="mi">1</code><code class="p">,</code> <code class="n">n_steps</code><code class="p">,</code> <code class="mi">1</code><code class="p">)</code>
    <code class="n">y_pred</code> <code class="o">=</code> <code class="n">sess</code><code class="o">.</code><code class="n">run</code><code class="p">(</code><code class="n">outputs</code><code class="p">,</code> <code class="n">feed_dict</code><code class="o">=</code><code class="p">{</code><code class="n">X</code><code class="p">:</code> <code class="n">X_batch</code><code class="p">})</code>
    <code class="n">sequence</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">y_pred</code><code class="p">[</code><code class="mi">0</code><code class="p">,</code> <code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="mi">0</code><code class="p">])</code></pre>

<figure><div id="creative_sequence_plot" class="figure">
<img src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1411.png" alt="mlst 1411" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1411.png" width="1440" height="493">
<h6><span class="label">Figure 14-11. </span>Creative sequences, seeded with zeros (left) or with an instance (right)</h6>
</div></figure>

<p>Now you can try to feed all your John Lennon albums to an RNN and see
 if it can generate the next “Imagine.” However, you will probably need a
 much more powerful RNN, with more neurons, and also much deeper. Let’s 
look at deep RNNs <a data-type="indexterm" data-primary="recurrent neural networks (RNNs)" data-secondary="training" data-startref="rnn14t" id="idm140582988017584"></a>now.</p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Deep RNNs"><div class="sect1" id="idm140582988016112">
<h1>Deep RNNs</h1>

<p>It <a data-type="indexterm" data-primary="recurrent neural networks (RNNs)" data-secondary="deep RNNs" id="rnn14drnn"></a><a data-type="indexterm" data-primary="deep RNNs" id="drnn14"></a>is quite common to stack multiple layers of cells, as shown in <a data-type="xref" href="#deep_rnn_diagram">Figure&nbsp;14-12</a>. This gives you a <em>deep RNN</em>.</p>

<p>To implement a deep RNN in TensorFlow, <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.contrib.rnn.MultiRNNCell" id="tfconrnnmrnncellch14"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.contrib.rnn.BasicRNNCell" id="tfcrbrcch10part3"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.nn.dynamic_rnn()" id="tfnndrch14part2"></a>you can create several cells and stack them into a <code>MultiRNNCell</code>.
 In the following code we stack three identical cells (but you could 
very well use various kinds of cells with a different number of 
neurons):</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">n_neurons</code> <code class="o">=</code> <code class="mi">100</code>
<code class="n">n_layers</code> <code class="o">=</code> <code class="mi">3</code>

<code class="n">layers</code> <code class="o">=</code> <code class="p">[</code><code class="n">tf</code><code class="o">.</code><code class="n">contrib</code><code class="o">.</code><code class="n">rnn</code><code class="o">.</code><code class="n">BasicRNNCell</code><code class="p">(</code><code class="n">num_units</code><code class="o">=</code><code class="n">n_neurons</code><code class="p">,</code>
                                      <code class="n">activation</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">relu</code><code class="p">)</code>
          <code class="k">for</code> <code class="n">layer</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">n_layers</code><code class="p">)]</code>
<code class="n">multi_layer_cell</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">contrib</code><code class="o">.</code><code class="n">rnn</code><code class="o">.</code><code class="n">MultiRNNCell</code><code class="p">(</code><code class="n">layers</code><code class="p">)</code>
<code class="n">outputs</code><code class="p">,</code> <code class="n">states</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">dynamic_rnn</code><code class="p">(</code><code class="n">multi_layer_cell</code><code class="p">,</code> <code class="n">X</code><code class="p">,</code> <code class="n">dtype</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">)</code></pre>

<figure class="smallerseventy"><div id="deep_rnn_diagram" class="figure">
<img src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1412.png" alt="mlst 1412" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1412.png" width="1440" height="813">
<h6><span class="label">Figure 14-12. </span>Deep RNN (left), unrolled through time (right)</h6>
</div></figure>

<p>That’s all there is to it! The <code>states</code> variable is a tuple containing one tensor per layer, each representing the final state of that layer’s cell (with shape <code>[batch_size, n_neurons]</code>). If you set <code>state_is_tuple=False</code> when creating the <code>MultiRNNCell</code>, then <code>states</code> becomes a single tensor containing the states from every layer, concatenated along the column axis (i.e., its shape is <code>[batch_size, n_layers * n_neurons]</code>). Note that before TensorFlow 0.11.0, this behavior was the default.</p>








<section data-type="sect2" data-pdf-bookmark="Distributing a Deep RNN Across Multiple GPUs"><div class="sect2" id="idm140582987922640">
<h2>Distributing a Deep RNN Across Multiple GPUs</h2>

<p><a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch12.html#distributed_chapter">Chapter&nbsp;12</a> pointed <a data-type="indexterm" data-primary="deep RNNs" data-secondary="distributing across multiple GPUs" id="idm140582987920432"></a>out that we can efficiently distribute deep RNNs across multiple GPUs by pinning each layer to a different GPU (see <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch12.html#split_rnn_network_diagram">Figure&nbsp;12-16</a>). However, if you try to create each cell in a different <code>device()</code> block, it will <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.device()" id="tfdevicech14"></a>not work:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">device</code><code class="p">(</code><code class="s2">"/gpu:0"</code><code class="p">):</code>  <code class="c1"># BAD! This is ignored.</code>
    <code class="n">layer1</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">contrib</code><code class="o">.</code><code class="n">rnn</code><code class="o">.</code><code class="n">BasicRNNCell</code><code class="p">(</code><code class="n">num_units</code><code class="o">=</code><code class="n">n_neurons</code><code class="p">)</code>

<code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">device</code><code class="p">(</code><code class="s2">"/gpu:1"</code><code class="p">):</code>  <code class="c1"># BAD! Ignored again.</code>
    <code class="n">layer2</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">contrib</code><code class="o">.</code><code class="n">rnn</code><code class="o">.</code><code class="n">BasicRNNCell</code><code class="p">(</code><code class="n">num_units</code><code class="o">=</code><code class="n">n_neurons</code><code class="p">)</code></pre>

<p>This fails because a <code>BasicRNNCell</code> is <a data-type="indexterm" data-primary="BasicRNNCell" id="basrnncellch14"></a>a cell factory, not a cell <em>per se</em>
 (as mentioned earlier); no cells get created when you create the 
factory, and thus no variables do either. The device block is simply 
ignored. The cells actually get created later. When you call <code>dynamic_rnn()</code>, <a data-type="indexterm" data-primary="dynamic_rnn()" id="idm140582987779760"></a>it calls the <code>MultiRNNCell</code>, <a data-type="indexterm" data-primary="MultiRNNCell" id="idm140582987778480"></a> which calls each individual <code>BasicRNNCell</code>, <a data-type="indexterm" data-primary="BasicRNNCell" data-startref="basrnncellch14" id="idm140582987777232"></a>which create the actual cells (including their variables). Unfortunately, <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.contrib.rnn.RNNCell" id="idm140582987776096"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.device()" data-startref="tfdevicech14" id="idm140582987775152"></a>none of these classes provide any way to control the devices on which the variables get created. If you try to put the <code>dynamic_rnn()</code>
 call within a device block, the whole RNN gets pinned to a single 
device. So are you stuck? Fortunately not! The trick is to create your 
own cell wrapper (or use the <code>tf.contrib.rnn.DeviceWrapper</code> class, which was added in TensorFlow 1.1):</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">import</code> <code class="nn">tensorflow</code> <code class="kn">as</code> <code class="nn">tf</code>

<code class="k">class</code> <code class="nc">DeviceCellWrapper</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">contrib</code><code class="o">.</code><code class="n">rnn</code><code class="o">.</code><code class="n">RNNCell</code><code class="p">):</code>
  <code class="k">def</code> <code class="nf-Magic">__init__</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">device</code><code class="p">,</code> <code class="n">cell</code><code class="p">):</code>
    <code class="bp">self</code><code class="o">.</code><code class="n">_cell</code> <code class="o">=</code> <code class="n">cell</code>
    <code class="bp">self</code><code class="o">.</code><code class="n">_device</code> <code class="o">=</code> <code class="n">device</code>

  <code class="nd">@property</code>
  <code class="k">def</code> <code class="nf">state_size</code><code class="p">(</code><code class="bp">self</code><code class="p">):</code>
    <code class="k">return</code> <code class="bp">self</code><code class="o">.</code><code class="n">_cell</code><code class="o">.</code><code class="n">state_size</code>

  <code class="nd">@property</code>
  <code class="k">def</code> <code class="nf">output_size</code><code class="p">(</code><code class="bp">self</code><code class="p">):</code>
    <code class="k">return</code> <code class="bp">self</code><code class="o">.</code><code class="n">_cell</code><code class="o">.</code><code class="n">output_size</code>

  <code class="k">def</code> <code class="nf-Magic">__call__</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">inputs</code><code class="p">,</code> <code class="n">state</code><code class="p">,</code> <code class="n">scope</code><code class="o">=</code><code class="bp">None</code><code class="p">):</code>
    <code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">device</code><code class="p">(</code><code class="bp">self</code><code class="o">.</code><code class="n">_device</code><code class="p">):</code>
        <code class="k">return</code> <code class="bp">self</code><code class="o">.</code><code class="n">_cell</code><code class="p">(</code><code class="n">inputs</code><code class="p">,</code> <code class="n">state</code><code class="p">,</code> <code class="n">scope</code><code class="p">)</code></pre>

<p>This wrapper simply proxies every method call to another cell, except it wraps the <code>__call__()</code> function within a device block.<sup><a data-type="noteref" id="idm140582987770848-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch14.html#idm140582987770848" class="totri-footnote">2</a></sup> Now you can distribute each layer on a different GPU:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">devices</code> <code class="o">=</code> <code class="p">[</code><code class="s2">"/gpu:0"</code><code class="p">,</code> <code class="s2">"/gpu:1"</code><code class="p">,</code> <code class="s2">"/gpu:2"</code><code class="p">]</code>
<code class="n">cells</code> <code class="o">=</code> <code class="p">[</code><code class="n">DeviceCellWrapper</code><code class="p">(</code><code class="n">dev</code><code class="p">,</code><code class="n">tf</code><code class="o">.</code><code class="n">contrib</code><code class="o">.</code><code class="n">rnn</code><code class="o">.</code><code class="n">BasicRNNCell</code><code class="p">(</code><code class="n">num_units</code><code class="o">=</code><code class="n">n_neurons</code><code class="p">))</code>
         <code class="k">for</code> <code class="n">dev</code> <code class="ow">in</code> <code class="n">devices</code><code class="p">]</code>
<code class="n">multi_layer_cell</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">contrib</code><code class="o">.</code><code class="n">rnn</code><code class="o">.</code><code class="n">MultiRNNCell</code><code class="p">(</code><code class="n">cells</code><code class="p">)</code>
<code class="n">outputs</code><code class="p">,</code> <code class="n">states</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">dynamic_rnn</code><code class="p">(</code><code class="n">multi_layer_cell</code><code class="p">,</code> <code class="n">X</code><code class="p">,</code> <code class="n">dtype</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">)</code></pre>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>Do not set <code>state_is_tuple=False</code>, <a data-type="indexterm" data-primary="state_is_tuple" id="idm140582987723136"></a>or the <code>MultiRNNCell</code> will concatenate all the cell states into a single tensor, on a single GPU.</p>
</div>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Applying Dropout"><div class="sect2" id="idm140582987514176">
<h2>Applying Dropout</h2>

<p>If <a data-type="indexterm" data-primary="deep RNNs" data-secondary="applying dropout" id="idm140582987512384"></a><a data-type="indexterm" data-primary="dropout" id="idm140582987511376"></a>you build a very deep RNN, it may end up overfitting the training set. <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.contrib.rnn.DropoutWrapper" id="idm140582987510576"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.contrib.rnn.BasicRNNCell" data-startref="tfcrbrcch10part3" id="idm140582987509664"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.contrib.rnn.MultiRNNCell" data-startref="tfconrnnmrnncellch14" id="idm140582987508480"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.nn.dynamic_rnn()" data-startref="tfnndrch14part2" id="idm140582987507296"></a>To prevent that, a common technique is to apply dropout (introduced in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#deep_chapter">Chapter&nbsp;11</a>).
 You can simply add a dropout layer before or after the RNN as usual, 
but if you also want to apply dropout between the RNN layers, you need 
to use a <code>DropoutWrapper</code>. The following code applies dropout to the inputs of each layer in the RNN:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">keep_prob</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">placeholder_with_default</code><code class="p">(</code><code class="mf">1.0</code><code class="p">,</code> <code class="n">shape</code><code class="o">=</code><code class="p">())</code>

<code class="n">cells</code> <code class="o">=</code> <code class="p">[</code><code class="n">tf</code><code class="o">.</code><code class="n">contrib</code><code class="o">.</code><code class="n">rnn</code><code class="o">.</code><code class="n">BasicRNNCell</code><code class="p">(</code><code class="n">num_units</code><code class="o">=</code><code class="n">n_neurons</code><code class="p">)</code>
         <code class="k">for</code> <code class="n">layer</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">n_layers</code><code class="p">)]</code>
<code class="n">cells_drop</code> <code class="o">=</code> <code class="p">[</code><code class="n">tf</code><code class="o">.</code><code class="n">contrib</code><code class="o">.</code><code class="n">rnn</code><code class="o">.</code><code class="n">DropoutWrapper</code><code class="p">(</code><code class="n">cell</code><code class="p">,</code> <code class="n">input_keep_prob</code><code class="o">=</code><code class="n">keep_prob</code><code class="p">)</code>
              <code class="k">for</code> <code class="n">cell</code> <code class="ow">in</code> <code class="n">cells</code><code class="p">]</code>
<code class="n">multi_layer_cell</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">contrib</code><code class="o">.</code><code class="n">rnn</code><code class="o">.</code><code class="n">MultiRNNCell</code><code class="p">(</code><code class="n">cells_drop</code><code class="p">)</code>
<code class="n">rnn_outputs</code><code class="p">,</code> <code class="n">states</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">dynamic_rnn</code><code class="p">(</code><code class="n">multi_layer_cell</code><code class="p">,</code> <code class="n">X</code><code class="p">,</code> <code class="n">dtype</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">)</code>
<code class="c1"># The rest of the construction phase is just like earlier.</code></pre>

<p>During training, you can feed any value you want to the <code>keep_prob</code> placeholder (typically, 0.5):</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">n_iterations</code> <code class="o">=</code> <code class="mi">1500</code>
<code class="n">batch_size</code> <code class="o">=</code> <code class="mi">50</code>
<code class="n">train_keep_prob</code> <code class="o">=</code> <code class="mf">0.5</code>

<code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">Session</code><code class="p">()</code> <code class="k">as</code> <code class="n">sess</code><code class="p">:</code>
    <code class="n">init</code><code class="o">.</code><code class="n">run</code><code class="p">()</code>
    <code class="k">for</code> <code class="n">iteration</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">n_iterations</code><code class="p">):</code>
        <code class="n">X_batch</code><code class="p">,</code> <code class="n">y_batch</code> <code class="o">=</code> <code class="n">next_batch</code><code class="p">(</code><code class="n">batch_size</code><code class="p">,</code> <code class="n">n_steps</code><code class="p">)</code>
        <code class="n">_</code><code class="p">,</code> <code class="n">mse</code> <code class="o">=</code> <code class="n">sess</code><code class="o">.</code><code class="n">run</code><code class="p">([</code><code class="n">training_op</code><code class="p">,</code> <code class="n">loss</code><code class="p">],</code>
                          <code class="n">feed_dict</code><code class="o">=</code><code class="p">{</code><code class="n">X</code><code class="p">:</code> <code class="n">X_batch</code><code class="p">,</code> <code class="n">y</code><code class="p">:</code> <code class="n">y_batch</code><code class="p">,</code>
                                     <code class="n">keep_prob</code><code class="p">:</code> <code class="n">train_keep_prob</code><code class="p">})</code>
    <code class="n">saver</code><code class="o">.</code><code class="n">save</code><code class="p">(</code><code class="n">sess</code><code class="p">,</code> <code class="s2">"./my_dropout_time_series_model"</code><code class="p">)</code></pre>

<p>During testing, you should let <code>keep_prob</code> default to 1.0, effectively turning dropout off (remember that it should only be active during training):</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">Session</code><code class="p">()</code> <code class="k">as</code> <code class="n">sess</code><code class="p">:</code>
    <code class="n">saver</code><code class="o">.</code><code class="n">restore</code><code class="p">(</code><code class="n">sess</code><code class="p">,</code> <code class="s2">"./my_dropout_time_series_model"</code><code class="p">)</code>

    <code class="n">X_new</code> <code class="o">=</code> <code class="p">[</code><code class="o">...</code><code class="p">]</code> <code class="c1"># some test data</code>
    <code class="n">y_pred</code> <code class="o">=</code> <code class="n">sess</code><code class="o">.</code><code class="n">run</code><code class="p">(</code><code class="n">outputs</code><code class="p">,</code> <code class="n">feed_dict</code><code class="o">=</code><code class="p">{</code><code class="n">X</code><code class="p">:</code> <code class="n">X_new</code><code class="p">})</code></pre>

<p>Note that it is also possible to apply dropout to the outputs by <a data-type="indexterm" data-primary="input_keep_prob" id="idm140582987263584"></a><a data-type="indexterm" data-primary="output_keep_prob" id="idm140582987239120"></a><a data-type="indexterm" data-primary="state_keep_prob" id="idm140582987238512"></a>setting <code>output_keep_prob</code>, and since TensorFlow 1.1, it is also possible to apply dropout to the cell’s state using <code>state_keep_prob</code>.</p>

<p>With that you should be able to train all sorts of RNNs! 
Unfortunately, if you want to train an RNN on long sequences, things 
will get a bit harder. Let’s see why and what you can do about it.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="The Difficulty of Training over Many Time Steps"><div class="sect2" id="idm140582987236016">
<h2>The Difficulty of Training over Many Time Steps</h2>

<p>To train an RNN on <a data-type="indexterm" data-primary="deep RNNs" data-secondary="long sequence difficulties" id="idm140582987234720"></a>long
 sequences, you will need to run it over many time steps, making the 
unrolled RNN a very deep network. Just like any deep neural network it 
may suffer from the <a data-type="indexterm" data-primary="gradients, vanishing and exploding" id="idm140582987416000"></a>vanishing/exploding gradients problem (discussed in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#deep_chapter">Chapter&nbsp;11</a>)
 and take forever to train. Many of the tricks we discussed to alleviate
 this problem can be used for deep unrolled RNNs as well: good parameter
 initialization, nonsaturating activation functions (e.g., ReLU), Batch 
Normalization, Gradient Clipping, and faster optimizers. However, if the
 RNN needs to handle even moderately long sequences (e.g., 100 inputs), 
then training will still be very slow.</p>

<p>The simplest and most common solution to this problem is to unroll 
the RNN only over a limited number of time steps during training. This 
is called <em>truncated backpropagation through time</em>. <a data-type="indexterm" data-primary="truncated backpropagation through time" id="idm140582987413056"></a><a data-type="indexterm" data-primary="deep RNNs" data-secondary="truncated backpropagation through time" id="idm140582987412336"></a>In <a data-type="indexterm" data-primary="TensorFlow" data-secondary="truncated backpropagation through time" id="idm140582987411248"></a>TensorFlow
 you can implement it simply by truncating the input sequences. For 
example, in the time series prediction problem, you would simply reduce <code>n_steps</code>
 during training. The problem, of course, is that the model will not be 
able to learn long-term patterns. One workaround could be to make sure 
that these shortened sequences contain both old and recent data, so that
 the model can learn to use both (e.g., the sequence could contain 
monthly data for the last five months, then weekly data for the last 
five weeks, then daily data over the last five days). But this 
workaround has its limits: what if fine-grained data from last year is 
actually useful? What if there was a brief but significant event that 
absolutely must be taken into account, even years later (e.g., the 
result of an election)?</p>

<p>Besides the long training time, a second problem faced by 
long-running RNNs is the fact that the memory of the first inputs 
gradually fades away. Indeed, due to the transformations that the data 
goes through when traversing an RNN, some information is lost after each
 time step. After a while, the RNN’s state contains virtually no trace 
of the first inputs. This can be a showstopper. For example, say you 
want to perform sentiment analysis on a long review that starts with the
 four words “I loved this movie,” but the rest of the review lists the 
many things that could have made the movie even better. If the RNN 
gradually forgets the first four words, it will completely misinterpret 
the review. To solve this problem, various types of cells with long-term
 memory have been introduced. They have proved so successful that the 
basic cells are not much used anymore. Let’s <a data-type="indexterm" data-primary="recurrent neural networks (RNNs)" data-secondary="deep RNNs" data-startref="rnn14drnn" id="idm140582987407616"></a><a data-type="indexterm" data-primary="deep RNNs" data-startref="drnn14" id="idm140582987406352"></a>first look at the most popular of these long memory cells: the LSTM cell.</p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="LSTM Cell"><div class="sect1" id="idm140582987405024">
<h1>LSTM Cell</h1>

<p>The <em>Long Short-Term Memory</em> (LSTM) <a data-type="indexterm" data-primary="recurrent neural networks (RNNs)" data-secondary="LSTM cell" id="rnn14lstmc"></a><a data-type="indexterm" data-primary="LSTM (Long Short-Term Memory) cell" id="lstmc14"></a>cell was <a href="https://goo.gl/j39AGv">proposed in 1997</a><sup><a data-type="noteref" id="idm140582987399776-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch14.html#idm140582987399776" class="totri-footnote">3</a></sup>
 by Sepp Hochreiter and Jürgen Schmidhuber, and it was gradually 
improved over the years by several researchers, such as Alex Graves, <a href="https://goo.gl/6BHh81">Haşim Sak</a>,<sup><a data-type="noteref" id="idm140582987398288-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch14.html#idm140582987398288" class="totri-footnote">4</a></sup> <a href="https://goo.gl/SZ9kzB">Wojciech Zaremba</a>,<sup><a data-type="noteref" id="idm140582987396736-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch14.html#idm140582987396736" class="totri-footnote">5</a></sup>
 and many more. If you consider the LSTM cell as a black box, it can be 
used very much like a basic cell, except it will perform much better; 
training will converge faster and it will detect long-term dependencies 
in the data. In TensorFlow, you can simply use a <code>BasicLSTMCell</code> <a data-type="indexterm" data-primary="BasicLSTMCell" id="idm140582987395360"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.contrib.rnn.BasicLSTMCell" id="idm140582987394624"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.contrib.rnn.BasicRNNCell" id="idm140582987393712"></a>instead of a <code>BasicRNNCell</code>:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">lstm_cell</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">contrib</code><code class="o">.</code><code class="n">rnn</code><code class="o">.</code><code class="n">BasicLSTMCell</code><code class="p">(</code><code class="n">num_units</code><code class="o">=</code><code class="n">n_neurons</code><code class="p">)</code></pre>

<p>LSTM cells manage two state vectors, and for performance reasons they are kept <span class="keep-together">separate</span> by default. You can change this default behavior by setting <code>state_is_tuple=False</code> <a data-type="indexterm" data-primary="state_is_tuple" id="idm140582987384240"></a>when creating the <code>BasicLSTMCell</code>.</p>

<p>So how does an LSTM cell work? The architecture of a basic LSTM cell is shown in <a data-type="xref" href="#lstm_cell_diagram">Figure&nbsp;14-13</a>.</p>

<figure><div id="lstm_cell_diagram" class="figure">
<img src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1413.png" alt="mlst 1413" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1413.png" width="1440" height="860">
<h6><span class="label">Figure 14-13. </span>LSTM cell</h6>
</div></figure>

<p>If you don’t look at what’s inside the box, the LSTM cell looks 
exactly like a regular cell, except that its state is split in two 
vectors: <strong>h</strong><sub>(<em>t</em>)</sub> and <strong>c</strong><sub>(<em>t</em>)</sub> (“c” stands for “cell”). You can think of <strong>h</strong><sub>(<em>t</em>)</sub> as the short-term state and <strong>c</strong><sub>(<em>t</em>)</sub> as the long-term state.</p>

<p>Now let’s open the box! The key idea is that the network can learn 
what to store in the long-term state, what to throw away, and what to 
read from it. As the long-term state <strong>c</strong><sub>(<em>t</em>–1)</sub> traverses the network from left to right, you can see that it first goes through <a data-type="indexterm" data-primary="forget gate" id="idm140582987152592"></a>a <em>forget gate</em>,
 dropping some memories, and then it adds some new memories via the 
addition operation (which adds the memories that were selected by an <a data-type="indexterm" data-primary="input gate" id="idm140582987151184"></a><em>input gate</em>). The result <strong>c</strong><sub>(<em>t</em>)</sub>
 is sent straight out, without any further transformation. So, at each 
time step, some memories are dropped and some memories are added. 
Moreover, after the addition operation, the long-term state is copied 
and passed through the tanh function, and then the result is filtered by
 <a data-type="indexterm" data-primary="output gate" id="idm140582987148608"></a>the <em>output gate</em>. This produces the short-term state <strong>h</strong><sub>(<em>t</em>)</sub> (which is equal to the cell’s output for this time step <strong>y</strong><sub>(<em>t</em>)</sub>). Now let’s look at where new memories come from and how the gates work.</p>

<p>First, the current input vector <strong>x</strong><sub>(<em>t</em>)</sub> and the previous short-term state <strong>h</strong><sub>(<em>t</em>–1)</sub> are fed to four different fully connected layers. They all serve a different purpose:</p>

<ul>
<li>
<p>The main layer is the one that outputs <strong>g</strong><sub>(<em>t</em>)</sub>. It has the usual role of analyzing the current inputs <strong>x</strong><sub>(<em>t</em>)</sub> and the previous (short-term) state <strong>h</strong><sub>(<em>t</em>–1)</sub>. In a basic cell, there is nothing else than this layer, and its output goes straight out to <strong>y</strong><sub>(<em>t</em>)</sub> and <strong>h</strong><sub>(<em>t</em>)</sub>.
 In contrast, in an LSTM cell this layer’s output does not go straight 
out, but instead it is partially stored in the long-term state.</p>
</li>
<li>
<p>The three other layers are <a data-type="indexterm" data-primary="gate controllers" id="idm140582987134208"></a><em>gate controllers</em>.
 Since they use the logistic activation function, their outputs range 
from 0 to 1. As you can see, their outputs are fed to element-wise 
multiplication operations, so if they output 0s, they close the gate, 
and if they output 1s, they open it. Specifically:</p>

<ul>
<li>
<p>The <em>forget gate</em> (controlled by <strong>f</strong><sub>(<em>t</em>)</sub>) controls which parts of the long-term state should be erased.</p>
</li>
<li>
<p>The <em>input gate</em> (controlled by <strong>i</strong><sub>(<em>t</em>)</sub>) controls which parts of <strong>g</strong><sub>(<em>t</em>)</sub> should be added to the long-term state (this is why we said it was only “partially stored”).</p>
</li>
<li>
<p>Finally, the <em>output gate</em> (controlled by <strong>o</strong><sub>(<em>t</em>)</sub>) controls which parts of the long-term state should be read and output at this time step (both to <strong>h</strong><sub>(<em>t</em>)</sub>) and <strong>y</strong><sub>(<em>t</em>)</sub>.</p>
</li>
</ul>
</li>
</ul>

<p>In short, an LSTM cell can learn to recognize an important input 
(that’s the role of the input gate), store it in the long-term state, 
learn to preserve it for as long as it is needed (that’s the role of the
 forget gate), and learn to extract it whenever it is needed. This 
explains why they have been amazingly successful at capturing long-term 
patterns in time series, long texts, audio recordings, and more.</p>

<p><a data-type="xref" href="#lstm_equation">Equation 14-3</a> 
summarizes how to compute the cell’s long-term state, its short-term 
state, and its output at each time step for a single instance (the 
equations for a whole mini-batch are very similar).</p>
<div id="lstm_equation" data-type="equation"><h5><span class="label">Equation 14-3. </span>LSTM computations</h5>
<img src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_130.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_130.png" width="1105" height="611"></div>

<ul>
<li>
<p><strong>W</strong><sub><em>xi</em></sub>, <strong>W</strong><sub><em>xf</em></sub>, <strong>W</strong><sub><em>xo</em></sub>, <strong>W</strong><sub><em>xg</em></sub> are the weight matrices of each of the four layers for their connection to the input vector <strong>x</strong><sub>(<em>t</em>)</sub>.</p>
</li>
<li>
<p><strong>W</strong><sub><em>hi</em></sub>, <strong>W</strong><sub><em>hf</em></sub>, <strong>W</strong><sub><em>ho</em></sub>, and <strong>W</strong><sub><em>hg</em></sub> are the weight matrices of each of the four layers for their connection to the previous short-term state <strong>h</strong><sub>(<em>t</em>–1)</sub>.</p>
</li>
<li>
<p><strong>b</strong><sub><em>i</em></sub>, <strong>b</strong><sub><em>f</em></sub>, <strong>b</strong><sub><em>o</em></sub>, and <strong>b</strong><sub><em>g</em></sub> are the bias terms for each of the four layers. Note that TensorFlow initializes <strong>b</strong><sub><em>f</em></sub> to a vector full of 1s instead of 0s. This prevents forgetting everything at the beginning of training.</p>
</li>
</ul>








<section data-type="sect2" data-pdf-bookmark="Peephole Connections"><div class="sect2" id="idm140582987341312">
<h2>Peephole Connections</h2>

<p>In a basic LSTM cell, <a data-type="indexterm" data-primary="peephole connections" id="idm140582987339776"></a>the gate controllers can look only at the input <strong>x</strong><sub>(<em>t</em>)</sub> and the previous short-term state <strong>h</strong><sub>(<em>t</em>–1)</sub>. It may be a good idea to give them a bit more context by letting them peek at the long-term state as well. This idea was <a href="https://goo.gl/ch8xz3">proposed by Felix Gers and Jürgen Schmidhuber in 2000</a>.<sup><a data-type="noteref" id="idm140582987335360-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch14.html#idm140582987335360" class="totri-footnote">6</a></sup> They proposed an LSTM variant with extra connections called <em>peephole connections</em>: the previous long-term state <strong>c</strong><sub>(<em>t</em>–1)</sub> is added as an input to the controllers of the forget gate and the input gate, and the current long-term state <strong>c</strong><sub>(<em>t</em>)</sub> is added as input to the controller of the output gate.</p>

<p>To implement peephole connections in TensorFlow, you must use the <code>LSTMCell</code> instead of the <code>BasicLSTMCell</code> and <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.contrib.rnn.BasicLSTMCell" id="idm140582987330480"></a> <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.contrib.rnn.LSTMCell" id="idm140582987329376"></a>set <code>use_peepholes=True</code>:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">lstm_cell</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">contrib</code><code class="o">.</code><code class="n">rnn</code><code class="o">.</code><code class="n">LSTMCell</code><code class="p">(</code><code class="n">num_units</code><code class="o">=</code><code class="n">n_neurons</code><code class="p">,</code> <code class="n">use_peepholes</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code></pre>

<p>There are many other variants of the LSTM cell. One particularly popular variant is the GRU cell, which we will look at now.</p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="GRU Cell"><div class="sect1" id="idm140582987404432">
<h1>GRU Cell</h1>

<p>The <em>Gated Recurrent Unit</em> (GRU) <a data-type="indexterm" data-primary="GRU (Gated Recurrent Unit) cell" id="gruc14"></a><a data-type="indexterm" data-primary="recurrent neural networks (RNNs)" data-secondary="GRU cell" id="rnn14gruc"></a>cell (see <a data-type="xref" href="#gru_cell_diagram">Figure&nbsp;14-14</a>) was proposed by Kyunghyun Cho et al. in a <a href="https://goo.gl/ZnAEOZ">2014 paper</a><sup><a data-type="noteref" id="idm140582987102480-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch14.html#idm140582987102480" class="totri-footnote">7</a></sup> that also introduced the Encoder–Decoder network we mentioned earlier.</p>

<figure><div id="gru_cell_diagram" class="figure">
<img src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1414.png" alt="mlst 1414" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1414.png" width="1618" height="1100">
<h6><span class="label">Figure 14-14. </span>GRU cell</h6>
</div></figure>

<p>The GRU cell is a simplified version of the LSTM cell, and it seems to perform just as well<sup><a data-type="noteref" id="idm140582987096560-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch14.html#idm140582987096560" class="totri-footnote">8</a></sup> (which explains its growing popularity). The main simplifications are:</p>

<ul>
<li>
<p>Both state vectors are merged into a single vector <strong>h</strong><sub>(<em>t</em>)</sub>.</p>
</li>
<li>
<p>A single gate controller controls both the forget gate and the input 
gate. If the gate controller outputs a 1, the forget gate is open and 
the input gate is closed. If it outputs a 0, the opposite happens. In 
other words, whenever a memory must be stored, the location where it 
will be stored is erased first. This is actually a frequent variant to 
the LSTM cell in and of itself.</p>
</li>
<li>
<p>There is no output gate; the full state vector is output at every 
time step. However, there is a new gate controller that controls which 
part of the previous state will be shown to the main layer.</p>
</li>
</ul>

<p><a data-type="xref" href="#gru_equation">Equation 14-4</a> summarizes how to compute the cell’s state at each time step for a single instance.</p>
<div id="gru_equation" data-type="equation"><h5><span class="label">Equation 14-4. </span>GRU computations</h5>
<img src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_131.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_131.png" width="1294" height="403"></div>

<p>Creating a GRU cell in TensorFlow is trivial:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">gru_cell</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">contrib</code><code class="o">.</code><code class="n">rnn</code><code class="o">.</code><code class="n">GRUCell</code><code class="p">(</code><code class="n">num_units</code><code class="o">=</code><code class="n">n_neurons</code><code class="p">)</code></pre>

<p>LSTM or GRU cells <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.contrib.rnn.GRUCell" id="idm140582987080160"></a>are one of the main reasons behind the success of RNNs in recent years, in particular <a data-type="indexterm" data-primary="GRU (Gated Recurrent Unit) cell" data-startref="gruc14" id="idm140582987079184"></a><a data-type="indexterm" data-primary="recurrent neural networks (RNNs)" data-secondary="GRU cell" data-startref="rnn14gruc" id="idm140582987078272"></a><a data-type="indexterm" data-primary="recurrent neural networks (RNNs)" data-secondary="LSTM cell" data-startref="rnn14lstmc" id="idm140582987077088"></a><a data-type="indexterm" data-primary="LSTM (Long Short-Term Memory) cell" data-startref="lstmc14" id="idm140582987075904"></a>for applications in <em>natural language processing</em> (NLP).</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Natural Language Processing"><div class="sect1" id="idm140582987107808">
<h1>Natural Language Processing</h1>

<p>Most <a data-type="indexterm" data-primary="natural language processing (NLP)" id="nlp14"></a><a data-type="indexterm" data-primary="recurrent neural networks (RNNs)" data-secondary="natural language processing (NLP)" id="rnn14nlp"></a><a data-type="indexterm" data-primary="machine translation" data-see="natural language processing (NLP)" id="idm140582986985568"></a>of
 the state-of-the-art NLP applications, such as machine translation, 
automatic summarization, parsing, sentiment analysis, and more, are now 
based (at least in part) on RNNs. In this last section, we will take a 
quick look at what a machine translation model looks like. This topic is
 very well covered by <a data-type="indexterm" data-primary="natural language processing (NLP)" data-secondary="TensorFlow tutorials" id="idm140582986984160"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="NLP tutorials" id="idm140582986983200"></a>TensorFlow’s awesome <a href="https://goo.gl/edArdi">Word2Vec</a> and <a href="https://goo.gl/L82gvS">Seq2Seq</a> tutorials, so you should definitely check them out.</p>








<section data-type="sect2" data-pdf-bookmark="Word Embeddings"><div class="sect2" id="idm140582986980656">
<h2>Word Embeddings</h2>

<p>Before <a data-type="indexterm" data-primary="natural language processing (NLP)" data-secondary="word embeddings" id="nlp14we"></a><a data-type="indexterm" data-primary="embeddings" id="e14"></a>we
 start, we need to choose a word representation. One option could be to 
represent each word using a one-hot vector. Suppose your vocabulary 
contains 50,000 words, then the n<sup>th</sup> word would be represented as a 50,000-dimensional vector, full of 0s except for a 1 at the n<sup>th</sup>
 position. However, with such a large vocabulary, this sparse 
representation would not be efficient at all. Ideally, you want similar 
words to have similar representations, making it easy for the model to 
generalize what it learns about a word to all similar words. For 
example, if the model is told that “I drink milk” is a valid sentence, 
and if it knows that “milk” is close to “water” but far from “shoes,” 
then it will know that “I drink water” is probably a valid sentence as 
well, while “I drink shoes” is probably not. But how can you come up 
with such a meaningful representation?</p>

<p>The most common solution is to represent each word in the vocabulary 
using a fairly small and dense vector (e.g., 150 dimensions), called an <em>embedding</em>,
 and just let the neural network learn a good embedding for each word 
during training. At the beginning of training, embeddings are simply 
chosen randomly, but during training, backpropagation automatically 
moves the embeddings around in a way that helps the neural network 
perform its task. Typically this means that similar words will gradually
 cluster close to one another, and even end up organized in a rather 
meaningful way. For example, embeddings may end up placed along various 
axes that represent gender, singular/plural, adjective/noun, and so on. 
The result can be truly amazing.<sup><a data-type="noteref" id="idm140582986973280-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch14.html#idm140582986973280" class="totri-footnote">9</a></sup></p>

<p>In TensorFlow, you first need to create the variable representing the embeddings for every word in your <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.random_uniform()" id="idm140582986970800"></a>vocabulary (initialized randomly):</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">vocabulary_size</code> <code class="o">=</code> <code class="mi">50000</code>
<code class="n">embedding_size</code> <code class="o">=</code> <code class="mi">150</code>

<code class="n">init_embeds</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">random_uniform</code><code class="p">([</code><code class="n">vocabulary_size</code><code class="p">,</code> <code class="n">embedding_size</code><code class="p">],</code> <code class="o">-</code><code class="mf">1.0</code><code class="p">,</code> <code class="mf">1.0</code><code class="p">)</code>
<code class="n">embeddings</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">Variable</code><code class="p">(</code><code class="n">init_embeds</code><code class="p">)</code></pre>

<p>Now suppose you want to feed the sentence “I drink milk” to your 
neural network. You should first preprocess the sentence and break it 
into a list of known words. For example you may remove unnecessary 
characters, replace unknown words by a predefined token word such as 
“[UNK]”, replace numerical values by “[NUM]”, replace URLs by “[URL]”, 
and so on. Once you have a list of known words, you can look up each 
word’s integer identifier (from 0 to 49999) in a dictionary, for example
 [72, 3335, 288]. At that point, you are ready to feed these word 
identifiers to TensorFlow using a placeholder, and apply the <code>embedding_lookup()</code> <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.nn.embedding_lookup()" id="idm140582987054336"></a><a data-type="indexterm" data-primary="embedding_lookup()" id="idm140582987053456"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.int32" id="idm140582987052784"></a>function to get the corresponding embeddings:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">train_inputs</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">placeholder</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">int32</code><code class="p">,</code> <code class="n">shape</code><code class="o">=</code><code class="p">[</code><code class="bp">None</code><code class="p">])</code>  <code class="c1"># from ids...</code>
<code class="n">embed</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">embedding_lookup</code><code class="p">(</code><code class="n">embeddings</code><code class="p">,</code> <code class="n">train_inputs</code><code class="p">)</code>  <code class="c1"># ...to embeddings</code></pre>

<p>Once your model has learned good word embeddings, they can actually 
be reused fairly efficiently in any NLP application: after all, “milk” 
is still close to “water” and far from “shoes” no matter what your 
application is. In fact, instead of training your own word embeddings, 
you may want to download pretrained word embeddings. Just like when 
reusing pretrained layers (see <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#deep_chapter">Chapter&nbsp;11</a>), you can choose to freeze the pretrained embeddings (e.g., creating the <code>embeddings</code> variable using <code>trainable=False</code>)
 or let backpropagation tweak them for your application. The first 
option will speed up training, but the second may lead to slightly 
higher performance.</p>
<div data-type="tip"><h6>Tip</h6>
<p>Embeddings are also useful for representing categorical attributes 
that can take on a large number of different values, especially when 
there are complex similarities between values. For example, consider 
professions, hobbies, dishes, species, brands, and so on.</p>
</div>

<p>You now have almost all the tools you need to implement a machine translation system. <a data-type="indexterm" data-primary="natural language processing (NLP)" data-secondary="word embeddings" data-startref="nlp14we" id="idm140582986831392"></a><a data-type="indexterm" data-primary="embeddings" data-startref="e14" id="idm140582986830176"></a>Let’s look at this now.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="An Encoder–Decoder Network for Machine Translation"><div class="sect2" id="idm140582986980032">
<h2>An Encoder–Decoder Network for Machine Translation</h2>

<p>Let’s <a data-type="indexterm" data-primary="natural language processing (NLP)" data-secondary="encoder-decoder network for machine translation" id="nlp14ednfmt"></a>take a look at a <a href="https://goo.gl/0g9zWP">simple machine translation model</a><sup><a data-type="noteref" id="idm140582986825408-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch14.html#idm140582986825408">10</a></sup> that will translate English sentences to French (see <a data-type="xref" href="#machine_translation_diagram">Figure&nbsp;14-15</a>).</p>

<figure><div id="machine_translation_diagram" class="figure">
<img src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1415.png" alt="mlst 1415" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1415.png" width="1440" height="981">
<h6><span class="label">Figure 14-15. </span>A simple machine translation model</h6>
</div></figure>

<p>The English sentences are fed to the encoder, and the decoder outputs
 the French translations. Note that the French translations are also 
used as inputs to the decoder, but pushed back by one step. In other 
words, the decoder is given as input the word that it <em>should</em> 
have output at the previous step (regardless of what it actually 
output). For the very first word, it is given a token that represents 
the beginning of the sentence (e.g., “&lt;go&gt;”). The decoder is 
expected to end the sentence with an end-of-sequence (EOS) token (e.g., 
“&lt;eos&gt;”).</p>

<p>Note that the English sentences are reversed before they are fed to 
the encoder. For example “I drink milk” is reversed to “milk drink I.” 
This ensures that the beginning of the English sentence will be fed last
 to the encoder, which is useful because that’s generally the first 
thing that the decoder needs to translate.</p>

<p>Each word is initially represented by a simple integer identifier 
(e.g., 288 for the word “milk”). Next, an embedding lookup returns the 
word embedding (as explained earlier, this is a dense, fairly 
low-dimensional vector). These word embeddings are what is actually fed 
to the encoder and the decoder.</p>

<p>At each step, the decoder outputs a score for each word in the output
 vocabulary (i.e., French), and then the Softmax layer turns these 
scores into probabilities. For example, at the first step the word “Je” 
may have a probability of 20%, “Tu” may have a probability of 1%, and so
 on. The word with the highest probability is output. This is very much 
like a regular classification task, so you can train the model using the
 <code>softmax_cross_entropy_with_logits()</code> function.</p>

<p>Note that at <a data-type="indexterm" data-primary="inference" id="idm140582986817344"></a>inference
 time (after training), you will not have the target sentence to feed to
 the decoder. Instead, simply feed the decoder the word that it output 
at the previous step, as shown in <a data-type="xref" href="#inference_decoder_diagram">Figure&nbsp;14-16</a> (this will require an embedding lookup that is not shown on the diagram).</p>

<figure class="smallerninety"><div id="inference_decoder_diagram" class="figure">
<img src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1416.png" alt="mlst 1416" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1416.png" width="1223" height="562">
<h6><span class="label">Figure 14-16. </span>Feeding the previous output word as input at inference time</h6>
</div></figure>

<p>Okay, now you have the big picture. However, if you go through TensorFlow’s sequence-to-sequence <a data-type="indexterm" data-primary="natural language processing (NLP)" data-secondary="TensorFlow tutorials" id="idm140582986812560"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="NLP tutorials" id="idm140582986811568"></a>tutorial and you look at the code in <em>rnn/translate/seq2seq_model.py</em> (in the <a href="https://github.com/tensorflow/models">TensorFlow models</a>), you will notice a few important differences:</p>

<ul>
<li class="currently-reading">
<p>First, so far we have assumed that all input sequences (to the encoder and to the decoder) <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.contrib.rnn.static_rnn()" id="tfcrsrch14part2"></a> <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.nn.dynamic_rnn()" id="tfnndrch14part3"></a>have
 a constant length. But obviously sentence lengths may vary. There are 
several ways that this can be handled—for example, using the <code>sequence_length</code> <a data-type="indexterm" data-primary="sequence_length" id="idm140582986929984"></a>argument to the <code>static_rnn()</code> or <code>dynamic_rnn()</code> <a data-type="indexterm" data-primary="static_rnn()" id="idm140582986928256"></a><a data-type="indexterm" data-primary="dynamic_rnn()" id="idm140582986927520"></a>functions
 to specify each sentence’s length (as discussed earlier). However, 
another approach is used in the tutorial (presumably for performance 
reasons): sentences are grouped into buckets of similar lengths (e.g., a
 bucket for the 1- to 6-word sentences, another for the 7- to 12-word 
sentences, and so on<sup><a data-type="noteref" id="idm140582986926400-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch14.html#idm140582986926400">11</a></sup>),
 and the shorter sentences are padded using a special padding token 
(e.g., “&lt;pad&gt;”). For example “I drink milk” becomes “&lt;pad&gt; 
&lt;pad&gt; &lt;pad&gt; milk drink I”, and its translation becomes “Je 
bois du lait &lt;eos&gt; &lt;pad&gt;”. Of course, we want to ignore any 
output past the EOS token. For this, the tutorial’s implementation uses a
 <code>target_weights</code> <a data-type="indexterm" data-primary="target_weights" id="idm140582986924944"></a>vector. For example, for the target sentence “Je bois du lait &lt;eos&gt; &lt;pad&gt;”, the weights would be set to <code>[1.0, 1.0, 1.0, 1.0, 1.0, 0.0]</code>
 (notice the weight 0.0 that corresponds to the padding token in the 
target sentence). Simply multiplying the losses by the target weights 
will zero out the losses that correspond to words past EOS tokens.</p>
</li>
<li class="currently-reading">
<p>Second, when the output vocabulary is large (which is the case here),
 outputting a probability for each and every possible word would be 
terribly slow. If the target vocabulary contains, say, 50,000 French 
words, then the decoder would output 50,000-dimensional vectors, and 
then computing the softmax function over such a large vector would be 
very computationally intensive. To avoid this, one solution is to let 
the decoder output much smaller vectors, such as 1,000-dimensional 
vectors, then use a sampling technique to estimate the loss without 
having to compute it over every single word in the target vocabulary. 
This <em>Sampled Softmax</em> <a data-type="indexterm" data-primary="Sampled Softmax" id="idm140582986921488"></a>technique was <a href="https://goo.gl/u0GR8k">introduced in 2015 by Sébastien Jean et al</a>.<sup><a data-type="noteref" id="idm140582986919872-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch14.html#idm140582986919872">12</a></sup> In TensorFlow you can use the <code>sampled_softmax_loss()</code> function.</p>
</li>
<li class="currently-reading">
<p>Third, the tutorial’s implementation uses an <em>attention mechanism</em> <a data-type="indexterm" data-primary="attention mechanism" id="idm140582986917280"></a>that
 lets the decoder peek into the input sequence. Attention augmented RNNs
 are beyond the scope of this book, but if you are interested there are 
helpful papers about <a href="https://goo.gl/8RCous">machine translation</a>,<sup><a data-type="noteref" id="idm140582986915568-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch14.html#idm140582986915568">13</a></sup> <a href="https://goo.gl/X0Nau8">machine reading</a>,<sup><a data-type="noteref" id="idm140582986914048-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch14.html#idm140582986914048">14</a></sup> and <a href="https://goo.gl/xmhvfK">image captions</a><sup><a data-type="noteref" id="idm140582986912672-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch14.html#idm140582986912672">15</a></sup> using attention.</p>
</li>
<li>
<p>Finally, the tutorial’s implementation makes use of the <code>tf.nn.legacy_seq2seq</code> module, which provides tools to build various Encoder–Decoder models easily. For example, the <code>embedding_rnn_seq2seq()</code>
 function creates a simple Encoder–Decoder model that automatically 
takes care of word embeddings for you, just like the one represented in <a data-type="xref" href="#machine_translation_diagram">Figure&nbsp;14-15</a>. This code will likely be updated quickly to use the new <code>tf.nn.seq2seq</code> module.</p>
</li>
</ul>

<p>You now have all the tools you need to understand the sequence-to-sequence tutorial’s implementation. <a data-type="indexterm" data-primary="natural language processing (NLP)" data-secondary="encoder-decoder network for machine translation" data-startref="nlp14ednfmt" id="idm140582986907952"></a><a data-type="indexterm" data-primary="natural language processing (NLP)" data-startref="nlp14" id="idm140582986906592"></a><a data-type="indexterm" data-primary="recurrent neural networks (RNNs)" data-secondary="natural language processing (NLP)" data-startref="rnn14nlp" id="idm140582986905632"></a>Check it out and train your own English-to-French translator!</p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Exercises"><div class="sect1" id="idm140582986904128">
<h1>Exercises</h1>
<ol>
<li>
<p>Can you think of a few applications for a sequence-to-sequence RNN? 
What about a sequence-to-vector RNN? And a vector-to-sequence RNN?</p>
</li>
<li>
<p>Why do people use encoder–decoder RNNs rather than plain sequence-to-sequence RNNs for automatic translation?</p>
</li>
<li>
<p>How could you combine a convolutional neural network with an RNN to classify videos?</p>
</li>
<li>
<p>What are <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.contrib.rnn.static_rnn()" data-startref="tfcrsrch14part2" id="idm140582986899104"></a> <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.nn.dynamic_rnn()" data-startref="tfnndrch14part3" id="idm140582986897728"></a>the advantages of building an RNN using <code>dynamic_rnn()</code> rather than <code>static_rnn()</code>?</p>
</li>
<li>
<p>How can you deal with variable-length input sequences? What about variable-length output sequences?</p>
</li>
<li>
<p>What is a common way to distribute training and execution of a deep RNN across multiple GPUs?</p>
</li>
<li>
<p><em>Embedded Reber grammars</em> <a data-type="indexterm" data-primary="Embedded Reber grammars" id="idm140582986892384"></a>were
 used by Hochreiter and Schmidhuber in their paper about LSTMs. They are
 artificial grammars that produce strings such as “BPBTSXXVPSEPE.” Check
 out Jenny Orr’s <a href="https://goo.gl/7CkNRn">nice introduction</a> 
to this topic. Choose a particular embedded Reber grammar (such as the 
one represented on Jenny Orr’s page), then train an RNN to identify 
whether a string respects that grammar or not. You will first need to 
write a function capable of generating a training batch containing about
 50% strings that respect the grammar, and 50% that don’t.</p>
</li>
<li>
<p>Tackle the “How much did it rain? II” <a href="https://goo.gl/0DS5Xe">Kaggle competition</a>.
 This is a time series prediction task: you are given snapshots of 
polarimetric radar values and asked to predict the hourly rain gauge 
total. Luis Andre Dutra e Silva’s <a href="https://goo.gl/fTA90W">interview</a>
 gives some interesting insights into the techniques he used to reach 
second place in the competition. In particular, he used an RNN composed 
of two LSTM layers.</p>
</li>
<li>
<p>Go through TensorFlow’s <a href="https://goo.gl/edArdi">Word2Vec</a> tutorial to create word embeddings, and then go through the <a href="https://goo.gl/L82gvS">Seq2Seq</a> tutorial to train an English-to-French translation system.</p>
</li>

</ol>

<p>Solutions to these exercises are <a data-type="indexterm" data-primary="recurrent neural networks (RNNs)" data-startref="rnn14" id="idm140582986884848"></a>available in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app01.html#solutions_appendix">Appendix&nbsp;A</a>.</p>
</div></section>







<div data-type="footnotes"><p data-type="footnote" id="idm140582990809232"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch14.html#idm140582990809232-marker" class="totri-footnote">1</a></sup>
 Note that many researchers prefer to use the hyperbolic tangent (tanh) 
activation function in RNNs rather than the ReLU activation function. 
For example, take a look at by Vu Pham et al.’s paper <a href="https://goo.gl/2WSnaj">“Dropout Improves Recurrent Neural Networks for Handwriting Recognition”</a>. <a data-type="indexterm" data-primary="hyperbolic tangent (htan activation function)" id="idm140582990807696"></a>However, ReLU-based RNNs are also possible, as shown in Quoc V. Le et al.’s paper <a href="https://goo.gl/NrKAP0">“A Simple Way to Initialize Recurrent Networks of Rectified Linear Units”</a>.</p><p data-type="footnote" id="idm140582987770848"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch14.html#idm140582987770848-marker" class="totri-footnote">2</a></sup> This uses the <em>decorator</em> design pattern.</p><p data-type="footnote" id="idm140582987399776"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch14.html#idm140582987399776-marker" class="totri-footnote">3</a></sup> “Long Short-Term Memory,” S. Hochreiter and J. Schmidhuber (1997).</p><p data-type="footnote" id="idm140582987398288"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch14.html#idm140582987398288-marker" class="totri-footnote">4</a></sup> “Long Short-Term Memory Recurrent Neural Network Architectures for Large Scale Acoustic Modeling,” H. Sak et al. (2014).</p><p data-type="footnote" id="idm140582987396736"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch14.html#idm140582987396736-marker" class="totri-footnote">5</a></sup> “Recurrent Neural Network Regularization,” W. Zaremba et al. (2015).</p><p data-type="footnote" id="idm140582987335360"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch14.html#idm140582987335360-marker" class="totri-footnote">6</a></sup> “Recurrent Nets that Time and Count,” F. Gers and J. Schmidhuber (2000).</p><p data-type="footnote" id="idm140582987102480"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch14.html#idm140582987102480-marker" class="totri-footnote">7</a></sup> “Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation,” K. Cho et al. (2014).</p><p data-type="footnote" id="idm140582987096560"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch14.html#idm140582987096560-marker" class="totri-footnote">8</a></sup> A 2015 paper by Klaus Greff et al., <a href="https://goo.gl/hZB4KW">“LSTM: A Search Space Odyssey,”</a> seems to show that all LSTM variants perform roughly the same.</p><p data-type="footnote" id="idm140582986973280"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch14.html#idm140582986973280-marker" class="totri-footnote">9</a></sup> For more details, check out Christopher Olah’s <a href="https://goo.gl/5rLNTj">great post</a>, or Sebastian Ruder’s <a href="https://goo.gl/ojJjiE">series of posts</a>.</p><p data-type="footnote" id="idm140582986825408"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch14.html#idm140582986825408-marker">10</a></sup> “Sequence to Sequence learning with Neural Networks,” I. Sutskever et al. (2014).</p><p data-type="footnote" id="idm140582986926400"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch14.html#idm140582986926400-marker">11</a></sup> The bucket sizes used in the tutorial are different.</p><p data-type="footnote" id="idm140582986919872"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch14.html#idm140582986919872-marker">12</a></sup> “On Using Very Large Target Vocabulary for Neural Machine Translation,” S. Jean et al. (2015).</p><p data-type="footnote" id="idm140582986915568"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch14.html#idm140582986915568-marker">13</a></sup> “Neural Machine Translation by Jointly Learning to Align and Translate,” D. Bahdanau et al. (2014).</p><p data-type="footnote" id="idm140582986914048"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch14.html#idm140582986914048-marker">14</a></sup> “Long Short-Term Memory-Networks for Machine Reading,” J. Cheng (2016).</p><p data-type="footnote" id="idm140582986912672"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch14.html#idm140582986912672-marker">15</a></sup> “Show, Attend and Tell: Neural Image Caption Generation with Visual Attention,” K. Xu et al. (2015).</p></div></div></section><div class="annotator-outer annotator-viewer viewer annotator-hide">
  <ul class="annotator-widget annotator-listing"></ul>
</div><div class="annotator-modal-wrapper annotator-editor-modal annotator-editor annotator-hide">
	<div class="annotator-outer editor">
		<h2 class="title">Highlight</h2>
		<form class="annotator-widget">
			<ul class="annotator-listing">
			<li class="annotator-item"><textarea id="annotator-field-4" placeholder="Add a note using markdown (optional)" class="js-editor" maxlength="750"></textarea></li></ul>
			<div class="annotator-controls">
				<a class="link-to-markdown" href="https://daringfireball.net/projects/markdown/basics" target="_blank">?</a>
				<ul>
					<li class="delete annotator-hide"><a href="#delete" class="annotator-delete-note button positive">Delete Note</a></li>
					<li class="save"><a href="#save" class="annotator-save annotator-focus button positive">Save Note</a></li>
					<li class="cancel"><a href="#cancel" class="annotator-cancel button">Cancel</a></li>
				</ul>
			</div>
		</form>
	</div>
</div><div class="annotator-modal-wrapper annotator-delete-confirm-modal" style="display: none;">
  <div class="annotator-outer">
    <h2 class="title">Highlight</h2>
      <a class="js-close-delete-confirm annotator-cancel close" href="#close">Close</a>
      <div class="annotator-widget">
         <div class="delete-confirm">
            Are you sure you want to permanently delete this note?
         </div>
         <div class="annotator-controls">
            <a href="#cancel" class="annotator-cancel button js-cancel-delete-confirm">No, I changed my mind</a>
            <a href="#delete" class="annotator-delete button positive js-delete-confirm">Yes, delete it</a>
         </div>
       </div>
   </div>
</div><div class="annotator-adder" style="display: none;">
	<ul class="adders ">
		
		<li class="copy"><a href="#">Copy</a></li>
		
		<li class="add-highlight"><a href="#">Add Highlight</a></li>
		<li class="add-note"><a href="#">
			
				Add Note
			
		</a></li>
		
	</ul>
</div></div></div>



  <div class="t-sbo-prev sbo-prev sbo-nav-bottom">
  
    
      
        <a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch13.html" class="prev nav-link">
      
          <span aria-hidden="true" class="pagination-label t-prev-label">Prev</span>
          <span class="visuallyhidden">Previous Chapter</span>
          <div class="pagination-title t-prev-title">13. Convolutional Neural Networks</div>
        </a>
    
  
  </div>

  <div class="t-sbo-next sbo-next sbo-nav-bottom">
  
    
      
        <a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch15.html" class="next nav-link">
      
          <span aria-hidden="true" class="pagination-label t-next-label">Next</span>
          <span class="visuallyhidden">Next Chapter</span>
          <div class="pagination-title t-next-title">15. Autoencoders</div>
        </a>
    
  
  </div>

</section>
  </div>
<section class="sbo-saved-archives"></section>



          
          
  




    
    
      <div id="js-subscribe-nag" class="subscribe-nag clearfix trial-panel t-subscribe-nag collapsed slideUp">
        
        
          
          
            <p class="usage-data">Find answers on the fly, or master something new. Subscribe today. <a href="https://www.safaribooksonline.com/subscribe/" class="ga-active-trial-subscribe-nag">See pricing options.</a></p>
          

          
        
        

      </div>

    
    



        
      </div>
      




  <footer class="pagefoot t-pagefoot" style="padding-bottom: 69px;">
    <a href="#" class="icon-up" style="display: block;"><div class="visuallyhidden">Back to top</div></a>
    <ul class="js-footer-nav">
      
        <li><a class="t-recommendations-footer" href="https://www.safaribooksonline.com/r/">Recommended</a></li>
      
      <li>
      
      <a class="t-queue-footer" href="https://www.safaribooksonline.com/s/">Queue</a>
      
      </li>
      
        <li><a class="t-recent-footer" href="https://www.safaribooksonline.com/history/">History</a></li>
        <li><a class="t-topics-footer" href="https://www.safaribooksonline.com/topics?q=*&amp;limit=21">Topics</a></li>
      
      
        <li><a class="t-tutorials-footer" href="https://www.safaribooksonline.com/tutorials/">Tutorials</a></li>
      
      <li><a class="t-settings-footer js-settings" href="https://www.safaribooksonline.com/u/">Settings</a></li>
      <li class="full-support"><a href="https://www.safaribooksonline.com/public/support">Support</a></li>
      <li><a href="https://www.safaribooksonline.com/apps/">Get the App</a></li>
      <li><a href="https://www.safaribooksonline.com/accounts/logout/">Sign Out</a></li>
    </ul>
    <span class="copyright">© 2017 <a href="https://www.safaribooksonline.com/" target="_blank">Safari</a>.</span>
    <a href="https://www.safaribooksonline.com/terms/">Terms of Service</a> /
    <a href="https://www.safaribooksonline.com/privacy/">Privacy Policy</a>
  </footer>

<script type="text/javascript">window.NREUM||(NREUM={});NREUM.info={"beacon":"bam.nr-data.net","queueTime":0,"licenseKey":"510f1a6865","errorBeacon":"bam.nr-data.net","transactionName":"YgdaZ0NSW0cEB0RdWltNfkZfUEFdCgofXFBHDVYdR1pQQxZeRl1QQj1aWkU=","applicationTime":651,"applicationID":"3275661","agent":""}</script>


    

    <script src="12.%20Distributing%20TensorFlow%20Across%20Devices%20and%20Servers%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/a_004.js" charset="utf-8"></script><script type="text/javascript" id="">!function(b,e,f,g,a,c,d){b.fbq||(a=b.fbq=function(){a.callMethod?a.callMethod.apply(a,arguments):a.queue.push(arguments)},b._fbq||(b._fbq=a),a.push=a,a.loaded=!0,a.version="2.0",a.queue=[],c=e.createElement(f),c.async=!0,c.src=g,d=e.getElementsByTagName(f)[0],d.parentNode.insertBefore(c,d))}(window,document,"script","https://connect.facebook.net/en_US/fbevents.js");fbq("init","1732687426968531");fbq("track","PageView");</script>
<noscript><img height="1" width="1" style="display:none" src="https://www.facebook.com/tr?id=1732687426968531&amp;ev=PageView&amp;noscript=1"></noscript><div style="width:0px; height:0px; display:none; visibility:hidden;" id="batBeacon0.3743867347277554"><img style="width:0px; height:0px; display:none; visibility:hidden;" id="batBeacon0.3342180628024528" alt="" src="12.%20Distributing%20TensorFlow%20Across%20Devices%20and%20Servers%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/0.txt" width="0" height="0"></div>
    <script src="12.%20Distributing%20TensorFlow%20Across%20Devices%20and%20Servers%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/a_005.js" charset="utf-8"></script>
  

<div class="annotator-notice"></div><div class="font-flyout" style="top: 200px; left: 1257px;"><div class="font-controls-panel">
	<div class="nightmodes">
		<ul>
			<li class="day"><a href="#" id="day-mode" title="Day Mode">
				<i class="fa fa-sun-o"></i>
				<span>Day Mode</span></a></li>
			<li class="cloudy"><a href="#" id="cloudy-mode" title="Cloudy Mode">
				<i class="fa fa-cloud"></i>
				<span>Cloud Mode</span>
			</a></li>
			<li class="night"><a href="#" id="night-mode" title="Night Mode">
				<i class="fa fa-moon-o"></i>
				<span>Night Mode</span>
			</a></li>
		</ul>
	</div>

	<div class="font-resizer resizer">
		<div class="draggable-containment-wrapper">
			<i class="fa fa-font left"></i>
			<span class="filler" style="width: 50%;"></span>
			<div id="js-font-size-draggable" class="draggable ui-widget-content ui-draggable ui-draggable-handle" style="position: relative; left: 80px;"></div>
			<i class="fa fa-font right"></i>
		</div>
	</div>

	<div class="column-resizer resizer">
		<div class="draggable-containment-wrapper">
			<i class="fa fa-compress left"></i>
			<span class="filler" style="width: 50%;"></span>
			<div id="js-column-size-draggable" class="draggable ui-widget-content ui-draggable ui-draggable-handle" style="position: relative; left: 80px;"></div>
			<i class="fa fa-expand right"></i>
		</div>
	</div>

	<a id="reset" class="button" href="#">Reset</a>
</div>
</div><iframe style="display: none;" src="12.%20Distributing%20TensorFlow%20Across%20Devices%20and%20Servers%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/pixel.html"></iframe><script src="12.%20Distributing%20TensorFlow%20Across%20Devices%20and%20Servers%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/a.js" type="text/javascript"></script><script src="12.%20Distributing%20TensorFlow%20Across%20Devices%20and%20Servers%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/a" type="text/javascript"></script><img src="12.%20Distributing%20TensorFlow%20Across%20Devices%20and%20Servers%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/seg.gif" alt="" style="display: none;" width="1" height="1" border="0"></body></html>