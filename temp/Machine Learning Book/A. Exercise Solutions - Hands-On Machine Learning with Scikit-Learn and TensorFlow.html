<!--[if IE]><![endif]-->
<!DOCTYPE html>
<!--[if IE 8]><html class="no-js ie8 oldie" lang="en" prefix="og: http://ogp.me/ns/# og:book: http://ogp.me/ns/book# og:video: http://ogp.me/ns/video#"

    
        itemscope itemtype="http://schema.org/Book http://schema.org/ItemPage"" data-login-url="/accounts/login/"
data-offline-url="/"
data-url="/library/view/hands-on-machine-learning/9781491962282/ch10.html"
data-csrf-cookie="csrfsafari"
data-highlight-privacy="private"


  data-user-id="2309833"
  data-user-uuid="2d2acfb7-1cff-4dc7-9037-8ffbac19b02e"
  data-username="ayushksinghal"
  data-account-type="Trial"
  
  data-activated-trial-date="12/02/2017"


  data-archive="9781491962282"
  data-publishers="O&#39;Reilly Media, Inc."



  data-htmlfile-name="ch10.html"
  data-epub-title="Hands-On Machine Learning with Scikit-Learn and TensorFlow" data-debug=0 data-testing=0><![endif]-->
<!--[if gt IE 8]><!-->
<html class="js flexbox flexboxlegacy no-touch no-websqldatabase indexeddb history csscolumns csstransforms localstorage sessionstorage applicationcache svg inlinesvg no-zoom gr__safaribooksonline_com" prefix="og: http://ogp.me/ns/# og:book: http://ogp.me/ns/book# og:video: http://ogp.me/ns/video#" itemscope="" itemtype="http://schema.org/Book http://schema.org/ItemPage" "="" data-login-url="/accounts/login/" data-offline-url="/" data-url="/library/view/hands-on-machine-learning/9781491962282/ch10.html" data-csrf-cookie="csrfsafari" data-highlight-privacy="private" data-user-id="2309833" data-user-uuid="2d2acfb7-1cff-4dc7-9037-8ffbac19b02e" data-username="ayushksinghal" data-account-type="Trial" data-activated-trial-date="12/02/2017" data-archive="9781491962282" data-publishers="O'Reilly Media, Inc." data-htmlfile-name="ch10.html" data-epub-title="Hands-On Machine Learning with Scikit-Learn and TensorFlow" data-debug="0" data-testing="0" style="" data-ember-extension="1" lang="en"><!--<![endif]--><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="author" content="Safari Books Online"><meta name="format-detection" content="telephone=no"><meta http-equiv="cleartype" content="on"><meta name="HandheldFriendly" content="True"><meta name="MobileOptimized" content="320"><meta name="apple-itunes-app" content="app-id=881697395, app-argument=safaridetail://9781491962282"><meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, maximum-scale=1.0"><meta property="twitter:account_id" content="4503599627559754"><script type="text/javascript" src="A.%20Exercise%20Solutions%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/510f1a6865.js"></script><script src="A.%20Exercise%20Solutions%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/nr-spa-1044.js"></script><script type="text/javascript" async="" src="A.%20Exercise%20Solutions%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/linkid.js"></script><script src="A.%20Exercise%20Solutions%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/1732687426968531.js" async=""></script><script async="" src="A.%20Exercise%20Solutions%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/fbevents.js"></script><script type="text/javascript" async="" src="A.%20Exercise%20Solutions%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/bat.js"></script><script type="text/javascript" async="" src="A.%20Exercise%20Solutions%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/conversion_async.js"></script><script type="text/javascript" async="" src="A.%20Exercise%20Solutions%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/insight.js"></script><script type="text/javascript" async="" src="A.%20Exercise%20Solutions%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/conversion_async.js"></script><script async="" src="A.%20Exercise%20Solutions%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/gtm.js"></script><script async="" src="A.%20Exercise%20Solutions%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/analytics.js"></script><script type="text/javascript">(window.NREUM||(NREUM={})).loader_config={xpid:"VQQDUVVVGwACU1RUAQA="};window.NREUM||(NREUM={}),__nr_require=function(t,e,n){function r(n){if(!e[n]){var o=e[n]={exports:{}};t[n][0].call(o.exports,function(e){var o=t[n][1][e];return r(o||e)},o,o.exports)}return e[n].exports}if("function"==typeof __nr_require)return __nr_require;for(var o=0;o<n.length;o++)r(n[o]);return r}({1:[function(t,e,n){function r(t){try{c.console&&console.log(t)}catch(e){}}var o,i=t("ee"),a=t(19),c={};try{o=localStorage.getItem("__nr_flags").split(","),console&&"function"==typeof console.log&&(c.console=!0,o.indexOf("dev")!==-1&&(c.dev=!0),o.indexOf("nr_dev")!==-1&&(c.nrDev=!0))}catch(s){}c.nrDev&&i.on("internal-error",function(t){r(t.stack)}),c.dev&&i.on("fn-err",function(t,e,n){r(n.stack)}),c.dev&&(r("NR AGENT IN DEVELOPMENT MODE"),r("flags: "+a(c,function(t,e){return t}).join(", ")))},{}],2:[function(t,e,n){function r(t,e,n,r,o){try{d?d-=1:i("err",[o||new UncaughtException(t,e,n)])}catch(c){try{i("ierr",[c,s.now(),!0])}catch(u){}}return"function"==typeof f&&f.apply(this,a(arguments))}function UncaughtException(t,e,n){this.message=t||"Uncaught error with no additional information",this.sourceURL=e,this.line=n}function o(t){i("err",[t,s.now()])}var i=t("handle"),a=t(20),c=t("ee"),s=t("loader"),f=window.onerror,u=!1,d=0;s.features.err=!0,t(1),window.onerror=r;try{throw new Error}catch(p){"stack"in p&&(t(12),t(11),"addEventListener"in window&&t(6),s.xhrWrappable&&t(13),u=!0)}c.on("fn-start",function(t,e,n){u&&(d+=1)}),c.on("fn-err",function(t,e,n){u&&(this.thrown=!0,o(n))}),c.on("fn-end",function(){u&&!this.thrown&&d>0&&(d-=1)}),c.on("internal-error",function(t){i("ierr",[t,s.now(),!0])})},{}],3:[function(t,e,n){t("loader").features.ins=!0},{}],4:[function(t,e,n){function r(){C++,M=y.hash,this[u]=b.now()}function o(){C--,y.hash!==M&&i(0,!0);var t=b.now();this[l]=~~this[l]+t-this[u],this[d]=t}function i(t,e){E.emit("newURL",[""+y,e])}function a(t,e){t.on(e,function(){this[e]=b.now()})}var c="-start",s="-end",f="-body",u="fn"+c,d="fn"+s,p="cb"+c,h="cb"+s,l="jsTime",m="fetch",v="addEventListener",w=window,y=w.location,b=t("loader");if(w[v]&&b.xhrWrappable){var g=t(9),x=t(10),E=t(8),O=t(6),R=t(12),P=t(7),T=t(13),S=t("ee"),N=S.get("tracer");t(14),b.features.spa=!0;var M,j=w[v],C=0;S.on(u,r),S.on(p,r),S.on(d,o),S.on(h,o),S.buffer([u,d,"xhr-done","xhr-resolved"]),O.buffer([u]),R.buffer(["setTimeout"+s,"clearTimeout"+c,u]),T.buffer([u,"new-xhr","send-xhr"+c]),P.buffer([m+c,m+"-done",m+f+c,m+f+s]),E.buffer(["newURL"]),g.buffer([u]),x.buffer(["propagate",p,h,"executor-err","resolve"+c]),N.buffer([u,"no-"+u]),a(T,"send-xhr"+c),a(S,"xhr-resolved"),a(S,"xhr-done"),a(P,m+c),a(P,m+"-done"),E.on("pushState-end",i),E.on("replaceState-end",i),j("hashchange",i,!0),j("load",i,!0),j("popstate",function(){i(0,C>1)},!0)}},{}],5:[function(t,e,n){function r(t){}if(window.performance&&window.performance.timing&&window.performance.getEntriesByType){var o=t("ee"),i=t("handle"),a=t(12),c=t(11),s="learResourceTimings",f="addEventListener",u="resourcetimingbufferfull",d="bstResource",p="resource",h="-start",l="-end",m="fn"+h,v="fn"+l,w="bstTimer",y="pushState",b=t("loader");b.features.stn=!0,t(8);var g=NREUM.o.EV;o.on(m,function(t,e){var n=t[0];n instanceof g&&(this.bstStart=b.now())}),o.on(v,function(t,e){var n=t[0];n instanceof g&&i("bst",[n,e,this.bstStart,b.now()])}),a.on(m,function(t,e,n){this.bstStart=b.now(),this.bstType=n}),a.on(v,function(t,e){i(w,[e,this.bstStart,b.now(),this.bstType])}),c.on(m,function(){this.bstStart=b.now()}),c.on(v,function(t,e){i(w,[e,this.bstStart,b.now(),"requestAnimationFrame"])}),o.on(y+h,function(t){this.time=b.now(),this.startPath=location.pathname+location.hash}),o.on(y+l,function(t){i("bstHist",[location.pathname+location.hash,this.startPath,this.time])}),f in window.performance&&(window.performance["c"+s]?window.performance[f](u,function(t){i(d,[window.performance.getEntriesByType(p)]),window.performance["c"+s]()},!1):window.performance[f]("webkit"+u,function(t){i(d,[window.performance.getEntriesByType(p)]),window.performance["webkitC"+s]()},!1)),document[f]("scroll",r,{passive:!0}),document[f]("keypress",r,!1),document[f]("click",r,!1)}},{}],6:[function(t,e,n){function r(t){for(var e=t;e&&!e.hasOwnProperty(u);)e=Object.getPrototypeOf(e);e&&o(e)}function o(t){c.inPlace(t,[u,d],"-",i)}function i(t,e){return t[1]}var a=t("ee").get("events"),c=t(22)(a,!0),s=t("gos"),f=XMLHttpRequest,u="addEventListener",d="removeEventListener";e.exports=a,"getPrototypeOf"in Object?(r(document),r(window),r(f.prototype)):f.prototype.hasOwnProperty(u)&&(o(window),o(f.prototype)),a.on(u+"-start",function(t,e){var n=t[1],r=s(n,"nr@wrapped",function(){function t(){if("function"==typeof n.handleEvent)return n.handleEvent.apply(n,arguments)}var e={object:t,"function":n}[typeof n];return e?c(e,"fn-",null,e.name||"anonymous"):n});this.wrapped=t[1]=r}),a.on(d+"-start",function(t){t[1]=this.wrapped||t[1]})},{}],7:[function(t,e,n){function r(t,e,n){var r=t[e];"function"==typeof r&&(t[e]=function(){var t=r.apply(this,arguments);return o.emit(n+"start",arguments,t),t.then(function(e){return o.emit(n+"end",[null,e],t),e},function(e){throw o.emit(n+"end",[e],t),e})})}var o=t("ee").get("fetch"),i=t(19);e.exports=o;var a=window,c="fetch-",s=c+"body-",f=["arrayBuffer","blob","json","text","formData"],u=a.Request,d=a.Response,p=a.fetch,h="prototype";u&&d&&p&&(i(f,function(t,e){r(u[h],e,s),r(d[h],e,s)}),r(a,"fetch",c),o.on(c+"end",function(t,e){var n=this;e?e.clone().arrayBuffer().then(function(t){n.rxSize=t.byteLength,o.emit(c+"done",[null,e],n)}):o.emit(c+"done",[t],n)}))},{}],8:[function(t,e,n){var r=t("ee").get("history"),o=t(22)(r);e.exports=r,o.inPlace(window.history,["pushState","replaceState"],"-")},{}],9:[function(t,e,n){var r=t("ee").get("mutation"),o=t(22)(r),i=NREUM.o.MO;e.exports=r,i&&(window.MutationObserver=function(t){return this instanceof i?new i(o(t,"fn-")):i.apply(this,arguments)},MutationObserver.prototype=i.prototype)},{}],10:[function(t,e,n){function r(t){var e=a.context(),n=c(t,"executor-",e),r=new f(n);return a.context(r).getCtx=function(){return e},a.emit("new-promise",[r,e],e),r}function o(t,e){return e}var i=t(22),a=t("ee").get("promise"),c=i(a),s=t(19),f=NREUM.o.PR;e.exports=a,f&&(window.Promise=r,["all","race"].forEach(function(t){var e=f[t];f[t]=function(n){function r(t){return function(){a.emit("propagate",[null,!o],i),o=o||!t}}var o=!1;s(n,function(e,n){Promise.resolve(n).then(r("all"===t),r(!1))});var i=e.apply(f,arguments),c=f.resolve(i);return c}}),["resolve","reject"].forEach(function(t){var e=f[t];f[t]=function(t){var n=e.apply(f,arguments);return t!==n&&a.emit("propagate",[t,!0],n),n}}),f.prototype["catch"]=function(t){return this.then(null,t)},f.prototype=Object.create(f.prototype,{constructor:{value:r}}),s(Object.getOwnPropertyNames(f),function(t,e){try{r[e]=f[e]}catch(n){}}),a.on("executor-start",function(t){t[0]=c(t[0],"resolve-",this),t[1]=c(t[1],"resolve-",this)}),a.on("executor-err",function(t,e,n){t[1](n)}),c.inPlace(f.prototype,["then"],"then-",o),a.on("then-start",function(t,e){this.promise=e,t[0]=c(t[0],"cb-",this),t[1]=c(t[1],"cb-",this)}),a.on("then-end",function(t,e,n){this.nextPromise=n;var r=this.promise;a.emit("propagate",[r,!0],n)}),a.on("cb-end",function(t,e,n){a.emit("propagate",[n,!0],this.nextPromise)}),a.on("propagate",function(t,e,n){this.getCtx&&!e||(this.getCtx=function(){if(t instanceof Promise)var e=a.context(t);return e&&e.getCtx?e.getCtx():this})}),r.toString=function(){return""+f})},{}],11:[function(t,e,n){var r=t("ee").get("raf"),o=t(22)(r),i="equestAnimationFrame";e.exports=r,o.inPlace(window,["r"+i,"mozR"+i,"webkitR"+i,"msR"+i],"raf-"),r.on("raf-start",function(t){t[0]=o(t[0],"fn-")})},{}],12:[function(t,e,n){function r(t,e,n){t[0]=a(t[0],"fn-",null,n)}function o(t,e,n){this.method=n,this.timerDuration=isNaN(t[1])?0:+t[1],t[0]=a(t[0],"fn-",this,n)}var i=t("ee").get("timer"),a=t(22)(i),c="setTimeout",s="setInterval",f="clearTimeout",u="-start",d="-";e.exports=i,a.inPlace(window,[c,"setImmediate"],c+d),a.inPlace(window,[s],s+d),a.inPlace(window,[f,"clearImmediate"],f+d),i.on(s+u,r),i.on(c+u,o)},{}],13:[function(t,e,n){function r(t,e){d.inPlace(e,["onreadystatechange"],"fn-",c)}function o(){var t=this,e=u.context(t);t.readyState>3&&!e.resolved&&(e.resolved=!0,u.emit("xhr-resolved",[],t)),d.inPlace(t,y,"fn-",c)}function i(t){b.push(t),l&&(x?x.then(a):v?v(a):(E=-E,O.data=E))}function a(){for(var t=0;t<b.length;t++)r([],b[t]);b.length&&(b=[])}function c(t,e){return e}function s(t,e){for(var n in t)e[n]=t[n];return e}t(6);var f=t("ee"),u=f.get("xhr"),d=t(22)(u),p=NREUM.o,h=p.XHR,l=p.MO,m=p.PR,v=p.SI,w="readystatechange",y=["onload","onerror","onabort","onloadstart","onloadend","onprogress","ontimeout"],b=[];e.exports=u;var g=window.XMLHttpRequest=function(t){var e=new h(t);try{u.emit("new-xhr",[e],e),e.addEventListener(w,o,!1)}catch(n){try{u.emit("internal-error",[n])}catch(r){}}return e};if(s(h,g),g.prototype=h.prototype,d.inPlace(g.prototype,["open","send"],"-xhr-",c),u.on("send-xhr-start",function(t,e){r(t,e),i(e)}),u.on("open-xhr-start",r),l){var x=m&&m.resolve();if(!v&&!m){var E=1,O=document.createTextNode(E);new l(a).observe(O,{characterData:!0})}}else f.on("fn-end",function(t){t[0]&&t[0].type===w||a()})},{}],14:[function(t,e,n){function r(t){var e=this.params,n=this.metrics;if(!this.ended){this.ended=!0;for(var r=0;r<d;r++)t.removeEventListener(u[r],this.listener,!1);if(!e.aborted){if(n.duration=a.now()-this.startTime,4===t.readyState){e.status=t.status;var i=o(t,this.lastSize);if(i&&(n.rxSize=i),this.sameOrigin){var s=t.getResponseHeader("X-NewRelic-App-Data");s&&(e.cat=s.split(", ").pop())}}else e.status=0;n.cbTime=this.cbTime,f.emit("xhr-done",[t],t),c("xhr",[e,n,this.startTime])}}}function o(t,e){var n=t.responseType;if("json"===n&&null!==e)return e;var r="arraybuffer"===n||"blob"===n||"json"===n?t.response:t.responseText;return l(r)}function i(t,e){var n=s(e),r=t.params;r.host=n.hostname+":"+n.port,r.pathname=n.pathname,t.sameOrigin=n.sameOrigin}var a=t("loader");if(a.xhrWrappable){var c=t("handle"),s=t(15),f=t("ee"),u=["load","error","abort","timeout"],d=u.length,p=t("id"),h=t(18),l=t(17),m=window.XMLHttpRequest;a.features.xhr=!0,t(13),f.on("new-xhr",function(t){var e=this;e.totalCbs=0,e.called=0,e.cbTime=0,e.end=r,e.ended=!1,e.xhrGuids={},e.lastSize=null,h&&(h>34||h<10)||window.opera||t.addEventListener("progress",function(t){e.lastSize=t.loaded},!1)}),f.on("open-xhr-start",function(t){this.params={method:t[0]},i(this,t[1]),this.metrics={}}),f.on("open-xhr-end",function(t,e){"loader_config"in NREUM&&"xpid"in NREUM.loader_config&&this.sameOrigin&&e.setRequestHeader("X-NewRelic-ID",NREUM.loader_config.xpid)}),f.on("send-xhr-start",function(t,e){var n=this.metrics,r=t[0],o=this;if(n&&r){var i=l(r);i&&(n.txSize=i)}this.startTime=a.now(),this.listener=function(t){try{"abort"===t.type&&(o.params.aborted=!0),("load"!==t.type||o.called===o.totalCbs&&(o.onloadCalled||"function"!=typeof e.onload))&&o.end(e)}catch(n){try{f.emit("internal-error",[n])}catch(r){}}};for(var c=0;c<d;c++)e.addEventListener(u[c],this.listener,!1)}),f.on("xhr-cb-time",function(t,e,n){this.cbTime+=t,e?this.onloadCalled=!0:this.called+=1,this.called!==this.totalCbs||!this.onloadCalled&&"function"==typeof n.onload||this.end(n)}),f.on("xhr-load-added",function(t,e){var n=""+p(t)+!!e;this.xhrGuids&&!this.xhrGuids[n]&&(this.xhrGuids[n]=!0,this.totalCbs+=1)}),f.on("xhr-load-removed",function(t,e){var n=""+p(t)+!!e;this.xhrGuids&&this.xhrGuids[n]&&(delete this.xhrGuids[n],this.totalCbs-=1)}),f.on("addEventListener-end",function(t,e){e instanceof m&&"load"===t[0]&&f.emit("xhr-load-added",[t[1],t[2]],e)}),f.on("removeEventListener-end",function(t,e){e instanceof m&&"load"===t[0]&&f.emit("xhr-load-removed",[t[1],t[2]],e)}),f.on("fn-start",function(t,e,n){e instanceof m&&("onload"===n&&(this.onload=!0),("load"===(t[0]&&t[0].type)||this.onload)&&(this.xhrCbStart=a.now()))}),f.on("fn-end",function(t,e){this.xhrCbStart&&f.emit("xhr-cb-time",[a.now()-this.xhrCbStart,this.onload,e],e)})}},{}],15:[function(t,e,n){e.exports=function(t){var e=document.createElement("a"),n=window.location,r={};e.href=t,r.port=e.port;var o=e.href.split("://");!r.port&&o[1]&&(r.port=o[1].split("/")[0].split("@").pop().split(":")[1]),r.port&&"0"!==r.port||(r.port="https"===o[0]?"443":"80"),r.hostname=e.hostname||n.hostname,r.pathname=e.pathname,r.protocol=o[0],"/"!==r.pathname.charAt(0)&&(r.pathname="/"+r.pathname);var i=!e.protocol||":"===e.protocol||e.protocol===n.protocol,a=e.hostname===document.domain&&e.port===n.port;return r.sameOrigin=i&&(!e.hostname||a),r}},{}],16:[function(t,e,n){function r(){}function o(t,e,n){return function(){return i(t,[f.now()].concat(c(arguments)),e?null:this,n),e?void 0:this}}var i=t("handle"),a=t(19),c=t(20),s=t("ee").get("tracer"),f=t("loader"),u=NREUM;"undefined"==typeof window.newrelic&&(newrelic=u);var d=["setPageViewName","setCustomAttribute","setErrorHandler","finished","addToTrace","inlineHit","addRelease"],p="api-",h=p+"ixn-";a(d,function(t,e){u[e]=o(p+e,!0,"api")}),u.addPageAction=o(p+"addPageAction",!0),u.setCurrentRouteName=o(p+"routeName",!0),e.exports=newrelic,u.interaction=function(){return(new r).get()};var l=r.prototype={createTracer:function(t,e){var n={},r=this,o="function"==typeof e;return i(h+"tracer",[f.now(),t,n],r),function(){if(s.emit((o?"":"no-")+"fn-start",[f.now(),r,o],n),o)try{return e.apply(this,arguments)}finally{s.emit("fn-end",[f.now()],n)}}}};a("setName,setAttribute,save,ignore,onEnd,getContext,end,get".split(","),function(t,e){l[e]=o(h+e)}),newrelic.noticeError=function(t){"string"==typeof t&&(t=new Error(t)),i("err",[t,f.now()])}},{}],17:[function(t,e,n){e.exports=function(t){if("string"==typeof t&&t.length)return t.length;if("object"==typeof t){if("undefined"!=typeof ArrayBuffer&&t instanceof ArrayBuffer&&t.byteLength)return t.byteLength;if("undefined"!=typeof Blob&&t instanceof Blob&&t.size)return t.size;if(!("undefined"!=typeof FormData&&t instanceof FormData))try{return JSON.stringify(t).length}catch(e){return}}}},{}],18:[function(t,e,n){var r=0,o=navigator.userAgent.match(/Firefox[\/\s](\d+\.\d+)/);o&&(r=+o[1]),e.exports=r},{}],19:[function(t,e,n){function r(t,e){var n=[],r="",i=0;for(r in t)o.call(t,r)&&(n[i]=e(r,t[r]),i+=1);return n}var o=Object.prototype.hasOwnProperty;e.exports=r},{}],20:[function(t,e,n){function r(t,e,n){e||(e=0),"undefined"==typeof n&&(n=t?t.length:0);for(var r=-1,o=n-e||0,i=Array(o<0?0:o);++r<o;)i[r]=t[e+r];return i}e.exports=r},{}],21:[function(t,e,n){e.exports={exists:"undefined"!=typeof window.performance&&window.performance.timing&&"undefined"!=typeof window.performance.timing.navigationStart}},{}],22:[function(t,e,n){function r(t){return!(t&&t instanceof Function&&t.apply&&!t[a])}var o=t("ee"),i=t(20),a="nr@original",c=Object.prototype.hasOwnProperty,s=!1;e.exports=function(t,e){function n(t,e,n,o){function nrWrapper(){var r,a,c,s;try{a=this,r=i(arguments),c="function"==typeof n?n(r,a):n||{}}catch(f){p([f,"",[r,a,o],c])}u(e+"start",[r,a,o],c);try{return s=t.apply(a,r)}catch(d){throw u(e+"err",[r,a,d],c),d}finally{u(e+"end",[r,a,s],c)}}return r(t)?t:(e||(e=""),nrWrapper[a]=t,d(t,nrWrapper),nrWrapper)}function f(t,e,o,i){o||(o="");var a,c,s,f="-"===o.charAt(0);for(s=0;s<e.length;s++)c=e[s],a=t[c],r(a)||(t[c]=n(a,f?c+o:o,i,c))}function u(n,r,o){if(!s||e){var i=s;s=!0;try{t.emit(n,r,o,e)}catch(a){p([a,n,r,o])}s=i}}function d(t,e){if(Object.defineProperty&&Object.keys)try{var n=Object.keys(t);return n.forEach(function(n){Object.defineProperty(e,n,{get:function(){return t[n]},set:function(e){return t[n]=e,e}})}),e}catch(r){p([r])}for(var o in t)c.call(t,o)&&(e[o]=t[o]);return e}function p(e){try{t.emit("internal-error",e)}catch(n){}}return t||(t=o),n.inPlace=f,n.flag=a,n}},{}],ee:[function(t,e,n){function r(){}function o(t){function e(t){return t&&t instanceof r?t:t?s(t,c,i):i()}function n(n,r,o,i){if(!p.aborted||i){t&&t(n,r,o);for(var a=e(o),c=l(n),s=c.length,f=0;f<s;f++)c[f].apply(a,r);var d=u[y[n]];return d&&d.push([b,n,r,a]),a}}function h(t,e){w[t]=l(t).concat(e)}function l(t){return w[t]||[]}function m(t){return d[t]=d[t]||o(n)}function v(t,e){f(t,function(t,n){e=e||"feature",y[n]=e,e in u||(u[e]=[])})}var w={},y={},b={on:h,emit:n,get:m,listeners:l,context:e,buffer:v,abort:a,aborted:!1};return b}function i(){return new r}function a(){(u.api||u.feature)&&(p.aborted=!0,u=p.backlog={})}var c="nr@context",s=t("gos"),f=t(19),u={},d={},p=e.exports=o();p.backlog=u},{}],gos:[function(t,e,n){function r(t,e,n){if(o.call(t,e))return t[e];var r=n();if(Object.defineProperty&&Object.keys)try{return Object.defineProperty(t,e,{value:r,writable:!0,enumerable:!1}),r}catch(i){}return t[e]=r,r}var o=Object.prototype.hasOwnProperty;e.exports=r},{}],handle:[function(t,e,n){function r(t,e,n,r){o.buffer([t],r),o.emit(t,e,n)}var o=t("ee").get("handle");e.exports=r,r.ee=o},{}],id:[function(t,e,n){function r(t){var e=typeof t;return!t||"object"!==e&&"function"!==e?-1:t===window?0:a(t,i,function(){return o++})}var o=1,i="nr@id",a=t("gos");e.exports=r},{}],loader:[function(t,e,n){function r(){if(!x++){var t=g.info=NREUM.info,e=p.getElementsByTagName("script")[0];if(setTimeout(u.abort,3e4),!(t&&t.licenseKey&&t.applicationID&&e))return u.abort();f(y,function(e,n){t[e]||(t[e]=n)}),s("mark",["onload",a()+g.offset],null,"api");var n=p.createElement("script");n.src="https://"+t.agent,e.parentNode.insertBefore(n,e)}}function o(){"complete"===p.readyState&&i()}function i(){s("mark",["domContent",a()+g.offset],null,"api")}function a(){return E.exists&&performance.now?Math.round(performance.now()):(c=Math.max((new Date).getTime(),c))-g.offset}var c=(new Date).getTime(),s=t("handle"),f=t(19),u=t("ee"),d=window,p=d.document,h="addEventListener",l="attachEvent",m=d.XMLHttpRequest,v=m&&m.prototype;NREUM.o={ST:setTimeout,SI:d.setImmediate,CT:clearTimeout,XHR:m,REQ:d.Request,EV:d.Event,PR:d.Promise,MO:d.MutationObserver};var w=""+location,y={beacon:"bam.nr-data.net",errorBeacon:"bam.nr-data.net",agent:"js-agent.newrelic.com/nr-spa-1044.min.js"},b=m&&v&&v[h]&&!/CriOS/.test(navigator.userAgent),g=e.exports={offset:c,now:a,origin:w,features:{},xhrWrappable:b};t(16),p[h]?(p[h]("DOMContentLoaded",i,!1),d[h]("load",r,!1)):(p[l]("onreadystatechange",o),d[l]("onload",r)),s("mark",["firstbyte",c],null,"api");var x=0,E=t(21)},{}]},{},["loader",2,14,5,3,4]);</script><link rel="apple-touch-icon" href="https://www.safaribooksonline.com/static/images/apple-touch-icon.8cc2fd27400e.png"><link rel="shortcut icon" href="https://www.safaribooksonline.com/favicon.ico" type="image/x-icon"><link href="A.%20Exercise%20Solutions%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/css.css" rel="stylesheet" type="text/css"><title>A. Exercise Solutions - Hands-On Machine Learning with Scikit-Learn and TensorFlow</title><link rel="stylesheet" href="A.%20Exercise%20Solutions%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/d6ec1592ffb3.css" type="text/css"><link rel="stylesheet" type="text/css" href="A.%20Exercise%20Solutions%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/annotator.css"><link rel="stylesheet" href="A.%20Exercise%20Solutions%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/font-awesome.css"><style type="text/css" title="ibis-book">@charset "utf-8";#sbo-rt-content html,#sbo-rt-content div,#sbo-rt-content div,#sbo-rt-content span,#sbo-rt-content applet,#sbo-rt-content object,#sbo-rt-content iframe,#sbo-rt-content h1,#sbo-rt-content h2,#sbo-rt-content h3,#sbo-rt-content h4,#sbo-rt-content h5,#sbo-rt-content h6,#sbo-rt-content p,#sbo-rt-content blockquote,#sbo-rt-content pre,#sbo-rt-content a,#sbo-rt-content abbr,#sbo-rt-content acronym,#sbo-rt-content address,#sbo-rt-content big,#sbo-rt-content cite,#sbo-rt-content code,#sbo-rt-content del,#sbo-rt-content dfn,#sbo-rt-content em,#sbo-rt-content img,#sbo-rt-content ins,#sbo-rt-content kbd,#sbo-rt-content q,#sbo-rt-content s,#sbo-rt-content samp,#sbo-rt-content small,#sbo-rt-content strike,#sbo-rt-content strong,#sbo-rt-content sub,#sbo-rt-content sup,#sbo-rt-content tt,#sbo-rt-content var,#sbo-rt-content b,#sbo-rt-content u,#sbo-rt-content i,#sbo-rt-content center,#sbo-rt-content dl,#sbo-rt-content dt,#sbo-rt-content dd,#sbo-rt-content ol,#sbo-rt-content ul,#sbo-rt-content li,#sbo-rt-content fieldset,#sbo-rt-content form,#sbo-rt-content label,#sbo-rt-content legend,#sbo-rt-content table,#sbo-rt-content caption,#sbo-rt-content tdiv,#sbo-rt-content tfoot,#sbo-rt-content thead,#sbo-rt-content tr,#sbo-rt-content th,#sbo-rt-content td,#sbo-rt-content article,#sbo-rt-content aside,#sbo-rt-content canvas,#sbo-rt-content details,#sbo-rt-content embed,#sbo-rt-content figure,#sbo-rt-content figcaption,#sbo-rt-content footer,#sbo-rt-content header,#sbo-rt-content hgroup,#sbo-rt-content menu,#sbo-rt-content nav,#sbo-rt-content output,#sbo-rt-content ruby,#sbo-rt-content section,#sbo-rt-content summary,#sbo-rt-content time,#sbo-rt-content mark,#sbo-rt-content audio,#sbo-rt-content video{margin:0;padding:0;border:0;font-size:100%;font:inherit;vertical-align:baseline}#sbo-rt-content article,#sbo-rt-content aside,#sbo-rt-content details,#sbo-rt-content figcaption,#sbo-rt-content figure,#sbo-rt-content footer,#sbo-rt-content header,#sbo-rt-content hgroup,#sbo-rt-content menu,#sbo-rt-content nav,#sbo-rt-content section{display:block}#sbo-rt-content div{line-height:1}#sbo-rt-content ol,#sbo-rt-content ul{list-style:none}#sbo-rt-content blockquote,#sbo-rt-content q{quotes:none}#sbo-rt-content blockquote:before,#sbo-rt-content blockquote:after,#sbo-rt-content q:before,#sbo-rt-content q:after{content:none}#sbo-rt-content table{border-collapse:collapse;border-spacing:0}@page{margin:5px !important}#sbo-rt-content p{margin:10px 0 0;line-height:125%;text-align:left}#sbo-rt-content p.byline{text-align:left;margin:-33px auto 35px;font-style:italic;font-weight:bold}#sbo-rt-content div.preface p+p.byline{margin:1em 0 0}#sbo-rt-content div.preface p.byline+p.byline{margin:0}#sbo-rt-content div.sect1>p.byline{margin:-.25em 0 1em}#sbo-rt-content div.sect1>p.byline+p.byline{margin-top:-1em}#sbo-rt-content em{font-style:italic;font-family:inherit}#sbo-rt-content em strong,#sbo-rt-content strong em{font-weight:bold;font-style:italic;font-family:inherit}#sbo-rt-content strong,#sbo-rt-content span.bold{font-weight:bold}#sbo-rt-content em.replaceable{font-style:italic}#sbo-rt-content strong.userinput{font-weight:bold;font-style:normal}#sbo-rt-content span.bolditalic{font-weight:bold;font-style:italic}#sbo-rt-content a.ulink,#sbo-rt-content a.xref,#sbo-rt-content a.email,#sbo-rt-content a.link,#sbo-rt-content a{text-decoration:none;color:#8e0012}#sbo-rt-content span.lineannotation{font-style:italic;color:#a62a2a;font-family:serif}#sbo-rt-content span.underline{text-decoration:underline}#sbo-rt-content span.strikethrough{text-decoration:line-through}#sbo-rt-content span.smallcaps{font-variant:small-caps}#sbo-rt-content span.cursor{background:#000;color:#fff}#sbo-rt-content span.smaller{font-size:75%}#sbo-rt-content .boxedtext,#sbo-rt-content .keycap{border-style:solid;border-width:1px;border-color:#000;padding:1px}#sbo-rt-content span.gray50{color:#7F7F7F;}#sbo-rt-content h1,#sbo-rt-content div.toc-title,#sbo-rt-content h2,#sbo-rt-content h3,#sbo-rt-content h4,#sbo-rt-content h5{-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;font-weight:bold;text-align:left;page-break-after:avoid !important;font-family:sans-serif,"DejaVuSans"}#sbo-rt-content div.toc-title{font-size:1.5em;margin-top:20px !important;margin-bottom:30px !important}#sbo-rt-content section[data-type="sect1"] h1{font-size:1.3em;color:#8e0012;margin:40px 0 8px 0}#sbo-rt-content section[data-type="sect2"] h2{font-size:1.1em;margin:30px 0 8px 0 !important}#sbo-rt-content section[data-type="sect3"] h3{font-size:1em;color:#555;margin:20px 0 8px 0 !important}#sbo-rt-content section[data-type="sect4"] h4{font-size:1em;font-weight:normal;font-style:italic;margin:15px 0 6px 0 !important}#sbo-rt-content section[data-type="chapter"]>div>h1,#sbo-rt-content section[data-type="preface"]>div>h1,#sbo-rt-content section[data-type="appendix"]>div>h1,#sbo-rt-content section[data-type="glossary"]>div>h1,#sbo-rt-content section[data-type="bibliography"]>div>h1,#sbo-rt-content section[data-type="index"]>div>h1{font-size:2em;line-height:1;margin-bottom:50px;color:#000;padding-bottom:10px;border-bottom:1px solid #000}#sbo-rt-content span.label,#sbo-rt-content span.keep-together{font-size:inherit;font-weight:inherit}#sbo-rt-content div[data-type="part"] h1{font-size:2em;text-align:center;margin-top:0 !important;margin-bottom:50px;padding:50px 0 10px 0;border-bottom:1px solid #000}#sbo-rt-content img.width-ninety{width:90%}#sbo-rt-content img{max-width:95%;margin:0 auto;padding:0}#sbo-rt-content div.figure{background-color:transparent;text-align:center !important;margin:15px 0 15px 0 !important;page-break-inside:avoid}#sbo-rt-content figure{margin:15px 0 15px 0 !important;page-break-inside:avoid}#sbo-rt-content div.figure h6{font-size:90%;text-align:center;font-weight:normal;font-style:italic;font-family:serif !important;color:#000;padding-top:10px !important;page-break-before:avoid;page-break-after:avoid}#sbo-rt-content div.informalfigure{text-align:center !important;padding:5px 0 !important}#sbo-rt-content div.sidebar{margin:15px 0 10px 0 !important;border:1px solid #DCDCDC;background-color:#F7F7F7;padding:15px !important;page-break-inside:avoid}#sbo-rt-content aside[data-type="sidebar"]{margin:15px 0 10px 0 !important;page-break-inside:avoid}#sbo-rt-content div.sidebar-title,#sbo-rt-content aside[data-type="sidebar"] h5{font-weight:bold;font-size:1em;font-family:sans-serif;text-transform:uppercase;letter-spacing:1px;text-align:center;margin:4px 0 6px 0 !important;page-break-inside:avoid}#sbo-rt-content div.sidebar ol,#sbo-rt-content div.sidebar ul,#sbo-rt-content aside[data-type="sidebar"] ol,#sbo-rt-content aside[data-type="sidebar"] ul{margin-left:1.25em !important}#sbo-rt-content div.sidebar div.figure p.title,#sbo-rt-content aside[data-type="sidebar"] figcaption,#sbo-rt-content div.sidebar div.informalfigure div.caption{font-size:90%;text-align:center;font-weight:normal;font-style:italic;font-family:serif !important;color:#000;padding:5px !important;page-break-before:avoid;page-break-after:avoid}#sbo-rt-content div.sidebar div.tip,#sbo-rt-content div.sidebar div[data-type="tip"],#sbo-rt-content div.sidebar div.note,#sbo-rt-content div.sidebar div[data-type="note"],#sbo-rt-content div.sidebar div.warning,#sbo-rt-content div.sidebar div[data-type="warning"],#sbo-rt-content div.sidebar div[data-type="caution"],#sbo-rt-content div.sidebar div[data-type="important"]{margin:20px auto 20px auto !important;font-size:90%;width:85%}#sbo-rt-content aside[data-type="sidebar"] p.byline{font-size:90%;font-weight:bold;font-style:italic;text-align:center;text-indent:0;margin:5px auto 6px;page-break-after:avoid}#sbo-rt-content pre{white-space:pre-wrap;font-family:"Ubuntu Mono",monospace;margin:25px 0 25px 20px;font-size:85%;display:block;-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;overflow-wrap:break-word}#sbo-rt-content div.note pre.programlisting,#sbo-rt-content div.tip pre.programlisting,#sbo-rt-content div.warning pre.programlisting,#sbo-rt-content div.caution pre.programlisting,#sbo-rt-content div.important pre.programlisting{margin-bottom:0}#sbo-rt-content code{font-family:"Ubuntu Mono",monospace;-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;overflow-wrap:break-word}#sbo-rt-content code strong em,#sbo-rt-content code em strong,#sbo-rt-content pre em strong,#sbo-rt-content pre strong em,#sbo-rt-content strong code em code,#sbo-rt-content em code strong code,#sbo-rt-content span.bolditalic code{font-weight:bold;font-style:italic;font-family:"Ubuntu Mono BoldItal",monospace}#sbo-rt-content code em,#sbo-rt-content em code,#sbo-rt-content pre em,#sbo-rt-content em.replaceable{font-family:"Ubuntu Mono Ital",monospace;font-style:italic}#sbo-rt-content code strong,#sbo-rt-content strong code,#sbo-rt-content pre strong,#sbo-rt-content strong.userinput{font-family:"Ubuntu Mono Bold",monospace;font-weight:bold}#sbo-rt-content div[data-type="example"]{margin:10px 0 15px 0 !important}#sbo-rt-content div[data-type="example"] h1,#sbo-rt-content div[data-type="example"] h2,#sbo-rt-content div[data-type="example"] h3,#sbo-rt-content div[data-type="example"] h4,#sbo-rt-content div[data-type="example"] h5,#sbo-rt-content div[data-type="example"] h6{font-style:italic;font-weight:normal;text-align:left !important;text-transform:none !important;font-family:serif !important;margin:10px 0 5px 0 !important;border-bottom:1px solid #000}#sbo-rt-content li pre.example{padding:10px 0 !important}#sbo-rt-content div[data-type="example"] pre[data-type="programlisting"],#sbo-rt-content div[data-type="example"] pre[data-type="screen"]{margin:0}#sbo-rt-content section[data-type="titlepage"]>div>h1{font-size:2em;margin:50px 0 10px 0 !important;line-height:1;text-align:center}#sbo-rt-content section[data-type="titlepage"] h2,#sbo-rt-content section[data-type="titlepage"] p.subtitle,#sbo-rt-content section[data-type="titlepage"] p[data-type="subtitle"]{font-size:1.3em;font-weight:normal;text-align:center;margin-top:.5em;color:#555}#sbo-rt-content section[data-type="titlepage"]>div>h2[data-type="author"],#sbo-rt-content section[data-type="titlepage"] p.author{font-size:1.3em;font-family:serif !important;font-weight:bold;margin:50px 0 !important;text-align:center}#sbo-rt-content section[data-type="titlepage"] p.edition{text-align:center;text-transform:uppercase;margin-top:2em}#sbo-rt-content section[data-type="titlepage"]{text-align:center}#sbo-rt-content section[data-type="titlepage"]:after{content:url(css_assets/titlepage_footer_ebook.png);margin:0 auto;max-width:80%}#sbo-rt-content div.book div.titlepage div.publishername{margin-top:60%;margin-bottom:20px;text-align:center;font-size:1.25em}#sbo-rt-content div.book div.titlepage div.locations p{margin:0;text-align:center}#sbo-rt-content div.book div.titlepage div.locations p.cities{font-size:80%;text-align:center;margin-top:5px}#sbo-rt-content section.preface[title="Dedication"]>div.titlepage h2.title{text-align:center;text-transform:uppercase;font-size:1.5em;margin-top:50px;margin-bottom:50px}#sbo-rt-content ul.stafflist{margin:15px 0 15px 20px !important}#sbo-rt-content ul.stafflist li{list-style-type:none;padding:5px 0}#sbo-rt-content ul.printings li{list-style-type:none}#sbo-rt-content section.preface[title="Dedication"] p{font-style:italic;text-align:center}#sbo-rt-content div.colophon h1.title{font-size:1.3em;margin:0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon h2.subtitle{margin:0 !important;color:#000;font-family:serif !important;font-size:1em;font-weight:normal}#sbo-rt-content div.colophon div.author h3.author{font-size:1.1em;font-family:serif !important;margin:10px 0 0 !important;font-weight:normal}#sbo-rt-content div.colophon div.editor h4,#sbo-rt-content div.colophon div.editor h3.editor{color:#000;font-size:.8em;margin:15px 0 0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon div.editor h3.editor{font-size:.8em;margin:0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon div.publisher{margin-top:10px}#sbo-rt-content div.colophon div.publisher p,#sbo-rt-content div.colophon div.publisher span.publishername{margin:0;font-size:.8em}#sbo-rt-content div.legalnotice p,#sbo-rt-content div.timestamp p{font-size:.8em}#sbo-rt-content div.timestamp p{margin-top:10px}#sbo-rt-content div.colophon[title="About the Author"] h1.title,#sbo-rt-content div.colophon[title="Colophon"] h1.title{font-size:1.5em;margin:0 !important;font-family:sans-serif !important}#sbo-rt-content section.chapter div.titlepage div.author{margin:10px 0 10px 0}#sbo-rt-content section.chapter div.titlepage div.author div.affiliation{font-style:italic}#sbo-rt-content div.attribution{margin:5px 0 0 50px !important}#sbo-rt-content h3.author span.orgname{display:none}#sbo-rt-content div.epigraph{margin:10px 0 10px 20px !important;page-break-inside:avoid;font-size:90%}#sbo-rt-content div.epigraph p{font-style:italic}#sbo-rt-content blockquote,#sbo-rt-content div.blockquote{margin:10px !important;page-break-inside:avoid;font-size:95%}#sbo-rt-content blockquote p,#sbo-rt-content div.blockquote p{font-style:italic;margin:.75em 0 0 !important}#sbo-rt-content blockquote div.attribution,#sbo-rt-content blockquote p[data-type="attribution"]{margin:5px 0 10px 30px !important;text-align:right;width:80%}#sbo-rt-content blockquote div.attribution p,#sbo-rt-content blockquote p[data-type="attribution"]{font-style:normal;margin-top:5px}#sbo-rt-content blockquote div.attribution p:before,#sbo-rt-content blockquote p[data-type="attribution"]:before{font-style:normal;content:"—";-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none}#sbo-rt-content p.right{text-align:right;margin:0}#sbo-rt-content div[data-type="footnotes"]{border-top:1px solid black;margin-top:1.5em}#sbo-rt-content sub,#sbo-rt-content sup{font-size:75%;line-height:0;position:relative}#sbo-rt-content sup{top:-.5em}#sbo-rt-content sub{bottom:-.25em}#sbo-rt-content div.refentry p.refname{font-size:1em;font-family:sans-serif,"DejaVuSans";font-weight:bold;margin-bottom:5px;overflow:auto;width:100%}#sbo-rt-content div.refentry{width:100%;display:block;margin-top:2em}#sbo-rt-content div.refsynopsisdiv{display:block;clear:both}#sbo-rt-content div.refentry header{page-break-inside:avoid !important;display:block;break-inside:avoid !important;padding-top:0;border-bottom:1px solid #000}#sbo-rt-content div.refsect1 h6{font-size:.9em;font-family:sans-serif,"DejaVuSans";font-weight:bold}#sbo-rt-content div.refsect1{margin-top:3em}#sbo-rt-content dt{padding-top:10px !important;padding-bottom:0 !important}#sbo-rt-content dd{margin-left:1.5em !important;margin-bottom:.25em}#sbo-rt-content dd ol,#sbo-rt-content dd ul{padding-left:1em}#sbo-rt-content dd li{margin-top:0;margin-bottom:0}#sbo-rt-content dd,#sbo-rt-content li{text-align:left}#sbo-rt-content ul,#sbo-rt-content ul>li,#sbo-rt-content ol ul,#sbo-rt-content ol ul>li,#sbo-rt-content ul ol ul,#sbo-rt-content ul ol ul>li{list-style-type:disc}#sbo-rt-content ul ul,#sbo-rt-content ul ul>li{list-style-type:square}#sbo-rt-content ul ul ul,#sbo-rt-content ul ul ul>li{list-style-type:circle}#sbo-rt-content ol,#sbo-rt-content ol>li,#sbo-rt-content ol ul ol,#sbo-rt-content ol ul ol>li,#sbo-rt-content ul ol,#sbo-rt-content ul ol>li{list-style-type:decimal}#sbo-rt-content ol ol,#sbo-rt-content ol ol>li{list-style-type:lower-alpha}#sbo-rt-content ol ol ol,#sbo-rt-content ol ol ol>li{list-style-type:lower-roman}#sbo-rt-content ol,#sbo-rt-content ul{list-style-position:outside;margin:15px 0 15px 1.25em;padding-left:2.25em}#sbo-rt-content ol li,#sbo-rt-content ul li{margin:.5em 0 .65em;line-height:125%}#sbo-rt-content div.orderedlistalpha{list-style-type:upper-alpha}#sbo-rt-content table.simplelist,#sbo-rt-content ul.simplelist{margin:15px 0 15px 20px !important}#sbo-rt-content ul.simplelist li{list-style-type:none;padding:5px 0}#sbo-rt-content table.simplelist td{border:none}#sbo-rt-content table.simplelist tr{border-bottom:none}#sbo-rt-content table.simplelist tr:nth-of-type(even){background-color:transparent}#sbo-rt-content dl.calloutlist p:first-child{margin-top:-25px !important}#sbo-rt-content dl.calloutlist dd{padding-left:0;margin-top:-25px}#sbo-rt-content dl.calloutlist img,#sbo-rt-content a.co img{padding:0}#sbo-rt-content div.toc ol{margin-top:8px !important;margin-bottom:8px !important;margin-left:0 !important;padding-left:0 !important}#sbo-rt-content div.toc ol ol{margin-left:30px !important;padding-left:0 !important}#sbo-rt-content div.toc ol li{list-style-type:none}#sbo-rt-content div.toc a{color:#8e0012}#sbo-rt-content div.toc ol a{font-size:1em;font-weight:bold}#sbo-rt-content div.toc ol>li>ol a{font-weight:bold;font-size:1em}#sbo-rt-content div.toc ol>li>ol>li>ol a{text-decoration:none;font-weight:normal;font-size:1em}#sbo-rt-content div.tip,#sbo-rt-content div[data-type="tip"],#sbo-rt-content div.note,#sbo-rt-content div[data-type="note"],#sbo-rt-content div.warning,#sbo-rt-content div[data-type="warning"],#sbo-rt-content div[data-type="caution"],#sbo-rt-content div[data-type="important"]{margin:30px !important;font-size:90%;padding:10px 8px 20px 8px !important;page-break-inside:avoid}#sbo-rt-content div.tip ol,#sbo-rt-content div.tip ul,#sbo-rt-content div[data-type="tip"] ol,#sbo-rt-content div[data-type="tip"] ul,#sbo-rt-content div.note ol,#sbo-rt-content div.note ul,#sbo-rt-content div[data-type="note"] ol,#sbo-rt-content div[data-type="note"] ul,#sbo-rt-content div.warning ol,#sbo-rt-content div.warning ul,#sbo-rt-content div[data-type="warning"] ol,#sbo-rt-content div[data-type="warning"] ul,#sbo-rt-content div[data-type="caution"] ol,#sbo-rt-content div[data-type="caution"] ul,#sbo-rt-content div[data-type="important"] ol,#sbo-rt-content div[data-type="important"] ul{margin-left:1.5em !important}#sbo-rt-content div.tip,#sbo-rt-content div[data-type="tip"],#sbo-rt-content div.note,#sbo-rt-content div[data-type="note"]{border:1px solid #BEBEBE;background-color:transparent}#sbo-rt-content div.warning,#sbo-rt-content div[data-type="warning"],#sbo-rt-content div[data-type="caution"],#sbo-rt-content div[data-type="important"]{border:1px solid #BC8F8F}#sbo-rt-content div.tip h3,#sbo-rt-content div[data-type="tip"] h6,#sbo-rt-content div[data-type="tip"] h1,#sbo-rt-content div.note h3,#sbo-rt-content div[data-type="note"] h6,#sbo-rt-content div[data-type="note"] h1,#sbo-rt-content div.warning h3,#sbo-rt-content div[data-type="warning"] h6,#sbo-rt-content div[data-type="warning"] h1,#sbo-rt-content div[data-type="caution"] h6,#sbo-rt-content div[data-type="caution"] h1,#sbo-rt-content div[data-type="important"] h1,#sbo-rt-content div[data-type="important"] h6{font-weight:bold;font-size:110%;font-family:sans-serif !important;text-transform:uppercase;letter-spacing:1px;text-align:center;margin:4px 0 6px !important}#sbo-rt-content div.tip h3,#sbo-rt-content div[data-type="tip"] h6,#sbo-rt-content div.note h3,#sbo-rt-content div[data-type="note"] h6,#sbo-rt-content div[data-type="tip"] h1,#sbo-rt-content div[data-type="note"] h1{color:#737373}#sbo-rt-content div.warning h3,#sbo-rt-content div[data-type="warning"] h6,#sbo-rt-content div[data-type="caution"] h6,#sbo-rt-content div[data-type="important"] h6,#sbo-rt-content div[data-type="warning"] h1,#sbo-rt-content div[data-type="caution"] h1,#sbo-rt-content div[data-type="important"] h1{color:#C67171}#sbo-rt-content div.sect1[title="Safari® Books Online"] div.note,#sbo-rt-content div.safarienabled{background-color:transparent;margin:8px 0 0 !important;border:0 solid #BEBEBE;font-size:100%;padding:0 !important;page-break-inside:avoid}#sbo-rt-content div.sect1[title="Safari® Books Online"] div.note h3,#sbo-rt-content div.safarienabled h6{display:none}#sbo-rt-content div.table,#sbo-rt-content table{margin:15px 0 30px 0 !important;max-width:95%;border:none !important;background:none;display:table !important}#sbo-rt-content div.table,#sbo-rt-content div.informaltable,#sbo-rt-content table{page-break-inside:avoid}#sbo-rt-content tr,#sbo-rt-content tr td{border-bottom:1px solid #c3c3c3}#sbo-rt-content thead td,#sbo-rt-content thead th{border-bottom:#9d9d9d 1px solid !important;border-top:#9d9d9d 1px solid !important}#sbo-rt-content tr:nth-of-type(even){background-color:#f1f6fc}#sbo-rt-content thead{font-family:sans-serif;font-weight:bold}#sbo-rt-content td,#sbo-rt-content th{display:table-cell;padding:.3em;text-align:left;vertical-align:middle;font-size:80%}#sbo-rt-content div.informaltable table{margin:10px auto !important}#sbo-rt-content div.informaltable table tr{border-bottom:none}#sbo-rt-content div.informaltable table tr:nth-of-type(even){background-color:transparent}#sbo-rt-content div.informaltable td,#sbo-rt-content div.informaltable th{border:#9d9d9d 1px solid}#sbo-rt-content div.table-title,#sbo-rt-content table caption{font-weight:normal;font-style:italic;font-family:serif;font-size:1em;margin:10px 0 10px 0 !important;padding:0;page-break-after:avoid;text-align:left !important}#sbo-rt-content table code{font-size:smaller}#sbo-rt-content div.equation,#sbo-rt-content div[data-type="equation"]{margin:10px 0 15px 0 !important}#sbo-rt-content div.equation-title,#sbo-rt-content div[data-type="equation"] h5{font-style:italic;font-weight:normal;font-family:serif !important;font-size:90%;margin:20px 0 10px 0 !important;page-break-after:avoid}#sbo-rt-content div.equation-contents{margin-left:20px}#sbo-rt-content span.inlinemediaobject{height:.85em;display:inline-block;margin-bottom:.2em}#sbo-rt-content span.inlinemediaobject img{margin:0;height:.85em}#sbo-rt-content div.informalequation{margin:20px 0 20px 20px;width:75%}#sbo-rt-content div.informalequation img{width:75%}#sbo-rt-content div.index{text-indent:0}#sbo-rt-content div.index li{line-height:140%}#sbo-rt-content div.index a.indexterm{color:#8e0012}#sbo-rt-content div.index ul,#sbo-rt-content div[data-type="index"] ul{list-style-type:none;padding-left:0;margin-left:0}#sbo-rt-content div.index ul li{padding-left:0;margin-left:0}#sbo-rt-content div.index ul li ul li{margin-left:1em}#sbo-rt-content code.boolean,#sbo-rt-content .navy{color:rgb(0,0,128);}#sbo-rt-content code.character,#sbo-rt-content .olive{color:rgb(128,128,0);}#sbo-rt-content code.comment,#sbo-rt-content .blue{color:rgb(0,0,255);}#sbo-rt-content code.conditional,#sbo-rt-content .limegreen{color:rgb(50,205,50);}#sbo-rt-content code.constant,#sbo-rt-content .darkorange{color:rgb(255,140,0);}#sbo-rt-content code.debug,#sbo-rt-content .darkred{color:rgb(139,0,0);}#sbo-rt-content code.define,#sbo-rt-content .darkgoldenrod,#sbo-rt-content .gold{color:rgb(184,134,11);}#sbo-rt-content code.delimiter,#sbo-rt-content .dimgray{color:rgb(105,105,105);}#sbo-rt-content code.error,#sbo-rt-content .red{color:rgb(255,0,0);}#sbo-rt-content code.exception,#sbo-rt-content .salmon{color:rgb(250,128,11);}#sbo-rt-content code.float,#sbo-rt-content .steelblue{color:rgb(70,130,180);}#sbo-rt-content pre code.function,#sbo-rt-content .green{color:rgb(0,128,0);}#sbo-rt-content code.identifier,#sbo-rt-content .royalblue{color:rgb(65,105,225);}#sbo-rt-content code.ignore,#sbo-rt-content .gray{color:rgb(128,128,128);}#sbo-rt-content code.include,#sbo-rt-content .purple{color:rgb(128,0,128);}#sbo-rt-content code.keyword,#sbo-rt-content .sienna{color:rgb(160,82,45);}#sbo-rt-content code.label,#sbo-rt-content .deeppink{color:rgb(255,20,147);}#sbo-rt-content code.macro,#sbo-rt-content .orangered{color:rgb(255,69,0);}#sbo-rt-content code.number,#sbo-rt-content .brown{color:rgb(165,42,42);}#sbo-rt-content code.operator,#sbo-rt-content .black{color:#000;}#sbo-rt-content code.preCondit,#sbo-rt-content .teal{color:rgb(0,128,128);}#sbo-rt-content code.preProc,#sbo-rt-content .fuschia{color:rgb(255,0,255);}#sbo-rt-content code.repeat,#sbo-rt-content .indigo{color:rgb(75,0,130);}#sbo-rt-content code.special,#sbo-rt-content .saddlebrown{color:rgb(139,69,19);}#sbo-rt-content code.specialchar,#sbo-rt-content .magenta{color:rgb(255,0,255);}#sbo-rt-content code.specialcomment,#sbo-rt-content .seagreen{color:rgb(46,139,87);}#sbo-rt-content code.statement,#sbo-rt-content .forestgreen{color:rgb(34,139,34);}#sbo-rt-content code.storageclass,#sbo-rt-content .plum{color:rgb(221,160,221);}#sbo-rt-content code.string,#sbo-rt-content .darkred{color:rgb(139,0,0);}#sbo-rt-content code.structure,#sbo-rt-content .chocolate{color:rgb(210,106,30);}#sbo-rt-content code.tag,#sbo-rt-content .darkcyan{color:rgb(0,139,139);}#sbo-rt-content code.todo,#sbo-rt-content .black{color:#000;}#sbo-rt-content code.type,#sbo-rt-content .mediumslateblue{color:rgb(123,104,238);}#sbo-rt-content code.typedef,#sbo-rt-content .darkgreen{color:rgb(0,100,0);}#sbo-rt-content code.underlined{text-decoration:underline;}#sbo-rt-content pre code.hll{background-color:#ffc}#sbo-rt-content pre code.c{color:#09F;font-style:italic}#sbo-rt-content pre code.err{color:#A00}#sbo-rt-content pre code.k{color:#069;font-weight:bold}#sbo-rt-content pre code.o{color:#555}#sbo-rt-content pre code.cm{color:#35586C;font-style:italic}#sbo-rt-content pre code.cp{color:#099}#sbo-rt-content pre code.c1{color:#35586C;font-style:italic}#sbo-rt-content pre code.cs{color:#35586C;font-weight:bold;font-style:italic}#sbo-rt-content pre code.gd{background-color:#FCC}#sbo-rt-content pre code.ge{font-style:italic}#sbo-rt-content pre code.gr{color:#F00}#sbo-rt-content pre code.gh{color:#030;font-weight:bold}#sbo-rt-content pre code.gi{background-color:#CFC}#sbo-rt-content pre code.go{color:#000}#sbo-rt-content pre code.gp{color:#009;font-weight:bold}#sbo-rt-content pre code.gs{font-weight:bold}#sbo-rt-content pre code.gu{color:#030;font-weight:bold}#sbo-rt-content pre code.gt{color:#9C6}#sbo-rt-content pre code.kc{color:#069;font-weight:bold}#sbo-rt-content pre code.kd{color:#069;font-weight:bold}#sbo-rt-content pre code.kn{color:#069;font-weight:bold}#sbo-rt-content pre code.kp{color:#069}#sbo-rt-content pre code.kr{color:#069;font-weight:bold}#sbo-rt-content pre code.kt{color:#078;font-weight:bold}#sbo-rt-content pre code.m{color:#F60}#sbo-rt-content pre code.s{color:#C30}#sbo-rt-content pre code.na{color:#309}#sbo-rt-content pre code.nb{color:#366}#sbo-rt-content pre code.nc{color:#0A8;font-weight:bold}#sbo-rt-content pre code.no{color:#360}#sbo-rt-content pre code.nd{color:#99F}#sbo-rt-content pre code.ni{color:#999;font-weight:bold}#sbo-rt-content pre code.ne{color:#C00;font-weight:bold}#sbo-rt-content pre code.nf{color:#C0F}#sbo-rt-content pre code.nl{color:#99F}#sbo-rt-content pre code.nn{color:#0CF;font-weight:bold}#sbo-rt-content pre code.nt{color:#309;font-weight:bold}#sbo-rt-content pre code.nv{color:#033}#sbo-rt-content pre code.ow{color:#000;font-weight:bold}#sbo-rt-content pre code.w{color:#bbb}#sbo-rt-content pre code.mf{color:#F60}#sbo-rt-content pre code.mh{color:#F60}#sbo-rt-content pre code.mi{color:#F60}#sbo-rt-content pre code.mo{color:#F60}#sbo-rt-content pre code.sb{color:#C30}#sbo-rt-content pre code.sc{color:#C30}#sbo-rt-content pre code.sd{color:#C30;font-style:italic}#sbo-rt-content pre code.s2{color:#C30}#sbo-rt-content pre code.se{color:#C30;font-weight:bold}#sbo-rt-content pre code.sh{color:#C30}#sbo-rt-content pre code.si{color:#A00}#sbo-rt-content pre code.sx{color:#C30}#sbo-rt-content pre code.sr{color:#3AA}#sbo-rt-content pre code.s1{color:#C30}#sbo-rt-content pre code.ss{color:#A60}#sbo-rt-content pre code.bp{color:#366}#sbo-rt-content pre code.vc{color:#033}#sbo-rt-content pre code.vg{color:#033}#sbo-rt-content pre code.vi{color:#033}#sbo-rt-content pre code.il{color:#F60}#sbo-rt-content pre code.g{color:#050}#sbo-rt-content pre code.l{color:#C60}#sbo-rt-content pre code.l{color:#F90}#sbo-rt-content pre code.n{color:#008}#sbo-rt-content pre code.nx{color:#008}#sbo-rt-content pre code.py{color:#96F}#sbo-rt-content pre code.p{color:#000}#sbo-rt-content pre code.x{color:#F06}#sbo-rt-content div.blockquote_sampler_toc{width:95%;margin:5px 5px 5px 10px !important}#sbo-rt-content div{font-family:serif;text-align:left}#sbo-rt-content .gray-background,#sbo-rt-content .reverse-video{background:#2E2E2E;color:#FFF}#sbo-rt-content .light-gray-background{background:#A0A0A0}#sbo-rt-content .preserve-whitespace{white-space:pre-wrap}#sbo-rt-content span.gray{color:#4C4C4C}#sbo-rt-content div[data-type="equation"].fifty-percent img{width:50%}</style><script> // <![CDATA[
    var g = {
      position_cache: {
        
          "chapter": "/api/v1/book/9781491962282/chapter/ch10.html",
          "book_id": "9781491962282",
          "chapter_uri": "ch10.html",
          "position": 2.55275831017,
          "user_uuid": "2d2acfb7-1cff-4dc7-9037-8ffbac19b02e",
          "next_chapter_uri": "/library/view/hands-on-machine-learning/9781491962282/ch11.html"
        
      },
      title: "Hands\u002DOn Machine Learning with Scikit\u002DLearn and TensorFlow",
      author_list: "Aurélien Géron",
      format: "book",
      source: "application/epub+zip",
      is_system_book: true,
      is_public: false,
      loaded_from_server: true,
      allow_scripts: false,
      has_mathml: false,
      show_ios_app_teaser: false
    };
    // ]]></script><script src="A.%20Exercise%20Solutions%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/modernizr.js"></script><script>
    
      
        

        

        
          
            window.PUBLIC_ANNOTATIONS = true;
          
        

      

      
        window.MOBILE_PUBLIC_ANNOTATIONS = false;
      

    

    
      window.PRIVACY_CONTROL_OVERRIDE = false;
    

    
      window.PRIVACY_CONTROL_SWITCH = true;
    

    
      window.PUBLISHER_PAGES = true;
    

      window.SBO = {
        "constants": {
          "SITB_ENDPOINT": "https://www.safaribooksonline.com/api/v2/sitb/",
          "SEARCH_SELECT_ENDPOINT": "https://www.safaribooksonline.com/api/v2/search/select/",
          "ENABLE_ONLINE_TRAINING": true
        }
      };
  </script><link rel="canonical" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html"><meta name="description" content=" Chapter 10. Introduction to Artificial Neural Networks Birds inspired us to fly, burdock plants inspired velcro, and nature has inspired many other inventions. It seems only logical, then, to look ... "><meta property="og:title" content="10. Introduction to Artificial Neural Networks"><meta itemprop="isPartOf" content="/library/view/hands-on-machine-learning/9781491962282/"><meta itemprop="name" content="10. Introduction to Artificial Neural Networks"><meta property="og:url" itemprop="url" content="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html"><meta property="og:site_name" content="Safari"><meta property="og:image" itemprop="thumbnailUrl" content="https://www.safaribooksonline.com/library/cover/9781491962282/"><meta property="og:description" itemprop="description" content=" Chapter 10. Introduction to Artificial Neural Networks Birds inspired us to fly, burdock plants inspired velcro, and nature has inspired many other inventions. It seems only logical, then, to look ... "><meta itemprop="inLanguage" content="en"><meta itemprop="publisher" content="O'Reilly Media, Inc."><meta property="og:type" content="book"><meta property="og:book:isbn" itemprop="isbn" content="9781491962299"><meta property="og:book:author" itemprop="author" content="Aurélien Géron"><meta property="og:book:tag" itemprop="about" content="Core Programming"><meta property="og:book:tag" itemprop="about" content="Engineering"><meta property="og:book:tag" itemprop="about" content="Python"><meta name="twitter:card" content="summary"><meta name="twitter:site" content="@safari"><style type="text/css" id="font-styles" data-template="#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-size: &lt;%= font_size %&gt; !important; }"></style><style type="text/css" id="font-family" data-template="#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-family: &lt;%= font_family %&gt; !important; }"></style><style type="text/css" id="column-width" data-template="#sbo-rt-content { max-width: &lt;%= column_width %&gt;% !important; margin: 0 auto !important; }"></style><noscript><meta http-equiv="refresh" content="0; url=/library/no-js/" /></noscript><script type="text/javascript">
  (function(i,s,o,g,r,a,m) {
    i['GoogleAnalyticsObject']=r;
    i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();
    a=s.createElement(o),m=s.getElementsByTagName(o)[0];
    a.async=1;
    a.src=g;
    m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  var matches = document.cookie.match(/BrowserCookie\s*=\s*([a-f0-9\-]{36})/),
      user_uuid = null;

  if (matches && matches.length === 2) {
    user_uuid = matches[1];
  }


  ga('create', 'UA-39299553-7', {'userId': '2d2acfb7-1cff-4dc7-9037-8ffbac19b02e' });



  
    ga('set', 'dimension1', 'Trial');
  


ga('set', 'dimension6', user_uuid);


  ga('set', 'dimension2', '2d2acfb7-1cff-4dc7-9037-8ffbac19b02e');
  






//enable enhanced link tracking
ga('require', 'linkid', 'linkid.js');

// reading interface will track pageviews itself
if (document.location.pathname.indexOf("/library/view") !== 0) {
  ga('send', 'pageview');
}
</script><script>
    (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    '//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-5P4V6Z');
  </script><script defer="defer" src="A.%20Exercise%20Solutions%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/vendor.js"></script><script defer="defer" src="A.%20Exercise%20Solutions%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/reader.js"></script><script async="" src="A.%20Exercise%20Solutions%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/MathJax.js"></script><style id="annotator-dynamic-style">.annotator-adder, .annotator-outer, .annotator-notice {
  z-index: 100019;
}
.annotator-filter {
  z-index: 100009;
}</style><script src="A.%20Exercise%20Solutions%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/a_002.js"></script><script src="A.%20Exercise%20Solutions%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/a_003.js"></script></head>


<body class="reading sidenav nav-collapsed  scalefonts subscribe-panel library" data-gr-c-s-loaded="true">

    
  
  <noscript> 
    <iframe src="//www.googletagmanager.com/ns.html?id=GTM-5P4V6Z"
            height="0" width="0"
            style="display:none;visibility:hidden">
    </iframe>
  </noscript>
  



    
      <div class="working hide" role="status">
        <div class="working-image"></div>
      </div>
      <div class="sbo-site-nav">
        





<a href="#container" class="skip">Skip to content</a><header class="topbar t-topbar"><nav role="navigation" class="js-site-nav"><ul class="topnav"><li class="t-logo"><a href="https://www.safaribooksonline.com/home/" class="l0 None safari-home nav-icn js-keyboard-nav-home"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width="20" height="20" version="1.1" fill="#4A3C31"><desc>Safari Home Icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M4 9.9L4 9.9 4 18 16 18 16 9.9 10 4 4 9.9ZM2.6 8.1L2.6 8.1 8.7 1.9 10 0.5 11.3 1.9 17.4 8.1 18 8.7 18 9.5 18 18.1 18 20 16.1 20 3.9 20 2 20 2 18.1 2 9.5 2 8.7 2.6 8.1Z"></path><rect x="10" y="12" width="3" height="7"></rect><rect transform="translate(18.121320, 10.121320) rotate(-315.000000) translate(-18.121320, -10.121320) " x="16.1" y="9.1" width="4" height="2"></rect><rect transform="translate(2.121320, 10.121320) scale(-1, 1) rotate(-315.000000) translate(-2.121320, -10.121320) " x="0.1" y="9.1" width="4" height="2"></rect></g></svg><span>Safari Home</span></a></li><li><a href="https://www.safaribooksonline.com/r/" class="t-recommendations-nav l0 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>recommendations icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M50 25C50 18.2 44.9 12.5 38.3 11.7 37.5 5.1 31.8 0 25 0 18.2 0 12.5 5.1 11.7 11.7 5.1 12.5 0 18.2 0 25 0 31.8 5.1 37.5 11.7 38.3 12.5 44.9 18.2 50 25 50 31.8 50 37.5 44.9 38.3 38.3 44.9 37.5 50 31.8 50 25ZM25 3.1C29.7 3.1 33.6 6.9 34.4 11.8 30.4 12.4 26.9 15.1 25 18.8 23.1 15.1 19.6 12.4 15.6 11.8 16.4 6.9 20.3 3.1 25 3.1ZM34.4 15.6C33.6 19.3 30.7 22.2 27.1 22.9 27.8 19.2 30.7 16.3 34.4 15.6ZM22.9 22.9C19.2 22.2 16.3 19.3 15.6 15.6 19.3 16.3 22.2 19.2 22.9 22.9ZM3.1 25C3.1 20.3 6.9 16.4 11.8 15.6 12.4 19.6 15.1 23.1 18.8 25 15.1 26.9 12.4 30.4 11.8 34.4 6.9 33.6 3.1 29.7 3.1 25ZM22.9 27.1C22.2 30.7 19.3 33.6 15.6 34.4 16.3 30.7 19.2 27.8 22.9 27.1ZM25 46.9C20.3 46.9 16.4 43.1 15.6 38.2 19.6 37.6 23.1 34.9 25 31.3 26.9 34.9 30.4 37.6 34.4 38.2 33.6 43.1 29.7 46.9 25 46.9ZM27.1 27.1C30.7 27.8 33.6 30.7 34.4 34.4 30.7 33.6 27.8 30.7 27.1 27.1ZM38.2 34.4C37.6 30.4 34.9 26.9 31.3 25 34.9 23.1 37.6 19.6 38.2 15.6 43.1 16.4 46.9 20.3 46.9 25 46.9 29.7 43.1 33.6 38.2 34.4Z"></path></g></svg><span>Recommended</span></a></li><li><a href="https://www.safaribooksonline.com/s/" class="t-queue-nav l0 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>queue icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M25 29.2C25.4 29.2 25.8 29.1 26.1 28.9L48.7 16.8C49.5 16.4 50 15.5 50 14.6 50 13.7 49.5 12.8 48.7 12.4L26.1 0.3C25.4-0.1 24.6-0.1 23.9 0.3L1.3 12.4C0.5 12.8 0 13.7 0 14.6 0 15.5 0.5 16.4 1.3 16.8L23.9 28.9C24.2 29.1 24.6 29.2 25 29.2ZM7.3 14.6L25 5.2 42.7 14.6 25 24 7.3 14.6ZM48.7 22.4L47.7 21.9 25 34.2 2.3 21.9 1.3 22.4C0.5 22.9 0 23.7 0 24.7 0 25.6 0.5 26.5 1.3 26.9L23.9 39.3C24.2 39.5 24.6 39.6 25 39.6 25.4 39.6 25.8 39.5 26.1 39.3L48.7 26.9C49.5 26.5 50 25.6 50 24.7 50 23.7 49.5 22.9 48.7 22.4ZM48.7 32.8L47.7 32.3 25 44.6 2.3 32.3 1.3 32.8C0.5 33.3 0 34.1 0 35.1 0 36 0.5 36.9 1.3 37.3L23.9 49.7C24.2 49.9 24.6 50 25 50 25.4 50 25.8 49.9 26.1 49.7L48.7 37.3C49.5 36.9 50 36 50 35.1 50 34.1 49.5 33.3 48.7 32.8Z"></path></g></svg><span>
                  Queue
              </span></a></li><li class="search"><a href="#" class="t-search-nav trigger nav-icn l0" data-dropdown-selector=".searchbox"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>search icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M31.3 0C20.9 0 12.5 8.4 12.5 18.8 12.5 22.5 13.6 25.9 15.4 28.8L1.2 42.9C-0.4 44.5-0.4 47.2 1.2 48.8 2 49.6 3.1 50 4.2 50 5.2 50 6.3 49.6 7.1 48.8L21.2 34.6C24.1 36.5 27.5 37.5 31.3 37.5 41.6 37.5 50 29.1 50 18.8 50 8.4 41.6 0 31.3 0ZM31.3 31.3C24.4 31.3 18.8 25.6 18.8 18.8 18.8 11.9 24.4 6.3 31.3 6.3 38.1 6.3 43.8 11.9 43.8 18.8 43.8 25.6 38.1 31.3 31.3 31.3Z"></path></g></svg><span>Search</span></a></li><li class="usermenu dropdown"><a href="#" class="trigger l0 nav-icn nav-dropdown"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width="20" height="20" version="1.1" fill="#4A3C31"><desc>navigation arrow</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M0.1 12.5L9.7 3.1C9.8 3 9.9 3 10 3 10.1 3 10.2 3 10.3 3.1L19.9 12.5C20 12.5 20 12.6 20 12.8 20 12.9 20 13 19.9 13L17 15.9C16.9 16 16.8 16 16.7 16 16.5 16 16.4 16 16.4 15.9L10 9.7 3.6 15.9C3.6 16 3.5 16 3.3 16 3.2 16 3.1 16 3 15.9L0.1 13C0 12.9 0 12.8 0 12.7 0 12.7 0 12.6 0.1 12.5Z"></path></g></svg><span>Expand Nav</span></a><div class="drop-content"><ul><li><a href="https://www.safaribooksonline.com/history/" class="t-recent-nav l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>recent items icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M25 0C11.2 0 0 11.2 0 25 0 38.8 11.2 50 25 50 38.8 50 50 38.8 50 25 50 11.2 38.8 0 25 0ZM6.3 25C6.3 14.6 14.6 6.3 25 6.3 35.4 6.3 43.8 14.6 43.8 25 43.8 35.4 35.4 43.8 25 43.8 14.6 43.8 6.3 35.4 6.3 25ZM31.8 31.5C32.5 30.5 32.4 29.2 31.6 28.3L27.1 23.8 27.1 12.8C27.1 11.5 26.2 10.4 25 10.4 23.9 10.4 22.9 11.5 22.9 12.8L22.9 25.7 28.8 31.7C29.2 32.1 29.7 32.3 30.2 32.3 30.8 32.3 31.3 32 31.8 31.5Z"></path></g></svg><span>History</span></a></li><li><a href="https://www.safaribooksonline.com/topics" class="t-topics-link l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 55" width="20" height="20" version="1.1" fill="#4A3C31"><desc>topics icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M25 55L50 41.262 50 13.762 25 0 0 13.762 0 41.262 25 55ZM8.333 37.032L8.333 17.968 25 8.462 41.667 17.968 41.667 37.032 25 46.538 8.333 37.032Z"></path></g></svg><span>Topics</span></a></li><li><a href="https://www.safaribooksonline.com/tutorials/" class="l1 nav-icn t-tutorials-nav js-toggle-menu-item None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width="20" height="20" version="1.1" fill="#4A3C31"><desc>tutorials icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M15.8 18.2C15.8 18.2 15.9 18.2 16 18.2 16.1 18.2 16.2 18.2 16.4 18.2 16.5 18.2 16.7 18.1 16.9 18 17 17.9 17.1 17.8 17.2 17.7 17.3 17.6 17.4 17.5 17.4 17.4 17.5 17.2 17.6 16.9 17.6 16.7 17.6 16.6 17.6 16.5 17.6 16.4 17.5 16.2 17.5 16.1 17.4 15.9 17.3 15.8 17.2 15.6 17 15.5 16.8 15.3 16.6 15.3 16.4 15.2 16.2 15.2 16 15.2 15.8 15.2 15.7 15.2 15.5 15.3 15.3 15.4 15.2 15.4 15.1 15.5 15 15.7 14.9 15.8 14.8 15.9 14.7 16 14.7 16.1 14.6 16.3 14.6 16.4 14.6 16.5 14.6 16.6 14.6 16.6 14.6 16.7 14.6 16.9 14.6 17 14.6 17.1 14.7 17.3 14.7 17.4 14.8 17.6 15 17.7 15.1 17.9 15.2 18 15.3 18 15.5 18.1 15.5 18.1 15.6 18.2 15.7 18.2 15.7 18.2 15.7 18.2 15.8 18.2L15.8 18.2ZM9.4 11.5C9.5 11.5 9.5 11.5 9.6 11.5 9.7 11.5 9.9 11.5 10 11.5 10.2 11.5 10.3 11.4 10.5 11.3 10.6 11.2 10.8 11.1 10.9 11 10.9 10.9 11 10.8 11.1 10.7 11.2 10.5 11.2 10.2 11.2 10 11.2 9.9 11.2 9.8 11.2 9.7 11.2 9.5 11.1 9.4 11 9.2 10.9 9.1 10.8 8.9 10.6 8.8 10.5 8.7 10.3 8.6 10 8.5 9.9 8.5 9.7 8.5 9.5 8.5 9.3 8.5 9.1 8.6 9 8.7 8.8 8.7 8.7 8.8 8.6 9 8.5 9.1 8.4 9.2 8.4 9.3 8.2 9.5 8.2 9.8 8.2 10 8.2 10.1 8.2 10.2 8.2 10.3 8.2 10.5 8.3 10.6 8.4 10.7 8.5 10.9 8.6 11.1 8.7 11.2 8.9 11.3 9 11.4 9.1 11.4 9.2 11.4 9.3 11.5 9.3 11.5 9.3 11.5 9.4 11.5 9.4 11.5L9.4 11.5ZM3 4.8C3.1 4.8 3.1 4.8 3.2 4.8 3.4 4.8 3.5 4.8 3.7 4.8 3.8 4.8 4 4.7 4.1 4.6 4.3 4.5 4.4 4.4 4.5 4.3 4.6 4.2 4.6 4.1 4.7 4 4.8 3.8 4.8 3.5 4.8 3.3 4.8 3.1 4.8 3 4.8 2.9 4.7 2.8 4.7 2.6 4.6 2.5 4.5 2.3 4.4 2.2 4.2 2.1 4 1.9 3.8 1.9 3.6 1.8 3.5 1.8 3.3 1.8 3.1 1.8 2.9 1.8 2.7 1.9 2.6 2 2.4 2.1 2.3 2.2 2.2 2.3 2.1 2.4 2 2.5 2 2.6 1.8 2.8 1.8 3 1.8 3.3 1.8 3.4 1.8 3.5 1.8 3.6 1.8 3.8 1.9 3.9 2 4 2.1 4.2 2.2 4.4 2.4 4.5 2.5 4.6 2.6 4.7 2.7 4.7 2.8 4.7 2.9 4.8 2.9 4.8 3 4.8 3 4.8 3 4.8L3 4.8ZM13.1 15.2C13.2 15.1 13.2 15.1 13.2 15.1 13.3 14.9 13.4 14.7 13.6 14.5 13.8 14.2 14.1 14 14.4 13.8 14.7 13.6 15.1 13.5 15.5 13.4 15.9 13.4 16.3 13.4 16.7 13.5 17.2 13.5 17.6 13.7 17.9 13.9 18.2 14.1 18.5 14.4 18.7 14.7 18.9 15 19.1 15.3 19.2 15.6 19.3 15.9 19.4 16.1 19.4 16.4 19.4 17 19.3 17.5 19.1 18.1 19 18.3 18.9 18.5 18.7 18.7 18.5 19 18.3 19.2 18 19.4 17.7 19.6 17.3 19.8 16.9 19.9 16.6 20 16.3 20 16 20 15.8 20 15.6 20 15.4 19.9 15.4 19.9 15.4 19.9 15.4 19.9 15.2 19.9 15 19.8 14.9 19.8 14.8 19.7 14.7 19.7 14.6 19.7 14.4 19.6 14.3 19.5 14.1 19.3 13.7 19.1 13.4 18.7 13.2 18.4 13.1 18.1 12.9 17.8 12.9 17.5 12.8 17.3 12.8 17.1 12.8 16.9L3.5 14.9C3.3 14.9 3.1 14.8 3 14.8 2.7 14.7 2.4 14.5 2.1 14.3 1.7 14 1.4 13.7 1.2 13.3 1 13 0.9 12.6 0.8 12.3 0.7 12 0.7 11.7 0.7 11.4 0.7 11 0.8 10.5 1 10.1 1.1 9.8 1.3 9.5 1.6 9.2 1.8 8.9 2.1 8.7 2.4 8.5 2.8 8.3 3.2 8.1 3.6 8.1 3.9 8 4.2 8 4.5 8 4.6 8 4.8 8 4.9 8.1L6.8 8.5C6.8 8.4 6.8 8.4 6.8 8.4 6.9 8.2 7.1 8 7.2 7.8 7.5 7.5 7.7 7.3 8 7.1 8.4 6.9 8.7 6.8 9.1 6.7 9.5 6.7 10 6.7 10.4 6.8 10.8 6.8 11.2 7 11.5 7.2 11.8 7.5 12.1 7.7 12.4 8 12.6 8.3 12.7 8.6 12.8 8.9 12.9 9.2 13 9.4 13 9.7 13 9.7 13 9.8 13 9.8 13.6 9.9 14.2 10.1 14.9 10.2 15 10.2 15 10.2 15.1 10.2 15.3 10.2 15.4 10.2 15.6 10.2 15.8 10.1 16 10 16.2 9.9 16.4 9.8 16.5 9.6 16.6 9.5 16.8 9.2 16.9 8.8 16.9 8.5 16.9 8.3 16.9 8.2 16.8 8 16.8 7.8 16.7 7.7 16.6 7.5 16.5 7.3 16.3 7.2 16.2 7.1 16 7 15.9 6.9 15.8 6.9 15.7 6.9 15.6 6.8 15.5 6.8L6.2 4.8C6.2 5 6 5.2 5.9 5.3 5.7 5.6 5.5 5.8 5.3 6 4.9 6.2 4.5 6.4 4.1 6.5 3.8 6.6 3.5 6.6 3.2 6.6 3 6.6 2.8 6.6 2.7 6.6 2.6 6.6 2.6 6.5 2.6 6.5 2.5 6.5 2.3 6.5 2.1 6.4 1.8 6.3 1.6 6.1 1.3 6 1 5.7 0.7 5.4 0.5 5 0.3 4.7 0.2 4.4 0.1 4.1 0 3.8 0 3.6 0 3.3 0 2.8 0.1 2.2 0.4 1.7 0.5 1.5 0.7 1.3 0.8 1.1 1.1 0.8 1.3 0.6 1.6 0.5 2 0.3 2.3 0.1 2.7 0.1 3.1 0 3.6 0 4 0.1 4.4 0.2 4.8 0.3 5.1 0.5 5.5 0.8 5.7 1 6 1.3 6.2 1.6 6.3 1.9 6.4 2.3 6.5 2.5 6.6 2.7 6.6 3 6.6 3 6.6 3.1 6.6 3.1 9.7 3.8 12.8 4.4 15.9 5.1 16.1 5.1 16.2 5.2 16.4 5.2 16.7 5.3 16.9 5.5 17.2 5.6 17.5 5.9 17.8 6.2 18.1 6.5 18.3 6.8 18.4 7.2 18.6 7.5 18.6 7.9 18.7 8.2 18.7 8.6 18.7 9 18.6 9.4 18.4 9.8 18.3 10.1 18.2 10.3 18 10.6 17.8 10.9 17.5 11.1 17.3 11.3 16.9 11.6 16.5 11.8 16 11.9 15.7 12 15.3 12 15 12 14.8 12 14.7 12 14.5 11.9 13.9 11.8 13.3 11.7 12.6 11.5 12.5 11.7 12.4 11.9 12.3 12 12.1 12.3 11.9 12.5 11.7 12.7 11.3 12.9 10.9 13.1 10.5 13.2 10.2 13.3 9.9 13.3 9.6 13.3 9.4 13.3 9.2 13.3 9 13.2 9 13.2 9 13.2 9 13.2 8.8 13.2 8.7 13.2 8.5 13.1 8.2 13 8 12.8 7.7 12.6 7.4 12.4 7.1 12 6.8 11.7 6.7 11.4 6.6 11.1 6.5 10.8 6.4 10.6 6.4 10.4 6.4 10.2 5.8 10.1 5.2 9.9 4.5 9.8 4.4 9.8 4.4 9.8 4.3 9.8 4.1 9.8 4 9.8 3.8 9.8 3.6 9.9 3.4 10 3.2 10.1 3 10.2 2.9 10.4 2.8 10.5 2.6 10.8 2.5 11.1 2.5 11.5 2.5 11.6 2.5 11.8 2.6 12 2.6 12.1 2.7 12.3 2.8 12.5 2.9 12.6 3.1 12.8 3.2 12.9 3.3 13 3.5 13.1 3.6 13.1 3.7 13.1 3.8 13.2 3.9 13.2L13.1 15.2 13.1 15.2Z"></path></g></svg><span>Tutorials</span></a></li><li class="nav-offers flyout-parent"><a href="#" class="l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>offers icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M35.9 20.6L27 15.5C26.1 15 24.7 15 23.7 15.5L14.9 20.6C13.9 21.1 13.2 22.4 13.2 23.4L13.2 41.4C13.2 42.4 13.9 43.7 14.9 44.2L23.3 49C24.2 49.5 25.6 49.5 26.6 49L35.9 43.6C36.8 43.1 37.6 41.8 37.6 40.8L37.6 23.4C37.6 22.4 36.8 21.1 35.9 20.6L35.9 20.6ZM40 8.2C39.1 7.6 37.6 7.6 36.7 8.2L30.2 11.9C29.3 12.4 29.3 13.2 30.2 13.8L39.1 18.8C40 19.4 40.7 20.6 40.7 21.7L40.7 39C40.7 40.1 41.4 40.5 42.4 40L48.2 36.6C49.1 36.1 49.8 34.9 49.8 33.8L49.8 15.6C49.8 14.6 49.1 13.3 48.2 12.8L40 8.2 40 8.2ZM27 10.1L33.6 6.4C34.5 5.9 34.5 5 33.6 4.5L26.6 0.5C25.6 0 24.2 0 23.3 0.5L16.7 4.2C15.8 4.7 15.8 5.6 16.7 6.1L23.7 10.1C24.7 10.6 26.1 10.6 27 10.1ZM10.1 21.7C10.1 20.6 10.8 19.4 11.7 18.8L20.6 13.8C21.5 13.2 21.5 12.4 20.6 11.9L13.6 7.9C12.7 7.4 11.2 7.4 10.3 7.9L1.6 12.8C0.7 13.3 0 14.6 0 15.6L0 33.8C0 34.9 0.7 36.1 1.6 36.6L8.4 40.5C9.3 41 10.1 40.6 10.1 39.6L10.1 21.7 10.1 21.7Z"></path></g></svg><span>Offers &amp; Deals</span></a><ul class="flyout"><li><a href="https://www.safaribooksonline.com/oreilly-newsletters/" class="l2 nav-icn"><span>Newsletters</span></a></li></ul></li><li class="nav-highlights"><a href="https://www.safaribooksonline.com/u/0011N00001APXw3QAH/" class="t-highlights-nav l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 35" width="20" height="20" version="1.1" fill="#4A3C31"><desc>highlights icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M13.325 18.071L8.036 18.071C8.036 11.335 12.36 7.146 22.5 5.594L22.5 0C6.37 1.113 0 10.632 0 22.113 0 29.406 3.477 35 10.403 35 15.545 35 19.578 31.485 19.578 26.184 19.578 21.556 17.211 18.891 13.325 18.071L13.325 18.071ZM40.825 18.071L35.565 18.071C35.565 11.335 39.86 7.146 50 5.594L50 0C33.899 1.113 27.5 10.632 27.5 22.113 27.5 29.406 30.977 35 37.932 35 43.045 35 47.078 31.485 47.078 26.184 47.078 21.556 44.74 18.891 40.825 18.071L40.825 18.071Z"></path></g></svg><span>Highlights</span></a></li><li><a href="https://www.safaribooksonline.com/u/" class="t-settings-nav l1 js-settings nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 53" width="20" height="20" version="1.1" fill="#4A3C31"><desc>settings icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M44.6 29.6C44.7 28.6 44.8 27.5 44.8 26.5 44.8 25.5 44.7 24.4 44.6 23.4L49.6 19C50 18.8 50.1 18.3 49.9 17.9 48.9 14.7 47.1 11.7 44.9 9.1 44.6 8.8 44.2 8.7 43.8 8.8L37.4 11.1C35.8 9.8 34 8.7 32.1 8L30.9 1.4C30.8 0.9 30.4 0.6 30 0.5 26.7-0.2 23.3-0.2 20 0.5 19.6 0.6 19.2 0.9 19.1 1.4L17.9 8C16 8.7 14.1 9.8 12.6 11.1L6.2 8.8C5.8 8.7 5.4 8.8 5.1 9.1 2.9 11.7 1.1 14.7 0.1 17.9 -0.1 18.3 0 18.8 0.4 19L5.4 23.4C5.3 24.4 5.2 25.5 5.2 26.5 5.2 27.5 5.3 28.6 5.4 29.6L0.4 34C0 34.2-0.1 34.7 0.1 35.1 1.1 38.3 2.9 41.4 5.1 43.9 5.4 44.2 5.8 44.4 6.2 44.2L12.6 42C14.1 43.2 16 44.3 17.9 45L19.1 51.7C19.2 52.1 19.6 52.5 20 52.5 21.6 52.8 23.3 53 25 53 26.7 53 28.4 52.8 30 52.5 30.4 52.5 30.8 52.1 30.9 51.7L32.1 45C34 44.3 35.8 43.2 37.4 42L43.8 44.2C44.2 44.4 44.6 44.2 44.9 43.9 47.1 41.4 48.9 38.3 49.9 35.1 50.1 34.7 50 34.2 49.6 34L44.6 29.6ZM25 36.4C19.6 36.4 15.2 32 15.2 26.5 15.2 21 19.6 16.6 25 16.6 30.4 16.6 34.8 21 34.8 26.5 34.8 32 30.4 36.4 25 36.4Z"></path></g></svg><span>Settings</span></a></li><li><a href="https://www.safaribooksonline.com/public/support" class="l1 no-icon">Support</a></li><li><a href="https://www.safaribooksonline.com/accounts/logout/" class="l1 no-icon">Sign Out</a></li></ul><ul class="profile"><li><a href="https://www.safaribooksonline.com/u/" class="l2 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 53" width="20" height="20" version="1.1" fill="#4A3C31"><desc>settings icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M44.6 29.6C44.7 28.6 44.8 27.5 44.8 26.5 44.8 25.5 44.7 24.4 44.6 23.4L49.6 19C50 18.8 50.1 18.3 49.9 17.9 48.9 14.7 47.1 11.7 44.9 9.1 44.6 8.8 44.2 8.7 43.8 8.8L37.4 11.1C35.8 9.8 34 8.7 32.1 8L30.9 1.4C30.8 0.9 30.4 0.6 30 0.5 26.7-0.2 23.3-0.2 20 0.5 19.6 0.6 19.2 0.9 19.1 1.4L17.9 8C16 8.7 14.1 9.8 12.6 11.1L6.2 8.8C5.8 8.7 5.4 8.8 5.1 9.1 2.9 11.7 1.1 14.7 0.1 17.9 -0.1 18.3 0 18.8 0.4 19L5.4 23.4C5.3 24.4 5.2 25.5 5.2 26.5 5.2 27.5 5.3 28.6 5.4 29.6L0.4 34C0 34.2-0.1 34.7 0.1 35.1 1.1 38.3 2.9 41.4 5.1 43.9 5.4 44.2 5.8 44.4 6.2 44.2L12.6 42C14.1 43.2 16 44.3 17.9 45L19.1 51.7C19.2 52.1 19.6 52.5 20 52.5 21.6 52.8 23.3 53 25 53 26.7 53 28.4 52.8 30 52.5 30.4 52.5 30.8 52.1 30.9 51.7L32.1 45C34 44.3 35.8 43.2 37.4 42L43.8 44.2C44.2 44.4 44.6 44.2 44.9 43.9 47.1 41.4 48.9 38.3 49.9 35.1 50.1 34.7 50 34.2 49.6 34L44.6 29.6ZM25 36.4C19.6 36.4 15.2 32 15.2 26.5 15.2 21 19.6 16.6 25 16.6 30.4 16.6 34.8 21 34.8 26.5 34.8 32 30.4 36.4 25 36.4Z"></path></g></svg><span>Settings</span></a><span class="l2 t-nag-notification" id="nav-nag"><strong class="trial-green">10</strong> days left in your trial.
  
  

  
    
      

<a class="" href="https://www.safaribooksonline.com/subscribe/">Subscribe</a>.


    
  

  

</span></li><li><a href="https://www.safaribooksonline.com/public/support" class="l2">Support</a></li><li><a href="https://www.safaribooksonline.com/accounts/logout/" class="l2">Sign Out</a></li></ul></div></li></ul></nav></header>


      </div>
      <div id="container" class="application" style="height: auto;">
        
          <div class="nav-container clearfix">
            


            
            
          </div>

          

  <div class="js-toc">
    
      <div class="sbo-reading-menu sbo-menu-top"><section class="sbo-toc-container toc-menu"><a href="#" class="sbo-toc-thumb"><span class="sbo-title ss-list"><h1><div class="visuallyhidden">Table of Contents for </div>
      
      Hands-On Machine Learning with Scikit-Learn and TensorFlow
      
    </h1></span></a><div class="toc-contents" style="max-height: 0px;">
  <div class="sbo-toc ">
    <button type="button" class="sbo-toc-thumb close"><div class="visuallyhidden">Close</div></button>
      <section class="ios-app-teaser">
        <ul>
            <li><a class="js-toc-link toc-link" href="https://itunes.apple.com/gb/app/safari-queue-library-over/id881697395?mt=8" role="button">Install App</a></li>
            <li><a class="js-toc-link toc-link" href="safaridetail://9781491962282" role="button">Open in App</a></li>
        </ul>
      </section>
      <div class="sbo-book-meta">
        
        <span class="cover">
         <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/">
          <img src="A.%20Exercise%20Solutions%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/a.jpg" alt="Cover image for Hands-On Machine Learning with Scikit-Learn and TensorFlow" width="140" height="184">
        </a>
        </span>
        <span class="title">
          
            
                <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/publisher/oreilly-media-inc/">
                  <img src="A.%20Exercise%20Solutions%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/ORM_logo_box_rgb.png" class="publisher-logo video" alt="publisher logo">
                </a>
            
          

          <a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/">Hands-On Machine Learning with Scikit-Learn and TensorFlow</a>
        </span>
        
        <span class="authors">by Aurélien Géron</span>
        

        
        <span class="publishers t-publishers">Published by
          <!-- Show publisher page link if publisher pages switch is on -->
          
            <a class="t-publisher-link toc-link js-toc-link" href="https://www.safaribooksonline.com/library/publisher/oreilly-media-inc/">
              O'Reilly Media, Inc.</a>, 2017
          
        </span>
        

    

    </div>
  <ol class="tocList">
    
    
    
     

     <li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/preface01.html#idm140583011384384">
        Preface 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/part01.html#fundamentals_part">
        I. The Fundamentals of Machine Learning 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch01.html#landscape_chapter">
        1. The Machine Learning Landscape 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch02.html#project_chapter">
        2. End-to-End Machine Learning Project 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch03.html#classification_chapter">
        3. Classification 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch04.html#linear_models_chapter">
        4. Training Models 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch05.html#svm_chapter">
        5. Support Vector Machines 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch06.html#trees_chapter">
        6. Decision Trees 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch07.html#ensembles_chapter">
        7. Ensemble Learning and Random Forests 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch08.html#dim_reduction_chapter">
        8. Dimensionality Reduction 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/part02.html#neural_nets_part">
        II. Neural Networks and Deep Learning 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch09.html#tensorflow_chapter">
        9. Up and Running with TensorFlow 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html#ann_chapter">
        10. Introduction to Artificial Neural Networks 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#deep_chapter">
        11. Training Deep Neural Nets 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch12.html#distributed_chapter">
        12. Distributing TensorFlow Across Devices and Servers 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch13.html#cnn_chapter">
        13. Convolutional Neural Networks 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch14.html#rnn_chapter">
        14. Recurrent Neural Networks 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch15.html#autoencoders_chapter">
        15. Autoencoders 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1 currently-reading">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch16.html#rl_chapter">
        16. Reinforcement Learning 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app01.html#solutions_appendix">
        A. Exercise Solutions 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app02.html#project_checklist_appendix">
        B. Machine Learning Project Checklist 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app03.html#svm_dual_problem_appendix">
        C. SVM Dual Problem 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app04.html#autodiff_appendix">
        D. Autodiff 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app05.html#other_ann_appendix">
        E. Other Popular ANN Architectures 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ix01.html#idm140582977822192">
        Index 
       </a>
      
        
      
   </li></ol>
 </div>



</div></section></div>

    

    <div class="interface-controls interface-controls-top">
      <ul class="interface-control-btns js-bitlist js-reader">
        <li class="js-search-in-archive search-in-archive t-search-in-archive"><a href="#" title="Search in archive" class="js-search-controls search-controls"><span class="icon">Search in book...</span></a><form class="search-archive-bar js-search-form"><input name="query" placeholder="Search inside this book..." autocomplete="off" type="search"></form><div class="search-archive-results"><div class="js-sitb-results-region"></div></div></li><li class="queue-control"><button type="button" class="rec-fav ss-queue js-queue js-current-chapter-queue" data-queue-endpoint="/api/v1/book/9781491962282/chapter/app01.html" data-for-analytics="9781491962282:app01.html" aria-label="Add to Queue"><span>Add to Queue</span></button></li><li class="js-font-control-panel font-control-activator"><a href="#" data-push-state="false" id="font-controls" title="Change font size" aria-label="Change font size"><span class="icon">Toggle Font Controls</span></a></li><li class="dropdown sharing-controls"><a href="#" class="trigger" data-push-state="false" title="Share" aria-label="Share"><i class="fa fa-share"></i></a><ul class="social-sharing dropdown-menu"><li class=""><a class="twitter share-button t-twitter" target="_blank" aria-label="Share this section on Twitter" title="Share this section on Twitter" href="https://twitter.com/share?url=https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html&amp;text=Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow&amp;via=safari"><span>Twitter</span></a></li><li class=""><a class="facebook share-button t-facebook" target="_blank" aria-label="Share this section on Facebook" title="Share this section on Facebook" href="https://www.facebook.com/sharer/sharer.php?u=https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html"><span>Facebook</span></a></li><li class=""><a class="googleplus share-button t-googleplus" target="_blank" aria-label="Share this secton on Google Plus" title="Share this secton on Google Plus" href="https://plus.google.com/share?url=https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html"><span>Google Plus</span></a></li><li class=""><a class="email share-button t-email" aria-label="Share this section via email" title="Share this section via email" href="mailto:?subject=Safari:%2010.%20Introduction%20to%20Artificial%20Neural%20Networks&amp;body=https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html%0D%0Afrom%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow%0D%0A"><span>Email</span></a></li></ul></li>
      </ul>
    </div>

    <section role="document">
	  <div class="t-sbo-prev sbo-prev sbo-nav-top">
  
    
      
        <a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch16.html" class="prev nav-link">
      
          <span aria-hidden="true" class="pagination-label t-prev-label">Prev</span>
          <span class="visuallyhidden">Previous Chapter</span>
          <div class="pagination-title t-prev-title">16. Reinforcement Learning</div>
        </a>
    
  
  </div>

  <div class="t-sbo-next sbo-next sbo-nav-top">
  
    
      
        <a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app02.html" class="next nav-link">
      
          <span aria-hidden="true" class="pagination-label t-next-label">Next</span>
          <span class="visuallyhidden">Next Chapter</span>
          <div class="pagination-title t-next-title">B. Machine Learning Project Checklist</div>
        </a>
    
  
  </div>



<div id="sbo-rt-content"><div class="annotator-wrapper"><section data-type="appendix" epub:type="appendix" data-pdf-bookmark="Appendix A. Exercise Solutions"><div class="appendix" id="solutions_appendix">
<h1><span class="label">Appendix A. </span>Exercise Solutions</h1>

<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Solutions to the coding exercises are available in the online Jupyter notebooks at <a href="https://github.com/ageron/handson-ml"><em class="hyperlink">https://github.com/ageron/handson-ml</em></a>.</p>
</div>






<section data-type="sect1" data-pdf-bookmark="Chapter&nbsp;1: The Machine Learning Landscape"><div class="sect1" id="idm140582979242816">
<h1><a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch01.html#landscape_chapter">Chapter&nbsp;1</a>: The Machine Learning Landscape</h1>
<ol>
<li>
<p>Machine Learning is about building systems that can learn from data. 
Learning means getting better at some task, given some performance 
measure.</p>
</li>
<li>
<p>Machine Learning is great for complex problems for which we have no 
algorithmic solution, to replace long lists of hand-tuned rules, to 
build systems that adapt to fluctuating environments, and finally to 
help humans learn (e.g., data mining).</p>
</li>
<li>
<p>A labeled training set is a training set that contains the desired solution (a.k.a. a label) for each instance.</p>
</li>
<li>
<p>The two most common supervised tasks are regression and classification.</p>
</li>
<li>
<p>Common unsupervised tasks include clustering, visualization, dimensionality reduction, and association rule learning.</p>
</li>
<li>
<p>Reinforcement Learning is likely to perform best if we want a robot 
to learn to walk in various unknown terrains since this is typically the
 type of problem that Reinforcement Learning tackles. It might be 
possible to express the problem as a supervised or semisupervised 
learning problem, but it would be less natural.</p>
</li>
<li>
<p>If you don’t know how to define the groups, then you can use a 
clustering algorithm (unsupervised learning) to segment your customers 
into clusters of similar customers. However, if you know what groups you
 would like to have, then you can feed many examples of each group to a 
classification algorithm (supervised learning), and it will classify all
 your customers into these groups.</p>
</li>
<li>
<p>Spam detection is a typical supervised learning problem: the 
algorithm is fed many emails along with their label (spam or not spam).</p>
</li>
<li>
<p>An online learning system can learn incrementally, as opposed to a 
batch learning system. This makes it capable of adapting rapidly to both
 changing data and autonomous systems, and of training on very large 
quantities of data.</p>
</li>
<li>
<p>Out-of-core algorithms can handle vast quantities of data that cannot
 fit in a computer’s main memory. An out-of-core learning algorithm 
chops the data into mini-batches and uses online learning techniques to 
learn from these mini-batches.</p>
</li>
<li>
<p>An instance-based learning system learns the training data by heart; 
then, when given a new instance, it uses a similarity measure to find 
the most similar learned instances and uses them to make predictions.</p>
</li>
<li>
<p>A model has one or more model parameters that determine what it will 
predict given a new instance (e.g., the slope of a linear model). A 
learning algorithm tries to find optimal values for these parameters 
such that the model generalizes well to new instances. A hyperparameter 
is a parameter of the learning algorithm itself, not of the model (e.g.,
 the amount of regularization to apply).</p>
</li>
<li>
<p>Model-based learning algorithms search for an optimal value for the 
model parameters such that the model will generalize well to new 
instances. We usually train such systems by minimizing a cost function 
that measures how bad the system is at making predictions on the 
training data, plus a penalty for model complexity if the model is 
regularized. To make predictions, we feed the new instance’s features 
into the model’s prediction function, using the parameter values found 
by the learning algorithm.</p>
</li>
<li>
<p>Some of the main challenges in Machine Learning are the lack of data,
 poor data quality, nonrepresentative data, uninformative features, 
excessively simple models that underfit the training data, and 
excessively complex models that overfit the data.</p>
</li>
<li>
<p>If a model performs great on the training data but generalizes poorly
 to new instances, the model is likely overfitting the training data (or
 we got extremely lucky on the training data). Possible solutions to 
overfitting are getting more data, simplifying the model (selecting a 
simpler algorithm, reducing the number of parameters or features used, 
or regularizing the model), or reducing the noise in the training data.</p>
</li>
<li>
<p>A test set is used to estimate the generalization error that a model 
will make on new instances, before the model is launched in production.</p>
</li>
<li>
<p>A validation set is used to compare models. It makes it possible to select the best model and tune the hyperparameters.</p>
</li>
<li>
<p>If you tune hyperparameters using the test set, you risk overfitting 
the test set, and the generalization error you measure will be 
optimistic (you may launch a model that performs worse than you expect).</p>
</li>
<li>
<p>Cross-validation is a technique that makes it possible to compare 
models (for model selection and hyperparameter tuning) without the need 
for a separate validation set. This saves precious training data.</p>
</li>

</ol>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Chapter&nbsp;2: End-to-End Machine Learning Project"><div class="sect1" id="idm140582979219360">
<h1><a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch02.html#project_chapter">Chapter&nbsp;2</a>: End-to-End Machine Learning Project</h1>

<p>See the Jupyter notebooks available at <a href="https://github.com/ageron/handson-ml"><em class="hyperlink">https://github.com/ageron/handson-ml</em></a>.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Chapter&nbsp;3: Classification"><div class="sect1" id="idm140582979215904">
<h1><a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch03.html#classification_chapter">Chapter&nbsp;3</a>: Classification</h1>

<p>See the Jupyter notebooks available at <a href="https://github.com/ageron/handson-ml"><em class="hyperlink">https://github.com/ageron/handson-ml</em></a>.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Chapter&nbsp;4: Training Models"><div class="sect1" id="idm140582979212448">
<h1><a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch04.html#linear_models_chapter">Chapter&nbsp;4</a>: Training Models</h1>
<ol>
<li>
<p>If you have a training set with millions of features you can use 
Stochastic Gradient Descent or Mini-batch Gradient Descent, and perhaps 
Batch Gradient Descent if the training set fits in memory. But you 
cannot use the Normal Equation because the computational complexity 
grows quickly (more than quadratically) with the number of features.</p>
</li>
<li>
<p>If the features in your training set have very different scales, the 
cost function will have the shape of an elongated bowl, so the Gradient 
Descent algorithms will take a long time to converge. To solve this you 
should scale the data before training the model. Note that the Normal 
Equation will work just fine without scaling. Moreover, regularized 
models may converge to a suboptimal solution if the features are not 
scaled: indeed, since regularization penalizes large weights, features 
with smaller values will tend to be ignored compared to features with 
larger values.</p>
</li>
<li>
<p>Gradient Descent cannot get stuck in a local minimum when training a 
Logistic Regression model because the cost function is convex.<sup><a data-type="noteref" id="idm140582979206640-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app01.html#idm140582979206640" class="totri-footnote">1</a></sup></p>
</li>
<li>
<p>If the optimization problem is convex (such as Linear Regression or 
Logistic Regression), and assuming the learning rate is not too high, 
then all Gradient Descent algorithms will approach the global optimum 
and end up producing fairly similar models. However, unless you 
gradually reduce the learning rate, Stochastic GD and Mini-batch GD will
 never truly converge; instead, they will keep jumping back and forth 
around the global optimum. This means that even if you let them run for a
 very long time, these Gradient Descent algorithms will produce slightly
 different models.</p>
</li>
<li>
<p>If the validation error consistently goes up after every epoch, then 
one possibility is that the learning rate is too high and the algorithm 
is diverging. If the training error also goes up, then this is clearly 
the problem and you should reduce the learning rate. However, if the 
training error is not going up, then your model is overfitting the 
training set and you should stop training.</p>
</li>
<li>
<p>Due to their random nature, neither Stochastic Gradient Descent nor 
Mini-batch Gradient Descent is guaranteed to make progress at every 
single training iteration. So if you immediately stop training when the 
validation error goes up, you may stop much too early, before the 
optimum is reached. A better option is to save the model at regular 
intervals, and when it has not improved for a long time (meaning it will
 probably never beat the record), you can revert to the best saved 
model.</p>
</li>
<li>
<p>Stochastic Gradient Descent has the fastest training iteration since 
it considers only one training instance at a time, so it is generally 
the first to reach the vicinity of the global optimum (or Mini-batch GD 
with a very small mini-batch size). However, only Batch Gradient Descent
 will actually converge, given enough training time. As mentioned, 
Stochastic GD and Mini-batch GD will bounce around the optimum, unless 
you gradually reduce the learning rate.</p>
</li>
<li>
<p>If the validation error is much higher than the training error, this 
is likely because your model is overfitting the training set. One way to
 try to fix this is to reduce the polynomial degree: a model with fewer 
degrees of freedom is less likely to overfit. Another thing you can try 
is to regularize the model—for example, by adding an ℓ<sub>2</sub> penalty (Ridge) or an ℓ<sub>1</sub>
 penalty (Lasso) to the cost function. This will also reduce the degrees
 of freedom of the model. Lastly, you can try to increase the size of 
the training set.</p>
</li>
<li>
<p>If both the training error and the validation error are almost equal 
and fairly high, the model is likely underfitting the training set, 
which means it has a high bias. You should try reducing the 
regularization hyperparameter <em>α</em>.</p>
</li>
<li>
<p>Let’s see:</p>

<ul>
<li>
<p>A model with some regularization typically performs better than a 
model without any regularization, so you should generally prefer Ridge 
Regression over plain Linear Regression.<sup><a data-type="noteref" id="idm140582979194560-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app01.html#idm140582979194560" class="totri-footnote">2</a></sup></p>
</li>
<li>
<p>Lasso Regression uses an ℓ<sub>1</sub> penalty, which tends to push 
the weights down to exactly zero. This leads to sparse models, where all
 weights are zero except for the most important weights. This is a way 
to perform feature selection automatically, which is good if you suspect
 that only a few features actually matter. When you are not sure, you 
should prefer Ridge Regression.</p>
</li>
<li>
<p>Elastic Net is generally preferred over Lasso since Lasso may behave 
erratically in some cases (when several features are strongly correlated
 or when there are more features than training instances). However, it 
does add an extra hyperparameter to tune. If you just want Lasso without
 the erratic behavior, you can just use Elastic Net with an <code>l1_ratio</code> close to 1.</p>
</li>
</ul>
</li>
<li>
<p>If you want to classify pictures as outdoor/indoor and 
daytime/nighttime, since these are not exclusive classes (i.e., all four
 combinations are possible) you should train two Logistic Regression 
classifiers.</p>
</li>
<li>
<p>See the Jupyter notebooks available at <a href="https://github.com/ageron/handson-ml"><em class="hyperlink">https://github.com/ageron/handson-ml</em></a>.</p>
</li>

</ol>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Chapter&nbsp;5: Support Vector Machines"><div class="sect1" id="idm140582979186672">
<h1><a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch05.html#svm_chapter">Chapter&nbsp;5</a>: Support Vector Machines</h1>
<ol>
<li>
<p>The fundamental idea behind Support Vector Machines is to fit the 
widest possible “street” between the classes. In other words, the goal 
is to have the largest possible margin between the decision boundary 
that separates the two classes and the training instances. When 
performing soft margin classification, the SVM searches for a compromise
 between perfectly separating the two classes and having the widest 
possible street (i.e., a few instances may end up on the street). 
Another key idea is to use kernels when training on nonlinear datasets.</p>
</li>
<li>
<p>After training an SVM, a <em>support vector</em> is any instance 
located on the “street” (see the previous answer), including its border.
 The decision boundary is entirely determined by the support vectors. 
Any instance that is <em>not</em> a support vector (i.e., off the 
street) has no influence whatsoever; you could remove them, add more 
instances, or move them around, and as long as they stay off the street 
they won’t affect the decision boundary. Computing the predictions only 
involves the support vectors, not the whole training set.</p>
</li>
<li>
<p>SVMs try to fit the largest possible “street” between the classes 
(see the first answer), so if the training set is not scaled, the SVM 
will tend to neglect small features (see <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch05.html#sensitivity_to_feature_scales_plot">Figure&nbsp;5-2</a>).</p>
</li>
<li>
<p>An SVM classifier can output the distance between the test instance 
and the decision boundary, and you can use this as a confidence score. 
However, this score cannot be directly converted into an estimation of 
the class probability. If you set <code>probability=True</code> when 
creating an SVM in Scikit-Learn, then after training it will calibrate 
the probabilities using Logistic Regression on the SVM’s scores (trained
 by an additional five-fold cross-validation on the training data). This
 will add the <code>predict_proba()</code> and <code>predict_log_proba()</code> methods to the SVM.</p>
</li>
<li>
<p>This question applies only to linear SVMs since kernelized can only 
use the dual form. The computational complexity of the primal form of 
the SVM problem is proportional to the number of training instances <em>m</em>, while the computational complexity of the dual form is proportional to a number between <em>m</em><sup>2</sup> and <em>m</em><sup>3</sup>. So if there are millions of instances, you should definitely use the primal form, because the dual form will be much too slow.</p>
</li>
<li>
<p>If an SVM classifier trained with an RBF kernel underfits the 
training set, there might be too much regularization. To decrease it, 
you need to increase <code>gamma</code> or <code>C</code> (or both).</p>
</li>
<li>
<p>Let’s call the QP parameters for the hard-margin problem <strong>H</strong>′, <strong>f</strong>′, <strong>A</strong>′ and <strong>b</strong>′ (see <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch05.html#quadratic_programming_paragraph">“Quadratic Programming”</a>). The QP parameters for the soft-margin problem have <em>m</em> additional parameters (<em>n</em><sub><em>p</em></sub> = <em>n</em> + 1 + <em>m</em>) and <em>m</em> additional constraints (<em>n</em><sub><em>c</em></sub> = 2<em>m</em>). They can be defined like so:</p>

<ul>
<li>
<p><strong>H</strong> is equal to <strong>H</strong>′, plus <em>m</em> columns of 0s on the right and <em>m</em> rows of 0s at the bottom: <img src="A.%20Exercise%20Solutions%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_147.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_147.png" width="61" height="30"></p>
</li>
<li>
<p><strong>f</strong> is equal to <strong>f</strong>′ with <em>m</em> additional elements, all equal to the value of the hyperparameter <em>C</em>.</p>
</li>
<li>
<p><strong>b</strong> is equal to <strong>b</strong>′ with <em>m</em> additional elements, all equal to 0.</p>
</li>
<li>
<p><strong>A</strong> is equal to <strong>A</strong>′, with an extra <em>m</em> × <em>m</em> identity matrix <strong>I</strong><sub><em>m</em></sub> appended to the right, – <strong>I</strong><sub><em>m</em></sub> just below it, and the rest filled with zeros: <img src="A.%20Exercise%20Solutions%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_148.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_148.png" width="72" height="30"></p>
</li>
</ul>
</li>

</ol>

<p>For the solutions to exercises 8, 9, and 10, please see the Jupyter notebooks available at <a href="https://github.com/ageron/handson-ml"><em class="hyperlink">https://github.com/ageron/handson-ml</em></a>.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Chapter&nbsp;6: Decision Trees"><div class="sect1" id="idm140582979149136">
<h1><a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch06.html#trees_chapter">Chapter&nbsp;6</a>: Decision Trees</h1>
<ol>
<li>
<p>The depth of a well-balanced binary tree containing <em>m</em> leaves is equal to log<sub>2</sub>(<em>m</em>)<sup><a data-type="noteref" id="idm140582979144768-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app01.html#idm140582979144768" class="totri-footnote">3</a></sup>,
 rounded up. A binary Decision Tree (one that makes only binary 
decisions, as is the case of all trees in Scikit-Learn) will end up more
 or less well balanced at the end of training, with one leaf per 
training instance if it is trained without restrictions. Thus, if the 
training set contains one million instances, the Decision Tree will have
 a depth of log<sub>2</sub>(10<sup>6</sup>) ≈ 20 (actually a bit more since the tree will generally not be perfectly well balanced).</p>
</li>
<li>
<p>A node’s Gini impurity is generally lower than its parent’s. This is 
due to the CART training algorithm’s cost function, which splits each 
node in a way that minimizes the weighted sum of its children’s Gini 
impurities. However, it is possible for a node to have a higher Gini 
impurity than its parent, as long as this increase is more than 
compensated for by a decrease of the other child’s impurity. For 
example, consider a node containing four instances of class A and 1 of 
class B. Its Gini impurity is <img src="A.%20Exercise%20Solutions%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_149.png" alt="1 minus one-fifth squared minus four-fifths squared" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_149.png" width="99" height="30">
 = 0.32. Now suppose the dataset is one-dimensional and the instances 
are lined up in the following order: A, B, A, A, A. You can verify that 
the algorithm will split this node after the second instance, producing 
one child node with instances A, B, and the other child node with 
instances A, A, A. The first child node’s Gini impurity is <img src="A.%20Exercise%20Solutions%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_150.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_150.png" width="100" height="30">
 = 0.5, which is higher than its parent. This is compensated for by the 
fact that the other node is pure, so the overall weighted Gini impurity 
is <img src="A.%20Exercise%20Solutions%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_151.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_151.png" width="36" height="30"> 0.5 + <img src="A.%20Exercise%20Solutions%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_152.png" alt="three-fifths times 0" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_152.png" width="54" height="30"> = 0.2 , which is lower than the parent’s Gini impurity.</p>
</li>
<li>
<p>If a Decision Tree is overfitting the training set, it may be a good idea to decrease <code>max_depth</code>, since this will constrain the model, regularizing it.</p>
</li>
<li>
<p>Decision Trees don’t care whether or not the training data is scaled 
or centered; that’s one of the nice things about them. So if a Decision 
Tree underfits the training set, scaling the input features will just be
 a waste of time.</p>
</li>
<li>
<p>The computational complexity of training a Decision Tree is <em>O</em>(<em>n</em> × <em>m</em> log(<em>m</em>)). So if you multiply the training set size by 10, the training time will be multiplied by <em>K</em> = (<em>n</em> × 10<em>m</em> × log(10<em>m</em>)) / (<em>n</em> × <em>m</em> × log(<em>m</em>)) = 10 × log(10<em>m</em>) / log(<em>m</em>). If <em>m</em> = 10<sup>6</sup>, then <em>K</em> ≈ 11.7, so you can expect the training time to be roughly 11.7 hours.</p>
</li>
<li>
<p>Presorting the training set speeds up training only if the dataset is
 smaller than a few thousand instances. If it contains 100,000 
instances, setting <code>presort=True</code> will considerably slow down training.</p>
</li>

</ol>

<p>For the solutions to exercises 7 and 8, please see the Jupyter notebooks available at <a href="https://github.com/ageron/handson-ml"><em class="hyperlink">https://github.com/ageron/handson-ml</em></a>.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Chapter&nbsp;7: Ensemble Learning and Random Forests"><div class="sect1" id="idm140582979122416">
<h1><a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch07.html#ensembles_chapter">Chapter&nbsp;7</a>: Ensemble Learning and Random Forests</h1>
<ol>
<li>
<p>If you have trained five different models and they all achieve 95% 
precision, you can try combining them into a voting ensemble, which will
 often give you even better results. It works better if the models are 
very different (e.g., an SVM classifier, a Decision Tree classifier, a 
Logistic Regression classifier, and so on). It is even better if they 
are trained on different training instances (that’s the whole point of 
bagging and pasting ensembles), but if not it will still work as long as
 the models are very different.</p>
</li>
<li>
<p>A hard voting classifier just counts the votes of each classifier in 
the ensemble and picks the class that gets the most votes. A soft voting
 classifier computes the average estimated class probability for each 
class and picks the class with the highest probability. This gives 
high-confidence votes more weight and often performs better, but it 
works only if every classifier is able to estimate class probabilities 
(e.g., for the SVM classifiers in Scikit-Learn you must set <code>probability=True</code>).</p>
</li>
<li>
<p>It is quite possible to speed up training of a bagging ensemble by 
distributing it across multiple servers, since each predictor in the 
ensemble is independent of the others. The same goes for pasting 
ensembles and Random Forests, for the same reason. However, each 
predictor in a boosting ensemble is built based on the previous 
predictor, so training is necessarily sequential, and you will not gain 
anything by distributing training across multiple servers. Regarding 
stacking ensembles, all the predictors in a given layer are independent 
of each other, so they can be trained in parallel on multiple servers. 
However, the predictors in one layer can only be trained after the 
predictors in the previous layer have all been trained.</p>
</li>
<li>
<p>With out-of-bag evaluation, each predictor in a bagging ensemble is 
evaluated using instances that it was not trained on (they were held 
out). This makes it possible to have a fairly unbiased evaluation of the
 ensemble without the need for an additional validation set. Thus, you 
have more instances available for training, and your ensemble can 
perform slightly better.</p>
</li>
<li>
<p>When you are growing a tree in a Random Forest, only a random subset 
of the features is considered for splitting at each node. This is true 
as well for Extra-Trees, but they go one step further: rather than 
searching for the best possible thresholds, like regular Decision Trees 
do, they use random thresholds for each feature. This extra randomness 
acts like a form of regularization: if a Random Forest overfits the 
training data, Extra-Trees might perform better. Moreover, since 
Extra-Trees don’t search for the best possible thresholds, they are much
 faster to train than Random Forests. However, they are neither faster 
nor slower than Random Forests when making predictions.</p>
</li>
<li>
<p>If your AdaBoost ensemble underfits the training data, you can try 
increasing the number of estimators or reducing the regularization 
hyperparameters of the base estimator. You may also try slightly 
increasing the learning rate.</p>
</li>
<li>
<p>If your Gradient Boosting ensemble overfits the training set, you 
should try decreasing the learning rate. You could also use early 
stopping to find the right number of predictors (you probably have too 
many).</p>
</li>

</ol>

<p>For the solutions to exercises 8 and 9, please see the Jupyter notebooks available at <a href="https://github.com/ageron/handson-ml"><em class="hyperlink">https://github.com/ageron/handson-ml</em></a>.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Chapter&nbsp;8: Dimensionality Reduction"><div class="sect1" id="idm140582979108608">
<h1><a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch08.html#dim_reduction_chapter">Chapter&nbsp;8</a>: Dimensionality Reduction</h1>
<ol>
<li>
<p>Motivations and drawbacks:</p>

<ul>
<li>
<p>The main motivations for dimensionality reduction are:</p>

<ul>
<li>
<p>To speed up a subsequent training algorithm (in some cases it may 
even remove noise and redundant features, making the training algorithm 
perform better).</p>
</li>
<li>
<p>To visualize the data and gain insights on the most important features.</p>
</li>
<li>
<p>Simply to save space (compression).</p>
</li>
</ul>
</li>
<li>
<p>The main drawbacks are:</p>

<ul>
<li>
<p>Some information is lost, possibly degrading the performance of subsequent training algorithms.</p>
</li>
<li>
<p>It can be computationally intensive.</p>
</li>
<li>
<p>It adds some complexity to your Machine Learning pipelines.</p>
</li>
<li>
<p>Transformed features are often hard to interpret.</p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>The curse of dimensionality refers to the fact that many problems 
that do not exist in low-dimensional space arise in high-dimensional 
space. In Machine Learning, one common manifestation is the fact that 
randomly sampled high-dimensional vectors are generally very sparse, 
increasing the risk of overfitting and making it very difficult to 
identify patterns in the data without having plenty of training data.</p>
</li>
<li>
<p>Once a dataset’s dimensionality has been reduced using one of the 
algorithms we discussed, it is almost always impossible to perfectly 
reverse the operation, because some information gets lost during 
dimensionality reduction. Moreover, while some algorithms (such as PCA) 
have a simple reverse transformation procedure that can reconstruct a 
dataset relatively similar to the original, other algorithms (such as 
T-SNE) do not.</p>
</li>
<li>
<p>PCA can be used to significantly reduce the dimensionality of most 
datasets, even if they are highly nonlinear, because it can at least get
 rid of useless dimensions. However, if there are no useless 
dimensions—for example, the Swiss roll—then reducing dimensionality with
 PCA will lose too much information. You want to unroll the Swiss roll, 
not squash it.</p>
</li>
<li>
<p>That’s a trick question: it depends on the dataset. Let’s look at two
 extreme examples. First, suppose the dataset is composed of points that
 are almost perfectly aligned. In this case, PCA can reduce the dataset 
down to just one dimension while still preserving 95% of the variance. 
Now imagine that the dataset is composed of perfectly random points, 
scattered all around the 1,000 dimensions. In this case roughly 950 
dimensions are required to preserve 95% of the variance. So the answer 
is, it depends on the dataset, and it could be any number between 1 and 
950. Plotting the explained variance as a function of the number of 
dimensions is one way to get a rough idea of the dataset’s intrinsic 
dimensionality.</p>
</li>
<li>
<p>Regular PCA is the default, but it works only if the dataset fits in 
memory. Incremental PCA is useful for large datasets that don’t fit in 
memory, but it is slower than regular PCA, so if the dataset fits in 
memory you should prefer regular PCA. Incremental PCA is also useful for
 online tasks, when you need to apply PCA on the fly, every time a new 
instance arrives. Randomized PCA is useful when you want to considerably
 reduce dimensionality and the dataset fits in memory; in this case, it 
is much faster than regular PCA. Finally, Kernel PCA is useful for 
nonlinear datasets.</p>
</li>
<li>
<p>Intuitively, a dimensionality reduction algorithm performs well if it
 eliminates a lot of dimensions from the dataset without losing too much
 information. One way to measure this is to apply the reverse 
transformation and measure the reconstruction error. However, not all 
dimensionality reduction algorithms provide a reverse transformation. 
Alternatively, if you are using dimensionality reduction as a 
preprocessing step before another Machine Learning algorithm (e.g., a 
Random Forest classifier), then you can simply measure the performance 
of that second algorithm; if dimensionality reduction did not lose too 
much information, then the algorithm should perform just as well as when
 using the original dataset.</p>
</li>
<li>
<p>It can absolutely make sense to chain two different dimensionality 
reduction algorithms. A common example is using PCA to quickly get rid 
of a large number of useless dimensions, then applying another much 
slower dimensionality reduction algorithm, such as LLE. This two-step 
approach will likely yield the same performance as using LLE only, but 
in a fraction of the time.</p>
</li>

</ol>

<p>For the solutions to exercises 9 and 10, please see the Jupyter notebooks available at <a href="https://github.com/ageron/handson-ml"><em class="hyperlink">https://github.com/ageron/handson-ml</em></a>.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Chapter&nbsp;9: Up and Running with TensorFlow"><div class="sect1" id="idm140582979083936">
<h1><a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch09.html#tensorflow_chapter">Chapter&nbsp;9</a>: Up and Running with TensorFlow</h1>
<ol>
<li>
<p>Main benefits and drawbacks of creating a computation graph rather than directly executing the computations:</p>

<ul>
<li>
<p>Main benefits:</p>

<ul>
<li>
<p>TensorFlow can automatically compute the gradients for you (using reverse-mode autodiff).</p>
</li>
<li>
<p>TensorFlow can take care of running the operations in parallel in different threads.</p>
</li>
<li>
<p>It makes it easier to run the same model across different devices.</p>
</li>
<li>
<p>It simplifies introspection—for example, to view the model in TensorBoard.</p>
</li>
</ul>
</li>
<li>
<p>Main drawbacks:</p>

<ul>
<li>
<p>It makes the learning curve steeper.</p>
</li>
<li>
<p>It makes step-by-step debugging harder.</p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Yes, the statement <code>a_val</code> <code>=</code> <code>a.eval(session=sess)</code> is indeed equivalent to <code>a_val</code> <code>=</code> <code>sess.run(a)</code>.</p>
</li>
<li>
<p>No, the statement <code>a_val, b_val</code> <code>=</code> <code>a.eval(session=sess), b.eval(session=sess)</code> is not equivalent to <code>a_val, b_val</code> <code>=</code> <code>sess.run([a, b])</code>. Indeed, the first statement runs the graph twice (once to compute <code>a</code>, once to compute <code>b</code>),
 while the second statement runs the graph only once. If any of these 
operations (or the ops they depend on) have side effects (e.g., a 
variable is modified, an item is inserted in a queue, or a reader reads a
 file), then the effects will be different. If they don’t have side 
effects, both statements will return the same result, but the second 
statement will be faster than the first.</p>
</li>
<li>
<p>No, you cannot run two graphs in the same session. You would have to merge the graphs into a single graph first.</p>
</li>
<li>
<p>In local TensorFlow, sessions manage variable values, so if you create a graph <code>g</code> containing a variable <code>w</code>, then start two threads and open a local session in each thread, both using the same graph <code>g</code>, then each session will have its own copy of the variable <code>w</code>.
 However, in distributed TensorFlow, variable values are stored in 
containers managed by the cluster, so if both sessions connect to the 
same cluster and use the same <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.container()" id="idm140582979059120"></a>container, then they will share the same variable value for <code>w</code>.</p>
</li>
<li>
<p>A variable is initialized when you call its initializer, and it is 
destroyed when the session ends. In distributed TensorFlow, variables 
live in containers on the cluster, so closing a session will not destroy
 the variable. To destroy a variable, you need to clear its container.</p>
</li>
<li>
<p>Variables and placeholders are extremely different, but beginners often confuse them:</p>

<ul>
<li>
<p>A variable is an operation that holds a value. If you run the 
variable, it returns that value. Before you can run it, you need to 
initialize it. You can change the variable’s value (for example, by 
using an assignment operation). It is stateful: the variable keeps the 
same value upon successive runs of the graph. It is typically used to 
hold model parameters but also for other purposes (e.g., to count the 
global training step).</p>
</li>
<li>
<p>Placeholders technically don’t do much: they just hold information 
about the type and shape of the tensor they represent, but they have no 
value. In fact, if you try to evaluate an operation that depends on a 
placeholder, you must feed TensorFlow the value of the placeholder 
(using the <code>feed_dict</code> argument) or else you will get an 
exception. Placeholders are typically used to feed training or test data
 to TensorFlow during the execution phase. They are also useful to pass a
 value to an assignment node, to change the value of a variable (e.g., 
model weights).</p>
</li>
</ul>
</li>
<li>
<p>If you run the graph to evaluate an operation that depends on a 
placeholder but you don’t feed its value, you get an exception. If the 
operation does not depend on the placeholder, then no exception is 
raised.</p>
</li>
<li>
<p>When you run a graph, you can feed the output value of any operation,
 not just the value of placeholders. In practice, however, this is 
rather rare (it can be useful, for example, when you are caching the 
output of frozen layers; see <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#deep_chapter">Chapter&nbsp;11</a>).</p>
</li>
<li>
<p>You can specify a variable’s initial value when constructing the 
graph, and it will be initialized later when you run the variable’s 
initializer during the execution phase. If you want to change that 
variable’s value to anything you want during the execution phase, then 
the simplest option is to create an assignment node (during the graph 
construction phase) using the <code>tf.assign()</code> function, <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.assign()" id="idm140582979047056"></a>passing
 the variable and a placeholder as parameters. During the execution 
phase, you can run the assignment operation and feed the variable’s new 
value using the <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.random_uniform()" id="idm140582979045744"></a> <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.Variable" id="idm140582979044672"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.float32" id="idm140582979043696"></a> <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.placeholder()" id="idm140582979042624"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.Session" id="idm140582979041648"></a>placeholder.</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">import</code> <code class="nn">tensorflow</code> <code class="kn">as</code> <code class="nn">tf</code>

<code class="n">x</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">Variable</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">random_uniform</code><code class="p">(</code><code class="n">shape</code><code class="o">=</code><code class="p">(),</code> <code class="n">minval</code><code class="o">=</code><code class="mf">0.0</code><code class="p">,</code> <code class="n">maxval</code><code class="o">=</code><code class="mf">1.0</code><code class="p">))</code>
<code class="n">x_new_val</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">placeholder</code><code class="p">(</code><code class="n">shape</code><code class="o">=</code><code class="p">(),</code> <code class="n">dtype</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">)</code>
<code class="n">x_assign</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">assign</code><code class="p">(</code><code class="n">x</code><code class="p">,</code> <code class="n">x_new_val</code><code class="p">)</code>

<code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">Session</code><code class="p">():</code>
    <code class="n">x</code><code class="o">.</code><code class="n">initializer</code><code class="o">.</code><code class="n">run</code><code class="p">()</code> <code class="c1"># random number is sampled *now*</code>
    <code class="k">print</code><code class="p">(</code><code class="n">x</code><code class="o">.</code><code class="n">eval</code><code class="p">())</code> <code class="c1"># 0.646157 (some random number)</code>
    <code class="n">x_assign</code><code class="o">.</code><code class="n">eval</code><code class="p">(</code><code class="n">feed_dict</code><code class="o">=</code><code class="p">{</code><code class="n">x_new_val</code><code class="p">:</code> <code class="mf">5.0</code><code class="p">})</code>
    <code class="k">print</code><code class="p">(</code><code class="n">x</code><code class="o">.</code><code class="n">eval</code><code class="p">())</code> <code class="c1"># 5.0</code></pre>
</li>
<li>
<p>Reverse-mode autodiff (implemented by TensorFlow) needs to traverse 
the graph only twice in order to compute the gradients of the cost 
function with regards to any number of variables. On the other hand, 
forward-mode autodiff would need to run once for each variable (so 10 
times if we want the gradients with regards to 10 different variables). 
As for symbolic differentiation, it would build a different graph to 
compute the gradients, so it would not traverse the original graph at 
all (except when building the new gradients graph). A highly optimized 
symbolic differentiation system could potentially run the new gradients 
graph only once to compute the gradients with regards to all variables, 
but that new graph may be horribly complex and inefficient compared to 
the original graph.</p>
</li>
<li>
<p>See the Jupyter notebooks available at <a href="https://github.com/ageron/handson-ml"><em class="hyperlink">https://github.com/ageron/handson-ml</em></a>.</p>
</li>

</ol>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Chapter&nbsp;10: Introduction to Artificial Neural Networks"><div class="sect1" id="idm140582978782752">
<h1><a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html#ann_chapter">Chapter&nbsp;10</a>: Introduction to Artificial Neural Networks</h1>
<ol>
<li>
<p>Here is a neural network based on the original artificial neurons that computes <em>A</em> ⊕ <em>B</em> (where ⊕ represents the exclusive OR), using the fact that <em>A</em> ⊕ <em>B</em> = (<em>A</em> ∧ ¬ <em>B</em>) ∨ (¬ <em>A</em> ∧ <em>B</em>). There are other solutions—for example, using the fact that <em>A</em> ⊕ <em>B</em> = (<em>A</em> ∨ <em>B</em>) ∧ ¬(<em>A</em> ∧ <em>B</em>), or the fact that <em>A</em> ⊕ <em>B</em> = (<em>A</em> ∨ <em>B</em>) ∧ (¬ <em>A</em> ∨ ∧ <em>B</em>), and so on.</p>

<figure><div class="figure">
<img src="A.%20Exercise%20Solutions%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/mlst_aain01.png" alt="mlst aain01" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_aain01.png" width="1440" height="649">
<h6></h6>
</div></figure>
</li>
<li>
<p>A classical Perceptron will converge only if the dataset is linearly 
separable, and it won’t be able to estimate class probabilities. In 
contrast, a Logistic Regression classifier will converge to a good 
solution even if the dataset is not linearly separable, and it will 
output class probabilities. If you change the Perceptron’s activation 
function to the logistic activation function (or the softmax activation 
function if there are multiple neurons), and if you train it using 
Gradient Descent (or some other optimization algorithm minimizing the 
cost function, typically cross entropy), then it becomes equivalent to a
 Logistic Regression classifier.</p>
</li>
<li>
<p>The logistic activation function was a key ingredient in training the
 first MLPs because its derivative is always nonzero, so Gradient 
Descent can always roll down the slope. When the activation function is a
 step function, Gradient Descent cannot move, as there is no slope at 
all.</p>
</li>
<li>
<p>The step function, the logistic function, the hyperbolic tangent, the rectified linear unit (see <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html#activation_functions_plot">Figure&nbsp;10-8</a>). See <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#deep_chapter">Chapter&nbsp;11</a> for other examples, such as ELU and variants of the ReLU.</p>
</li>
<li>
<p>Considering the MLP described in the question: suppose you have an 
MLP composed of one input layer with 10 passthrough neurons, followed by
 one hidden layer with 50 artificial neurons, and finally one output 
layer with 3 artificial neurons. All artificial neurons use the ReLU 
activation function.</p>

<ul>
<li>
<p>The shape of the input matrix <strong>X</strong> is <em>m</em> × 10, where <em>m</em> represents the training batch size.</p>
</li>
<li>
<p>The shape of the hidden layer’s weight vector <strong>W</strong><sub><em>h</em></sub> is 10 × 50 and the length of its bias vector <strong>b</strong><sub><em>h</em></sub> is 50.</p>
</li>
<li>
<p>The shape of the output layer’s weight vector <strong>W</strong><sub><em>o</em></sub> is 50 × 3, and the length of its bias vector <strong>b</strong><sub><em>o</em></sub> is 3.</p>
</li>
<li>
<p>The shape of the network’s output matrix <strong>Y</strong> is <em>m</em> × 3.</p>
</li>
<li>
<p><strong>Y</strong> = ReLU(ReLU(<strong>X</strong> · <strong>W</strong><sub><em>h</em></sub> + <strong>b</strong><sub><em>h</em></sub>) · <strong>W</strong><sub><em>o</em></sub> + <strong>b</strong><sub><em>o</em></sub>).
 Recall that the ReLU function just sets every negative number in the 
matrix to zero. Also note that when you are adding a bias vector to a 
matrix, it is added to every single row in the matrix, which is called <em>broadcasting</em>.</p>
</li>
</ul>
</li>
<li>
<p>To classify email into spam or ham, you just need one neuron in the 
output layer of a neural network—for example, indicating the probability
 that the email is spam. You would typically use the logistic activation
 function in the output layer when estimating a probability. If instead 
you want to tackle MNIST, you need 10 neurons in the output layer, and 
you must replace the logistic function with the softmax activation 
function, which can handle multiple classes, outputting one probability 
per class. Now, if you want your neural network to predict housing 
prices like in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch02.html#project_chapter">Chapter&nbsp;2</a>, then you need one output neuron, using no activation function at all in the output layer.<sup><a data-type="noteref" id="idm140582978745024-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app01.html#idm140582978745024" class="totri-footnote">4</a></sup></p>
</li>
<li>
<p>Backpropagation is a technique used to train artificial neural 
networks. It first computes the gradients of the cost function with 
regards to every model parameter (all the weights and biases), and then 
it performs a Gradient Descent step using these gradients. This 
backpropagation step is typically performed thousands or millions of 
times, using many training batches, until the model parameters converge 
to values that (hopefully) minimize the cost function. To compute the 
gradients, backpropagation uses reverse-mode autodiff (although it 
wasn’t called that when backpropagation was invented, and it has been 
reinvented several times). Reverse-mode autodiff performs a forward pass
 through a computation graph, computing every node’s value for the 
current training batch, and then it performs a reverse pass, computing 
all the gradients at once (see <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app04.html#autodiff_appendix">Appendix&nbsp;D</a>
 for more details). So what’s the difference? Well, backpropagation 
refers to the whole process of training an artificial neural network 
using multiple backpropagation steps, each of which computes gradients 
and uses them to perform a Gradient Descent step. In contrast, 
reverse-mode autodiff is a simply a technique to compute gradients 
efficiently, and it happens to be used by backpropagation.</p>
</li>
<li>
<p>Here is a list of all the hyperparameters you can tweak in a basic 
MLP: the number of hidden layers, the number of neurons in each hidden 
layer, and the activation function used in each hidden layer and in the 
output layer.<sup><a data-type="noteref" id="idm140582978739264-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app01.html#idm140582978739264" class="totri-footnote">5</a></sup> In general, the ReLU activation function (or one of its variants; see <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#deep_chapter">Chapter&nbsp;11</a>)
 is a good default for the hidden layers. For the output layer, in 
general you will want the logistic activation function for binary 
classification, the softmax activation function for multiclass 
classification, or no activation function for regression.</p>

<p>If the MLP overfits the training data, you can try reducing the 
number of hidden layers and reducing the number of neurons per hidden 
layer.</p>
</li>
<li>
<p>See the Jupyter notebooks available at <a href="https://github.com/ageron/handson-ml"><em class="hyperlink">https://github.com/ageron/handson-ml</em></a>.</p>
</li>

</ol>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Chapter&nbsp;11: Training Deep Neural Nets"><div class="sect1" id="idm140582978731552">
<h1><a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#deep_chapter">Chapter&nbsp;11</a>: Training Deep Neural Nets</h1>
<ol>
<li>
<p>No, all weights should be sampled independently; they should not all 
have the same initial value. One important goal of sampling weights 
randomly is to break symmetries: if all the weights have the same 
initial value, even if that value is not zero, then symmetry is not 
broken (i.e., all neurons in a given layer are equivalent), and 
backpropagation will be unable to break it. Concretely, this means that 
all the neurons in any given layer will always have the same weights. 
It’s like having just one neuron per layer, and much slower. It is 
virtually impossible for such a configuration to converge to a good 
solution.</p>
</li>
<li>
<p>It is perfectly fine to initialize the bias terms to zero. Some 
people like to initialize them just like weights, and that’s okay too; 
it does not make much difference.</p>
</li>
<li>
<p>A few advantages of the ELU function over the ReLU function are:</p>

<ul>
<li>
<p>It can take on negative values, so the average output of the neurons 
in any given layer is typically closer to 0 than when using the ReLU 
activation function (which never outputs negative values). This helps 
alleviate the vanishing gradients problem.</p>
</li>
<li>
<p>It always has a nonzero derivative, which avoids the dying units issue that can affect ReLU units.</p>
</li>
<li>
<p>It is smooth everywhere, whereas the ReLU’s slope abruptly jumps from 0 to 1 at <em>z</em> = 0. Such an abrupt change can slow down Gradient Descent because it will bounce around <em>z</em> = 0.</p>
</li>
</ul>
</li>
<li>
<p>The ELU activation function is a good default. If you need the neural
 network to be as fast as possible, you can use one of the leaky ReLU 
variants instead (e.g., a simple leaky ReLU using the default 
hyperparameter value). The simplicity of the ReLU activation function 
makes it many people’s preferred option, despite the fact that they are 
generally outperformed by the ELU and leaky ReLU. However, the ReLU 
activation function’s capability of outputting precisely zero can be 
useful in some cases (e.g., see <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch15.html#autoencoders_chapter">Chapter&nbsp;15</a>).
 The hyperbolic tangent (tanh) can be useful in the output layer if you 
need to output a number between –1 and 1, but nowadays it is not used 
much in hidden layers. The logistic activation function is also useful 
in the output layer when you need to estimate a probability (e.g., for 
binary classification), but it is also rarely used in hidden layers 
(there are exceptions—for example, for the coding layer of variational 
autoencoders; see <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch15.html#autoencoders_chapter">Chapter&nbsp;15</a>).
 Finally, the softmax activation function is useful in the output layer 
to output probabilities for mutually exclusive classes, but other than 
that it is rarely (if ever) used in hidden layers.</p>
</li>
<li>
<p>If you set the <code>momentum</code> hyperparameter too close to 1 (e.g., 0.99999) when using a <code>MomentumOptimizer</code>,
 then the algorithm will likely pick up a lot of speed, hopefully 
roughly toward the global minimum, but then it will shoot right past the
 minimum, due to its <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.train.MomentumOptimizer" data-startref="tftrainmoappa" id="idm140582978716144"></a>momentum.
 Then it will slow down and come back, accelerate again, overshoot 
again, and so on. It may oscillate this way many times before 
converging, so overall it will take much longer to converge than with a 
smaller <code>momentum</code> value.</p>
</li>
<li>
<p>One way to produce a sparse model (i.e., with most weights equal to 
zero) is to train the model normally, then zero out tiny weights. For 
more sparsity, you can apply ℓ<sub>1</sub> regularization during training, which pushes the optimizer toward sparsity. A third option is to combine ℓ<sub>1</sub> regularization with <em>dual averaging</em>, using TensorFlow’s <code>FTRLOptimizer</code> class.</p>
</li>
<li>
<p>Yes, dropout does slow down training, in general roughly by a factor 
of two. However, it has no impact on inference since it is only turned 
on during training.</p>
</li>

</ol>

<p>For the solutions to exercises 8, 9, and 10, please see the Jupyter notebooks available at <a href="https://github.com/ageron/handson-ml"><em class="hyperlink">https://github.com/ageron/handson-ml</em></a>.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Chapter&nbsp;12: Distributing TensorFlow Across Devices and Servers"><div class="sect1" id="idm140582978708112">
<h1><a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch12.html#distributed_chapter">Chapter&nbsp;12</a>: Distributing TensorFlow Across Devices and Servers</h1>
<ol>
<li>
<p>When a TensorFlow process starts, it grabs all the available memory on all GPU devices that are visible to it, so if you get a <code>CUDA_ERROR_OUT_OF_MEMORY</code>
 when starting your TensorFlow program, it probably means that other 
processes are running that have already grabbed all the memory on at 
least one visible GPU device (most likely it is another TensorFlow 
process). To fix this problem, a trivial solution is to stop the other 
processes and try again. However, if you need all processes to run 
simultaneously, a simple option is to dedicate different devices to each
 process, by setting the <code>CUDA_VISIBLE_DEVICES</code> environment variable appropriately for each device. Another option is to configure <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.ConfigProto" id="idm140582978703616"></a>TensorFlow to grab only part of the GPU memory, instead of all of it, by creating a <code>ConfigProto</code>, setting its <code>gpu_options.per_process_gpu_memory_fraction</code> to the proportion of the total memory that it should grab (e.g., 0.4), and using this <code>ConfigProto</code> when opening a session. The last option is to tell TensorFlow to grab memory only when it needs it by setting the <code>gpu_options.allow_growth</code> to <code>True</code>.
 However, this last option is usually not recommended because any memory
 that TensorFlow grabs is never released, and it is harder to guarantee a
 repeatable behavior (there may be race conditions depending on which 
processes start first, how much memory they need during training, and so
 on).</p>
</li>
<li>
<p>By pinning an operation on a device, you are telling TensorFlow that 
this is where you would like this operation to be placed. However, some 
constraints may prevent TensorFlow from honoring your request. For 
example, the operation may have no implementation (called a <em>kernel</em>)
 for that particular type of device. In this case, TensorFlow will raise
 an exception by default, but you can configure it to fall back to the 
CPU instead (this is called <em>soft placement</em>). Another example is
 an operation that can modify a variable; this operation and the 
variable need to be collocated. So the difference between pinning an 
operation and placing an operation is that pinning is what you ask 
TensorFlow (“Please place this operation on GPU #1”) while placement is 
what TensorFlow actually ends up doing (“Sorry, falling back to the 
CPU”).</p>
</li>
<li>
<p>If you are running on a GPU-enabled TensorFlow installation, and you 
just use the default placement, then if all operations have a GPU kernel
 (i.e., a GPU implementation), yes, they will all be placed on the first
 GPU. However, if one or more operations do not have a GPU kernel, then 
by default TensorFlow will raise an exception. If you configure 
TensorFlow to fall back to the CPU instead (soft placement), then all 
operations will be placed on the first GPU except the ones without a GPU
 kernel and all the operations that must be collocated with them (see 
the answer to the previous exercise).</p>
</li>
<li>
<p>Yes, if you pin a variable to <code>/gpu:0</code>, it can be used by operations placed on <span class="keep-together"><code>/gpu:1</code></span>.
 TensorFlow will automatically take care of adding the appropriate 
operations to transfer the variable’s value across devices. The same 
goes for devices located on different servers (as long as they are part 
of the same cluster).</p>
</li>
<li>
<p>Yes, two operations placed on the same device can run in parallel: 
TensorFlow automatically takes care of running operations in parallel 
(on different CPU cores or different GPU threads), as long as no 
operation depends on another operation’s output. Moreover, you can start
 multiple sessions in parallel threads (or processes), and evaluate 
operations in each thread. Since sessions are independent, TensorFlow 
will be able to evaluate any operation from one session in parallel with
 any operation from another session.</p>
</li>
<li>
<p>Control dependencies are used when you want to postpone the 
evaluation of an operation X until after some other operations are run, 
even though these operations are not required to compute X. This is 
useful in particular when X would occupy a lot of memory and you only 
need it later in the computation graph, or if X uses up a lot of I/O 
(for example, it requires a large variable value located on a different 
device or server) and you don’t want it to run at the same time as other
 I/O-hungry operations, to avoid saturating the bandwidth.</p>
</li>
<li>
<p>You’re in luck! In distributed TensorFlow, the variable values live 
in containers managed by the cluster, so even if you close the session 
and exit the client program, the model parameters are still alive and 
well on the cluster. You simply need to open a new session to the 
cluster and save the model (make sure you don’t call the variable 
initializers or restore a previous model, as this would destroy your 
precious new model!).</p>
</li>

</ol>

<p>For the solutions to exercises 8, 9, and 10, please see the Jupyter notebooks available at <a href="https://github.com/ageron/handson-ml"><em class="hyperlink">https://github.com/ageron/handson-ml</em></a>.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Chapter&nbsp;13: Convolutional Neural Networks"><div class="sect1" id="idm140582978687248">
<h1><a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch13.html#cnn_chapter">Chapter&nbsp;13</a>: Convolutional Neural Networks</h1>
<ol>
<li>
<p>These are the main advantages of a CNN over a fully connected DNN for image classification:</p>

<ul>
<li>
<p>Because consecutive layers are only partially connected and because 
it heavily reuses its weights, a CNN has many fewer parameters than a 
fully connected DNN, which makes it much faster to train, reduces the 
risk of overfitting, and requires much less training data.</p>
</li>
<li>
<p>When a CNN has learned a kernel that can detect a particular feature,
 it can detect that feature anywhere on the image. In contrast, when a 
DNN learns a feature in one location, it can detect it only in that 
particular location. Since images typically have very repetitive 
features, CNNs are able to generalize much better than DNNs for image 
processing tasks such as classification, using fewer training examples.</p>
</li>
<li>
<p>Finally, a DNN has no prior knowledge of how pixels are organized; it
 does not know that nearby pixels are close. A CNN’s architecture embeds
 this prior knowledge. Lower layers typically identify features in small
 areas of the images, while higher layers combine the lower-level 
features into larger features. This works well with most natural images,
 giving CNNs a decisive head start compared to DNNs.</p>
</li>
</ul>
</li>
<li>
<p>Let’s compute how many parameters the CNN has. Since its first 
convolutional layer has 3 × 3 kernels, and the input has three channels 
(red, green, and blue), then each feature map has 3 × 3 × 3 weights, 
plus a bias term. That’s 28 parameters per feature map. Since this first
 convolutional layer has 100 feature maps, it has a total of 2,800 
parameters. The second convolutional layer has 3 × 3 kernels, and its 
input is the set of 100 feature maps of the previous layer, so each 
feature map has 3 × 3 × 100 = 900 weights, plus a bias term. Since it 
has 200 feature maps, this layer has 901 × 200 = 180,200 parameters. 
Finally, the third and last convolutional layer also has 3 × 3 kernels, 
and its input is the set of 200 feature maps of the previous layers, so 
each feature map has 3 × 3 × 200 = 1,800 weights, plus a bias term. 
Since it has 400 feature maps, this layer has a total of 1,801 × 400 = 
720,400 parameters. All in all, the CNN has 2,800 + 180,200 + 720,400 = 
 903,400 parameters.</p>

<p>Now let’s compute how much RAM this neural network will require (at 
least) when making a prediction for a single instance. First let’s 
compute the feature map size for each layer. Since we are using a stride
 of 2 and SAME padding, the horizontal and vertical size of the feature 
maps are divided by 2 at each layer (rounding up if necessary), so as 
the input channels are 200 × 300 pixels, the first layer’s feature maps 
are 100 × 150, the second layer’s feature maps are 50 × 75, and the 
third layer’s feature maps are 25 × 38. Since 32 bits is 4 bytes and the
 first convolutional layer has 100 feature maps, this first layer takes 
up 4 x 100 × 150 × 100 = 6 million bytes (about 5.7 MB, considering that
 1 MB = 1,024 KB and 1 KB = 1,024 bytes). The second layer takes up 4 × 
50 × 75 × 200 = 3 million bytes (about 2.9 MB). Finally, the third layer
 takes up 4 × 25 × 38 × 400 = 1,520,000 bytes (about 1.4 MB). However, 
once a layer has been computed, the memory occupied by the previous 
layer can be released, so if everything is well optimized, only 6 + 3 = 9
 million bytes (about 8.6 MB) of RAM will be required (when the second 
layer has just been computed, but the memory occupied by the first layer
 is not released yet). But wait, you also need to add the memory 
occupied by the CNN’s parameters. We computed earlier that it has 
903,400 parameters, each using up 4 bytes, so this adds 3,613,600 bytes 
(about 3.4 MB). The total RAM required is (at least) 12,613,600 bytes 
(about 12.0 MB).</p>

<p>Lastly, let’s compute the minimum amount of RAM required when 
training the CNN on a mini-batch of 50 images. During training 
TensorFlow uses backpropagation, which requires keeping all values 
computed during the forward pass until the reverse pass begins. So we 
must compute the total RAM required by all layers for a single instance 
and multiply that by 50! At that point let’s start counting in megabytes
 rather than bytes. We computed before that the three layers require 
respectively 5.7, 2.9, and 1.4 MB for each instance. That’s a total of 
10.0 MB per instance. So for 50 instances the total RAM is 500 MB. Add 
to that the RAM required by the input images, which is 50 × 4 × 200 × 
300 × 3 = 36 million bytes (about 34.3 MB), plus the RAM required for 
the model parameters, which is about 3.4 MB (computed earlier), plus 
some RAM for the gradients (we will neglect them since they can be 
released gradually as backpropagation goes down the layers during the 
reverse pass). We are up to a total of roughly 500.0 + 34.3 + 3.4 = 
537.7 MB. And that’s really an optimistic bare minimum.</p>
</li>
<li>
<p>If your GPU runs out of memory while training a CNN, here are five 
things you could try to solve the problem (other than purchasing a GPU 
with more RAM):</p>

<ul>
<li>
<p>Reduce the mini-batch size.</p>
</li>
<li>
<p>Reduce dimensionality using a larger stride in one or more layers.</p>
</li>
<li>
<p>Remove one or more layers.</p>
</li>
<li>
<p>Use 16-bit floats instead of 32-bit floats.</p>
</li>
<li>
<p>Distribute the CNN across multiple devices.</p>
</li>
</ul>
</li>
<li>
<p>A max pooling layer has no parameters at all, whereas a convolutional layer has quite a few (see the previous questions).</p>
</li>
<li>
<p>A <em>local response normalization</em> layer makes the neurons that 
most strongly activate inhibit neurons at the same location but in 
neighboring feature maps, which encourages different feature maps to 
specialize and pushes them apart, forcing them to explore a wider range 
of features. It is typically used in the lower layers to have a larger 
pool of low-level features that the upper layers can build upon.</p>
</li>
<li>
<p>The main innovations in AlexNet compared to LeNet-5 are (1) it is 
much larger and deeper, and (2) it stacks convolutional layers directly 
on top of each other, instead of stacking a pooling layer on top of each
 convolutional layer. The main innovation in GoogLeNet is the 
introduction of <em>inception modules</em>, which make it possible to 
have a much deeper net than previous CNN architectures, with fewer 
parameters. Finally, ResNet’s main innovation is the introduction of 
skip connections, which make it possible to go well beyond 100 layers. 
Arguably, its simplicity and consistency are also rather innovative.</p>
</li>

</ol>

<p>For the solutions to exercises 7, 8, 9, and 10, please see the Jupyter notebooks available at <a href="https://github.com/ageron/handson-ml"><em class="hyperlink">https://github.com/ageron/handson-ml</em></a>.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Chapter&nbsp;14: Recurrent Neural Networks"><div class="sect1" id="idm140582978662000">
<h1><a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch14.html#rnn_chapter">Chapter&nbsp;14</a>: Recurrent Neural Networks</h1>
<ol>
<li>
<p>Here are a few RNN applications:</p>

<ul>
<li>
<p>For a sequence-to-sequence RNN: predicting the weather (or any other 
time series), machine translation (using an encoder–decoder 
architecture), video captioning, speech to text, music generation (or 
other sequence generation), identifying the chords of a song.</p>
</li>
<li>
<p>For a sequence-to-vector RNN: classifying music samples by music 
genre, analyzing the sentiment of a book review, predicting what word an
 aphasic patient is thinking of based on readings from brain implants, 
predicting the probability that a user will want to watch a movie based 
on her watch history (this is one of many possible implementations of <em>collaborative filtering</em>).</p>
</li>
<li>
<p>For a vector-to-sequence RNN: image captioning, creating a music 
playlist based on an embedding of the current artist, generating a 
melody based on a set of parameters, locating pedestrians in a picture 
(e.g., a video frame from a self-driving car’s camera).</p>
</li>
</ul>
</li>
<li>
<p>In general, if you translate a sentence one word at a time, the 
result will be terrible. For example, the French sentence “Je vous en 
prie” means “You are welcome,” but if you translate it one word at a 
time, you get “I you in pray.” Huh? It is much better to read the whole 
sentence first and then translate it. A plain sequence-to-sequence RNN 
would start translating a sentence immediately after reading the first 
word, while an encoder–decoder RNN will first read the whole sentence 
and then translate it. That said, one could imagine a plain 
sequence-to-sequence RNN that would output silence whenever it is unsure
 about what to say next (just like human translators do when they must 
translate a live broadcast).</p>
</li>
<li>
<p>To classify videos based on the visual content, one possible 
architecture could be to take (say) one frame per second, then run each 
frame through a convolutional neural network, feed the output of the CNN
 to a sequence-to-vector RNN, and finally run its output through a 
softmax layer, giving you all the class probabilities. For training you 
would just use cross entropy as the cost function. If you wanted to use 
the audio for classification as well, you could convert every second of 
audio to a spectrograph, feed this spectrograph to a CNN, and feed the 
output of this CNN to the RNN (along with the corresponding output of 
the other CNN).</p>
</li>
<li>
<p>Building an RNN using <code>dynamic_rnn()</code> rather than <code>static_rnn()</code> offers several <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.contrib.rnn.static_rnn()" id="tfcrsrappa"></a> <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.nn.dynamic_rnn()" id="tfnndrappa"></a>advantages:</p>

<ul>
<li>
<p>It is based on a <code>while_loop()</code> operation that is able to swap the GPU’s memory to the CPU’s memory during backpropagation, avoiding out-of-memory errors.</p>
</li>
<li>
<p>It is arguably easier to use, as it can directly take a single tensor
 as input and output (covering all time steps), rather than a list of 
tensors (one per time step). No need to <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.unstack()" id="idm140582978644208"></a>stack, unstack, or transpose.</p>
</li>
<li>
<p>It generates a smaller graph, easier to visualize in TensorBoard.</p>
</li>
</ul>
</li>
<li>
<p>To handle variable length input sequences, the simplest option is to set the <code>sequence_length</code> parameter when calling the <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.contrib.rnn.static_rnn()" data-startref="tfcrsrappa" id="idm140582978597984"></a> <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.nn.dynamic_rnn()" data-startref="tfnndrappa" id="idm140582978596608"></a><code>static_rnn()</code> or <code>dynamic_rnn()</code>
 functions. Another option is to pad the smaller inputs (e.g., with 
zeros) to make them the same size as the largest input (this may be 
faster than the first option if the input sequences all have very 
similar lengths). To handle variable-length output sequences, if you 
know in advance the length of each output sequence, you can use the <code>sequence_length</code>
 parameter (for example, consider a sequence-to-sequence RNN that labels
 every frame in a video with a violence score: the output sequence will 
be exactly the same length as the input sequence). If you don’t know in 
advance the length of the output sequence, you can use the padding 
trick: always output the same size sequence, but ignore any outputs that
 come after the end-of-sequence token (by ignoring them when computing 
the cost function).</p>
</li>
<li>
<p>To distribute training and execution of a deep RNN across multiple 
GPUs, a common technique is simply to place each layer on a different 
GPU (see <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch12.html#distributed_chapter">Chapter&nbsp;12</a>).</p>
</li>

</ol>

<p>For the solutions to exercises 7, 8, and 9, please see the Jupyter notebooks available at <a href="https://github.com/ageron/handson-ml"><em class="hyperlink">https://github.com/ageron/handson-ml</em></a>.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Chapter&nbsp;15: Autoencoders"><div class="sect1" id="idm140582978589568">
<h1><a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch15.html#autoencoders_chapter">Chapter&nbsp;15</a>: Autoencoders</h1>
<ol>
<li>
<p>Here are some of the main tasks that autoencoders are used for:</p>

<ul>
<li>
<p>Feature extraction</p>
</li>
<li>
<p>Unsupervised pretraining</p>
</li>
<li>
<p>Dimensionality reduction</p>
</li>
<li>
<p>Generative models</p>
</li>
<li>
<p>Anomaly detection (an autoencoder is generally bad at reconstructing outliers)</p>
</li>
</ul>
</li>
<li>
<p>If you want to train a classifier and you have plenty of unlabeled 
training data, but only a few thousand labeled instances, then you could
 first train a deep autoencoder on the full dataset (labeled + 
unlabeled), then reuse its lower half for the classifier (i.e., reuse 
the layers up to the codings layer, included) and train the classifier 
using the labeled data. If you have little labeled data, you probably 
want to freeze the reused layers when training the classifier.</p>
</li>
<li>
<p>The fact that an autoencoder perfectly reconstructs its inputs does 
not necessarily mean that it is a good autoencoder; perhaps it is simply
 an overcomplete autoencoder that learned to copy its inputs to the 
codings layer and then to the outputs. In fact, even if the codings 
layer contained a single neuron, it would be possible for a very deep 
autoencoder to learn to map each training instance to a different coding
 (e.g., the first instance could be mapped to 0.001, the second to 
0.002, the third to 0.003, and so on), and it could learn “by heart” to 
reconstruct the right training instance for each coding. It would 
perfectly reconstruct its inputs without really learning any useful 
pattern in the data. In practice such a mapping is unlikely to happen, 
but it illustrates the fact that perfect reconstructions are not a 
guarantee that the autoencoder learned anything useful. However, if it 
produces very bad reconstructions, then it is almost guaranteed to be a 
bad autoencoder. To evaluate the performance of an autoencoder, one 
option is to measure the reconstruction loss (e.g., compute the MSE, the
 mean square of the outputs minus the inputs). Again, a high 
reconstruction loss is a good sign that the autoencoder is bad, but a 
low reconstruction loss is not a guarantee that it is good. You should 
also evaluate the autoencoder according to what it will be used for. For
 example, if you are using it for unsupervised pretraining of a 
classifier, then you should also evaluate the classifier’s performance.</p>
</li>
<li>
<p>An undercomplete autoencoder is one whose codings layer is smaller 
than the input and output layers. If it is larger, then it is an 
overcomplete autoencoder. The main risk of an excessively undercomplete 
autoencoder is that it may fail to reconstruct the inputs. The main risk
 of an overcomplete autoencoder is that it may just copy the inputs to 
the outputs, without learning any useful feature.</p>
</li>
<li>
<p>To tie the weights of an encoder layer and its corresponding decoder 
layer, you simply make the decoder weights equal to the transpose of the
 encoder weights. This reduces the number of parameters in the model by 
half, often making training converge faster with less training data, and
 reducing the risk of overfitting the training set.</p>
</li>
<li>
<p>To visualize the features learned by the lower layer of a stacked 
autoencoder, a common technique is simply to plot the weights of each 
neuron, by reshaping each weight vector to the size of an input image 
(e.g., for MNIST, reshaping a weight vector of shape <code>[784]</code> to <code>[28, 28]</code>).
 To visualize the features learned by higher layers, one technique is to
 display the training instances that most activate each neuron.</p>
</li>
<li>
<p>A generative model is a model capable of randomly generating outputs 
that resemble the training instances. For example, once trained 
successfully on the MNIST dataset, a generative model can be used to 
randomly generate realistic images of digits. The output distribution is
 typically similar to the training data. For example, since MNIST 
contains many images of each digit, the generative model would output 
roughly the same number of images of each digit. Some generative models 
can be parametrized—for example, to generate only some kinds of outputs.
 An example of a generative autoencoder is the variational autoencoder.</p>
</li>

</ol>

<p>For the solutions to exercises 8, 9, and 10, please see the Jupyter notebooks available at <a href="https://github.com/ageron/handson-ml"><em class="hyperlink">https://github.com/ageron/handson-ml</em></a>.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Chapter&nbsp;16: Reinforcement Learning"><div class="sect1" id="idm140582978569840">
<h1><a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch16.html#rl_chapter">Chapter&nbsp;16</a>: Reinforcement Learning</h1>
<ol>
<li>
<p>Reinforcement Learning is an area of Machine Learning aimed at 
creating agents capable of taking actions in an environment in a way 
that maximizes rewards over time. There are many differences between RL 
and regular supervised and unsupervised learning. Here are a few:</p>

<ul>
<li>
<p>In supervised and unsupervised learning, the goal is generally to 
find patterns in the data and use them to make predictions. In 
Reinforcement Learning, the goal is to find a good policy.</p>
</li>
<li>
<p>Unlike in supervised learning, the agent is not explicitly given the “right” answer. It must learn by trial and error.</p>
</li>
<li>
<p>Unlike in unsupervised learning, there is a form of supervision, 
through rewards. We do not tell the agent how to perform the task, but 
we do tell it when it is making progress or when it is failing.</p>
</li>
<li>
<p>A Reinforcement Learning agent needs to find the right balance 
between exploring the environment, looking for new ways of getting 
rewards, and exploiting sources of rewards that it already knows. In 
contrast, supervised and unsupervised learning systems generally don’t 
need to worry about exploration; they just feed on the training data 
they are given.</p>
</li>
<li>
<p>In supervised and unsupervised learning, training instances are 
typically independent (in fact, they are generally shuffled). In 
Reinforcement Learning, consecutive observations are generally <em>not</em>
 independent. An agent may remain in the same region of the environment 
for a while before it moves on, so consecutive observations will be very
 correlated. In some cases a replay memory is used to ensure that the 
training algorithm gets fairly independent observations.</p>
</li>
</ul>
</li>
<li>
<p>Here are a few possible applications of Reinforcement Learning, other than those mentioned in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch16.html#rl_chapter">Chapter&nbsp;16</a>:</p>
<dl>
<dt>Music personalization</dt>
<dd>
<p>The environment is a user’s personalized web radio. The agent is the 
software deciding what song to play next for that user. Its possible 
actions are to play any song in the catalog (it must try to choose a 
song the user will enjoy) or to play an advertisement (it must try to 
choose an ad that the user will be interested in). It gets a small 
reward every time the user listens to a song, a larger reward every time
 the user listens to an ad, a negative reward when the user skips a song
 or an ad, and a very negative reward if the user leaves.</p>
</dd>
<dt>Marketing</dt>
<dd>
<p>The environment is your company’s marketing department. The agent is 
the software that defines which customers a mailing campaign should be 
sent to, given their profile and purchase history (for each customer it 
has two possible actions: send or don’t send). It gets a negative reward
 for the cost of the mailing campaign, and a positive reward for 
estimated revenue generated from this campaign.</p>
</dd>
<dt>Product delivery</dt>
<dd>
<p>Let the agent control a fleet of delivery trucks, deciding what they 
should pick up at the depots, where they should go, what they should 
drop off, and so on. They would get positive rewards for each product 
delivered on time, and negative rewards for late deliveries.</p>
</dd>
</dl>
</li>
<li>
<p>When estimating the value of an action, Reinforcement Learning 
algorithms typically sum all the rewards that this action led to, giving
 more weight to immediate rewards, and less weight to later rewards 
(considering that an action has more influence on the near future than 
on the distant future). To model this, a discount rate is typically 
applied at each time step. For example, with a discount rate of 0.9, a 
reward of 100 that is received two time steps later is counted as only 
0.9<sup>2</sup> × 100 = 81 when you are estimating the value of the 
action. You can think of the discount rate as a measure of how much the 
future is valued relative to the present: if it is very close to 1, then
 the future is valued almost as much as the present. If it is close to 
0, then only immediate rewards matter. Of course, this impacts the 
optimal policy tremendously: if you value the future, you may be willing
 to put up with a lot of immediate pain for the prospect of eventual 
rewards, while if you don’t value the future, you will just grab any 
immediate reward you can find, never investing in the future.</p>
</li>
<li>
<p>To measure the performance of a Reinforcement Learning agent, you can
 simply sum up the rewards it gets. In a simulated environment, you can 
run many episodes and look at the total rewards it gets on average (and 
possibly look at the min, max, standard deviation, and so on).</p>
</li>
<li>
<p>The credit assignment problem is the fact that when a Reinforcement 
Learning agent receives a reward, it has no direct way of knowing which 
of its previous actions contributed to this reward. It typically occurs 
when there is a large delay between an action and the resulting rewards 
(e.g., during a game of Atari’s <em>Pong</em>, there may be a few dozen 
time steps between the moment the agent hits the ball and the moment it 
wins the point). One way to alleviate it is to provide the agent with 
shorter-term rewards, when possible. This usually requires prior 
knowledge about the task. For example, if we want to build an agent that
 will learn to play chess, instead of giving it a reward only when it 
wins the game, we could give it a reward every time it captures one of 
the opponent’s pieces.</p>
</li>
<li>
<p>An agent can often remain in the same region of its environment for a
 while, so all of its experiences will be very similar for that period 
of time. This can introduce some bias in the learning algorithm. It may 
tune its policy for this region of the environment, but it will not 
perform well as soon as it moves out of this region. To solve this 
problem, you can use a replay memory; instead of using only the most 
immediate experiences for learning, the agent will learn based on a 
buffer of its past experiences, recent and not so recent (perhaps this 
is why we dream at night: to replay our experiences of the day and 
better learn from them?).</p>
</li>
<li>
<p>An off-policy RL algorithm learns the value of the optimal policy 
(i.e., the sum of discounted rewards that can be expected for each state
 if the agent acts optimally) while the agent follows a different 
policy. Q-Learning is a good example of such an algorithm. In contrast, 
an on-policy algorithm learns the value of the policy that the agent 
actually executes, including both exploration and exploitation.</p>
</li>

</ol>

<p>For the solutions to exercises 8, 9, and 10, please see the Jupyter notebooks available at <a href="https://github.com/ageron/handson-ml"><em class="hyperlink">https://github.com/ageron/handson-ml</em></a>.</p>
</div></section>







<div data-type="footnotes"><p data-type="footnote" id="idm140582979206640"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app01.html#idm140582979206640-marker" class="totri-footnote">1</a></sup> If you draw a straight line between any two points on the curve, the line never crosses the curve.</p><p data-type="footnote" id="idm140582979194560"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app01.html#idm140582979194560-marker" class="totri-footnote">2</a></sup>
 Moreover, the Normal Equation requires computing the inverse of a 
matrix, but that matrix is not always invertible. In contrast, the 
matrix for Ridge Regression is always invertible.</p><p data-type="footnote" id="idm140582979144768"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app01.html#idm140582979144768-marker" class="totri-footnote">3</a></sup> log<sub>2</sub> is the binary log, log<sub>2</sub>(<em>m</em>) = log(<em>m</em>) / log(2).</p><p data-type="footnote" id="idm140582978745024"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app01.html#idm140582978745024-marker" class="totri-footnote">4</a></sup>
 When the values to predict can vary by many orders of magnitude, then 
you may want to predict the logarithm of the target value rather than 
the target value directly. Simply computing the exponential of the 
neural network’s output will give you the estimated value (since exp(log
 <em>v</em>) = <em>v</em>).</p><p data-type="footnote" id="idm140582978739264"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app01.html#idm140582978739264-marker" class="totri-footnote">5</a></sup> In <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#deep_chapter">Chapter&nbsp;11</a>
 we discuss many techniques that introduce additional hyperparameters: 
type of weight initialization, activation function hyperparameters 
(e.g., amount of leak in leaky ReLU), Gradient Clipping threshold, type 
of optimizer and its hyperparameters <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.train.MomentumOptimizer" id="tftrainmoappa"></a>(e.g., the momentum hyperparameter when using a <code>MomentumOptimizer</code>),
 type of regularization for each layer, and the regularization 
hyperparameters (e.g., dropout rate when using dropout) and so on.</p></div></div></section><div class="annotator-outer annotator-viewer viewer annotator-hide">
  <ul class="annotator-widget annotator-listing"></ul>
</div><div class="annotator-modal-wrapper annotator-editor-modal annotator-editor annotator-hide">
	<div class="annotator-outer editor">
		<h2 class="title">Highlight</h2>
		<form class="annotator-widget">
			<ul class="annotator-listing">
			<li class="annotator-item"><textarea id="annotator-field-7" placeholder="Add a note using markdown (optional)" class="js-editor" maxlength="750"></textarea></li></ul>
			<div class="annotator-controls">
				<a class="link-to-markdown" href="https://daringfireball.net/projects/markdown/basics" target="_blank">?</a>
				<ul>
					<li class="delete annotator-hide"><a href="#delete" class="annotator-delete-note button positive">Delete Note</a></li>
					<li class="save"><a href="#save" class="annotator-save annotator-focus button positive">Save Note</a></li>
					<li class="cancel"><a href="#cancel" class="annotator-cancel button">Cancel</a></li>
				</ul>
			</div>
		</form>
	</div>
</div><div class="annotator-modal-wrapper annotator-delete-confirm-modal" style="display: none;">
  <div class="annotator-outer">
    <h2 class="title">Highlight</h2>
      <a class="js-close-delete-confirm annotator-cancel close" href="#close">Close</a>
      <div class="annotator-widget">
         <div class="delete-confirm">
            Are you sure you want to permanently delete this note?
         </div>
         <div class="annotator-controls">
            <a href="#cancel" class="annotator-cancel button js-cancel-delete-confirm">No, I changed my mind</a>
            <a href="#delete" class="annotator-delete button positive js-delete-confirm">Yes, delete it</a>
         </div>
       </div>
   </div>
</div><div class="annotator-adder" style="display: none;">
	<ul class="adders ">
		
		<li class="copy"><a href="#">Copy</a></li>
		
		<li class="add-highlight"><a href="#">Add Highlight</a></li>
		<li class="add-note"><a href="#">
			
				Add Note
			
		</a></li>
		
	</ul>
</div></div></div>



  <div class="t-sbo-prev sbo-prev sbo-nav-bottom">
  
    
      
        <a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch16.html" class="prev nav-link">
      
          <span aria-hidden="true" class="pagination-label t-prev-label">Prev</span>
          <span class="visuallyhidden">Previous Chapter</span>
          <div class="pagination-title t-prev-title">16. Reinforcement Learning</div>
        </a>
    
  
  </div>

  <div class="t-sbo-next sbo-next sbo-nav-bottom">
  
    
      
        <a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app02.html" class="next nav-link">
      
          <span aria-hidden="true" class="pagination-label t-next-label">Next</span>
          <span class="visuallyhidden">Next Chapter</span>
          <div class="pagination-title t-next-title">B. Machine Learning Project Checklist</div>
        </a>
    
  
  </div>

</section>
  </div>
<section class="sbo-saved-archives"></section>



          
          
  




    
    
      <div id="js-subscribe-nag" class="subscribe-nag clearfix trial-panel t-subscribe-nag collapsed slideUp">
        
        
          
          
            <p class="usage-data">Find answers on the fly, or master something new. Subscribe today. <a href="https://www.safaribooksonline.com/subscribe/" class="ga-active-trial-subscribe-nag">See pricing options.</a></p>
          

          
        
        

      </div>

    
    



        
      </div>
      




  <footer class="pagefoot t-pagefoot" style="padding-bottom: 69px;">
    <a href="#" class="icon-up" style="display: block;"><div class="visuallyhidden">Back to top</div></a>
    <ul class="js-footer-nav">
      
        <li><a class="t-recommendations-footer" href="https://www.safaribooksonline.com/r/">Recommended</a></li>
      
      <li>
      
      <a class="t-queue-footer" href="https://www.safaribooksonline.com/s/">Queue</a>
      
      </li>
      
        <li><a class="t-recent-footer" href="https://www.safaribooksonline.com/history/">History</a></li>
        <li><a class="t-topics-footer" href="https://www.safaribooksonline.com/topics?q=*&amp;limit=21">Topics</a></li>
      
      
        <li><a class="t-tutorials-footer" href="https://www.safaribooksonline.com/tutorials/">Tutorials</a></li>
      
      <li><a class="t-settings-footer js-settings" href="https://www.safaribooksonline.com/u/">Settings</a></li>
      <li class="full-support"><a href="https://www.safaribooksonline.com/public/support">Support</a></li>
      <li><a href="https://www.safaribooksonline.com/apps/">Get the App</a></li>
      <li><a href="https://www.safaribooksonline.com/accounts/logout/">Sign Out</a></li>
    </ul>
    <span class="copyright">© 2017 <a href="https://www.safaribooksonline.com/" target="_blank">Safari</a>.</span>
    <a href="https://www.safaribooksonline.com/terms/">Terms of Service</a> /
    <a href="https://www.safaribooksonline.com/privacy/">Privacy Policy</a>
  </footer>

<script type="text/javascript">window.NREUM||(NREUM={});NREUM.info={"beacon":"bam.nr-data.net","queueTime":0,"licenseKey":"510f1a6865","errorBeacon":"bam.nr-data.net","transactionName":"YgdaZ0NSW0cEB0RdWltNfkZfUEFdCgofXFBHDVYdR1pQQxZeRl1QQj1aWkU=","applicationTime":651,"applicationID":"3275661","agent":""}</script>


    

    <script src="A.%20Exercise%20Solutions%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/a_005.js" charset="utf-8"></script><script type="text/javascript" id="">!function(b,e,f,g,a,c,d){b.fbq||(a=b.fbq=function(){a.callMethod?a.callMethod.apply(a,arguments):a.queue.push(arguments)},b._fbq||(b._fbq=a),a.push=a,a.loaded=!0,a.version="2.0",a.queue=[],c=e.createElement(f),c.async=!0,c.src=g,d=e.getElementsByTagName(f)[0],d.parentNode.insertBefore(c,d))}(window,document,"script","https://connect.facebook.net/en_US/fbevents.js");fbq("init","1732687426968531");fbq("track","PageView");</script>
<noscript><img height="1" width="1" style="display:none" src="https://www.facebook.com/tr?id=1732687426968531&amp;ev=PageView&amp;noscript=1"></noscript><div style="width:0px; height:0px; display:none; visibility:hidden;" id="batBeacon0.3743867347277554"><img style="width:0px; height:0px; display:none; visibility:hidden;" id="batBeacon0.3342180628024528" alt="" src="A.%20Exercise%20Solutions%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/0.txt" width="0" height="0"></div>
    <script src="A.%20Exercise%20Solutions%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/a_004.js" charset="utf-8"></script>
  

<div class="annotator-notice"></div><div class="font-flyout" style="top: 200px; left: 1257px;"><div class="font-controls-panel">
	<div class="nightmodes">
		<ul>
			<li class="day"><a href="#" id="day-mode" title="Day Mode">
				<i class="fa fa-sun-o"></i>
				<span>Day Mode</span></a></li>
			<li class="cloudy"><a href="#" id="cloudy-mode" title="Cloudy Mode">
				<i class="fa fa-cloud"></i>
				<span>Cloud Mode</span>
			</a></li>
			<li class="night"><a href="#" id="night-mode" title="Night Mode">
				<i class="fa fa-moon-o"></i>
				<span>Night Mode</span>
			</a></li>
		</ul>
	</div>

	<div class="font-resizer resizer">
		<div class="draggable-containment-wrapper">
			<i class="fa fa-font left"></i>
			<span class="filler" style="width: 50%;"></span>
			<div id="js-font-size-draggable" class="draggable ui-widget-content ui-draggable ui-draggable-handle" style="position: relative; left: 80px;"></div>
			<i class="fa fa-font right"></i>
		</div>
	</div>

	<div class="column-resizer resizer">
		<div class="draggable-containment-wrapper">
			<i class="fa fa-compress left"></i>
			<span class="filler" style="width: 50%;"></span>
			<div id="js-column-size-draggable" class="draggable ui-widget-content ui-draggable ui-draggable-handle" style="position: relative; left: 80px;"></div>
			<i class="fa fa-expand right"></i>
		</div>
	</div>

	<a id="reset" class="button" href="#">Reset</a>
</div>
</div><iframe style="display: none;" src="A.%20Exercise%20Solutions%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/pixel.html"></iframe><script src="A.%20Exercise%20Solutions%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/a.js" type="text/javascript"></script><script src="A.%20Exercise%20Solutions%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/a" type="text/javascript"></script><img src="A.%20Exercise%20Solutions%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/seg.gif" alt="" style="display: none;" width="1" height="1" border="0"></body></html>