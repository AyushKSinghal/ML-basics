<!--[if IE]><![endif]-->
<!DOCTYPE html>
<!--[if IE 8]><html class="no-js ie8 oldie" lang="en" prefix="og: http://ogp.me/ns/# og:book: http://ogp.me/ns/book# og:video: http://ogp.me/ns/video#"

    
        itemscope itemtype="http://schema.org/Book http://schema.org/ItemPage"" data-login-url="/accounts/login/"
data-offline-url="/"
data-url="/library/view/hands-on-machine-learning/9781491962282/ch10.html"
data-csrf-cookie="csrfsafari"
data-highlight-privacy="private"


  data-user-id="2309833"
  data-user-uuid="2d2acfb7-1cff-4dc7-9037-8ffbac19b02e"
  data-username="ayushksinghal"
  data-account-type="Trial"
  
  data-activated-trial-date="12/02/2017"


  data-archive="9781491962282"
  data-publishers="O&#39;Reilly Media, Inc."



  data-htmlfile-name="ch10.html"
  data-epub-title="Hands-On Machine Learning with Scikit-Learn and TensorFlow" data-debug=0 data-testing=0><![endif]-->
<!--[if gt IE 8]><!-->
<html class="js flexbox flexboxlegacy no-touch no-websqldatabase indexeddb history csscolumns csstransforms localstorage sessionstorage applicationcache svg inlinesvg no-zoom gr__safaribooksonline_com" prefix="og: http://ogp.me/ns/# og:book: http://ogp.me/ns/book# og:video: http://ogp.me/ns/video#" itemscope="" itemtype="http://schema.org/Book http://schema.org/ItemPage" "="" data-login-url="/accounts/login/" data-offline-url="/" data-url="/library/view/hands-on-machine-learning/9781491962282/ch10.html" data-csrf-cookie="csrfsafari" data-highlight-privacy="private" data-user-id="2309833" data-user-uuid="2d2acfb7-1cff-4dc7-9037-8ffbac19b02e" data-username="ayushksinghal" data-account-type="Trial" data-activated-trial-date="12/02/2017" data-archive="9781491962282" data-publishers="O'Reilly Media, Inc." data-htmlfile-name="ch10.html" data-epub-title="Hands-On Machine Learning with Scikit-Learn and TensorFlow" data-debug="0" data-testing="0" style="" data-ember-extension="1" lang="en"><!--<![endif]--><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="author" content="Safari Books Online"><meta name="format-detection" content="telephone=no"><meta http-equiv="cleartype" content="on"><meta name="HandheldFriendly" content="True"><meta name="MobileOptimized" content="320"><meta name="apple-itunes-app" content="app-id=881697395, app-argument=safaridetail://9781491962282"><meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, maximum-scale=1.0"><meta property="twitter:account_id" content="4503599627559754"><script type="text/javascript" src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/510f1a6865.js"></script><script src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/nr-spa-1044.js"></script><script type="text/javascript" async="" src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/linkid.js"></script><script src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/1732687426968531.js" async=""></script><script async="" src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/fbevents.js"></script><script type="text/javascript" async="" src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/bat.js"></script><script type="text/javascript" async="" src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/conversion_async.js"></script><script type="text/javascript" async="" src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/insight.js"></script><script type="text/javascript" async="" src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/conversion_async.js"></script><script async="" src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/gtm.js"></script><script async="" src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/analytics.js"></script><script type="text/javascript">(window.NREUM||(NREUM={})).loader_config={xpid:"VQQDUVVVGwACU1RUAQA="};window.NREUM||(NREUM={}),__nr_require=function(t,e,n){function r(n){if(!e[n]){var o=e[n]={exports:{}};t[n][0].call(o.exports,function(e){var o=t[n][1][e];return r(o||e)},o,o.exports)}return e[n].exports}if("function"==typeof __nr_require)return __nr_require;for(var o=0;o<n.length;o++)r(n[o]);return r}({1:[function(t,e,n){function r(t){try{c.console&&console.log(t)}catch(e){}}var o,i=t("ee"),a=t(19),c={};try{o=localStorage.getItem("__nr_flags").split(","),console&&"function"==typeof console.log&&(c.console=!0,o.indexOf("dev")!==-1&&(c.dev=!0),o.indexOf("nr_dev")!==-1&&(c.nrDev=!0))}catch(s){}c.nrDev&&i.on("internal-error",function(t){r(t.stack)}),c.dev&&i.on("fn-err",function(t,e,n){r(n.stack)}),c.dev&&(r("NR AGENT IN DEVELOPMENT MODE"),r("flags: "+a(c,function(t,e){return t}).join(", ")))},{}],2:[function(t,e,n){function r(t,e,n,r,o){try{d?d-=1:i("err",[o||new UncaughtException(t,e,n)])}catch(c){try{i("ierr",[c,s.now(),!0])}catch(u){}}return"function"==typeof f&&f.apply(this,a(arguments))}function UncaughtException(t,e,n){this.message=t||"Uncaught error with no additional information",this.sourceURL=e,this.line=n}function o(t){i("err",[t,s.now()])}var i=t("handle"),a=t(20),c=t("ee"),s=t("loader"),f=window.onerror,u=!1,d=0;s.features.err=!0,t(1),window.onerror=r;try{throw new Error}catch(p){"stack"in p&&(t(12),t(11),"addEventListener"in window&&t(6),s.xhrWrappable&&t(13),u=!0)}c.on("fn-start",function(t,e,n){u&&(d+=1)}),c.on("fn-err",function(t,e,n){u&&(this.thrown=!0,o(n))}),c.on("fn-end",function(){u&&!this.thrown&&d>0&&(d-=1)}),c.on("internal-error",function(t){i("ierr",[t,s.now(),!0])})},{}],3:[function(t,e,n){t("loader").features.ins=!0},{}],4:[function(t,e,n){function r(){C++,M=y.hash,this[u]=b.now()}function o(){C--,y.hash!==M&&i(0,!0);var t=b.now();this[l]=~~this[l]+t-this[u],this[d]=t}function i(t,e){E.emit("newURL",[""+y,e])}function a(t,e){t.on(e,function(){this[e]=b.now()})}var c="-start",s="-end",f="-body",u="fn"+c,d="fn"+s,p="cb"+c,h="cb"+s,l="jsTime",m="fetch",v="addEventListener",w=window,y=w.location,b=t("loader");if(w[v]&&b.xhrWrappable){var g=t(9),x=t(10),E=t(8),O=t(6),R=t(12),P=t(7),T=t(13),S=t("ee"),N=S.get("tracer");t(14),b.features.spa=!0;var M,j=w[v],C=0;S.on(u,r),S.on(p,r),S.on(d,o),S.on(h,o),S.buffer([u,d,"xhr-done","xhr-resolved"]),O.buffer([u]),R.buffer(["setTimeout"+s,"clearTimeout"+c,u]),T.buffer([u,"new-xhr","send-xhr"+c]),P.buffer([m+c,m+"-done",m+f+c,m+f+s]),E.buffer(["newURL"]),g.buffer([u]),x.buffer(["propagate",p,h,"executor-err","resolve"+c]),N.buffer([u,"no-"+u]),a(T,"send-xhr"+c),a(S,"xhr-resolved"),a(S,"xhr-done"),a(P,m+c),a(P,m+"-done"),E.on("pushState-end",i),E.on("replaceState-end",i),j("hashchange",i,!0),j("load",i,!0),j("popstate",function(){i(0,C>1)},!0)}},{}],5:[function(t,e,n){function r(t){}if(window.performance&&window.performance.timing&&window.performance.getEntriesByType){var o=t("ee"),i=t("handle"),a=t(12),c=t(11),s="learResourceTimings",f="addEventListener",u="resourcetimingbufferfull",d="bstResource",p="resource",h="-start",l="-end",m="fn"+h,v="fn"+l,w="bstTimer",y="pushState",b=t("loader");b.features.stn=!0,t(8);var g=NREUM.o.EV;o.on(m,function(t,e){var n=t[0];n instanceof g&&(this.bstStart=b.now())}),o.on(v,function(t,e){var n=t[0];n instanceof g&&i("bst",[n,e,this.bstStart,b.now()])}),a.on(m,function(t,e,n){this.bstStart=b.now(),this.bstType=n}),a.on(v,function(t,e){i(w,[e,this.bstStart,b.now(),this.bstType])}),c.on(m,function(){this.bstStart=b.now()}),c.on(v,function(t,e){i(w,[e,this.bstStart,b.now(),"requestAnimationFrame"])}),o.on(y+h,function(t){this.time=b.now(),this.startPath=location.pathname+location.hash}),o.on(y+l,function(t){i("bstHist",[location.pathname+location.hash,this.startPath,this.time])}),f in window.performance&&(window.performance["c"+s]?window.performance[f](u,function(t){i(d,[window.performance.getEntriesByType(p)]),window.performance["c"+s]()},!1):window.performance[f]("webkit"+u,function(t){i(d,[window.performance.getEntriesByType(p)]),window.performance["webkitC"+s]()},!1)),document[f]("scroll",r,{passive:!0}),document[f]("keypress",r,!1),document[f]("click",r,!1)}},{}],6:[function(t,e,n){function r(t){for(var e=t;e&&!e.hasOwnProperty(u);)e=Object.getPrototypeOf(e);e&&o(e)}function o(t){c.inPlace(t,[u,d],"-",i)}function i(t,e){return t[1]}var a=t("ee").get("events"),c=t(22)(a,!0),s=t("gos"),f=XMLHttpRequest,u="addEventListener",d="removeEventListener";e.exports=a,"getPrototypeOf"in Object?(r(document),r(window),r(f.prototype)):f.prototype.hasOwnProperty(u)&&(o(window),o(f.prototype)),a.on(u+"-start",function(t,e){var n=t[1],r=s(n,"nr@wrapped",function(){function t(){if("function"==typeof n.handleEvent)return n.handleEvent.apply(n,arguments)}var e={object:t,"function":n}[typeof n];return e?c(e,"fn-",null,e.name||"anonymous"):n});this.wrapped=t[1]=r}),a.on(d+"-start",function(t){t[1]=this.wrapped||t[1]})},{}],7:[function(t,e,n){function r(t,e,n){var r=t[e];"function"==typeof r&&(t[e]=function(){var t=r.apply(this,arguments);return o.emit(n+"start",arguments,t),t.then(function(e){return o.emit(n+"end",[null,e],t),e},function(e){throw o.emit(n+"end",[e],t),e})})}var o=t("ee").get("fetch"),i=t(19);e.exports=o;var a=window,c="fetch-",s=c+"body-",f=["arrayBuffer","blob","json","text","formData"],u=a.Request,d=a.Response,p=a.fetch,h="prototype";u&&d&&p&&(i(f,function(t,e){r(u[h],e,s),r(d[h],e,s)}),r(a,"fetch",c),o.on(c+"end",function(t,e){var n=this;e?e.clone().arrayBuffer().then(function(t){n.rxSize=t.byteLength,o.emit(c+"done",[null,e],n)}):o.emit(c+"done",[t],n)}))},{}],8:[function(t,e,n){var r=t("ee").get("history"),o=t(22)(r);e.exports=r,o.inPlace(window.history,["pushState","replaceState"],"-")},{}],9:[function(t,e,n){var r=t("ee").get("mutation"),o=t(22)(r),i=NREUM.o.MO;e.exports=r,i&&(window.MutationObserver=function(t){return this instanceof i?new i(o(t,"fn-")):i.apply(this,arguments)},MutationObserver.prototype=i.prototype)},{}],10:[function(t,e,n){function r(t){var e=a.context(),n=c(t,"executor-",e),r=new f(n);return a.context(r).getCtx=function(){return e},a.emit("new-promise",[r,e],e),r}function o(t,e){return e}var i=t(22),a=t("ee").get("promise"),c=i(a),s=t(19),f=NREUM.o.PR;e.exports=a,f&&(window.Promise=r,["all","race"].forEach(function(t){var e=f[t];f[t]=function(n){function r(t){return function(){a.emit("propagate",[null,!o],i),o=o||!t}}var o=!1;s(n,function(e,n){Promise.resolve(n).then(r("all"===t),r(!1))});var i=e.apply(f,arguments),c=f.resolve(i);return c}}),["resolve","reject"].forEach(function(t){var e=f[t];f[t]=function(t){var n=e.apply(f,arguments);return t!==n&&a.emit("propagate",[t,!0],n),n}}),f.prototype["catch"]=function(t){return this.then(null,t)},f.prototype=Object.create(f.prototype,{constructor:{value:r}}),s(Object.getOwnPropertyNames(f),function(t,e){try{r[e]=f[e]}catch(n){}}),a.on("executor-start",function(t){t[0]=c(t[0],"resolve-",this),t[1]=c(t[1],"resolve-",this)}),a.on("executor-err",function(t,e,n){t[1](n)}),c.inPlace(f.prototype,["then"],"then-",o),a.on("then-start",function(t,e){this.promise=e,t[0]=c(t[0],"cb-",this),t[1]=c(t[1],"cb-",this)}),a.on("then-end",function(t,e,n){this.nextPromise=n;var r=this.promise;a.emit("propagate",[r,!0],n)}),a.on("cb-end",function(t,e,n){a.emit("propagate",[n,!0],this.nextPromise)}),a.on("propagate",function(t,e,n){this.getCtx&&!e||(this.getCtx=function(){if(t instanceof Promise)var e=a.context(t);return e&&e.getCtx?e.getCtx():this})}),r.toString=function(){return""+f})},{}],11:[function(t,e,n){var r=t("ee").get("raf"),o=t(22)(r),i="equestAnimationFrame";e.exports=r,o.inPlace(window,["r"+i,"mozR"+i,"webkitR"+i,"msR"+i],"raf-"),r.on("raf-start",function(t){t[0]=o(t[0],"fn-")})},{}],12:[function(t,e,n){function r(t,e,n){t[0]=a(t[0],"fn-",null,n)}function o(t,e,n){this.method=n,this.timerDuration=isNaN(t[1])?0:+t[1],t[0]=a(t[0],"fn-",this,n)}var i=t("ee").get("timer"),a=t(22)(i),c="setTimeout",s="setInterval",f="clearTimeout",u="-start",d="-";e.exports=i,a.inPlace(window,[c,"setImmediate"],c+d),a.inPlace(window,[s],s+d),a.inPlace(window,[f,"clearImmediate"],f+d),i.on(s+u,r),i.on(c+u,o)},{}],13:[function(t,e,n){function r(t,e){d.inPlace(e,["onreadystatechange"],"fn-",c)}function o(){var t=this,e=u.context(t);t.readyState>3&&!e.resolved&&(e.resolved=!0,u.emit("xhr-resolved",[],t)),d.inPlace(t,y,"fn-",c)}function i(t){b.push(t),l&&(x?x.then(a):v?v(a):(E=-E,O.data=E))}function a(){for(var t=0;t<b.length;t++)r([],b[t]);b.length&&(b=[])}function c(t,e){return e}function s(t,e){for(var n in t)e[n]=t[n];return e}t(6);var f=t("ee"),u=f.get("xhr"),d=t(22)(u),p=NREUM.o,h=p.XHR,l=p.MO,m=p.PR,v=p.SI,w="readystatechange",y=["onload","onerror","onabort","onloadstart","onloadend","onprogress","ontimeout"],b=[];e.exports=u;var g=window.XMLHttpRequest=function(t){var e=new h(t);try{u.emit("new-xhr",[e],e),e.addEventListener(w,o,!1)}catch(n){try{u.emit("internal-error",[n])}catch(r){}}return e};if(s(h,g),g.prototype=h.prototype,d.inPlace(g.prototype,["open","send"],"-xhr-",c),u.on("send-xhr-start",function(t,e){r(t,e),i(e)}),u.on("open-xhr-start",r),l){var x=m&&m.resolve();if(!v&&!m){var E=1,O=document.createTextNode(E);new l(a).observe(O,{characterData:!0})}}else f.on("fn-end",function(t){t[0]&&t[0].type===w||a()})},{}],14:[function(t,e,n){function r(t){var e=this.params,n=this.metrics;if(!this.ended){this.ended=!0;for(var r=0;r<d;r++)t.removeEventListener(u[r],this.listener,!1);if(!e.aborted){if(n.duration=a.now()-this.startTime,4===t.readyState){e.status=t.status;var i=o(t,this.lastSize);if(i&&(n.rxSize=i),this.sameOrigin){var s=t.getResponseHeader("X-NewRelic-App-Data");s&&(e.cat=s.split(", ").pop())}}else e.status=0;n.cbTime=this.cbTime,f.emit("xhr-done",[t],t),c("xhr",[e,n,this.startTime])}}}function o(t,e){var n=t.responseType;if("json"===n&&null!==e)return e;var r="arraybuffer"===n||"blob"===n||"json"===n?t.response:t.responseText;return l(r)}function i(t,e){var n=s(e),r=t.params;r.host=n.hostname+":"+n.port,r.pathname=n.pathname,t.sameOrigin=n.sameOrigin}var a=t("loader");if(a.xhrWrappable){var c=t("handle"),s=t(15),f=t("ee"),u=["load","error","abort","timeout"],d=u.length,p=t("id"),h=t(18),l=t(17),m=window.XMLHttpRequest;a.features.xhr=!0,t(13),f.on("new-xhr",function(t){var e=this;e.totalCbs=0,e.called=0,e.cbTime=0,e.end=r,e.ended=!1,e.xhrGuids={},e.lastSize=null,h&&(h>34||h<10)||window.opera||t.addEventListener("progress",function(t){e.lastSize=t.loaded},!1)}),f.on("open-xhr-start",function(t){this.params={method:t[0]},i(this,t[1]),this.metrics={}}),f.on("open-xhr-end",function(t,e){"loader_config"in NREUM&&"xpid"in NREUM.loader_config&&this.sameOrigin&&e.setRequestHeader("X-NewRelic-ID",NREUM.loader_config.xpid)}),f.on("send-xhr-start",function(t,e){var n=this.metrics,r=t[0],o=this;if(n&&r){var i=l(r);i&&(n.txSize=i)}this.startTime=a.now(),this.listener=function(t){try{"abort"===t.type&&(o.params.aborted=!0),("load"!==t.type||o.called===o.totalCbs&&(o.onloadCalled||"function"!=typeof e.onload))&&o.end(e)}catch(n){try{f.emit("internal-error",[n])}catch(r){}}};for(var c=0;c<d;c++)e.addEventListener(u[c],this.listener,!1)}),f.on("xhr-cb-time",function(t,e,n){this.cbTime+=t,e?this.onloadCalled=!0:this.called+=1,this.called!==this.totalCbs||!this.onloadCalled&&"function"==typeof n.onload||this.end(n)}),f.on("xhr-load-added",function(t,e){var n=""+p(t)+!!e;this.xhrGuids&&!this.xhrGuids[n]&&(this.xhrGuids[n]=!0,this.totalCbs+=1)}),f.on("xhr-load-removed",function(t,e){var n=""+p(t)+!!e;this.xhrGuids&&this.xhrGuids[n]&&(delete this.xhrGuids[n],this.totalCbs-=1)}),f.on("addEventListener-end",function(t,e){e instanceof m&&"load"===t[0]&&f.emit("xhr-load-added",[t[1],t[2]],e)}),f.on("removeEventListener-end",function(t,e){e instanceof m&&"load"===t[0]&&f.emit("xhr-load-removed",[t[1],t[2]],e)}),f.on("fn-start",function(t,e,n){e instanceof m&&("onload"===n&&(this.onload=!0),("load"===(t[0]&&t[0].type)||this.onload)&&(this.xhrCbStart=a.now()))}),f.on("fn-end",function(t,e){this.xhrCbStart&&f.emit("xhr-cb-time",[a.now()-this.xhrCbStart,this.onload,e],e)})}},{}],15:[function(t,e,n){e.exports=function(t){var e=document.createElement("a"),n=window.location,r={};e.href=t,r.port=e.port;var o=e.href.split("://");!r.port&&o[1]&&(r.port=o[1].split("/")[0].split("@").pop().split(":")[1]),r.port&&"0"!==r.port||(r.port="https"===o[0]?"443":"80"),r.hostname=e.hostname||n.hostname,r.pathname=e.pathname,r.protocol=o[0],"/"!==r.pathname.charAt(0)&&(r.pathname="/"+r.pathname);var i=!e.protocol||":"===e.protocol||e.protocol===n.protocol,a=e.hostname===document.domain&&e.port===n.port;return r.sameOrigin=i&&(!e.hostname||a),r}},{}],16:[function(t,e,n){function r(){}function o(t,e,n){return function(){return i(t,[f.now()].concat(c(arguments)),e?null:this,n),e?void 0:this}}var i=t("handle"),a=t(19),c=t(20),s=t("ee").get("tracer"),f=t("loader"),u=NREUM;"undefined"==typeof window.newrelic&&(newrelic=u);var d=["setPageViewName","setCustomAttribute","setErrorHandler","finished","addToTrace","inlineHit","addRelease"],p="api-",h=p+"ixn-";a(d,function(t,e){u[e]=o(p+e,!0,"api")}),u.addPageAction=o(p+"addPageAction",!0),u.setCurrentRouteName=o(p+"routeName",!0),e.exports=newrelic,u.interaction=function(){return(new r).get()};var l=r.prototype={createTracer:function(t,e){var n={},r=this,o="function"==typeof e;return i(h+"tracer",[f.now(),t,n],r),function(){if(s.emit((o?"":"no-")+"fn-start",[f.now(),r,o],n),o)try{return e.apply(this,arguments)}finally{s.emit("fn-end",[f.now()],n)}}}};a("setName,setAttribute,save,ignore,onEnd,getContext,end,get".split(","),function(t,e){l[e]=o(h+e)}),newrelic.noticeError=function(t){"string"==typeof t&&(t=new Error(t)),i("err",[t,f.now()])}},{}],17:[function(t,e,n){e.exports=function(t){if("string"==typeof t&&t.length)return t.length;if("object"==typeof t){if("undefined"!=typeof ArrayBuffer&&t instanceof ArrayBuffer&&t.byteLength)return t.byteLength;if("undefined"!=typeof Blob&&t instanceof Blob&&t.size)return t.size;if(!("undefined"!=typeof FormData&&t instanceof FormData))try{return JSON.stringify(t).length}catch(e){return}}}},{}],18:[function(t,e,n){var r=0,o=navigator.userAgent.match(/Firefox[\/\s](\d+\.\d+)/);o&&(r=+o[1]),e.exports=r},{}],19:[function(t,e,n){function r(t,e){var n=[],r="",i=0;for(r in t)o.call(t,r)&&(n[i]=e(r,t[r]),i+=1);return n}var o=Object.prototype.hasOwnProperty;e.exports=r},{}],20:[function(t,e,n){function r(t,e,n){e||(e=0),"undefined"==typeof n&&(n=t?t.length:0);for(var r=-1,o=n-e||0,i=Array(o<0?0:o);++r<o;)i[r]=t[e+r];return i}e.exports=r},{}],21:[function(t,e,n){e.exports={exists:"undefined"!=typeof window.performance&&window.performance.timing&&"undefined"!=typeof window.performance.timing.navigationStart}},{}],22:[function(t,e,n){function r(t){return!(t&&t instanceof Function&&t.apply&&!t[a])}var o=t("ee"),i=t(20),a="nr@original",c=Object.prototype.hasOwnProperty,s=!1;e.exports=function(t,e){function n(t,e,n,o){function nrWrapper(){var r,a,c,s;try{a=this,r=i(arguments),c="function"==typeof n?n(r,a):n||{}}catch(f){p([f,"",[r,a,o],c])}u(e+"start",[r,a,o],c);try{return s=t.apply(a,r)}catch(d){throw u(e+"err",[r,a,d],c),d}finally{u(e+"end",[r,a,s],c)}}return r(t)?t:(e||(e=""),nrWrapper[a]=t,d(t,nrWrapper),nrWrapper)}function f(t,e,o,i){o||(o="");var a,c,s,f="-"===o.charAt(0);for(s=0;s<e.length;s++)c=e[s],a=t[c],r(a)||(t[c]=n(a,f?c+o:o,i,c))}function u(n,r,o){if(!s||e){var i=s;s=!0;try{t.emit(n,r,o,e)}catch(a){p([a,n,r,o])}s=i}}function d(t,e){if(Object.defineProperty&&Object.keys)try{var n=Object.keys(t);return n.forEach(function(n){Object.defineProperty(e,n,{get:function(){return t[n]},set:function(e){return t[n]=e,e}})}),e}catch(r){p([r])}for(var o in t)c.call(t,o)&&(e[o]=t[o]);return e}function p(e){try{t.emit("internal-error",e)}catch(n){}}return t||(t=o),n.inPlace=f,n.flag=a,n}},{}],ee:[function(t,e,n){function r(){}function o(t){function e(t){return t&&t instanceof r?t:t?s(t,c,i):i()}function n(n,r,o,i){if(!p.aborted||i){t&&t(n,r,o);for(var a=e(o),c=l(n),s=c.length,f=0;f<s;f++)c[f].apply(a,r);var d=u[y[n]];return d&&d.push([b,n,r,a]),a}}function h(t,e){w[t]=l(t).concat(e)}function l(t){return w[t]||[]}function m(t){return d[t]=d[t]||o(n)}function v(t,e){f(t,function(t,n){e=e||"feature",y[n]=e,e in u||(u[e]=[])})}var w={},y={},b={on:h,emit:n,get:m,listeners:l,context:e,buffer:v,abort:a,aborted:!1};return b}function i(){return new r}function a(){(u.api||u.feature)&&(p.aborted=!0,u=p.backlog={})}var c="nr@context",s=t("gos"),f=t(19),u={},d={},p=e.exports=o();p.backlog=u},{}],gos:[function(t,e,n){function r(t,e,n){if(o.call(t,e))return t[e];var r=n();if(Object.defineProperty&&Object.keys)try{return Object.defineProperty(t,e,{value:r,writable:!0,enumerable:!1}),r}catch(i){}return t[e]=r,r}var o=Object.prototype.hasOwnProperty;e.exports=r},{}],handle:[function(t,e,n){function r(t,e,n,r){o.buffer([t],r),o.emit(t,e,n)}var o=t("ee").get("handle");e.exports=r,r.ee=o},{}],id:[function(t,e,n){function r(t){var e=typeof t;return!t||"object"!==e&&"function"!==e?-1:t===window?0:a(t,i,function(){return o++})}var o=1,i="nr@id",a=t("gos");e.exports=r},{}],loader:[function(t,e,n){function r(){if(!x++){var t=g.info=NREUM.info,e=p.getElementsByTagName("script")[0];if(setTimeout(u.abort,3e4),!(t&&t.licenseKey&&t.applicationID&&e))return u.abort();f(y,function(e,n){t[e]||(t[e]=n)}),s("mark",["onload",a()+g.offset],null,"api");var n=p.createElement("script");n.src="https://"+t.agent,e.parentNode.insertBefore(n,e)}}function o(){"complete"===p.readyState&&i()}function i(){s("mark",["domContent",a()+g.offset],null,"api")}function a(){return E.exists&&performance.now?Math.round(performance.now()):(c=Math.max((new Date).getTime(),c))-g.offset}var c=(new Date).getTime(),s=t("handle"),f=t(19),u=t("ee"),d=window,p=d.document,h="addEventListener",l="attachEvent",m=d.XMLHttpRequest,v=m&&m.prototype;NREUM.o={ST:setTimeout,SI:d.setImmediate,CT:clearTimeout,XHR:m,REQ:d.Request,EV:d.Event,PR:d.Promise,MO:d.MutationObserver};var w=""+location,y={beacon:"bam.nr-data.net",errorBeacon:"bam.nr-data.net",agent:"js-agent.newrelic.com/nr-spa-1044.min.js"},b=m&&v&&v[h]&&!/CriOS/.test(navigator.userAgent),g=e.exports={offset:c,now:a,origin:w,features:{},xhrWrappable:b};t(16),p[h]?(p[h]("DOMContentLoaded",i,!1),d[h]("load",r,!1)):(p[l]("onreadystatechange",o),d[l]("onload",r)),s("mark",["firstbyte",c],null,"api");var x=0,E=t(21)},{}]},{},["loader",2,14,5,3,4]);</script><link rel="apple-touch-icon" href="https://www.safaribooksonline.com/static/images/apple-touch-icon.8cc2fd27400e.png"><link rel="shortcut icon" href="https://www.safaribooksonline.com/favicon.ico" type="image/x-icon"><link href="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/css.css" rel="stylesheet" type="text/css"><title>11. Training Deep Neural Nets - Hands-On Machine Learning with Scikit-Learn and TensorFlow</title><link rel="stylesheet" href="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/d6ec1592ffb3.css" type="text/css"><link rel="stylesheet" type="text/css" href="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/annotator.css"><link rel="stylesheet" href="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/font-awesome.css"><style type="text/css" title="ibis-book">@charset "utf-8";#sbo-rt-content html,#sbo-rt-content div,#sbo-rt-content div,#sbo-rt-content span,#sbo-rt-content applet,#sbo-rt-content object,#sbo-rt-content iframe,#sbo-rt-content h1,#sbo-rt-content h2,#sbo-rt-content h3,#sbo-rt-content h4,#sbo-rt-content h5,#sbo-rt-content h6,#sbo-rt-content p,#sbo-rt-content blockquote,#sbo-rt-content pre,#sbo-rt-content a,#sbo-rt-content abbr,#sbo-rt-content acronym,#sbo-rt-content address,#sbo-rt-content big,#sbo-rt-content cite,#sbo-rt-content code,#sbo-rt-content del,#sbo-rt-content dfn,#sbo-rt-content em,#sbo-rt-content img,#sbo-rt-content ins,#sbo-rt-content kbd,#sbo-rt-content q,#sbo-rt-content s,#sbo-rt-content samp,#sbo-rt-content small,#sbo-rt-content strike,#sbo-rt-content strong,#sbo-rt-content sub,#sbo-rt-content sup,#sbo-rt-content tt,#sbo-rt-content var,#sbo-rt-content b,#sbo-rt-content u,#sbo-rt-content i,#sbo-rt-content center,#sbo-rt-content dl,#sbo-rt-content dt,#sbo-rt-content dd,#sbo-rt-content ol,#sbo-rt-content ul,#sbo-rt-content li,#sbo-rt-content fieldset,#sbo-rt-content form,#sbo-rt-content label,#sbo-rt-content legend,#sbo-rt-content table,#sbo-rt-content caption,#sbo-rt-content tdiv,#sbo-rt-content tfoot,#sbo-rt-content thead,#sbo-rt-content tr,#sbo-rt-content th,#sbo-rt-content td,#sbo-rt-content article,#sbo-rt-content aside,#sbo-rt-content canvas,#sbo-rt-content details,#sbo-rt-content embed,#sbo-rt-content figure,#sbo-rt-content figcaption,#sbo-rt-content footer,#sbo-rt-content header,#sbo-rt-content hgroup,#sbo-rt-content menu,#sbo-rt-content nav,#sbo-rt-content output,#sbo-rt-content ruby,#sbo-rt-content section,#sbo-rt-content summary,#sbo-rt-content time,#sbo-rt-content mark,#sbo-rt-content audio,#sbo-rt-content video{margin:0;padding:0;border:0;font-size:100%;font:inherit;vertical-align:baseline}#sbo-rt-content article,#sbo-rt-content aside,#sbo-rt-content details,#sbo-rt-content figcaption,#sbo-rt-content figure,#sbo-rt-content footer,#sbo-rt-content header,#sbo-rt-content hgroup,#sbo-rt-content menu,#sbo-rt-content nav,#sbo-rt-content section{display:block}#sbo-rt-content div{line-height:1}#sbo-rt-content ol,#sbo-rt-content ul{list-style:none}#sbo-rt-content blockquote,#sbo-rt-content q{quotes:none}#sbo-rt-content blockquote:before,#sbo-rt-content blockquote:after,#sbo-rt-content q:before,#sbo-rt-content q:after{content:none}#sbo-rt-content table{border-collapse:collapse;border-spacing:0}@page{margin:5px !important}#sbo-rt-content p{margin:10px 0 0;line-height:125%;text-align:left}#sbo-rt-content p.byline{text-align:left;margin:-33px auto 35px;font-style:italic;font-weight:bold}#sbo-rt-content div.preface p+p.byline{margin:1em 0 0}#sbo-rt-content div.preface p.byline+p.byline{margin:0}#sbo-rt-content div.sect1>p.byline{margin:-.25em 0 1em}#sbo-rt-content div.sect1>p.byline+p.byline{margin-top:-1em}#sbo-rt-content em{font-style:italic;font-family:inherit}#sbo-rt-content em strong,#sbo-rt-content strong em{font-weight:bold;font-style:italic;font-family:inherit}#sbo-rt-content strong,#sbo-rt-content span.bold{font-weight:bold}#sbo-rt-content em.replaceable{font-style:italic}#sbo-rt-content strong.userinput{font-weight:bold;font-style:normal}#sbo-rt-content span.bolditalic{font-weight:bold;font-style:italic}#sbo-rt-content a.ulink,#sbo-rt-content a.xref,#sbo-rt-content a.email,#sbo-rt-content a.link,#sbo-rt-content a{text-decoration:none;color:#8e0012}#sbo-rt-content span.lineannotation{font-style:italic;color:#a62a2a;font-family:serif}#sbo-rt-content span.underline{text-decoration:underline}#sbo-rt-content span.strikethrough{text-decoration:line-through}#sbo-rt-content span.smallcaps{font-variant:small-caps}#sbo-rt-content span.cursor{background:#000;color:#fff}#sbo-rt-content span.smaller{font-size:75%}#sbo-rt-content .boxedtext,#sbo-rt-content .keycap{border-style:solid;border-width:1px;border-color:#000;padding:1px}#sbo-rt-content span.gray50{color:#7F7F7F;}#sbo-rt-content h1,#sbo-rt-content div.toc-title,#sbo-rt-content h2,#sbo-rt-content h3,#sbo-rt-content h4,#sbo-rt-content h5{-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;font-weight:bold;text-align:left;page-break-after:avoid !important;font-family:sans-serif,"DejaVuSans"}#sbo-rt-content div.toc-title{font-size:1.5em;margin-top:20px !important;margin-bottom:30px !important}#sbo-rt-content section[data-type="sect1"] h1{font-size:1.3em;color:#8e0012;margin:40px 0 8px 0}#sbo-rt-content section[data-type="sect2"] h2{font-size:1.1em;margin:30px 0 8px 0 !important}#sbo-rt-content section[data-type="sect3"] h3{font-size:1em;color:#555;margin:20px 0 8px 0 !important}#sbo-rt-content section[data-type="sect4"] h4{font-size:1em;font-weight:normal;font-style:italic;margin:15px 0 6px 0 !important}#sbo-rt-content section[data-type="chapter"]>div>h1,#sbo-rt-content section[data-type="preface"]>div>h1,#sbo-rt-content section[data-type="appendix"]>div>h1,#sbo-rt-content section[data-type="glossary"]>div>h1,#sbo-rt-content section[data-type="bibliography"]>div>h1,#sbo-rt-content section[data-type="index"]>div>h1{font-size:2em;line-height:1;margin-bottom:50px;color:#000;padding-bottom:10px;border-bottom:1px solid #000}#sbo-rt-content span.label,#sbo-rt-content span.keep-together{font-size:inherit;font-weight:inherit}#sbo-rt-content div[data-type="part"] h1{font-size:2em;text-align:center;margin-top:0 !important;margin-bottom:50px;padding:50px 0 10px 0;border-bottom:1px solid #000}#sbo-rt-content img.width-ninety{width:90%}#sbo-rt-content img{max-width:95%;margin:0 auto;padding:0}#sbo-rt-content div.figure{background-color:transparent;text-align:center !important;margin:15px 0 15px 0 !important;page-break-inside:avoid}#sbo-rt-content figure{margin:15px 0 15px 0 !important;page-break-inside:avoid}#sbo-rt-content div.figure h6{font-size:90%;text-align:center;font-weight:normal;font-style:italic;font-family:serif !important;color:#000;padding-top:10px !important;page-break-before:avoid;page-break-after:avoid}#sbo-rt-content div.informalfigure{text-align:center !important;padding:5px 0 !important}#sbo-rt-content div.sidebar{margin:15px 0 10px 0 !important;border:1px solid #DCDCDC;background-color:#F7F7F7;padding:15px !important;page-break-inside:avoid}#sbo-rt-content aside[data-type="sidebar"]{margin:15px 0 10px 0 !important;page-break-inside:avoid}#sbo-rt-content div.sidebar-title,#sbo-rt-content aside[data-type="sidebar"] h5{font-weight:bold;font-size:1em;font-family:sans-serif;text-transform:uppercase;letter-spacing:1px;text-align:center;margin:4px 0 6px 0 !important;page-break-inside:avoid}#sbo-rt-content div.sidebar ol,#sbo-rt-content div.sidebar ul,#sbo-rt-content aside[data-type="sidebar"] ol,#sbo-rt-content aside[data-type="sidebar"] ul{margin-left:1.25em !important}#sbo-rt-content div.sidebar div.figure p.title,#sbo-rt-content aside[data-type="sidebar"] figcaption,#sbo-rt-content div.sidebar div.informalfigure div.caption{font-size:90%;text-align:center;font-weight:normal;font-style:italic;font-family:serif !important;color:#000;padding:5px !important;page-break-before:avoid;page-break-after:avoid}#sbo-rt-content div.sidebar div.tip,#sbo-rt-content div.sidebar div[data-type="tip"],#sbo-rt-content div.sidebar div.note,#sbo-rt-content div.sidebar div[data-type="note"],#sbo-rt-content div.sidebar div.warning,#sbo-rt-content div.sidebar div[data-type="warning"],#sbo-rt-content div.sidebar div[data-type="caution"],#sbo-rt-content div.sidebar div[data-type="important"]{margin:20px auto 20px auto !important;font-size:90%;width:85%}#sbo-rt-content aside[data-type="sidebar"] p.byline{font-size:90%;font-weight:bold;font-style:italic;text-align:center;text-indent:0;margin:5px auto 6px;page-break-after:avoid}#sbo-rt-content pre{white-space:pre-wrap;font-family:"Ubuntu Mono",monospace;margin:25px 0 25px 20px;font-size:85%;display:block;-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;overflow-wrap:break-word}#sbo-rt-content div.note pre.programlisting,#sbo-rt-content div.tip pre.programlisting,#sbo-rt-content div.warning pre.programlisting,#sbo-rt-content div.caution pre.programlisting,#sbo-rt-content div.important pre.programlisting{margin-bottom:0}#sbo-rt-content code{font-family:"Ubuntu Mono",monospace;-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;overflow-wrap:break-word}#sbo-rt-content code strong em,#sbo-rt-content code em strong,#sbo-rt-content pre em strong,#sbo-rt-content pre strong em,#sbo-rt-content strong code em code,#sbo-rt-content em code strong code,#sbo-rt-content span.bolditalic code{font-weight:bold;font-style:italic;font-family:"Ubuntu Mono BoldItal",monospace}#sbo-rt-content code em,#sbo-rt-content em code,#sbo-rt-content pre em,#sbo-rt-content em.replaceable{font-family:"Ubuntu Mono Ital",monospace;font-style:italic}#sbo-rt-content code strong,#sbo-rt-content strong code,#sbo-rt-content pre strong,#sbo-rt-content strong.userinput{font-family:"Ubuntu Mono Bold",monospace;font-weight:bold}#sbo-rt-content div[data-type="example"]{margin:10px 0 15px 0 !important}#sbo-rt-content div[data-type="example"] h1,#sbo-rt-content div[data-type="example"] h2,#sbo-rt-content div[data-type="example"] h3,#sbo-rt-content div[data-type="example"] h4,#sbo-rt-content div[data-type="example"] h5,#sbo-rt-content div[data-type="example"] h6{font-style:italic;font-weight:normal;text-align:left !important;text-transform:none !important;font-family:serif !important;margin:10px 0 5px 0 !important;border-bottom:1px solid #000}#sbo-rt-content li pre.example{padding:10px 0 !important}#sbo-rt-content div[data-type="example"] pre[data-type="programlisting"],#sbo-rt-content div[data-type="example"] pre[data-type="screen"]{margin:0}#sbo-rt-content section[data-type="titlepage"]>div>h1{font-size:2em;margin:50px 0 10px 0 !important;line-height:1;text-align:center}#sbo-rt-content section[data-type="titlepage"] h2,#sbo-rt-content section[data-type="titlepage"] p.subtitle,#sbo-rt-content section[data-type="titlepage"] p[data-type="subtitle"]{font-size:1.3em;font-weight:normal;text-align:center;margin-top:.5em;color:#555}#sbo-rt-content section[data-type="titlepage"]>div>h2[data-type="author"],#sbo-rt-content section[data-type="titlepage"] p.author{font-size:1.3em;font-family:serif !important;font-weight:bold;margin:50px 0 !important;text-align:center}#sbo-rt-content section[data-type="titlepage"] p.edition{text-align:center;text-transform:uppercase;margin-top:2em}#sbo-rt-content section[data-type="titlepage"]{text-align:center}#sbo-rt-content section[data-type="titlepage"]:after{content:url(css_assets/titlepage_footer_ebook.png);margin:0 auto;max-width:80%}#sbo-rt-content div.book div.titlepage div.publishername{margin-top:60%;margin-bottom:20px;text-align:center;font-size:1.25em}#sbo-rt-content div.book div.titlepage div.locations p{margin:0;text-align:center}#sbo-rt-content div.book div.titlepage div.locations p.cities{font-size:80%;text-align:center;margin-top:5px}#sbo-rt-content section.preface[title="Dedication"]>div.titlepage h2.title{text-align:center;text-transform:uppercase;font-size:1.5em;margin-top:50px;margin-bottom:50px}#sbo-rt-content ul.stafflist{margin:15px 0 15px 20px !important}#sbo-rt-content ul.stafflist li{list-style-type:none;padding:5px 0}#sbo-rt-content ul.printings li{list-style-type:none}#sbo-rt-content section.preface[title="Dedication"] p{font-style:italic;text-align:center}#sbo-rt-content div.colophon h1.title{font-size:1.3em;margin:0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon h2.subtitle{margin:0 !important;color:#000;font-family:serif !important;font-size:1em;font-weight:normal}#sbo-rt-content div.colophon div.author h3.author{font-size:1.1em;font-family:serif !important;margin:10px 0 0 !important;font-weight:normal}#sbo-rt-content div.colophon div.editor h4,#sbo-rt-content div.colophon div.editor h3.editor{color:#000;font-size:.8em;margin:15px 0 0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon div.editor h3.editor{font-size:.8em;margin:0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon div.publisher{margin-top:10px}#sbo-rt-content div.colophon div.publisher p,#sbo-rt-content div.colophon div.publisher span.publishername{margin:0;font-size:.8em}#sbo-rt-content div.legalnotice p,#sbo-rt-content div.timestamp p{font-size:.8em}#sbo-rt-content div.timestamp p{margin-top:10px}#sbo-rt-content div.colophon[title="About the Author"] h1.title,#sbo-rt-content div.colophon[title="Colophon"] h1.title{font-size:1.5em;margin:0 !important;font-family:sans-serif !important}#sbo-rt-content section.chapter div.titlepage div.author{margin:10px 0 10px 0}#sbo-rt-content section.chapter div.titlepage div.author div.affiliation{font-style:italic}#sbo-rt-content div.attribution{margin:5px 0 0 50px !important}#sbo-rt-content h3.author span.orgname{display:none}#sbo-rt-content div.epigraph{margin:10px 0 10px 20px !important;page-break-inside:avoid;font-size:90%}#sbo-rt-content div.epigraph p{font-style:italic}#sbo-rt-content blockquote,#sbo-rt-content div.blockquote{margin:10px !important;page-break-inside:avoid;font-size:95%}#sbo-rt-content blockquote p,#sbo-rt-content div.blockquote p{font-style:italic;margin:.75em 0 0 !important}#sbo-rt-content blockquote div.attribution,#sbo-rt-content blockquote p[data-type="attribution"]{margin:5px 0 10px 30px !important;text-align:right;width:80%}#sbo-rt-content blockquote div.attribution p,#sbo-rt-content blockquote p[data-type="attribution"]{font-style:normal;margin-top:5px}#sbo-rt-content blockquote div.attribution p:before,#sbo-rt-content blockquote p[data-type="attribution"]:before{font-style:normal;content:"—";-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none}#sbo-rt-content p.right{text-align:right;margin:0}#sbo-rt-content div[data-type="footnotes"]{border-top:1px solid black;margin-top:1.5em}#sbo-rt-content sub,#sbo-rt-content sup{font-size:75%;line-height:0;position:relative}#sbo-rt-content sup{top:-.5em}#sbo-rt-content sub{bottom:-.25em}#sbo-rt-content div.refentry p.refname{font-size:1em;font-family:sans-serif,"DejaVuSans";font-weight:bold;margin-bottom:5px;overflow:auto;width:100%}#sbo-rt-content div.refentry{width:100%;display:block;margin-top:2em}#sbo-rt-content div.refsynopsisdiv{display:block;clear:both}#sbo-rt-content div.refentry header{page-break-inside:avoid !important;display:block;break-inside:avoid !important;padding-top:0;border-bottom:1px solid #000}#sbo-rt-content div.refsect1 h6{font-size:.9em;font-family:sans-serif,"DejaVuSans";font-weight:bold}#sbo-rt-content div.refsect1{margin-top:3em}#sbo-rt-content dt{padding-top:10px !important;padding-bottom:0 !important}#sbo-rt-content dd{margin-left:1.5em !important;margin-bottom:.25em}#sbo-rt-content dd ol,#sbo-rt-content dd ul{padding-left:1em}#sbo-rt-content dd li{margin-top:0;margin-bottom:0}#sbo-rt-content dd,#sbo-rt-content li{text-align:left}#sbo-rt-content ul,#sbo-rt-content ul>li,#sbo-rt-content ol ul,#sbo-rt-content ol ul>li,#sbo-rt-content ul ol ul,#sbo-rt-content ul ol ul>li{list-style-type:disc}#sbo-rt-content ul ul,#sbo-rt-content ul ul>li{list-style-type:square}#sbo-rt-content ul ul ul,#sbo-rt-content ul ul ul>li{list-style-type:circle}#sbo-rt-content ol,#sbo-rt-content ol>li,#sbo-rt-content ol ul ol,#sbo-rt-content ol ul ol>li,#sbo-rt-content ul ol,#sbo-rt-content ul ol>li{list-style-type:decimal}#sbo-rt-content ol ol,#sbo-rt-content ol ol>li{list-style-type:lower-alpha}#sbo-rt-content ol ol ol,#sbo-rt-content ol ol ol>li{list-style-type:lower-roman}#sbo-rt-content ol,#sbo-rt-content ul{list-style-position:outside;margin:15px 0 15px 1.25em;padding-left:2.25em}#sbo-rt-content ol li,#sbo-rt-content ul li{margin:.5em 0 .65em;line-height:125%}#sbo-rt-content div.orderedlistalpha{list-style-type:upper-alpha}#sbo-rt-content table.simplelist,#sbo-rt-content ul.simplelist{margin:15px 0 15px 20px !important}#sbo-rt-content ul.simplelist li{list-style-type:none;padding:5px 0}#sbo-rt-content table.simplelist td{border:none}#sbo-rt-content table.simplelist tr{border-bottom:none}#sbo-rt-content table.simplelist tr:nth-of-type(even){background-color:transparent}#sbo-rt-content dl.calloutlist p:first-child{margin-top:-25px !important}#sbo-rt-content dl.calloutlist dd{padding-left:0;margin-top:-25px}#sbo-rt-content dl.calloutlist img,#sbo-rt-content a.co img{padding:0}#sbo-rt-content div.toc ol{margin-top:8px !important;margin-bottom:8px !important;margin-left:0 !important;padding-left:0 !important}#sbo-rt-content div.toc ol ol{margin-left:30px !important;padding-left:0 !important}#sbo-rt-content div.toc ol li{list-style-type:none}#sbo-rt-content div.toc a{color:#8e0012}#sbo-rt-content div.toc ol a{font-size:1em;font-weight:bold}#sbo-rt-content div.toc ol>li>ol a{font-weight:bold;font-size:1em}#sbo-rt-content div.toc ol>li>ol>li>ol a{text-decoration:none;font-weight:normal;font-size:1em}#sbo-rt-content div.tip,#sbo-rt-content div[data-type="tip"],#sbo-rt-content div.note,#sbo-rt-content div[data-type="note"],#sbo-rt-content div.warning,#sbo-rt-content div[data-type="warning"],#sbo-rt-content div[data-type="caution"],#sbo-rt-content div[data-type="important"]{margin:30px !important;font-size:90%;padding:10px 8px 20px 8px !important;page-break-inside:avoid}#sbo-rt-content div.tip ol,#sbo-rt-content div.tip ul,#sbo-rt-content div[data-type="tip"] ol,#sbo-rt-content div[data-type="tip"] ul,#sbo-rt-content div.note ol,#sbo-rt-content div.note ul,#sbo-rt-content div[data-type="note"] ol,#sbo-rt-content div[data-type="note"] ul,#sbo-rt-content div.warning ol,#sbo-rt-content div.warning ul,#sbo-rt-content div[data-type="warning"] ol,#sbo-rt-content div[data-type="warning"] ul,#sbo-rt-content div[data-type="caution"] ol,#sbo-rt-content div[data-type="caution"] ul,#sbo-rt-content div[data-type="important"] ol,#sbo-rt-content div[data-type="important"] ul{margin-left:1.5em !important}#sbo-rt-content div.tip,#sbo-rt-content div[data-type="tip"],#sbo-rt-content div.note,#sbo-rt-content div[data-type="note"]{border:1px solid #BEBEBE;background-color:transparent}#sbo-rt-content div.warning,#sbo-rt-content div[data-type="warning"],#sbo-rt-content div[data-type="caution"],#sbo-rt-content div[data-type="important"]{border:1px solid #BC8F8F}#sbo-rt-content div.tip h3,#sbo-rt-content div[data-type="tip"] h6,#sbo-rt-content div[data-type="tip"] h1,#sbo-rt-content div.note h3,#sbo-rt-content div[data-type="note"] h6,#sbo-rt-content div[data-type="note"] h1,#sbo-rt-content div.warning h3,#sbo-rt-content div[data-type="warning"] h6,#sbo-rt-content div[data-type="warning"] h1,#sbo-rt-content div[data-type="caution"] h6,#sbo-rt-content div[data-type="caution"] h1,#sbo-rt-content div[data-type="important"] h1,#sbo-rt-content div[data-type="important"] h6{font-weight:bold;font-size:110%;font-family:sans-serif !important;text-transform:uppercase;letter-spacing:1px;text-align:center;margin:4px 0 6px !important}#sbo-rt-content div.tip h3,#sbo-rt-content div[data-type="tip"] h6,#sbo-rt-content div.note h3,#sbo-rt-content div[data-type="note"] h6,#sbo-rt-content div[data-type="tip"] h1,#sbo-rt-content div[data-type="note"] h1{color:#737373}#sbo-rt-content div.warning h3,#sbo-rt-content div[data-type="warning"] h6,#sbo-rt-content div[data-type="caution"] h6,#sbo-rt-content div[data-type="important"] h6,#sbo-rt-content div[data-type="warning"] h1,#sbo-rt-content div[data-type="caution"] h1,#sbo-rt-content div[data-type="important"] h1{color:#C67171}#sbo-rt-content div.sect1[title="Safari® Books Online"] div.note,#sbo-rt-content div.safarienabled{background-color:transparent;margin:8px 0 0 !important;border:0 solid #BEBEBE;font-size:100%;padding:0 !important;page-break-inside:avoid}#sbo-rt-content div.sect1[title="Safari® Books Online"] div.note h3,#sbo-rt-content div.safarienabled h6{display:none}#sbo-rt-content div.table,#sbo-rt-content table{margin:15px 0 30px 0 !important;max-width:95%;border:none !important;background:none;display:table !important}#sbo-rt-content div.table,#sbo-rt-content div.informaltable,#sbo-rt-content table{page-break-inside:avoid}#sbo-rt-content tr,#sbo-rt-content tr td{border-bottom:1px solid #c3c3c3}#sbo-rt-content thead td,#sbo-rt-content thead th{border-bottom:#9d9d9d 1px solid !important;border-top:#9d9d9d 1px solid !important}#sbo-rt-content tr:nth-of-type(even){background-color:#f1f6fc}#sbo-rt-content thead{font-family:sans-serif;font-weight:bold}#sbo-rt-content td,#sbo-rt-content th{display:table-cell;padding:.3em;text-align:left;vertical-align:middle;font-size:80%}#sbo-rt-content div.informaltable table{margin:10px auto !important}#sbo-rt-content div.informaltable table tr{border-bottom:none}#sbo-rt-content div.informaltable table tr:nth-of-type(even){background-color:transparent}#sbo-rt-content div.informaltable td,#sbo-rt-content div.informaltable th{border:#9d9d9d 1px solid}#sbo-rt-content div.table-title,#sbo-rt-content table caption{font-weight:normal;font-style:italic;font-family:serif;font-size:1em;margin:10px 0 10px 0 !important;padding:0;page-break-after:avoid;text-align:left !important}#sbo-rt-content table code{font-size:smaller}#sbo-rt-content div.equation,#sbo-rt-content div[data-type="equation"]{margin:10px 0 15px 0 !important}#sbo-rt-content div.equation-title,#sbo-rt-content div[data-type="equation"] h5{font-style:italic;font-weight:normal;font-family:serif !important;font-size:90%;margin:20px 0 10px 0 !important;page-break-after:avoid}#sbo-rt-content div.equation-contents{margin-left:20px}#sbo-rt-content span.inlinemediaobject{height:.85em;display:inline-block;margin-bottom:.2em}#sbo-rt-content span.inlinemediaobject img{margin:0;height:.85em}#sbo-rt-content div.informalequation{margin:20px 0 20px 20px;width:75%}#sbo-rt-content div.informalequation img{width:75%}#sbo-rt-content div.index{text-indent:0}#sbo-rt-content div.index li{line-height:140%}#sbo-rt-content div.index a.indexterm{color:#8e0012}#sbo-rt-content div.index ul,#sbo-rt-content div[data-type="index"] ul{list-style-type:none;padding-left:0;margin-left:0}#sbo-rt-content div.index ul li{padding-left:0;margin-left:0}#sbo-rt-content div.index ul li ul li{margin-left:1em}#sbo-rt-content code.boolean,#sbo-rt-content .navy{color:rgb(0,0,128);}#sbo-rt-content code.character,#sbo-rt-content .olive{color:rgb(128,128,0);}#sbo-rt-content code.comment,#sbo-rt-content .blue{color:rgb(0,0,255);}#sbo-rt-content code.conditional,#sbo-rt-content .limegreen{color:rgb(50,205,50);}#sbo-rt-content code.constant,#sbo-rt-content .darkorange{color:rgb(255,140,0);}#sbo-rt-content code.debug,#sbo-rt-content .darkred{color:rgb(139,0,0);}#sbo-rt-content code.define,#sbo-rt-content .darkgoldenrod,#sbo-rt-content .gold{color:rgb(184,134,11);}#sbo-rt-content code.delimiter,#sbo-rt-content .dimgray{color:rgb(105,105,105);}#sbo-rt-content code.error,#sbo-rt-content .red{color:rgb(255,0,0);}#sbo-rt-content code.exception,#sbo-rt-content .salmon{color:rgb(250,128,11);}#sbo-rt-content code.float,#sbo-rt-content .steelblue{color:rgb(70,130,180);}#sbo-rt-content pre code.function,#sbo-rt-content .green{color:rgb(0,128,0);}#sbo-rt-content code.identifier,#sbo-rt-content .royalblue{color:rgb(65,105,225);}#sbo-rt-content code.ignore,#sbo-rt-content .gray{color:rgb(128,128,128);}#sbo-rt-content code.include,#sbo-rt-content .purple{color:rgb(128,0,128);}#sbo-rt-content code.keyword,#sbo-rt-content .sienna{color:rgb(160,82,45);}#sbo-rt-content code.label,#sbo-rt-content .deeppink{color:rgb(255,20,147);}#sbo-rt-content code.macro,#sbo-rt-content .orangered{color:rgb(255,69,0);}#sbo-rt-content code.number,#sbo-rt-content .brown{color:rgb(165,42,42);}#sbo-rt-content code.operator,#sbo-rt-content .black{color:#000;}#sbo-rt-content code.preCondit,#sbo-rt-content .teal{color:rgb(0,128,128);}#sbo-rt-content code.preProc,#sbo-rt-content .fuschia{color:rgb(255,0,255);}#sbo-rt-content code.repeat,#sbo-rt-content .indigo{color:rgb(75,0,130);}#sbo-rt-content code.special,#sbo-rt-content .saddlebrown{color:rgb(139,69,19);}#sbo-rt-content code.specialchar,#sbo-rt-content .magenta{color:rgb(255,0,255);}#sbo-rt-content code.specialcomment,#sbo-rt-content .seagreen{color:rgb(46,139,87);}#sbo-rt-content code.statement,#sbo-rt-content .forestgreen{color:rgb(34,139,34);}#sbo-rt-content code.storageclass,#sbo-rt-content .plum{color:rgb(221,160,221);}#sbo-rt-content code.string,#sbo-rt-content .darkred{color:rgb(139,0,0);}#sbo-rt-content code.structure,#sbo-rt-content .chocolate{color:rgb(210,106,30);}#sbo-rt-content code.tag,#sbo-rt-content .darkcyan{color:rgb(0,139,139);}#sbo-rt-content code.todo,#sbo-rt-content .black{color:#000;}#sbo-rt-content code.type,#sbo-rt-content .mediumslateblue{color:rgb(123,104,238);}#sbo-rt-content code.typedef,#sbo-rt-content .darkgreen{color:rgb(0,100,0);}#sbo-rt-content code.underlined{text-decoration:underline;}#sbo-rt-content pre code.hll{background-color:#ffc}#sbo-rt-content pre code.c{color:#09F;font-style:italic}#sbo-rt-content pre code.err{color:#A00}#sbo-rt-content pre code.k{color:#069;font-weight:bold}#sbo-rt-content pre code.o{color:#555}#sbo-rt-content pre code.cm{color:#35586C;font-style:italic}#sbo-rt-content pre code.cp{color:#099}#sbo-rt-content pre code.c1{color:#35586C;font-style:italic}#sbo-rt-content pre code.cs{color:#35586C;font-weight:bold;font-style:italic}#sbo-rt-content pre code.gd{background-color:#FCC}#sbo-rt-content pre code.ge{font-style:italic}#sbo-rt-content pre code.gr{color:#F00}#sbo-rt-content pre code.gh{color:#030;font-weight:bold}#sbo-rt-content pre code.gi{background-color:#CFC}#sbo-rt-content pre code.go{color:#000}#sbo-rt-content pre code.gp{color:#009;font-weight:bold}#sbo-rt-content pre code.gs{font-weight:bold}#sbo-rt-content pre code.gu{color:#030;font-weight:bold}#sbo-rt-content pre code.gt{color:#9C6}#sbo-rt-content pre code.kc{color:#069;font-weight:bold}#sbo-rt-content pre code.kd{color:#069;font-weight:bold}#sbo-rt-content pre code.kn{color:#069;font-weight:bold}#sbo-rt-content pre code.kp{color:#069}#sbo-rt-content pre code.kr{color:#069;font-weight:bold}#sbo-rt-content pre code.kt{color:#078;font-weight:bold}#sbo-rt-content pre code.m{color:#F60}#sbo-rt-content pre code.s{color:#C30}#sbo-rt-content pre code.na{color:#309}#sbo-rt-content pre code.nb{color:#366}#sbo-rt-content pre code.nc{color:#0A8;font-weight:bold}#sbo-rt-content pre code.no{color:#360}#sbo-rt-content pre code.nd{color:#99F}#sbo-rt-content pre code.ni{color:#999;font-weight:bold}#sbo-rt-content pre code.ne{color:#C00;font-weight:bold}#sbo-rt-content pre code.nf{color:#C0F}#sbo-rt-content pre code.nl{color:#99F}#sbo-rt-content pre code.nn{color:#0CF;font-weight:bold}#sbo-rt-content pre code.nt{color:#309;font-weight:bold}#sbo-rt-content pre code.nv{color:#033}#sbo-rt-content pre code.ow{color:#000;font-weight:bold}#sbo-rt-content pre code.w{color:#bbb}#sbo-rt-content pre code.mf{color:#F60}#sbo-rt-content pre code.mh{color:#F60}#sbo-rt-content pre code.mi{color:#F60}#sbo-rt-content pre code.mo{color:#F60}#sbo-rt-content pre code.sb{color:#C30}#sbo-rt-content pre code.sc{color:#C30}#sbo-rt-content pre code.sd{color:#C30;font-style:italic}#sbo-rt-content pre code.s2{color:#C30}#sbo-rt-content pre code.se{color:#C30;font-weight:bold}#sbo-rt-content pre code.sh{color:#C30}#sbo-rt-content pre code.si{color:#A00}#sbo-rt-content pre code.sx{color:#C30}#sbo-rt-content pre code.sr{color:#3AA}#sbo-rt-content pre code.s1{color:#C30}#sbo-rt-content pre code.ss{color:#A60}#sbo-rt-content pre code.bp{color:#366}#sbo-rt-content pre code.vc{color:#033}#sbo-rt-content pre code.vg{color:#033}#sbo-rt-content pre code.vi{color:#033}#sbo-rt-content pre code.il{color:#F60}#sbo-rt-content pre code.g{color:#050}#sbo-rt-content pre code.l{color:#C60}#sbo-rt-content pre code.l{color:#F90}#sbo-rt-content pre code.n{color:#008}#sbo-rt-content pre code.nx{color:#008}#sbo-rt-content pre code.py{color:#96F}#sbo-rt-content pre code.p{color:#000}#sbo-rt-content pre code.x{color:#F06}#sbo-rt-content div.blockquote_sampler_toc{width:95%;margin:5px 5px 5px 10px !important}#sbo-rt-content div{font-family:serif;text-align:left}#sbo-rt-content .gray-background,#sbo-rt-content .reverse-video{background:#2E2E2E;color:#FFF}#sbo-rt-content .light-gray-background{background:#A0A0A0}#sbo-rt-content .preserve-whitespace{white-space:pre-wrap}#sbo-rt-content span.gray{color:#4C4C4C}#sbo-rt-content div[data-type="equation"].fifty-percent img{width:50%}</style><script> // <![CDATA[
    var g = {
      position_cache: {
        
          "chapter": "/api/v1/book/9781491962282/chapter/ch10.html",
          "book_id": "9781491962282",
          "chapter_uri": "ch10.html",
          "position": 2.55275831017,
          "user_uuid": "2d2acfb7-1cff-4dc7-9037-8ffbac19b02e",
          "next_chapter_uri": "/library/view/hands-on-machine-learning/9781491962282/ch11.html"
        
      },
      title: "Hands\u002DOn Machine Learning with Scikit\u002DLearn and TensorFlow",
      author_list: "Aurélien Géron",
      format: "book",
      source: "application/epub+zip",
      is_system_book: true,
      is_public: false,
      loaded_from_server: true,
      allow_scripts: false,
      has_mathml: false,
      show_ios_app_teaser: false
    };
    // ]]></script><script src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/modernizr.js"></script><script>
    
      
        

        

        
          
            window.PUBLIC_ANNOTATIONS = true;
          
        

      

      
        window.MOBILE_PUBLIC_ANNOTATIONS = false;
      

    

    
      window.PRIVACY_CONTROL_OVERRIDE = false;
    

    
      window.PRIVACY_CONTROL_SWITCH = true;
    

    
      window.PUBLISHER_PAGES = true;
    

      window.SBO = {
        "constants": {
          "SITB_ENDPOINT": "https://www.safaribooksonline.com/api/v2/sitb/",
          "SEARCH_SELECT_ENDPOINT": "https://www.safaribooksonline.com/api/v2/search/select/",
          "ENABLE_ONLINE_TRAINING": true
        }
      };
  </script><link rel="canonical" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html"><meta name="description" content=" Chapter 10. Introduction to Artificial Neural Networks Birds inspired us to fly, burdock plants inspired velcro, and nature has inspired many other inventions. It seems only logical, then, to look ... "><meta property="og:title" content="10. Introduction to Artificial Neural Networks"><meta itemprop="isPartOf" content="/library/view/hands-on-machine-learning/9781491962282/"><meta itemprop="name" content="10. Introduction to Artificial Neural Networks"><meta property="og:url" itemprop="url" content="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html"><meta property="og:site_name" content="Safari"><meta property="og:image" itemprop="thumbnailUrl" content="https://www.safaribooksonline.com/library/cover/9781491962282/"><meta property="og:description" itemprop="description" content=" Chapter 10. Introduction to Artificial Neural Networks Birds inspired us to fly, burdock plants inspired velcro, and nature has inspired many other inventions. It seems only logical, then, to look ... "><meta itemprop="inLanguage" content="en"><meta itemprop="publisher" content="O'Reilly Media, Inc."><meta property="og:type" content="book"><meta property="og:book:isbn" itemprop="isbn" content="9781491962299"><meta property="og:book:author" itemprop="author" content="Aurélien Géron"><meta property="og:book:tag" itemprop="about" content="Core Programming"><meta property="og:book:tag" itemprop="about" content="Engineering"><meta property="og:book:tag" itemprop="about" content="Python"><meta name="twitter:card" content="summary"><meta name="twitter:site" content="@safari"><style type="text/css" id="font-styles" data-template="#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-size: &lt;%= font_size %&gt; !important; }"></style><style type="text/css" id="font-family" data-template="#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-family: &lt;%= font_family %&gt; !important; }"></style><style type="text/css" id="column-width" data-template="#sbo-rt-content { max-width: &lt;%= column_width %&gt;% !important; margin: 0 auto !important; }"></style><noscript><meta http-equiv="refresh" content="0; url=/library/no-js/" /></noscript><script type="text/javascript">
  (function(i,s,o,g,r,a,m) {
    i['GoogleAnalyticsObject']=r;
    i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();
    a=s.createElement(o),m=s.getElementsByTagName(o)[0];
    a.async=1;
    a.src=g;
    m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  var matches = document.cookie.match(/BrowserCookie\s*=\s*([a-f0-9\-]{36})/),
      user_uuid = null;

  if (matches && matches.length === 2) {
    user_uuid = matches[1];
  }


  ga('create', 'UA-39299553-7', {'userId': '2d2acfb7-1cff-4dc7-9037-8ffbac19b02e' });



  
    ga('set', 'dimension1', 'Trial');
  


ga('set', 'dimension6', user_uuid);


  ga('set', 'dimension2', '2d2acfb7-1cff-4dc7-9037-8ffbac19b02e');
  






//enable enhanced link tracking
ga('require', 'linkid', 'linkid.js');

// reading interface will track pageviews itself
if (document.location.pathname.indexOf("/library/view") !== 0) {
  ga('send', 'pageview');
}
</script><script>
    (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    '//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-5P4V6Z');
  </script><script defer="defer" src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/vendor.js"></script><script defer="defer" src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/reader.js"></script><script async="" src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/MathJax.js"></script><style id="annotator-dynamic-style">.annotator-adder, .annotator-outer, .annotator-notice {
  z-index: 100019;
}
.annotator-filter {
  z-index: 100009;
}</style><script src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/a_002.js"></script><script src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/a_003.js"></script></head>


<body class="reading sidenav nav-collapsed  scalefonts subscribe-panel library" data-gr-c-s-loaded="true">

    
  
  <noscript> 
    <iframe src="//www.googletagmanager.com/ns.html?id=GTM-5P4V6Z"
            height="0" width="0"
            style="display:none;visibility:hidden">
    </iframe>
  </noscript>
  



    
      <div class="working hide" role="status">
        <div class="working-image"></div>
      </div>
      <div class="sbo-site-nav">
        





<a href="#container" class="skip">Skip to content</a><header class="topbar t-topbar"><nav role="navigation" class="js-site-nav"><ul class="topnav"><li class="t-logo"><a href="https://www.safaribooksonline.com/home/" class="l0 None safari-home nav-icn js-keyboard-nav-home"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width="20" height="20" version="1.1" fill="#4A3C31"><desc>Safari Home Icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M4 9.9L4 9.9 4 18 16 18 16 9.9 10 4 4 9.9ZM2.6 8.1L2.6 8.1 8.7 1.9 10 0.5 11.3 1.9 17.4 8.1 18 8.7 18 9.5 18 18.1 18 20 16.1 20 3.9 20 2 20 2 18.1 2 9.5 2 8.7 2.6 8.1Z"></path><rect x="10" y="12" width="3" height="7"></rect><rect transform="translate(18.121320, 10.121320) rotate(-315.000000) translate(-18.121320, -10.121320) " x="16.1" y="9.1" width="4" height="2"></rect><rect transform="translate(2.121320, 10.121320) scale(-1, 1) rotate(-315.000000) translate(-2.121320, -10.121320) " x="0.1" y="9.1" width="4" height="2"></rect></g></svg><span>Safari Home</span></a></li><li><a href="https://www.safaribooksonline.com/r/" class="t-recommendations-nav l0 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>recommendations icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M50 25C50 18.2 44.9 12.5 38.3 11.7 37.5 5.1 31.8 0 25 0 18.2 0 12.5 5.1 11.7 11.7 5.1 12.5 0 18.2 0 25 0 31.8 5.1 37.5 11.7 38.3 12.5 44.9 18.2 50 25 50 31.8 50 37.5 44.9 38.3 38.3 44.9 37.5 50 31.8 50 25ZM25 3.1C29.7 3.1 33.6 6.9 34.4 11.8 30.4 12.4 26.9 15.1 25 18.8 23.1 15.1 19.6 12.4 15.6 11.8 16.4 6.9 20.3 3.1 25 3.1ZM34.4 15.6C33.6 19.3 30.7 22.2 27.1 22.9 27.8 19.2 30.7 16.3 34.4 15.6ZM22.9 22.9C19.2 22.2 16.3 19.3 15.6 15.6 19.3 16.3 22.2 19.2 22.9 22.9ZM3.1 25C3.1 20.3 6.9 16.4 11.8 15.6 12.4 19.6 15.1 23.1 18.8 25 15.1 26.9 12.4 30.4 11.8 34.4 6.9 33.6 3.1 29.7 3.1 25ZM22.9 27.1C22.2 30.7 19.3 33.6 15.6 34.4 16.3 30.7 19.2 27.8 22.9 27.1ZM25 46.9C20.3 46.9 16.4 43.1 15.6 38.2 19.6 37.6 23.1 34.9 25 31.3 26.9 34.9 30.4 37.6 34.4 38.2 33.6 43.1 29.7 46.9 25 46.9ZM27.1 27.1C30.7 27.8 33.6 30.7 34.4 34.4 30.7 33.6 27.8 30.7 27.1 27.1ZM38.2 34.4C37.6 30.4 34.9 26.9 31.3 25 34.9 23.1 37.6 19.6 38.2 15.6 43.1 16.4 46.9 20.3 46.9 25 46.9 29.7 43.1 33.6 38.2 34.4Z"></path></g></svg><span>Recommended</span></a></li><li><a href="https://www.safaribooksonline.com/s/" class="t-queue-nav l0 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>queue icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M25 29.2C25.4 29.2 25.8 29.1 26.1 28.9L48.7 16.8C49.5 16.4 50 15.5 50 14.6 50 13.7 49.5 12.8 48.7 12.4L26.1 0.3C25.4-0.1 24.6-0.1 23.9 0.3L1.3 12.4C0.5 12.8 0 13.7 0 14.6 0 15.5 0.5 16.4 1.3 16.8L23.9 28.9C24.2 29.1 24.6 29.2 25 29.2ZM7.3 14.6L25 5.2 42.7 14.6 25 24 7.3 14.6ZM48.7 22.4L47.7 21.9 25 34.2 2.3 21.9 1.3 22.4C0.5 22.9 0 23.7 0 24.7 0 25.6 0.5 26.5 1.3 26.9L23.9 39.3C24.2 39.5 24.6 39.6 25 39.6 25.4 39.6 25.8 39.5 26.1 39.3L48.7 26.9C49.5 26.5 50 25.6 50 24.7 50 23.7 49.5 22.9 48.7 22.4ZM48.7 32.8L47.7 32.3 25 44.6 2.3 32.3 1.3 32.8C0.5 33.3 0 34.1 0 35.1 0 36 0.5 36.9 1.3 37.3L23.9 49.7C24.2 49.9 24.6 50 25 50 25.4 50 25.8 49.9 26.1 49.7L48.7 37.3C49.5 36.9 50 36 50 35.1 50 34.1 49.5 33.3 48.7 32.8Z"></path></g></svg><span>
                  Queue
              </span></a></li><li class="search"><a href="#" class="t-search-nav trigger nav-icn l0" data-dropdown-selector=".searchbox"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>search icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M31.3 0C20.9 0 12.5 8.4 12.5 18.8 12.5 22.5 13.6 25.9 15.4 28.8L1.2 42.9C-0.4 44.5-0.4 47.2 1.2 48.8 2 49.6 3.1 50 4.2 50 5.2 50 6.3 49.6 7.1 48.8L21.2 34.6C24.1 36.5 27.5 37.5 31.3 37.5 41.6 37.5 50 29.1 50 18.8 50 8.4 41.6 0 31.3 0ZM31.3 31.3C24.4 31.3 18.8 25.6 18.8 18.8 18.8 11.9 24.4 6.3 31.3 6.3 38.1 6.3 43.8 11.9 43.8 18.8 43.8 25.6 38.1 31.3 31.3 31.3Z"></path></g></svg><span>Search</span></a></li><li class="usermenu dropdown"><a href="#" class="trigger l0 nav-icn nav-dropdown"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width="20" height="20" version="1.1" fill="#4A3C31"><desc>navigation arrow</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M0.1 12.5L9.7 3.1C9.8 3 9.9 3 10 3 10.1 3 10.2 3 10.3 3.1L19.9 12.5C20 12.5 20 12.6 20 12.8 20 12.9 20 13 19.9 13L17 15.9C16.9 16 16.8 16 16.7 16 16.5 16 16.4 16 16.4 15.9L10 9.7 3.6 15.9C3.6 16 3.5 16 3.3 16 3.2 16 3.1 16 3 15.9L0.1 13C0 12.9 0 12.8 0 12.7 0 12.7 0 12.6 0.1 12.5Z"></path></g></svg><span>Expand Nav</span></a><div class="drop-content"><ul><li><a href="https://www.safaribooksonline.com/history/" class="t-recent-nav l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>recent items icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M25 0C11.2 0 0 11.2 0 25 0 38.8 11.2 50 25 50 38.8 50 50 38.8 50 25 50 11.2 38.8 0 25 0ZM6.3 25C6.3 14.6 14.6 6.3 25 6.3 35.4 6.3 43.8 14.6 43.8 25 43.8 35.4 35.4 43.8 25 43.8 14.6 43.8 6.3 35.4 6.3 25ZM31.8 31.5C32.5 30.5 32.4 29.2 31.6 28.3L27.1 23.8 27.1 12.8C27.1 11.5 26.2 10.4 25 10.4 23.9 10.4 22.9 11.5 22.9 12.8L22.9 25.7 28.8 31.7C29.2 32.1 29.7 32.3 30.2 32.3 30.8 32.3 31.3 32 31.8 31.5Z"></path></g></svg><span>History</span></a></li><li><a href="https://www.safaribooksonline.com/topics" class="t-topics-link l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 55" width="20" height="20" version="1.1" fill="#4A3C31"><desc>topics icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M25 55L50 41.262 50 13.762 25 0 0 13.762 0 41.262 25 55ZM8.333 37.032L8.333 17.968 25 8.462 41.667 17.968 41.667 37.032 25 46.538 8.333 37.032Z"></path></g></svg><span>Topics</span></a></li><li><a href="https://www.safaribooksonline.com/tutorials/" class="l1 nav-icn t-tutorials-nav js-toggle-menu-item None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width="20" height="20" version="1.1" fill="#4A3C31"><desc>tutorials icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M15.8 18.2C15.8 18.2 15.9 18.2 16 18.2 16.1 18.2 16.2 18.2 16.4 18.2 16.5 18.2 16.7 18.1 16.9 18 17 17.9 17.1 17.8 17.2 17.7 17.3 17.6 17.4 17.5 17.4 17.4 17.5 17.2 17.6 16.9 17.6 16.7 17.6 16.6 17.6 16.5 17.6 16.4 17.5 16.2 17.5 16.1 17.4 15.9 17.3 15.8 17.2 15.6 17 15.5 16.8 15.3 16.6 15.3 16.4 15.2 16.2 15.2 16 15.2 15.8 15.2 15.7 15.2 15.5 15.3 15.3 15.4 15.2 15.4 15.1 15.5 15 15.7 14.9 15.8 14.8 15.9 14.7 16 14.7 16.1 14.6 16.3 14.6 16.4 14.6 16.5 14.6 16.6 14.6 16.6 14.6 16.7 14.6 16.9 14.6 17 14.6 17.1 14.7 17.3 14.7 17.4 14.8 17.6 15 17.7 15.1 17.9 15.2 18 15.3 18 15.5 18.1 15.5 18.1 15.6 18.2 15.7 18.2 15.7 18.2 15.7 18.2 15.8 18.2L15.8 18.2ZM9.4 11.5C9.5 11.5 9.5 11.5 9.6 11.5 9.7 11.5 9.9 11.5 10 11.5 10.2 11.5 10.3 11.4 10.5 11.3 10.6 11.2 10.8 11.1 10.9 11 10.9 10.9 11 10.8 11.1 10.7 11.2 10.5 11.2 10.2 11.2 10 11.2 9.9 11.2 9.8 11.2 9.7 11.2 9.5 11.1 9.4 11 9.2 10.9 9.1 10.8 8.9 10.6 8.8 10.5 8.7 10.3 8.6 10 8.5 9.9 8.5 9.7 8.5 9.5 8.5 9.3 8.5 9.1 8.6 9 8.7 8.8 8.7 8.7 8.8 8.6 9 8.5 9.1 8.4 9.2 8.4 9.3 8.2 9.5 8.2 9.8 8.2 10 8.2 10.1 8.2 10.2 8.2 10.3 8.2 10.5 8.3 10.6 8.4 10.7 8.5 10.9 8.6 11.1 8.7 11.2 8.9 11.3 9 11.4 9.1 11.4 9.2 11.4 9.3 11.5 9.3 11.5 9.3 11.5 9.4 11.5 9.4 11.5L9.4 11.5ZM3 4.8C3.1 4.8 3.1 4.8 3.2 4.8 3.4 4.8 3.5 4.8 3.7 4.8 3.8 4.8 4 4.7 4.1 4.6 4.3 4.5 4.4 4.4 4.5 4.3 4.6 4.2 4.6 4.1 4.7 4 4.8 3.8 4.8 3.5 4.8 3.3 4.8 3.1 4.8 3 4.8 2.9 4.7 2.8 4.7 2.6 4.6 2.5 4.5 2.3 4.4 2.2 4.2 2.1 4 1.9 3.8 1.9 3.6 1.8 3.5 1.8 3.3 1.8 3.1 1.8 2.9 1.8 2.7 1.9 2.6 2 2.4 2.1 2.3 2.2 2.2 2.3 2.1 2.4 2 2.5 2 2.6 1.8 2.8 1.8 3 1.8 3.3 1.8 3.4 1.8 3.5 1.8 3.6 1.8 3.8 1.9 3.9 2 4 2.1 4.2 2.2 4.4 2.4 4.5 2.5 4.6 2.6 4.7 2.7 4.7 2.8 4.7 2.9 4.8 2.9 4.8 3 4.8 3 4.8 3 4.8L3 4.8ZM13.1 15.2C13.2 15.1 13.2 15.1 13.2 15.1 13.3 14.9 13.4 14.7 13.6 14.5 13.8 14.2 14.1 14 14.4 13.8 14.7 13.6 15.1 13.5 15.5 13.4 15.9 13.4 16.3 13.4 16.7 13.5 17.2 13.5 17.6 13.7 17.9 13.9 18.2 14.1 18.5 14.4 18.7 14.7 18.9 15 19.1 15.3 19.2 15.6 19.3 15.9 19.4 16.1 19.4 16.4 19.4 17 19.3 17.5 19.1 18.1 19 18.3 18.9 18.5 18.7 18.7 18.5 19 18.3 19.2 18 19.4 17.7 19.6 17.3 19.8 16.9 19.9 16.6 20 16.3 20 16 20 15.8 20 15.6 20 15.4 19.9 15.4 19.9 15.4 19.9 15.4 19.9 15.2 19.9 15 19.8 14.9 19.8 14.8 19.7 14.7 19.7 14.6 19.7 14.4 19.6 14.3 19.5 14.1 19.3 13.7 19.1 13.4 18.7 13.2 18.4 13.1 18.1 12.9 17.8 12.9 17.5 12.8 17.3 12.8 17.1 12.8 16.9L3.5 14.9C3.3 14.9 3.1 14.8 3 14.8 2.7 14.7 2.4 14.5 2.1 14.3 1.7 14 1.4 13.7 1.2 13.3 1 13 0.9 12.6 0.8 12.3 0.7 12 0.7 11.7 0.7 11.4 0.7 11 0.8 10.5 1 10.1 1.1 9.8 1.3 9.5 1.6 9.2 1.8 8.9 2.1 8.7 2.4 8.5 2.8 8.3 3.2 8.1 3.6 8.1 3.9 8 4.2 8 4.5 8 4.6 8 4.8 8 4.9 8.1L6.8 8.5C6.8 8.4 6.8 8.4 6.8 8.4 6.9 8.2 7.1 8 7.2 7.8 7.5 7.5 7.7 7.3 8 7.1 8.4 6.9 8.7 6.8 9.1 6.7 9.5 6.7 10 6.7 10.4 6.8 10.8 6.8 11.2 7 11.5 7.2 11.8 7.5 12.1 7.7 12.4 8 12.6 8.3 12.7 8.6 12.8 8.9 12.9 9.2 13 9.4 13 9.7 13 9.7 13 9.8 13 9.8 13.6 9.9 14.2 10.1 14.9 10.2 15 10.2 15 10.2 15.1 10.2 15.3 10.2 15.4 10.2 15.6 10.2 15.8 10.1 16 10 16.2 9.9 16.4 9.8 16.5 9.6 16.6 9.5 16.8 9.2 16.9 8.8 16.9 8.5 16.9 8.3 16.9 8.2 16.8 8 16.8 7.8 16.7 7.7 16.6 7.5 16.5 7.3 16.3 7.2 16.2 7.1 16 7 15.9 6.9 15.8 6.9 15.7 6.9 15.6 6.8 15.5 6.8L6.2 4.8C6.2 5 6 5.2 5.9 5.3 5.7 5.6 5.5 5.8 5.3 6 4.9 6.2 4.5 6.4 4.1 6.5 3.8 6.6 3.5 6.6 3.2 6.6 3 6.6 2.8 6.6 2.7 6.6 2.6 6.6 2.6 6.5 2.6 6.5 2.5 6.5 2.3 6.5 2.1 6.4 1.8 6.3 1.6 6.1 1.3 6 1 5.7 0.7 5.4 0.5 5 0.3 4.7 0.2 4.4 0.1 4.1 0 3.8 0 3.6 0 3.3 0 2.8 0.1 2.2 0.4 1.7 0.5 1.5 0.7 1.3 0.8 1.1 1.1 0.8 1.3 0.6 1.6 0.5 2 0.3 2.3 0.1 2.7 0.1 3.1 0 3.6 0 4 0.1 4.4 0.2 4.8 0.3 5.1 0.5 5.5 0.8 5.7 1 6 1.3 6.2 1.6 6.3 1.9 6.4 2.3 6.5 2.5 6.6 2.7 6.6 3 6.6 3 6.6 3.1 6.6 3.1 9.7 3.8 12.8 4.4 15.9 5.1 16.1 5.1 16.2 5.2 16.4 5.2 16.7 5.3 16.9 5.5 17.2 5.6 17.5 5.9 17.8 6.2 18.1 6.5 18.3 6.8 18.4 7.2 18.6 7.5 18.6 7.9 18.7 8.2 18.7 8.6 18.7 9 18.6 9.4 18.4 9.8 18.3 10.1 18.2 10.3 18 10.6 17.8 10.9 17.5 11.1 17.3 11.3 16.9 11.6 16.5 11.8 16 11.9 15.7 12 15.3 12 15 12 14.8 12 14.7 12 14.5 11.9 13.9 11.8 13.3 11.7 12.6 11.5 12.5 11.7 12.4 11.9 12.3 12 12.1 12.3 11.9 12.5 11.7 12.7 11.3 12.9 10.9 13.1 10.5 13.2 10.2 13.3 9.9 13.3 9.6 13.3 9.4 13.3 9.2 13.3 9 13.2 9 13.2 9 13.2 9 13.2 8.8 13.2 8.7 13.2 8.5 13.1 8.2 13 8 12.8 7.7 12.6 7.4 12.4 7.1 12 6.8 11.7 6.7 11.4 6.6 11.1 6.5 10.8 6.4 10.6 6.4 10.4 6.4 10.2 5.8 10.1 5.2 9.9 4.5 9.8 4.4 9.8 4.4 9.8 4.3 9.8 4.1 9.8 4 9.8 3.8 9.8 3.6 9.9 3.4 10 3.2 10.1 3 10.2 2.9 10.4 2.8 10.5 2.6 10.8 2.5 11.1 2.5 11.5 2.5 11.6 2.5 11.8 2.6 12 2.6 12.1 2.7 12.3 2.8 12.5 2.9 12.6 3.1 12.8 3.2 12.9 3.3 13 3.5 13.1 3.6 13.1 3.7 13.1 3.8 13.2 3.9 13.2L13.1 15.2 13.1 15.2Z"></path></g></svg><span>Tutorials</span></a></li><li class="nav-offers flyout-parent"><a href="#" class="l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>offers icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M35.9 20.6L27 15.5C26.1 15 24.7 15 23.7 15.5L14.9 20.6C13.9 21.1 13.2 22.4 13.2 23.4L13.2 41.4C13.2 42.4 13.9 43.7 14.9 44.2L23.3 49C24.2 49.5 25.6 49.5 26.6 49L35.9 43.6C36.8 43.1 37.6 41.8 37.6 40.8L37.6 23.4C37.6 22.4 36.8 21.1 35.9 20.6L35.9 20.6ZM40 8.2C39.1 7.6 37.6 7.6 36.7 8.2L30.2 11.9C29.3 12.4 29.3 13.2 30.2 13.8L39.1 18.8C40 19.4 40.7 20.6 40.7 21.7L40.7 39C40.7 40.1 41.4 40.5 42.4 40L48.2 36.6C49.1 36.1 49.8 34.9 49.8 33.8L49.8 15.6C49.8 14.6 49.1 13.3 48.2 12.8L40 8.2 40 8.2ZM27 10.1L33.6 6.4C34.5 5.9 34.5 5 33.6 4.5L26.6 0.5C25.6 0 24.2 0 23.3 0.5L16.7 4.2C15.8 4.7 15.8 5.6 16.7 6.1L23.7 10.1C24.7 10.6 26.1 10.6 27 10.1ZM10.1 21.7C10.1 20.6 10.8 19.4 11.7 18.8L20.6 13.8C21.5 13.2 21.5 12.4 20.6 11.9L13.6 7.9C12.7 7.4 11.2 7.4 10.3 7.9L1.6 12.8C0.7 13.3 0 14.6 0 15.6L0 33.8C0 34.9 0.7 36.1 1.6 36.6L8.4 40.5C9.3 41 10.1 40.6 10.1 39.6L10.1 21.7 10.1 21.7Z"></path></g></svg><span>Offers &amp; Deals</span></a><ul class="flyout"><li><a href="https://www.safaribooksonline.com/oreilly-newsletters/" class="l2 nav-icn"><span>Newsletters</span></a></li></ul></li><li class="nav-highlights"><a href="https://www.safaribooksonline.com/u/0011N00001APXw3QAH/" class="t-highlights-nav l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 35" width="20" height="20" version="1.1" fill="#4A3C31"><desc>highlights icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M13.325 18.071L8.036 18.071C8.036 11.335 12.36 7.146 22.5 5.594L22.5 0C6.37 1.113 0 10.632 0 22.113 0 29.406 3.477 35 10.403 35 15.545 35 19.578 31.485 19.578 26.184 19.578 21.556 17.211 18.891 13.325 18.071L13.325 18.071ZM40.825 18.071L35.565 18.071C35.565 11.335 39.86 7.146 50 5.594L50 0C33.899 1.113 27.5 10.632 27.5 22.113 27.5 29.406 30.977 35 37.932 35 43.045 35 47.078 31.485 47.078 26.184 47.078 21.556 44.74 18.891 40.825 18.071L40.825 18.071Z"></path></g></svg><span>Highlights</span></a></li><li><a href="https://www.safaribooksonline.com/u/" class="t-settings-nav l1 js-settings nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 53" width="20" height="20" version="1.1" fill="#4A3C31"><desc>settings icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M44.6 29.6C44.7 28.6 44.8 27.5 44.8 26.5 44.8 25.5 44.7 24.4 44.6 23.4L49.6 19C50 18.8 50.1 18.3 49.9 17.9 48.9 14.7 47.1 11.7 44.9 9.1 44.6 8.8 44.2 8.7 43.8 8.8L37.4 11.1C35.8 9.8 34 8.7 32.1 8L30.9 1.4C30.8 0.9 30.4 0.6 30 0.5 26.7-0.2 23.3-0.2 20 0.5 19.6 0.6 19.2 0.9 19.1 1.4L17.9 8C16 8.7 14.1 9.8 12.6 11.1L6.2 8.8C5.8 8.7 5.4 8.8 5.1 9.1 2.9 11.7 1.1 14.7 0.1 17.9 -0.1 18.3 0 18.8 0.4 19L5.4 23.4C5.3 24.4 5.2 25.5 5.2 26.5 5.2 27.5 5.3 28.6 5.4 29.6L0.4 34C0 34.2-0.1 34.7 0.1 35.1 1.1 38.3 2.9 41.4 5.1 43.9 5.4 44.2 5.8 44.4 6.2 44.2L12.6 42C14.1 43.2 16 44.3 17.9 45L19.1 51.7C19.2 52.1 19.6 52.5 20 52.5 21.6 52.8 23.3 53 25 53 26.7 53 28.4 52.8 30 52.5 30.4 52.5 30.8 52.1 30.9 51.7L32.1 45C34 44.3 35.8 43.2 37.4 42L43.8 44.2C44.2 44.4 44.6 44.2 44.9 43.9 47.1 41.4 48.9 38.3 49.9 35.1 50.1 34.7 50 34.2 49.6 34L44.6 29.6ZM25 36.4C19.6 36.4 15.2 32 15.2 26.5 15.2 21 19.6 16.6 25 16.6 30.4 16.6 34.8 21 34.8 26.5 34.8 32 30.4 36.4 25 36.4Z"></path></g></svg><span>Settings</span></a></li><li><a href="https://www.safaribooksonline.com/public/support" class="l1 no-icon">Support</a></li><li><a href="https://www.safaribooksonline.com/accounts/logout/" class="l1 no-icon">Sign Out</a></li></ul><ul class="profile"><li><a href="https://www.safaribooksonline.com/u/" class="l2 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 53" width="20" height="20" version="1.1" fill="#4A3C31"><desc>settings icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M44.6 29.6C44.7 28.6 44.8 27.5 44.8 26.5 44.8 25.5 44.7 24.4 44.6 23.4L49.6 19C50 18.8 50.1 18.3 49.9 17.9 48.9 14.7 47.1 11.7 44.9 9.1 44.6 8.8 44.2 8.7 43.8 8.8L37.4 11.1C35.8 9.8 34 8.7 32.1 8L30.9 1.4C30.8 0.9 30.4 0.6 30 0.5 26.7-0.2 23.3-0.2 20 0.5 19.6 0.6 19.2 0.9 19.1 1.4L17.9 8C16 8.7 14.1 9.8 12.6 11.1L6.2 8.8C5.8 8.7 5.4 8.8 5.1 9.1 2.9 11.7 1.1 14.7 0.1 17.9 -0.1 18.3 0 18.8 0.4 19L5.4 23.4C5.3 24.4 5.2 25.5 5.2 26.5 5.2 27.5 5.3 28.6 5.4 29.6L0.4 34C0 34.2-0.1 34.7 0.1 35.1 1.1 38.3 2.9 41.4 5.1 43.9 5.4 44.2 5.8 44.4 6.2 44.2L12.6 42C14.1 43.2 16 44.3 17.9 45L19.1 51.7C19.2 52.1 19.6 52.5 20 52.5 21.6 52.8 23.3 53 25 53 26.7 53 28.4 52.8 30 52.5 30.4 52.5 30.8 52.1 30.9 51.7L32.1 45C34 44.3 35.8 43.2 37.4 42L43.8 44.2C44.2 44.4 44.6 44.2 44.9 43.9 47.1 41.4 48.9 38.3 49.9 35.1 50.1 34.7 50 34.2 49.6 34L44.6 29.6ZM25 36.4C19.6 36.4 15.2 32 15.2 26.5 15.2 21 19.6 16.6 25 16.6 30.4 16.6 34.8 21 34.8 26.5 34.8 32 30.4 36.4 25 36.4Z"></path></g></svg><span>Settings</span></a><span class="l2 t-nag-notification" id="nav-nag"><strong class="trial-green">10</strong> days left in your trial.
  
  

  
    
      

<a class="" href="https://www.safaribooksonline.com/subscribe/">Subscribe</a>.


    
  

  

</span></li><li><a href="https://www.safaribooksonline.com/public/support" class="l2">Support</a></li><li><a href="https://www.safaribooksonline.com/accounts/logout/" class="l2">Sign Out</a></li></ul></div></li></ul></nav></header>


      </div>
      <div id="container" class="application" style="height: auto;">
        
          <div class="nav-container clearfix">
            


            
            
          </div>

          

  <div class="js-toc">
    
      <div class="sbo-reading-menu sbo-menu-top"><section class="sbo-toc-container toc-menu"><a href="#" class="sbo-toc-thumb"><span class="sbo-title ss-list"><h1><div class="visuallyhidden">Table of Contents for </div>
      
      Hands-On Machine Learning with Scikit-Learn and TensorFlow
      
    </h1></span></a><div class="toc-contents" style="max-height: 0px;">
  <div class="sbo-toc ">
    <button type="button" class="sbo-toc-thumb close"><div class="visuallyhidden">Close</div></button>
      <section class="ios-app-teaser">
        <ul>
            <li><a class="js-toc-link toc-link" href="https://itunes.apple.com/gb/app/safari-queue-library-over/id881697395?mt=8" role="button">Install App</a></li>
            <li><a class="js-toc-link toc-link" href="safaridetail://9781491962282" role="button">Open in App</a></li>
        </ul>
      </section>
      <div class="sbo-book-meta">
        
        <span class="cover">
         <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/">
          <img src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/a.jpg" alt="Cover image for Hands-On Machine Learning with Scikit-Learn and TensorFlow" width="140" height="184">
        </a>
        </span>
        <span class="title">
          
            
                <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/publisher/oreilly-media-inc/">
                  <img src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/ORM_logo_box_rgb.png" class="publisher-logo video" alt="publisher logo">
                </a>
            
          

          <a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/">Hands-On Machine Learning with Scikit-Learn and TensorFlow</a>
        </span>
        
        <span class="authors">by Aurélien Géron</span>
        

        
        <span class="publishers t-publishers">Published by
          <!-- Show publisher page link if publisher pages switch is on -->
          
            <a class="t-publisher-link toc-link js-toc-link" href="https://www.safaribooksonline.com/library/publisher/oreilly-media-inc/">
              O'Reilly Media, Inc.</a>, 2017
          
        </span>
        

    

    </div>
  <ol class="tocList">
    
    
    
     

     <li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/preface01.html#idm140583011384384">
        Preface 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/part01.html#fundamentals_part">
        I. The Fundamentals of Machine Learning 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch01.html#landscape_chapter">
        1. The Machine Learning Landscape 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch02.html#project_chapter">
        2. End-to-End Machine Learning Project 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch03.html#classification_chapter">
        3. Classification 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch04.html#linear_models_chapter">
        4. Training Models 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch05.html#svm_chapter">
        5. Support Vector Machines 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch06.html#trees_chapter">
        6. Decision Trees 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch07.html#ensembles_chapter">
        7. Ensemble Learning and Random Forests 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch08.html#dim_reduction_chapter">
        8. Dimensionality Reduction 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/part02.html#neural_nets_part">
        II. Neural Networks and Deep Learning 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch09.html#tensorflow_chapter">
        9. Up and Running with TensorFlow 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html#ann_chapter">
        10. Introduction to Artificial Neural Networks 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1 currently-reading">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#deep_chapter">
        11. Training Deep Neural Nets 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch12.html#distributed_chapter">
        12. Distributing TensorFlow Across Devices and Servers 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch13.html#cnn_chapter">
        13. Convolutional Neural Networks 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch14.html#rnn_chapter">
        14. Recurrent Neural Networks 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch15.html#autoencoders_chapter">
        15. Autoencoders 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch16.html#rl_chapter">
        16. Reinforcement Learning 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app01.html#solutions_appendix">
        A. Exercise Solutions 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app02.html#project_checklist_appendix">
        B. Machine Learning Project Checklist 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app03.html#svm_dual_problem_appendix">
        C. SVM Dual Problem 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app04.html#autodiff_appendix">
        D. Autodiff 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app05.html#other_ann_appendix">
        E. Other Popular ANN Architectures 
       </a>
      
        
      
    
    
     

     </li><li class="toc-level1">
        
        <a class="js-toc-link toc-link" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ix01.html#idm140582977822192">
        Index 
       </a>
      
        
      
   </li></ol>
 </div>



</div></section></div>

    

    <div class="interface-controls interface-controls-top">
      <ul class="interface-control-btns js-bitlist js-reader">
        <li class="js-search-in-archive search-in-archive t-search-in-archive"><a href="#" title="Search in archive" class="js-search-controls search-controls"><span class="icon">Search in book...</span></a><form class="search-archive-bar js-search-form"><input name="query" placeholder="Search inside this book..." autocomplete="off" type="search"></form><div class="search-archive-results"><div class="js-sitb-results-region"></div></div></li><li class="queue-control"><button type="button" class="rec-fav ss-queue js-queue js-current-chapter-queue" data-queue-endpoint="/api/v1/book/9781491962282/chapter/ch11.html" data-for-analytics="9781491962282:ch11.html" aria-label="Add to Queue"><span>Add to Queue</span></button></li><li class="js-font-control-panel font-control-activator"><a href="#" data-push-state="false" id="font-controls" title="Change font size" aria-label="Change font size"><span class="icon">Toggle Font Controls</span></a></li><li class="dropdown sharing-controls"><a href="#" class="trigger" data-push-state="false" title="Share" aria-label="Share"><i class="fa fa-share"></i></a><ul class="social-sharing dropdown-menu"><li class=""><a class="twitter share-button t-twitter" target="_blank" aria-label="Share this section on Twitter" title="Share this section on Twitter" href="https://twitter.com/share?url=https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html&amp;text=Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow&amp;via=safari"><span>Twitter</span></a></li><li class=""><a class="facebook share-button t-facebook" target="_blank" aria-label="Share this section on Facebook" title="Share this section on Facebook" href="https://www.facebook.com/sharer/sharer.php?u=https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html"><span>Facebook</span></a></li><li class=""><a class="googleplus share-button t-googleplus" target="_blank" aria-label="Share this secton on Google Plus" title="Share this secton on Google Plus" href="https://plus.google.com/share?url=https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html"><span>Google Plus</span></a></li><li class=""><a class="email share-button t-email" aria-label="Share this section via email" title="Share this section via email" href="mailto:?subject=Safari:%2010.%20Introduction%20to%20Artificial%20Neural%20Networks&amp;body=https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html%0D%0Afrom%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow%0D%0A"><span>Email</span></a></li></ul></li>
      </ul>
    </div>

    <section role="document">
	  <div class="t-sbo-prev sbo-prev sbo-nav-top">
  
    
      
        <a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html" class="prev nav-link">
      
          <span aria-hidden="true" class="pagination-label t-prev-label">Prev</span>
          <span class="visuallyhidden">Previous Chapter</span>
          <div class="pagination-title t-prev-title">10. Introduction to Artificial Neural Networks</div>
        </a>
    
  
  </div>

  <div class="t-sbo-next sbo-next sbo-nav-top">
  
    
      
        <a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch12.html" class="next nav-link">
      
          <span aria-hidden="true" class="pagination-label t-next-label">Next</span>
          <span class="visuallyhidden">Next Chapter</span>
          <div class="pagination-title t-next-title">12. Distributing TensorFlow Across Devices and Servers</div>
        </a>
    
  
  </div>



<div id="sbo-rt-content"><div class="annotator-wrapper"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 11. Training Deep Neural Nets"><div class="chapter" id="deep_chapter">
<h1><span class="label">Chapter 11. </span>Training Deep Neural Nets</h1>


<p>In <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html#ann_chapter">Chapter&nbsp;10</a> <a data-type="indexterm" data-primary="deep neural networks (DNNs)" id="dnn11"></a>we
 introduced artificial neural networks and trained our first deep neural
 network. But it was a very shallow DNN, with only two hidden layers. 
What if you need to tackle a very complex problem, such as detecting 
hundreds of types of objects in high-resolution images? You may need to 
train a much deeper DNN, perhaps with (say) 10 layers, each containing 
hundreds of neurons, connected by hundreds of thousands of connections. 
This would not be a walk in the park:</p>

<ul>
<li>
<p>First, you would be faced with the <a data-type="indexterm" data-primary="gradients, vanishing and exploding" id="gvae11"></a><a data-type="indexterm" data-primary="deep neural networks (DNNs)" data-secondary="vanishing and exploding gradients" id="dnn11vaev"></a>tricky <em>vanishing gradients</em> problem (or the related <em>exploding gradients</em> problem) that affects deep neural networks and makes lower layers very hard to train.</p>
</li>
<li>
<p>Second, with such a large network, training would be extremely slow.</p>
</li>
<li>
<p>Third, a model with millions of parameters would severely risk overfitting the training set.</p>
</li>
</ul>

<p>In this chapter, we will go through each of these problems in turn 
and present techniques to solve them. We will start by explaining the 
vanishing gradients problem and exploring some of the most popular 
solutions to this problem. Next we will look at various optimizers that 
can speed up training large models tremendously compared to plain <a data-type="indexterm" data-primary="Gradient Descent (GD)" id="idm140583000656864"></a>Gradient Descent. Finally, we will go through a few popular regularization techniques for large neural networks.</p>

<p>With these tools, you will be able to train very deep nets: welcome to Deep Learning!</p>






<section data-type="sect1" data-pdf-bookmark="Vanishing/Exploding Gradients Problems"><div class="sect1" id="idm140583000655392">
<h1>Vanishing/Exploding Gradients Problems</h1>

<p>As we discussed in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html#ann_chapter">Chapter&nbsp;10</a>, the <a data-type="indexterm" data-primary="backpropagation" id="idm140583000652784"></a>backpropagation
 algorithm works by going from the output layer to the input layer, 
propagating the error gradient on the way. Once the algorithm has 
computed the gradient of the <a data-type="indexterm" data-primary="cost function" data-secondary="in Gradient Descent" data-secondary-sortas="Gradient" id="idm140583000651760"></a>cost
 function with regards to each parameter in the network, it uses these 
gradients to update each parameter with a Gradient Descent step.</p>

<p>Unfortunately, gradients often get smaller and smaller as the 
algorithm progresses down to the lower layers. As a result, the Gradient
 Descent update leaves the lower layer connection weights virtually 
unchanged, and training never converges to a good solution. This <a data-type="indexterm" data-primary="vanishing gradients" data-seealso="gradients, vanishing and exploding" id="idm140583000649360"></a>is called the <em>vanishing gradients</em>
 problem. In some cases, the opposite can happen: the gradients can grow
 bigger and bigger, so many layers get insanely large weight updates and
 the algorithm diverges. This is the <em>exploding gradients</em> problem, <a data-type="indexterm" data-primary="exploding gradients" data-seealso="gradients, vanishing and exploding" id="idm140583000647216"></a>which is mostly encountered in recurrent neural networks (see <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch14.html#rnn_chapter">Chapter&nbsp;14</a>). More generally, <a data-type="indexterm" data-primary="deep neural networks (DNNs)" data-secondary="unstable gradients" id="idm140583000645184"></a>deep neural networks suffer from unstable gradients; different layers may learn at widely different speeds.</p>

<p><a data-type="indexterm" data-primary="Xavier initialization" id="xis11"></a><a data-type="indexterm" data-primary="Glorot initialization" id="gi11"></a><a data-type="indexterm" data-primary="He initialization" id="hi11"></a><a data-type="indexterm" data-primary="gradients, vanishing and exploding" data-secondary="Glorot and He initialization" id="gve11gahi"></a>Although
 this unfortunate behavior has been empirically observed for quite a 
while (it was one of the reasons why deep neural networks were mostly 
abandoned for a long time), it is only around 2010 that significant 
progress was made in understanding it. A paper titled <a href="http://goo.gl/1rhAef">“Understanding the Difficulty of Training Deep Feedforward Neural Networks”</a> by Xavier Glorot and Yoshua Bengio<sup><a data-type="noteref" id="idm140583000536464-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140583000536464" class="totri-footnote">1</a></sup>
 found a few suspects, including the combination of the popular logistic
 sigmoid activation function and the weight initialization technique 
that was most popular at the time, namely <a data-type="indexterm" data-primary="random initialization" id="idm140583000535520"></a>random
 initialization using a normal distribution with a mean of 0 and a 
standard deviation of 1. In short, they showed that with this activation
 function and this initialization scheme, the variance of the outputs of
 each layer is much greater than the variance of its inputs. Going 
forward in the network, the variance keeps increasing after each layer 
until the activation function saturates at the top layers. This is 
actually made worse by the fact that the logistic function has a mean of
 0.5, not 0 <a data-type="indexterm" data-primary="hyperbolic tangent (htan activation function)" id="idm140583000534256"></a>(the hyperbolic tangent function has a mean of 0 and behaves slightly better than the logistic function in deep networks).</p>

<p>Looking at the logistic activation function (see <a data-type="xref" href="#sigmoid_saturation_plot">Figure&nbsp;11-1</a>),
 you can see that when inputs become large (negative or positive), the 
function saturates at 0 or 1, with a derivative extremely close to 0. 
Thus when backpropagation kicks in, it has virtually no gradient to 
propagate back through the network, and what little gradient exists 
keeps getting diluted as backpropagation progresses down through the top
 layers, so there is really nothing left for the lower layers.</p>

<figure class="smallerseventy"><div id="sigmoid_saturation_plot" class="figure">
<img src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/mlst_1101.png" alt="mlst 1101" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1101.png" width="1440" height="928">
<h6><span class="label">Figure 11-1. </span>Logistic activation function saturation</h6>
</div></figure>








<section data-type="sect2" data-pdf-bookmark="Xavier and He Initialization"><div class="sect2" id="idm140583000529520">
<h2>Xavier and He Initialization</h2>

<p>In their paper, Glorot and Bengio propose a way to significantly 
alleviate this problem. We need the signal to flow properly in both 
directions: in the forward direction when making predictions, and in the
 reverse direction when backpropagating gradients. We don’t want the 
signal to die out, nor do we want it to explode and saturate. For the 
signal to flow properly, the authors argue that we need the variance of 
the outputs of each layer to be equal to the variance of its inputs,<sup><a data-type="noteref" id="idm140583000528000-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140583000528000" class="totri-footnote">2</a></sup>
 and we also need the gradients to have equal variance before and after 
flowing through a layer in the reverse direction (please check out the 
paper if you are interested in the mathematical details). It is actually
 not possible to guarantee both unless the layer has an equal number of 
input and output connections, but they proposed a good compromise that 
has proven to work very well in practice: the connection weights must be
 initialized randomly as described in <a data-type="xref" href="#xavier_initialization_equation">Equation 11-1</a>, where <em>n</em><sub>inputs</sub> and <em>n</em><sub>outputs</sub> are the number of input and output connections for the layer whose weights are being initialized <a data-type="indexterm" data-primary="fan-in" id="idm140583000523088"></a><a data-type="indexterm" data-primary="fan-out" id="idm140583000522384"></a>(also called <em>fan-in</em> and <em>fan-out</em>). This initialization strategy is often called <em>Xavier initialization</em> (after the author’s first name), or sometimes <em>Glorot initialization</em>.</p>
<div id="xavier_initialization_equation" data-type="equation" class="pagebreak-before less_space">
<h5><span class="label">Equation 11-1. </span>Xavier initialization (when using the logistic activation function)</h5>
<img src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_102.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_102.png" width="2063" height="277">
</div>

<p>When the number of input connections is roughly equal to the number of output connections, you get simpler equations<sup><a data-type="noteref" id="idm140583000517168-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140583000517168" class="totri-footnote">3</a></sup> (e.g., <img src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_103.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_103.png" width="132" height="30"> or <img src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_104.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_104.png" width="143" height="30">).</p>

<p>Using the Xavier initialization strategy can speed up training 
considerably, and it is one of the tricks that led to the current 
success of Deep Learning. Some <a href="http://goo.gl/VHP3pB">recent papers</a><sup><a data-type="noteref" id="idm140583000513424-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140583000513424" class="totri-footnote">4</a></sup> have provided similar strategies for different activation functions, as shown in <a data-type="xref" href="#initialization_table">Table&nbsp;11-1</a>. The initialization strategy for the <a data-type="indexterm" data-primary="ReLU function" id="relu11"></a>ReLU activation function (and its variants, including the ELU activation described shortly) is sometimes <a data-type="indexterm" data-primary="hyperbolic tangent (htan activation function)" id="idm140583000510592"></a>called <em>He initialization</em> (after the last name of its author). This is the strategy we used in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html#ann_chapter">Chapter&nbsp;10</a>.</p>
<table id="initialization_table">
<caption><span class="label">Table 11-1. </span>Initialization parameters for each type of activation function</caption>
<thead>
<tr>
<th>Activation function</th>
<th>Uniform distribution [–r, r]</th>
<th>Normal distribution</th>
</tr>
</thead>
<tbody>
<tr>
<td><p>Logistic</p></td>
<td><p><img src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_105.png" alt="r equals StartRoot StartFraction 6 Over n Subscript inputs Baseline plus n Subscript outputs Baseline EndFraction EndRoot" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_105.png" width="135" height="30"></p></td>
<td><p><img src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_106.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_106.png" width="141" height="30"></p></td>
</tr>
<tr>
<td><p>Hyperbolic tangent</p></td>
<td><p><img src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_107.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_107.png" width="143" height="30"></p></td>
<td><p><img src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_108.png" alt="sigma equals 4 StartRoot StartFraction 2 Over n Subscript inputs Baseline plus n Subscript outputs Baseline EndFraction EndRoot" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_108.png" width="148" height="30"></p></td>
</tr>
<tr>
<td><p>ReLU (and its variants)</p></td>
<td><p><img src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_109.png" alt="r equals StartRoot 2 EndRoot StartRoot StartFraction 6 Over n Subscript inputs Baseline plus n Subscript outputs Baseline EndFraction EndRoot" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_109.png" width="153" height="30"></p></td>
<td><p><img src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_110.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_110.png" width="158" height="30"></p></td>
</tr>
</tbody>
</table>

<p>By default, the <code>tf.layers.dense()</code> function <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.contrib.layers.variance_scaling_initializer()" id="tfclvsich11"></a><a data-type="indexterm" data-primary="tf.layers.dense()" id="idm140583000492768"></a>(introduced in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html#ann_chapter">Chapter&nbsp;10</a>) uses Xavier initialization (with a uniform distribution). You can change this to He initialization by using the <code>variance_scaling_initializer()</code> <a data-type="indexterm" data-primary="variance_scaling_initializer()" id="idm140583000490624"></a>function like this:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">he_init</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">contrib</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">variance_scaling_initializer</code><code class="p">()</code>
<code class="n">hidden1</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">dense</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">n_hidden1</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">relu</code><code class="p">,</code>
                          <code class="n">kernel_initializer</code><code class="o">=</code><code class="n">he_init</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"hidden1"</code><code class="p">)</code></pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>He initialization considers only the fan-in, <a data-type="indexterm" data-primary="fan-in" id="idm140583000464352"></a><a data-type="indexterm" data-primary="fan-out" id="idm140583000463488"></a>not the average between fan-in and fan-out like in Xavier initialization. This is also the default for the <code>variance_scaling_initializer()</code> function, but you can change this by setting the <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.contrib.layers.variance_scaling_initializer()" data-startref="tfclvsich11" id="idm140583000462112"></a><a data-type="indexterm" data-primary="gradients, vanishing and exploding" data-secondary="Glorot and He initialization" data-startref="gve11gahi" id="idm140583000460800"></a><a data-type="indexterm" data-primary="Xavier initialization" data-startref="xis11" id="idm140583000459648"></a><a data-type="indexterm" data-primary="Glorot initialization" data-startref="gi11" id="idm140583000458704"></a><a data-type="indexterm" data-primary="He initialization" data-startref="hi11" id="idm140583000456816"></a>argument <code>mode="FAN_AVG"</code>.</p>
</div>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Nonsaturating Activation Functions"><div class="sect2" id="idm140583000455200">
<h2>Nonsaturating Activation Functions</h2>

<p>One <a data-type="indexterm" data-primary="nonsaturating activation functions" id="naf11"></a><a data-type="indexterm" data-primary="gradients, vanishing and exploding" data-secondary="nonsaturating activation functions" id="gvae11naf"></a>of
 the insights in the 2010 paper by Glorot and Bengio was that the 
vanishing/exploding gradients problems were in part due to a poor choice
 of activation function. Until then most people had assumed that if 
Mother Nature had chosen to use roughly sigmoid activation functions in 
biological neurons, they must be an excellent choice. But it turns out 
that other activation functions behave much better in deep neural 
networks, in particular the ReLU activation function, mostly because it 
does not saturate for positive values (and also because it is quite fast
 to compute).</p>

<p>Unfortunately, the ReLU activation function is not perfect. It suffers from a problem known as <a data-type="indexterm" data-primary="dying ReLUs" id="idm140583000450208"></a>the <em>dying ReLUs</em>:
 during training, some neurons effectively die, meaning they stop 
outputting anything other than 0. In some cases, you may find that half 
of your network’s neurons are dead, especially if you used a large 
learning rate. During training, if a neuron’s weights get updated such 
that the weighted sum of the neuron’s inputs is negative, it will start 
outputting&nbsp;0. When this happens, the neuron is unlikely to come 
back to life since the gradient of the ReLU function is&nbsp;0 when its 
input is negative.</p>

<p>To solve this problem, you may want to use a variant of the ReLU function, such as the <em>leaky ReLU</em>. <a data-type="indexterm" data-primary="leaky ReLU" id="idm140583000447216"></a>This function is defined as LeakyReLU<sub><em>α</em></sub>(<em>z</em>) = max(<em>αz</em>, <em>z</em>) (see <a data-type="xref" href="#leaky_relu">Figure&nbsp;11-2</a>). The hyperparameter <em>α</em> defines how much the function “leaks”: it is the slope of the function for <em>z</em>
 &lt; 0, and is typically set to 0.01. This small slope ensures that 
leaky ReLUs never die; they can go into a long coma, but they have a 
chance to eventually wake up. A <a href="https://goo.gl/B1xhKn">recent paper</a><sup><a data-type="noteref" id="idm140583000442064-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140583000442064" class="totri-footnote">5</a></sup>
 compared several variants of the ReLU activation function and one of 
its conclusions was that the leaky variants always outperformed the 
strict ReLU activation function. In fact, setting <em>α</em> = 0.2 (huge leak) seemed to result in better performance than <em>α</em> = 0.01 (small leak). They also evaluated the <em>randomized leaky ReLU</em> (RReLU), where <em>α</em>
 is picked randomly in a given range during training, and it is fixed to
 an average value during testing. It also performed fairly well and 
seemed to act as a regularizer (reducing the risk of overfitting <a data-type="indexterm" data-primary="RReLU (randomized leaky ReLU)" id="idm140583000439168"></a><a data-type="indexterm" data-primary="randomized leaky ReLU  (RReLU)" id="idm140583000438448"></a>the training set). Finally, they also evaluated the <em>parametric leaky ReLU</em> (PReLU), <a data-type="indexterm" data-primary="PReLU (parametric leaky ReLU)" id="idm140583000437248"></a>where <em>α</em>
 is authorized to be learned during training (instead of being a 
hyperparameter, it becomes a parameter that can be modified by 
backpropagation like any other parameter). This was reported to strongly
 outperform ReLU on large image datasets, but on smaller datasets it 
runs the risk of overfitting the training set.</p>

<figure class="smallerfiftyfive"><div id="leaky_relu" class="figure">
<img src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/mlst_1102.png" alt="mlst 1102" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1102.png" width="1440" height="926">
<h6><span class="label">Figure 11-2. </span>Leaky ReLU</h6>
</div></figure>

<p>Last but not least, a <a href="http://goo.gl/Sdl2P7">2015 paper</a> by Djork-Arné Clevert et al.<sup><a data-type="noteref" id="idm140583000432272-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140583000432272" class="totri-footnote">6</a></sup> proposed a new activation function called the <em>exponential linear unit</em> (ELU) <a data-type="indexterm" data-primary="exponential linear unit (ELU)" id="elu11"></a>that
 outperformed all the ReLU variants in their experiments: training time 
was reduced and the neural network performed better on the test set. It 
is represented in <a data-type="xref" href="#elu_activation_plot">Figure&nbsp;11-3</a>, and <a data-type="xref" href="#elu_activation_equation">Equation 11-2</a> shows its definition.</p>
<div id="elu_activation_equation" data-type="equation">
<h5><span class="label">Equation 11-2. </span>ELU activation function</h5>
<img src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_111.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_111.png" width="936" height="134">
</div>

<figure class="smallerfiftyfive"><div id="elu_activation_plot" class="figure">
<img src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/mlst_1103.png" alt="mlst 1103" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1103.png" width="1440" height="922">
<h6><span class="label">Figure 11-3. </span>ELU activation function</h6>
</div></figure>

<p>It looks a lot like the ReLU function, with a few major differences:</p>

<ul>
<li>
<p>First it takes on negative values when <em>z</em> &lt; 0, which 
allows the unit to have an average output closer to 0. This helps 
alleviate the vanishing gradients problem, as discussed earlier. The 
hyperparameter <em>α</em> defines the value that the ELU function approaches when <em>z</em> is a large negative number. It is usually set to 1, but you can tweak it like any other hyperparameter if you want.</p>
</li>
<li>
<p>Second, it has a nonzero gradient for <em>z</em> &lt; 0, which avoids the dying units issue.</p>
</li>
<li>
<p>Third, the function is smooth everywhere, including around <em>z</em> = 0, which helps speed up Gradient Descent, since it does not bounce as much left and right of <em>z</em> = 0.</p>
</li>
</ul>

<p>The main drawback of the ELU activation function is that it is slower
 to compute than the ReLU and its variants (due to the use of the 
exponential function), but during training this is compensated by the 
faster convergence rate. However, at test time an ELU network will be 
slower than a ReLU network.</p>
<div data-type="tip"><h6>Tip</h6>
<p>So which activation function should you use for the hidden layers of 
your deep neural networks? Although your mileage will vary, in general 
ELU &gt; leaky ReLU (and its variants) &gt; ReLU &gt; tanh &gt; 
logistic. If you care a lot about runtime performance, then you may 
prefer leaky ReLUs over ELUs. If you don’t want to tweak yet another 
hyperparameter, you may just use the default <em>α</em> values suggested
 earlier (0.01 for the leaky ReLU, and 1 for ELU). If you have spare 
time and computing power, you can use cross-validation to evaluate other
 activation functions, in particular RReLU if your network is 
overfitting, or PReLU if you have a huge training set.</p>
</div>

<p>TensorFlow offers an <code>elu()</code> function that you can use to build your neural network. Simply set the <code>activation</code> argument when calling the <code>dense()</code> function, <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.nn.elu()" id="idm140583000412640"></a>like this:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">hidden1</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">dense</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">n_hidden1</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">elu</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"hidden1"</code><code class="p">)</code></pre>

<p>TensorFlow does not have a predefined function for leaky ReLUs, but it is easy enough to <a data-type="indexterm" data-primary="ReLU function" data-startref="relu11" id="idm140583000390832"></a><a data-type="indexterm" data-primary="gradients, vanishing and exploding" data-secondary="nonsaturating activation functions" data-startref="gvae11naf" id="idm140583000389984"></a><a data-type="indexterm" data-primary="nonsaturating activation functions" data-startref="naf11" id="idm140583000388832"></a><a data-type="indexterm" data-primary="exponential linear unit (ELU)" data-startref="elu11" id="idm140583000387920"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.maximum()" id="idm140583000387008"></a>define:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">def</code> <code class="nf">leaky_relu</code><code class="p">(</code><code class="n">z</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="bp">None</code><code class="p">):</code>
    <code class="k">return</code> <code class="n">tf</code><code class="o">.</code><code class="n">maximum</code><code class="p">(</code><code class="mf">0.01</code> <code class="o">*</code> <code class="n">z</code><code class="p">,</code> <code class="n">z</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="n">name</code><code class="p">)</code>

<code class="n">hidden1</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">dense</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">n_hidden1</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="n">leaky_relu</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"hidden1"</code><code class="p">)</code></pre>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Batch Normalization"><div class="sect2" id="idm140583000454544">
<h2>Batch Normalization</h2>

<p>Although <a data-type="indexterm" data-primary="Batch Normalization" id="bn11"></a><a data-type="indexterm" data-primary="gradients, vanishing and exploding" data-secondary="Batch Normalization" id="gvae11bn"></a>using
 He initialization along with ELU (or any variant of ReLU) can 
significantly reduce the vanishing/exploding gradients problems at the 
beginning of training, it doesn’t guarantee that they won’t come back 
during training.</p>

<p>In a <a href="https://goo.gl/gA4GSP">2015 paper</a>,<sup><a data-type="noteref" id="idm140583000276592-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140583000276592" class="totri-footnote">7</a></sup> Sergey Ioffe and Christian Szegedy proposed a technique called <em>Batch Normalization</em>
 (BN) to address the vanishing/exploding gradients problems, and more 
generally the problem that the distribution of each layer’s inputs 
changes during training, as the parameters of the previous layers <a data-type="indexterm" data-primary="Internal Covariate  Shift  problem" id="idm140583000275120"></a>change (which they call the <em>Internal Covariate Shift</em> problem).</p>

<p>The technique consists of adding an operation in the model just 
before the activation function of each layer, simply zero-centering and 
normalizing the inputs, then scaling and shifting the result using two 
new parameters per layer (one for scaling, the other for shifting). In 
other words, this operation lets the model learn the optimal scale and 
mean of the inputs for each layer.</p>

<p>In order to zero-center and normalize the inputs, the algorithm needs
 to estimate the inputs’ mean and standard deviation. It does so by 
evaluating the mean and standard deviation of the inputs over the 
current mini-batch (hence the name “Batch Normalization”). The whole <a data-type="indexterm" data-primary="Batch Normalization" data-secondary="operation summary" id="idm140583000272544"></a>operation is summarized in <a data-type="xref" href="#batch_normalization_algorithm">Equation 11-3</a>.</p>
<div class="fifty-percent" id="batch_normalization_algorithm" data-type="equation"><h5><span class="label">Equation 11-3. </span>Batch Normalization algorithm</h5>
<img src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_112.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_112.png" width="777" height="687"></div>

<ul>
<li>
<p><em>μ</em><sub><em>B</em></sub> is the empirical mean, evaluated over the whole mini-batch <em>B</em>.</p>
</li>
<li>
<p><em>σ</em><sub><em>B</em></sub> is the empirical standard deviation, also evaluated over the whole mini-batch.</p>
</li>
<li>
<p><em>m</em><sub><em>B</em></sub> is the number of instances in the mini-batch.</p>
</li>
<li>
<p><img src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_113.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_113.png" width="13" height="23"><sup><em>(i)</em></sup> is the zero-centered and normalized input.</p>
</li>
<li>
<p><em>γ</em> is the scaling parameter for the layer.</p>
</li>
<li>
<p><em>β</em> is the shifting parameter (offset) for the layer.</p>
</li>
<li>
<p><em>ϵ</em> is a tiny number to avoid division by zero (typically 10<sup>–5</sup>). This is called <a data-type="indexterm" data-primary="smoothing terms" id="idm140583000222400"></a>a <em>smoothing term</em>.</p>
</li>
<li>
<p><strong>z</strong><sup><em>(i)</em></sup> is the output of the BN operation: it is a scaled and shifted version of the inputs.</p>
</li>
</ul>

<p>At test time, there is no mini-batch to compute the empirical mean 
and standard deviation, so instead you simply use the whole training 
set’s mean and standard deviation. These are typically efficiently 
computed during training using a moving average. So, in total, four 
parameters are learned for each batch-normalized layer: <em>γ</em> (scale), <em>β</em> (offset), <em>μ</em> (mean), and <em>σ</em> (standard deviation).</p>

<p>The authors demonstrated that this technique considerably improved 
all the deep neural networks they experimented with. The vanishing 
gradients problem was strongly reduced, to the point that they could use
 saturating activation functions such as the tanh and even the logistic 
activation function. The networks were also much less sensitive to the 
weight initialization. They were able to use much larger learning rates,
 significantly speeding up the learning process. Specifically, they note
 that “Applied to a state-of-the-art image classification model, Batch 
Normalization achieves the same accuracy with 14 times fewer training 
steps, and beats the original model by a significant margin. […] Using 
an ensemble of batch-normalized networks, we improve upon the best 
published result on ImageNet classification: reaching 4.9% top-5 
validation error (and 4.8% test error), exceeding the accuracy of human 
raters.” Finally, like a gift that keeps on giving, Batch Normalization 
also acts like a regularizer, reducing the need for other regularization
 techniques (such as dropout, described later in the chapter).</p>

<p>Batch Normalization does, however, add some complexity to the model 
(although it removes the need for normalizing the input data since the 
first hidden layer will take care of that, provided it is 
batch-normalized). Moreover, there is a runtime penalty: the neural 
network makes slower predictions due to the extra computations required 
at each layer. So if you need predictions to be lightning-fast, you may 
want to check how well plain ELU + He initialization perform before 
playing with Batch Normalization.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>You may find that training is rather slow at first while Gradient 
Descent is searching for the optimal scales and offsets for each layer, 
but it accelerates once it has found reasonably good values.</p>
</div>










<section data-type="sect3" data-pdf-bookmark="Implementing Batch Normalization with TensorFlow"><div class="sect3" id="idm140583000213120">
<h3>Implementing Batch Normalization with TensorFlow</h3>

<p>TensorFlow <a data-type="indexterm" data-primary="Batch Normalization" data-secondary="with TensorFlow" data-secondary-sortas="TensorFlow" id="bn11wtf"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="Batch Normalization with" id="tf11bnw"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.layers.batch_normalization()" id="tfclbnch11"></a>provides a <code>tf.nn.batch_normalization()</code>
 function that simply centers and normalizes the inputs, but you must 
compute the mean and standard deviation yourself (based on the 
mini-batch data during training or on the full dataset during testing, 
as just discussed) and pass them as parameters to this function, and you
 must also handle the creation of the scaling and offset parameters (and
 pass them to this function). It is doable, but not the most convenient 
approach. Instead, you should use the <code>tf.layers.batch_normalization()</code> function, <a data-type="indexterm" data-primary="batch_normalization()" id="bnormparen11"></a>which handles all this for you, as in the following code:</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">import</code> <code class="nn">tensorflow</code> <code class="kn">as</code> <code class="nn">tf</code>

<code class="n">n_inputs</code> <code class="o">=</code> <code class="mi">28</code> <code class="o">*</code> <code class="mi">28</code>
<code class="n">n_hidden1</code> <code class="o">=</code> <code class="mi">300</code>
<code class="n">n_hidden2</code> <code class="o">=</code> <code class="mi">100</code>
<code class="n">n_outputs</code> <code class="o">=</code> <code class="mi">10</code>

<code class="n">X</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">placeholder</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">,</code> <code class="n">shape</code><code class="o">=</code><code class="p">(</code><code class="bp">None</code><code class="p">,</code> <code class="n">n_inputs</code><code class="p">),</code> <code class="n">name</code><code class="o">=</code><code class="s2">"X"</code><code class="p">)</code>

<code class="n">training</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">placeholder_with_default</code><code class="p">(</code><code class="bp">False</code><code class="p">,</code> <code class="n">shape</code><code class="o">=</code><code class="p">(),</code> <code class="n">name</code><code class="o">=</code><code class="s1">'training'</code><code class="p">)</code>

<code class="n">hidden1</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">dense</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">n_hidden1</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"hidden1"</code><code class="p">)</code>
<code class="n">bn1</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">batch_normalization</code><code class="p">(</code><code class="n">hidden1</code><code class="p">,</code> <code class="n">training</code><code class="o">=</code><code class="n">training</code><code class="p">,</code> <code class="n">momentum</code><code class="o">=</code><code class="mf">0.9</code><code class="p">)</code>
<code class="n">bn1_act</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">elu</code><code class="p">(</code><code class="n">bn1</code><code class="p">)</code>
<code class="n">hidden2</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">dense</code><code class="p">(</code><code class="n">bn1_act</code><code class="p">,</code> <code class="n">n_hidden2</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"hidden2"</code><code class="p">)</code>
<code class="n">bn2</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">batch_normalization</code><code class="p">(</code><code class="n">hidden2</code><code class="p">,</code> <code class="n">training</code><code class="o">=</code><code class="n">training</code><code class="p">,</code> <code class="n">momentum</code><code class="o">=</code><code class="mf">0.9</code><code class="p">)</code>
<code class="n">bn2_act</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">elu</code><code class="p">(</code><code class="n">bn2</code><code class="p">)</code>
<code class="n">logits_before_bn</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">dense</code><code class="p">(</code><code class="n">bn2_act</code><code class="p">,</code> <code class="n">n_outputs</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"outputs"</code><code class="p">)</code>
<code class="n">logits</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">batch_normalization</code><code class="p">(</code><code class="n">logits_before_bn</code><code class="p">,</code> <code class="n">training</code><code class="o">=</code><code class="n">training</code><code class="p">,</code>
                                       <code class="n">momentum</code><code class="o">=</code><code class="mf">0.9</code><code class="p">)</code></pre>

<p>Let’s walk through this code. The first lines are fairly self-explanatory, until we define the <code>training</code> <a data-type="indexterm" data-primary="training" id="trainch11"></a>placeholder: we will set it to <code>True</code> during training, but otherwise it will default to <code>False</code>. This will be used to tell the <code>tf.layers.batch_normalization()</code>
 function whether it should use the current mini-batch’s mean and 
standard deviation (during training) or the whole training set’s mean 
and standard deviation (during testing).</p>

<p>Then, we alternate fully connected layers and batch normalization layers: the fully connected layers are created using the <code>tf.layers.dense()</code> <a data-type="indexterm" data-primary="tf.layers.dense()" id="idm140583000062624"></a>function, just like we did in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html#ann_chapter">Chapter&nbsp;10</a>.
 Note that we don’t specify any activation function for the fully 
connected layers because we want to apply the activation function after 
each batch normalization layer.<sup><a data-type="noteref" id="idm140583000060768-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140583000060768" class="totri-footnote">8</a></sup> We create the batch normalization layers using the <code>tf.layers.batch_normalization()</code> <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.layers.batch_normalization()" data-startref="tfclbnch11" id="idm140583000059456"></a>function, setting its <code>training</code> and <code>momentum</code> parameters. The BN algorithm uses <em>exponential decay</em> to <a data-type="indexterm" data-primary="exponential decay" id="idm140583000056736"></a>compute the running averages, which is why it requires the <code>momentum</code> parameter: given a new value <em>v</em>, the running average <img src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_114.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_114.png" width="12" height="23"> is updated through the equation:</p>
<div data-type="equation">
<img src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_115.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_115.png" width="1156" height="68">
</div>

<p>A good momentum value is typically close to 1—for example, 0.9, 0.99,
 or 0.999 (you want more 9s for larger datasets and smaller 
mini-batches).</p>

<p>You may have noticed that the code is quite repetitive, with the same
 batch normalization parameters appearing over and over again. To avoid 
this repetition, you can use the <code>partial()</code> function from the <code>functools</code>
 module (part of Python’s standard library). It creates a thin wrapper 
around a function and allows you to define default values for some 
parameters. The creation of the network layers in the preceding code can
 be modified like so:<a data-type="indexterm" data-primary="functools.partial()" id="idm140583000051200"></a></p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">functools</code> <code class="kn">import</code> <code class="n">partial</code>

<code class="n">my_batch_norm_layer</code> <code class="o">=</code> <code class="n">partial</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">batch_normalization</code><code class="p">,</code>
                              <code class="n">training</code><code class="o">=</code><code class="n">training</code><code class="p">,</code> <code class="n">momentum</code><code class="o">=</code><code class="mf">0.9</code><code class="p">)</code>

<code class="n">hidden1</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">dense</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">n_hidden1</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"hidden1"</code><code class="p">)</code>
<code class="n">bn1</code> <code class="o">=</code> <code class="n">my_batch_norm_layer</code><code class="p">(</code><code class="n">hidden1</code><code class="p">)</code>
<code class="n">bn1_act</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">elu</code><code class="p">(</code><code class="n">bn1</code><code class="p">)</code>
<code class="n">hidden2</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">dense</code><code class="p">(</code><code class="n">bn1_act</code><code class="p">,</code> <code class="n">n_hidden2</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"hidden2"</code><code class="p">)</code>
<code class="n">bn2</code> <code class="o">=</code> <code class="n">my_batch_norm_layer</code><code class="p">(</code><code class="n">hidden2</code><code class="p">)</code>
<code class="n">bn2_act</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">elu</code><code class="p">(</code><code class="n">bn2</code><code class="p">)</code>
<code class="n">logits_before_bn</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">dense</code><code class="p">(</code><code class="n">bn2_act</code><code class="p">,</code> <code class="n">n_outputs</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"outputs"</code><code class="p">)</code>
<code class="n">logits</code> <code class="o">=</code> <code class="n">my_batch_norm_layer</code><code class="p">(</code><code class="n">logits_before_bn</code><code class="p">)</code></pre>

<p>It may not look much better than before in this small example, but if
 you have 10 layers and want to use the same activation function, 
initializer, regularizer, and so on, in all layers, this trick will make
 your code much more readable.</p>

<p>The rest of the construction phase is the same as in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html#ann_chapter">Chapter&nbsp;10</a>: define <a data-type="indexterm" data-primary="cost function" data-secondary="in batch normalization" data-secondary-sortas="batch norm" id="idm140582999716432"></a>the
 cost function, create an optimizer, tell it to minimize the cost 
function, define the evaluation operations, create a variable 
initializer, create a <code>Saver</code>, and so on.</p>

<p>The execution phase is also pretty much the same, with two 
exceptions. First, during training, whenever you run an operation that 
depends on the <code>batch_normalization()</code> layer, you need to set the <code>training</code> <a data-type="indexterm" data-primary="batch_normalization()" data-startref="bnormparen11" id="idm140582999712864"></a><a data-type="indexterm" data-primary="training" data-startref="trainch11" id="idm140582999711856"></a>placeholder to <code>True</code>. Second, the <code>batch_normalization()</code>
 function creates a few operations that must be evaluated at each step 
during training in order to update the moving averages (recall that 
these moving averages are needed to evaluate the training set’s mean and
 standard deviation). These operations are automatically added to the <code>UPDATE_OPS</code> collection, so all we need to do is get the list of operations in that collection and run them at each training iteration:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">extra_update_ops</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">get_collection</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">GraphKeys</code><code class="o">.</code><code class="n">UPDATE_OPS</code><code class="p">)</code>

<code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">Session</code><code class="p">()</code> <code class="k">as</code> <code class="n">sess</code><code class="p">:</code>
    <code class="n">init</code><code class="o">.</code><code class="n">run</code><code class="p">()</code>
    <code class="k">for</code> <code class="n">epoch</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">n_epochs</code><code class="p">):</code>
        <code class="k">for</code> <code class="n">iteration</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">mnist</code><code class="o">.</code><code class="n">train</code><code class="o">.</code><code class="n">num_examples</code> <code class="o">//</code> <code class="n">batch_size</code><code class="p">):</code>
            <code class="n">X_batch</code><code class="p">,</code> <code class="n">y_batch</code> <code class="o">=</code> <code class="n">mnist</code><code class="o">.</code><code class="n">train</code><code class="o">.</code><code class="n">next_batch</code><code class="p">(</code><code class="n">batch_size</code><code class="p">)</code>
            <code class="n">sess</code><code class="o">.</code><code class="n">run</code><code class="p">([</code><code class="n">training_op</code><code class="p">,</code> <code class="n">extra_update_ops</code><code class="p">],</code>
                     <code class="n">feed_dict</code><code class="o">=</code><code class="p">{</code><code class="n">training</code><code class="p">:</code> <code class="bp">True</code><code class="p">,</code> <code class="n">X</code><code class="p">:</code> <code class="n">X_batch</code><code class="p">,</code> <code class="n">y</code><code class="p">:</code> <code class="n">y_batch</code><code class="p">})</code>
        <code class="n">accuracy_val</code> <code class="o">=</code> <code class="n">accuracy</code><code class="o">.</code><code class="n">eval</code><code class="p">(</code><code class="n">feed_dict</code><code class="o">=</code><code class="p">{</code><code class="n">X</code><code class="p">:</code> <code class="n">mnist</code><code class="o">.</code><code class="n">test</code><code class="o">.</code><code class="n">images</code><code class="p">,</code>
                                                <code class="n">y</code><code class="p">:</code> <code class="n">mnist</code><code class="o">.</code><code class="n">test</code><code class="o">.</code><code class="n">labels</code><code class="p">})</code>
        <code class="k">print</code><code class="p">(</code><code class="n">epoch</code><code class="p">,</code> <code class="s2">"Test accuracy:"</code><code class="p">,</code> <code class="n">accuracy_val</code><code class="p">)</code>

    <code class="n">save_path</code> <code class="o">=</code> <code class="n">saver</code><code class="o">.</code><code class="n">save</code><code class="p">(</code><code class="n">sess</code><code class="p">,</code> <code class="s2">"./my_model_final.ckpt"</code><code class="p">)</code></pre>

<p>That’s all! In this tiny example with just two layers, it’s unlikely 
that Batch Normalization will have a very positive impact, but for 
deeper networks it can make a tremendous <a data-type="indexterm" data-primary="Batch Normalization" data-secondary="with TensorFlow" data-secondary-sortas="TensorFlow" data-startref="bn11wtf" id="idm140582999706832"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="Batch Normalization with" data-startref="tf11bnw" id="idm140582999705472"></a><a data-type="indexterm" data-primary="Batch Normalization" data-startref="bn11" id="idm140582999935536"></a><a data-type="indexterm" data-primary="gradients, vanishing and exploding" data-secondary="Batch Normalization" data-startref="gvae11bn" id="idm140582999934592"></a>difference.</p>
</div></section>



</div></section>













<section data-type="sect2" data-pdf-bookmark="Gradient Clipping"><div class="sect2" id="idm140583000281168">
<h2>Gradient Clipping</h2>

<p>A popular <a data-type="indexterm" data-primary="gradients, vanishing and exploding" data-secondary="gradient clipping" id="gvae11gc"></a>technique
 to lessen the exploding gradients problem is to simply clip the 
gradients during backpropagation so that they never exceed some 
threshold (this is mostly useful for recurrent neural networks; see <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch14.html#rnn_chapter">Chapter&nbsp;14</a>). This is called <a href="http://goo.gl/dRDAaf"><em>Gradient Clipping</em></a>.<sup><a data-type="noteref" id="idm140582999928672-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140582999928672" class="totri-footnote">9</a></sup>
 In general people now prefer Batch Normalization, but it’s still useful
 to know about Gradient Clipping and how to implement it.</p>

<p>In TensorFlow, the optimizer’s <code>minimize()</code> <a data-type="indexterm" data-primary="minimize()" id="idm140582999926704"></a>function takes care of both computing the gradients and applying them, so you must instead call <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.train.GradientDescentOptimizer" id="idm140582999925728"></a>the optimizer’s <code>compute_gradients()</code> <a data-type="indexterm" data-primary="compute_gradients()" id="idm140582999924224"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.clip_by_value()" id="idm140582999923488"></a>method first, then create an operation to clip the gradients using the <code>clip_by_value()</code> <a data-type="indexterm" data-primary="clip_by_value()" id="idm140582999922032"></a>function, and finally create an operation to apply the clipped gradients using the optimizer’s <code>apply_gradients()</code> <a data-type="indexterm" data-primary="apply_gradients()" id="idm140582999920672"></a>method:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">threshold</code> <code class="o">=</code> <code class="mf">1.0</code>
<code class="n">optimizer</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">train</code><code class="o">.</code><code class="n">GradientDescentOptimizer</code><code class="p">(</code><code class="n">learning_rate</code><code class="p">)</code>
<code class="n">grads_and_vars</code> <code class="o">=</code> <code class="n">optimizer</code><code class="o">.</code><code class="n">compute_gradients</code><code class="p">(</code><code class="n">loss</code><code class="p">)</code>
<code class="n">capped_gvs</code> <code class="o">=</code> <code class="p">[(</code><code class="n">tf</code><code class="o">.</code><code class="n">clip_by_value</code><code class="p">(</code><code class="n">grad</code><code class="p">,</code> <code class="o">-</code><code class="n">threshold</code><code class="p">,</code> <code class="n">threshold</code><code class="p">),</code> <code class="n">var</code><code class="p">)</code>
              <code class="k">for</code> <code class="n">grad</code><code class="p">,</code> <code class="n">var</code> <code class="ow">in</code> <code class="n">grads_and_vars</code><code class="p">]</code>
<code class="n">training_op</code> <code class="o">=</code> <code class="n">optimizer</code><code class="o">.</code><code class="n">apply_gradients</code><code class="p">(</code><code class="n">capped_gvs</code><code class="p">)</code></pre>

<p>You would then run this <code>training_op</code> at every training 
step, as usual. It will compute the gradients, clip them between –1.0 
and 1.0, and apply them. The threshold is a hyperparameter you <a data-type="indexterm" data-primary="gradients, vanishing and exploding" data-startref="gvae11" id="idm140582999418832"></a><a data-type="indexterm" data-primary="deep neural networks (DNNs)" data-secondary="vanishing and exploding gradients" data-startref="dnn11vaev" id="idm140582999418096"></a>can tune.</p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Reusing Pretrained Layers"><div class="sect1" id="idm140583000654768">
<h1>Reusing Pretrained Layers</h1>

<p>It <a data-type="indexterm" data-primary="deep neural networks (DNNs)" data-secondary="reusing pretrained layers" id="dnn11rpl"></a><a data-type="indexterm" data-primary="pretrained layers reuse" id="plr11"></a><a data-type="indexterm" data-primary="transfer learning" data-seealso="pretrained layers reuse" id="tl11"></a>is
 generally not a good idea to train a very large DNN from scratch: 
instead, you should always try to find an existing neural network that 
accomplishes a similar task to the one you are trying to tackle, then 
just reuse the lower layers of this network: this is called <em>transfer learning</em>. It will not only speed up training considerably, but will also require much less training data.</p>

<p>For example, suppose that you have access to a DNN that was trained 
to classify pictures into 100 different categories, including animals, 
plants, vehicles, and everyday objects. You now want to train a DNN to 
classify specific types of vehicles. These tasks are very similar, so 
you should try to reuse parts of the first network (see <a data-type="xref" href="#reuse_pretrained_diagram">Figure&nbsp;11-4</a>).</p>

<figure class="smallersixtyfive"><div id="reuse_pretrained_diagram" class="figure">
<img src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/mlst_1104.png" alt="mlst 1104" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1104.png" width="1440" height="1113">
<h6><span class="label">Figure 11-4. </span>Reusing pretrained layers</h6>
</div></figure>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>If the input pictures of your new task don’t have the same size as 
the ones used in the original task, you will have to add a preprocessing
 step to resize them to the size expected by the original model. More 
generally, transfer learning will only work well if the inputs have 
similar low-level features.</p>
</div>








<section data-type="sect2" data-pdf-bookmark="Reusing a TensorFlow Model"><div class="sect2" id="idm140582999600864">
<h2>Reusing a TensorFlow Model</h2>

<p>If <a data-type="indexterm" data-primary="pretrained layers reuse" data-secondary="TensorFlow model" id="plr11tfm"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="reusing pretrained layers" id="tf11rpl"></a>the original model was trained using TensorFlow, you can simply restore it and train it on the new task. As we discussed in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch09.html#tensorflow_chapter">Chapter&nbsp;9</a>, you can use the <code>import_meta_graph()</code> function to import the operations into the default graph. This returns a <code>Saver</code> that you can later use to load the model’s state:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">saver</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">train</code><code class="o">.</code><code class="n">import_meta_graph</code><code class="p">(</code><code class="s2">"./my_model_final.ckpt.meta"</code><code class="p">)</code></pre>

<p>You must then get a handle on the operations and tensors you will need for training. For this, you can use the graph’s <code>get_operation_by_name()</code> and <code>get_tensor_by_name()</code> methods. The name of a tensor is the name of the operation that outputs it followed by <code>:0</code> (or <code>:1</code> if it is the second output, <code>:2</code> if it is the third, and so on):</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">X</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">get_default_graph</code><code class="p">()</code><code class="o">.</code><code class="n">get_tensor_by_name</code><code class="p">(</code><code class="s2">"X:0"</code><code class="p">)</code>
<code class="n">y</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">get_default_graph</code><code class="p">()</code><code class="o">.</code><code class="n">get_tensor_by_name</code><code class="p">(</code><code class="s2">"y:0"</code><code class="p">)</code>
<code class="n">accuracy</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">get_default_graph</code><code class="p">()</code><code class="o">.</code><code class="n">get_tensor_by_name</code><code class="p">(</code><code class="s2">"eval/accuracy:0"</code><code class="p">)</code>
<code class="n">training_op</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">get_default_graph</code><code class="p">()</code><code class="o">.</code><code class="n">get_operation_by_name</code><code class="p">(</code><code class="s2">"GradientDescent"</code><code class="p">)</code></pre>

<p>If the pretrained model is not well documented, then you will have to
 explore the graph to find the names of the operations you will need. In
 this case, <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.global_variables()" id="idm140582999588336"></a>you can either explore the graph using TensorBoard (for this you must first export the graph using a <code>FileWriter</code>, as discussed in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch09.html#tensorflow_chapter">Chapter&nbsp;9</a>), or you can use the graph’s <code>get_operations()</code> method to list all the operations:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">for</code> <code class="n">op</code> <code class="ow">in</code> <code class="n">tf</code><code class="o">.</code><code class="n">get_default_graph</code><code class="p">()</code><code class="o">.</code><code class="n">get_operations</code><code class="p">():</code>
    <code class="k">print</code><code class="p">(</code><code class="n">op</code><code class="o">.</code><code class="n">name</code><code class="p">)</code></pre>

<p>If you are the author of the original model, you could make things 
easier for people who will reuse your model by giving operations very 
clear names and documenting them. Another approach is to create a 
collection containing all the important operations that people will want
 to get a handle on:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">for</code> <code class="n">op</code> <code class="ow">in</code> <code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">y</code><code class="p">,</code> <code class="n">accuracy</code><code class="p">,</code> <code class="n">training_op</code><code class="p">):</code>
    <code class="n">tf</code><code class="o">.</code><code class="n">add_to_collection</code><code class="p">(</code><code class="s2">"my_important_ops"</code><code class="p">,</code> <code class="n">op</code><code class="p">)</code></pre>

<p>This way people who reuse your model will be able to simply write:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">X</code><code class="p">,</code> <code class="n">y</code><code class="p">,</code> <code class="n">accuracy</code><code class="p">,</code> <code class="n">training_op</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">get_collection</code><code class="p">(</code><code class="s2">"my_important_ops"</code><code class="p">)</code></pre>

<p>You can then restore the model’s state using the <code>Saver</code> and continue training using your own data:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">Session</code><code class="p">()</code> <code class="k">as</code> <code class="n">sess</code><code class="p">:</code>
    <code class="n">saver</code><code class="o">.</code><code class="n">restore</code><code class="p">(</code><code class="n">sess</code><code class="p">,</code> <code class="s2">"./my_model_final.ckpt"</code><code class="p">)</code>
    <code class="p">[</code><code class="o">...</code><code class="p">]</code> <code class="c1"># train the model on your own data</code></pre>

<p>Alternatively, if you have access to the Python code that built the original graph, you can use it instead of <code>import_meta_graph()</code>.</p>

<p>In general, you will want to reuse only part of the original model, typically the lower layers. If you use <code>import_meta_graph()</code>
 to restore the graph, it will load the entire original graph, but 
nothing prevents you from just ignoring the layers you do not care 
about. For example, as shown in <a data-type="xref" href="#reuse_pretrained_diagram">Figure&nbsp;11-4</a>,
 you could build new layers (e.g., one hidden layer and one output 
layer) on top of a pretrained layer (e.g., pretrained hidden layer 3). 
You would also need to compute the loss for this new output, and create 
an optimizer to minimize that loss.</p>

<p>If you have access to the pretrained graph’s Python code, you can 
just reuse the parts you need and chop out the rest. However, in this 
case you need a <code>Saver</code> to restore the pretrained model 
(specifying which variables you want to restore; otherwise, TensorFlow 
will complain that the graphs do not match), and another <code>Saver</code> to save the new model. For example, the following code restores only hidden layers 1, 2, and 3:</p>

<pre data-type="programlisting" data-code-language="python"><code class="p">[</code><code class="o">...</code><code class="p">]</code> <code class="c1"># build the new model with the same hidden layers 1-3 as before</code>

<code class="n">reuse_vars</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">get_collection</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">GraphKeys</code><code class="o">.</code><code class="n">GLOBAL_VARIABLES</code><code class="p">,</code>
                               <code class="n">scope</code><code class="o">=</code><code class="s2">"hidden[123]"</code><code class="p">)</code> <code class="c1"># regular expression</code>
<code class="n">reuse_vars_dict</code> <code class="o">=</code> <code class="nb">dict</code><code class="p">([(</code><code class="n">var</code><code class="o">.</code><code class="n">op</code><code class="o">.</code><code class="n">name</code><code class="p">,</code> <code class="n">var</code><code class="p">)</code> <code class="k">for</code> <code class="n">var</code> <code class="ow">in</code> <code class="n">reuse_vars</code><code class="p">])</code>
<code class="n">restore_saver</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">train</code><code class="o">.</code><code class="n">Saver</code><code class="p">(</code><code class="n">reuse_vars_dict</code><code class="p">)</code> <code class="c1"># to restore layers 1-3</code>

<code class="n">init</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">global_variables_initializer</code><code class="p">()</code> <code class="c1"># to init all variables, old and new</code>
<code class="n">saver</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">train</code><code class="o">.</code><code class="n">Saver</code><code class="p">()</code> <code class="c1"># to save the new model</code>

<code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">Session</code><code class="p">()</code> <code class="k">as</code> <code class="n">sess</code><code class="p">:</code>
    <code class="n">init</code><code class="o">.</code><code class="n">run</code><code class="p">()</code>
    <code class="n">restore_saver</code><code class="o">.</code><code class="n">restore</code><code class="p">(</code><code class="n">sess</code><code class="p">,</code> <code class="s2">"./my_model_final.ckpt"</code><code class="p">)</code>
    <code class="p">[</code><code class="o">...</code><code class="p">]</code> <code class="c1"># train the model</code>
    <code class="n">save_path</code> <code class="o">=</code> <code class="n">saver</code><code class="o">.</code><code class="n">save</code><code class="p">(</code><code class="n">sess</code><code class="p">,</code> <code class="s2">"./my_new_model_final.ckpt"</code><code class="p">)</code></pre>

<p>First <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.GraphKeys.GLOBAL_VARIABLES" id="tfgktrainvarch11"></a> <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.get_collection()" id="tfgetcollch11"></a>we
 build the new model, making sure to copy the original model’s hidden 
layers 1 to 3. Then we get the list of all variables in hidden layers 1 
to 3, using the regular expression <code>"hidden[123]"</code>. Next, we 
create a dictionary that maps the name of each variable in the original 
model to its name in the new model (generally you want to keep the exact
 same names). Then we create a <code>Saver</code> that will restore only these variables. We also create an operation to initialize all the variables (old and new) and a second <code>Saver</code>
 to save the entire new model, not just layers 1 to 3. We then start a 
session and initialize all variables in the model, then restore the 
variable values from the original model’s layers 1 to 3. Finally, we 
train the model on the new task and save it.</p>
<div data-type="tip"><h6>Tip</h6>
<p>The more similar the tasks are, the more layers you want to reuse 
(starting with the lower layers). For very similar tasks, you can try 
keeping all the hidden layers and just replace the output <a data-type="indexterm" data-primary="pretrained layers reuse" data-secondary="TensorFlow model" data-startref="plr11tfm" id="idm140582999121392"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="reusing pretrained layers" data-startref="tf11rpl" id="idm140582999120144"></a>layer.</p>
</div>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Reusing Models from Other Frameworks"><div class="sect2" id="idm140582999600240">
<h2>Reusing Models from Other Frameworks</h2>

<p>If the <a data-type="indexterm" data-primary="pretrained layers reuse" data-secondary="other frameworks" id="idm140582999117392"></a>model
 was trained using another framework, you will need to load the model 
parameters manually (e.g., using Theano code if it was trained with 
Theano), then assign them to the appropriate variables. This can be 
quite tedious. For example, the following code shows how you would copy 
the weight and biases from the first hidden layer of a <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.variable_scope()" id="idm140582999115904"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.get_variable()" id="idm140582999114960"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.assign()" id="idm140582999114016"></a>model trained using another framework:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">original_w</code> <code class="o">=</code> <code class="p">[</code><code class="o">...</code><code class="p">]</code> <code class="c1"># Load the weights from the other framework</code>
<code class="n">original_b</code> <code class="o">=</code> <code class="p">[</code><code class="o">...</code><code class="p">]</code> <code class="c1"># Load the biases from the other framework</code>

<code class="n">X</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">placeholder</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">,</code> <code class="n">shape</code><code class="o">=</code><code class="p">(</code><code class="bp">None</code><code class="p">,</code> <code class="n">n_inputs</code><code class="p">),</code> <code class="n">name</code><code class="o">=</code><code class="s2">"X"</code><code class="p">)</code>
<code class="n">hidden1</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">dense</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">n_hidden1</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">relu</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"hidden1"</code><code class="p">)</code>
<code class="p">[</code><code class="o">...</code><code class="p">]</code> <code class="c1"># Build the rest of the model</code>

<code class="c1"># Get a handle on the assignment nodes for the hidden1 variables</code>
<code class="n">graph</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">get_default_graph</code><code class="p">()</code>
<code class="n">assign_kernel</code> <code class="o">=</code> <code class="n">graph</code><code class="o">.</code><code class="n">get_operation_by_name</code><code class="p">(</code><code class="s2">"hidden1/kernel/Assign"</code><code class="p">)</code>
<code class="n">assign_bias</code> <code class="o">=</code> <code class="n">graph</code><code class="o">.</code><code class="n">get_operation_by_name</code><code class="p">(</code><code class="s2">"hidden1/bias/Assign"</code><code class="p">)</code>
<code class="n">init_kernel</code> <code class="o">=</code> <code class="n">assign_kernel</code><code class="o">.</code><code class="n">inputs</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code>
<code class="n">init_bias</code> <code class="o">=</code> <code class="n">assign_bias</code><code class="o">.</code><code class="n">inputs</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code>

<code class="n">init</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">global_variables_initializer</code><code class="p">()</code>

<code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">Session</code><code class="p">()</code> <code class="k">as</code> <code class="n">sess</code><code class="p">:</code>
    <code class="n">sess</code><code class="o">.</code><code class="n">run</code><code class="p">(</code><code class="n">init</code><code class="p">,</code> <code class="n">feed_dict</code><code class="o">=</code><code class="p">{</code><code class="n">init_kernel</code><code class="p">:</code> <code class="n">original_w</code><code class="p">,</code> <code class="n">init_bias</code><code class="p">:</code> <code class="n">original_b</code><code class="p">})</code>
    <code class="c1"># [...] Train the model on your new task</code></pre>

<p>In this implementation, we first load the pretrained model using the 
other framework (not shown here), and we extract from it the model 
parameters we want to reuse. Next, we build our TensorFlow model as 
usual. Then comes the tricky part: every TensorFlow variable has an 
associated assignment operation that is used to initialize it. We start 
by getting a handle on these assignment operations (they have the same 
name as the variable, plus <code>"/Assign"</code>). We also get a handle
 on each assignment operation’s second input: in the case of an 
assignment operation, the second input corresponds to the value that 
will be assigned to the variable, so in this case it is the variable’s 
initialization value. Once we start the session, we run the usual 
initialization operation, but this time we feed it the values we want 
for the variables we want to reuse. Alternatively, we could have created
 new assignment operations and placeholders, and used them to set the 
values of the variables after initialization. But why create new nodes 
in the graph when everything we need is already there?</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Freezing the Lower Layers"><div class="sect2" id="idm140582999104688">
<h2>Freezing the Lower Layers</h2>

<p>It <a data-type="indexterm" data-primary="pretrained layers reuse" data-secondary="freezing lower layers" id="idm140582999006288"></a><a data-type="indexterm" data-primary="frozen layers" id="fl11"></a>is
 likely that the lower layers of the first DNN have learned to detect 
low-level features in pictures that will be useful across both image 
classification tasks, so you can just reuse these layers as they are. It
 is generally a good idea to “freeze” their <a data-type="indexterm" data-primary="weights" data-secondary="freezing" id="idm140582999003936"></a>weights
 when training the new DNN: if the lower-layer weights are fixed, then 
the higher-layer weights will be easier to train (because they won’t 
have to learn a moving target). To freeze the lower layers during 
training, one solution is to give the optimizer the list of variables to
 train, excluding the variables <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.GraphKeys.TRAINABLE_VARIABLES" data-startref="tfgktrainvarch11" id="idm140582999002528"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.get_collection()" data-startref="tfgetcollch11" id="idm140582999001344"></a>from the lower layers:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">train_vars</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">get_collection</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">GraphKeys</code><code class="o">.</code><code class="n">TRAINABLE_VARIABLES</code><code class="p">,</code>
                               <code class="n">scope</code><code class="o">=</code><code class="s2">"hidden[34]|outputs"</code><code class="p">)</code>
<code class="n">training_op</code> <code class="o">=</code> <code class="n">optimizer</code><code class="o">.</code><code class="n">minimize</code><code class="p">(</code><code class="n">loss</code><code class="p">,</code> <code class="n">var_list</code><code class="o">=</code><code class="n">train_vars</code><code class="p">)</code></pre>

<p>The first line gets the list of all trainable variables in hidden 
layers 3 and 4 and in the output layer. This leaves out the variables in
 the hidden layers 1 and 2. Next we provide this restricted list of 
trainable variables to the optimizer’s <code>minimize()</code> <a data-type="indexterm" data-primary="minimize()" id="idm140582998766960"></a>function. Ta-da! Layers 1 and 2 are now frozen: they will not budge during training (these are often called <em>frozen layers</em>).</p>

<p>Another option is to add a <code>stop_gradient()</code> layer in the graph. Any layer below it will be frozen:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">name_scope</code><code class="p">(</code><code class="s2">"dnn"</code><code class="p">):</code>
    <code class="n">hidden1</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">dense</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">n_hidden1</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">relu</code><code class="p">,</code>
                              <code class="n">name</code><code class="o">=</code><code class="s2">"hidden1"</code><code class="p">)</code> <code class="c1"># reused frozen</code>
    <code class="n">hidden2</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">dense</code><code class="p">(</code><code class="n">hidden1</code><code class="p">,</code> <code class="n">n_hidden2</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">relu</code><code class="p">,</code>
                              <code class="n">name</code><code class="o">=</code><code class="s2">"hidden2"</code><code class="p">)</code> <code class="c1"># reused frozen</code>
    <code class="n">hidden2_stop</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">stop_gradient</code><code class="p">(</code><code class="n">hidden2</code><code class="p">)</code>
    <code class="n">hidden3</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">dense</code><code class="p">(</code><code class="n">hidden2_stop</code><code class="p">,</code> <code class="n">n_hidden3</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">relu</code><code class="p">,</code>
                              <code class="n">name</code><code class="o">=</code><code class="s2">"hidden3"</code><code class="p">)</code> <code class="c1"># reused, not frozen</code>
    <code class="n">hidden4</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">dense</code><code class="p">(</code><code class="n">hidden3</code><code class="p">,</code> <code class="n">n_hidden4</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">relu</code><code class="p">,</code>
                              <code class="n">name</code><code class="o">=</code><code class="s2">"hidden4"</code><code class="p">)</code> <code class="c1"># new!</code>
    <code class="n">logits</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">dense</code><code class="p">(</code><code class="n">hidden4</code><code class="p">,</code> <code class="n">n_outputs</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"outputs"</code><code class="p">)</code> <code class="c1"># new!</code></pre>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Caching the Frozen Layers"><div class="sect2" id="idm140582998763408">
<h2>Caching the Frozen Layers</h2>

<p>Since <a data-type="indexterm" data-primary="pretrained layers reuse" data-secondary="caching frozen layers" id="idm140582998762272"></a>the
 frozen layers won’t change, it is possible to cache the output of the 
topmost frozen layer for each training instance. Since training goes 
through the whole dataset many times, this will give you a huge speed 
boost as you will only need to go through the frozen layers once per 
training instance (instead of once per epoch). For example, you could 
first run the whole training set through the lower layers (assuming you 
have enough RAM), then during training, instead of building batches of 
training instances, you would build batches of outputs from hidden 
layer&nbsp;2 and feed them to the training operation:</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">import</code> <code class="nn">numpy</code> <code class="kn">as</code> <code class="nn">np</code>

<code class="n">n_batches</code> <code class="o">=</code> <code class="n">mnist</code><code class="o">.</code><code class="n">train</code><code class="o">.</code><code class="n">num_examples</code> <code class="o">//</code> <code class="n">batch_size</code>

<code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">Session</code><code class="p">()</code> <code class="k">as</code> <code class="n">sess</code><code class="p">:</code>
    <code class="n">init</code><code class="o">.</code><code class="n">run</code><code class="p">()</code>
    <code class="n">restore_saver</code><code class="o">.</code><code class="n">restore</code><code class="p">(</code><code class="n">sess</code><code class="p">,</code> <code class="s2">"./my_model_final.ckpt"</code><code class="p">)</code>

    <code class="n">h2_cache</code> <code class="o">=</code> <code class="n">sess</code><code class="o">.</code><code class="n">run</code><code class="p">(</code><code class="n">hidden2</code><code class="p">,</code> <code class="n">feed_dict</code><code class="o">=</code><code class="p">{</code><code class="n">X</code><code class="p">:</code> <code class="n">mnist</code><code class="o">.</code><code class="n">train</code><code class="o">.</code><code class="n">images</code><code class="p">})</code>

    <code class="k">for</code> <code class="n">epoch</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">n_epochs</code><code class="p">):</code>
        <code class="n">shuffled_idx</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">permutation</code><code class="p">(</code><code class="n">mnist</code><code class="o">.</code><code class="n">train</code><code class="o">.</code><code class="n">num_examples</code><code class="p">)</code>
        <code class="n">hidden2_batches</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">array_split</code><code class="p">(</code><code class="n">h2_cache</code><code class="p">[</code><code class="n">shuffled_idx</code><code class="p">],</code> <code class="n">n_batches</code><code class="p">)</code>
        <code class="n">y_batches</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">array_split</code><code class="p">(</code><code class="n">mnist</code><code class="o">.</code><code class="n">train</code><code class="o">.</code><code class="n">labels</code><code class="p">[</code><code class="n">shuffled_idx</code><code class="p">],</code> <code class="n">n_batches</code><code class="p">)</code>
        <code class="k">for</code> <code class="n">hidden2_batch</code><code class="p">,</code> <code class="n">y_batch</code> <code class="ow">in</code> <code class="nb">zip</code><code class="p">(</code><code class="n">hidden2_batches</code><code class="p">,</code> <code class="n">y_batches</code><code class="p">):</code>
            <code class="n">sess</code><code class="o">.</code><code class="n">run</code><code class="p">(</code><code class="n">training_op</code><code class="p">,</code> <code class="n">feed_dict</code><code class="o">=</code><code class="p">{</code><code class="n">hidden2</code><code class="p">:</code><code class="n">hidden2_batch</code><code class="p">,</code> <code class="n">y</code><code class="p">:</code><code class="n">y_batch</code><code class="p">})</code>

    <code class="n">save_path</code> <code class="o">=</code> <code class="n">saver</code><code class="o">.</code><code class="n">save</code><code class="p">(</code><code class="n">sess</code><code class="p">,</code> <code class="s2">"./my_new_model_final.ckpt"</code><code class="p">)</code></pre>

<p>The last line of the training loop runs the training operation 
defined earlier (which does not touch layers 1 and 2), and feeds it a 
batch of outputs from the second hidden layer (as well as the targets 
for that batch). Since we give TensorFlow the output of hidden 
layer&nbsp;2, it does not try to evaluate <a data-type="indexterm" data-primary="frozen layers" data-startref="fl11" id="idm140582998642000"></a>it (or any node it depends on).</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Tweaking, Dropping, or Replacing the Upper Layers"><div class="sect2" id="idm140582998640768">
<h2>Tweaking, Dropping, or Replacing the Upper Layers</h2>

<p>The <a data-type="indexterm" data-primary="pretrained layers reuse" data-secondary="upper layers" id="idm140582998534288"></a>output
 layer of the original model should usually be replaced since it is most
 likely not useful at all for the new task, and it may not even have the
 right number of outputs for the new task.</p>

<p>Similarly, the upper hidden layers of the original model are less 
likely to be as useful as the lower layers, since the high-level 
features that are most useful for the new task may differ significantly 
from the ones that were most useful for the original task. You want to 
find the right number of layers to reuse.</p>

<p>Try freezing all the copied layers first, then train your model and 
see how it performs. Then try unfreezing one or two of the top hidden 
layers to let backpropagation tweak them and see if performance 
improves. The more training data you have, the more layers you can 
unfreeze.</p>

<p>If you still cannot get good performance, and you have little 
training data, try dropping the top hidden layer(s) and freeze all 
remaining hidden layers again. You can iterate until you find the right 
number of layers to reuse. If you have plenty of training data, you may 
try replacing the top hidden layers instead of dropping them, and even 
add more hidden layers.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Model Zoos"><div class="sect2" id="idm140582998530592">
<h2>Model Zoos</h2>

<p>Where <a data-type="indexterm" data-primary="pretrained layers reuse" data-secondary="model zoos" id="idm140582998529376"></a><a data-type="indexterm" data-primary="model zoos" id="idm140582998528368"></a>can
 you find a neural network trained for a task similar to the one you 
want to tackle? The first place to look is obviously in your own catalog
 of models. This is one good reason to save all your models and organize
 them so you can retrieve them later easily. Another option is to search
 in a <em>model zoo</em>. Many people train Machine Learning models for various tasks and kindly release their pretrained models to the public.</p>

<p>TensorFlow <a data-type="indexterm" data-primary="TensorFlow" data-secondary="model zoo" id="idm140582998526112"></a>has its own model zoo available at <a href="https://github.com/tensorflow/models"><em class="hyperlink">https://github.com/tensorflow/models</em></a>. In particular, it contains most of the state-of-the-art image classification nets such as VGG, Inception, and <a data-type="indexterm" data-primary="residual network (ResNet)" id="idm140582998523744"></a>ResNet (see <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch13.html#cnn_chapter">Chapter&nbsp;13</a>, and check out the <em>models/slim</em> directory), including the code, the pretrained models, and tools to download popular image datasets.</p>

<p>Another popular model zoo is <a data-type="indexterm" data-primary="Caffe model zoo" id="idm140582998521264"></a>Caffe’s <a href="https://goo.gl/XI02X3">Model Zoo</a>.
 It also contains many computer vision models (e.g., LeNet, AlexNet, 
ZFNet, GoogLeNet, VGGNet, inception) trained on various datasets (e.g., 
ImageNet, Places Database, CIFAR10, etc.). Saumitro Dasgupta wrote a 
converter, which is available at <a href="https://github.com/ethereon/caffe-tensorflow"><em class="hyperlink">https://github.com/ethereon/caffe-tensorflow</em></a>.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Unsupervised Pretraining"><div class="sect2" id="idm140582998518016">
<h2>Unsupervised Pretraining</h2>

<p>Suppose <a data-type="indexterm" data-primary="pretrained layers reuse" data-secondary="unsupervised pretraining" id="plr11up"></a><a data-type="indexterm" data-primary="unsupervised pretraining" id="up11"></a>you
 want to tackle a complex task for which you don’t have much labeled 
training data, but unfortunately you cannot find a model trained on a 
similar task. Don’t lose all hope! First, you should of course try to 
gather more labeled training data, but if this is too hard or too 
expensive, you may still be able to perform <em>unsupervised pretraining</em> (see <a data-type="xref" href="#unsupervised_pretraining_diagram">Figure&nbsp;11-5</a>).
 That is, if you have plenty of unlabeled training data, you can try to 
train the layers one by one, starting with the lowest layer and then 
going up, using an unsupervised feature detector algorithm such <a data-type="indexterm" data-primary="restricted Boltzmann machines (RBMs)" id="idm140582998512304"></a>as <em>Restricted Boltzmann Machines</em> (RBMs; see <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app05.html#other_ann_appendix">Appendix&nbsp;E</a>) or autoencoders (see <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch15.html#autoencoders_chapter">Chapter&nbsp;15</a>).
 Each layer is trained on the output of the previously trained layers 
(all layers except the one being trained are frozen). Once all layers 
have been trained this way, you can fine-tune the network using 
supervised learning (i.e., with backpropagation).</p>

<p>This is a rather long and tedious process, but it often works well; 
in fact, it is this technique that Geoffrey Hinton and his team used in 
2006 and which led to the revival of neural networks and the success of 
Deep Learning. Until 2010, unsupervised pretraining (typically using 
RBMs) was the norm for deep nets, and it was only after the vanishing 
gradients problem was alleviated that it became much more common to 
train DNNs purely using <a data-type="indexterm" data-primary="backpropagation" id="idm140582998508416"></a>backpropagation.
 However, unsupervised pretraining (today typically using autoencoders 
rather than RBMs) is still a good option when you have a complex task to
 solve, no similar model you can reuse, and little labeled training data
 but plenty of unlabeled <a data-type="indexterm" data-primary="pretrained layers reuse" data-secondary="unsupervised pretraining" data-startref="plr11up" id="idm140582998507312"></a><a data-type="indexterm" data-primary="unsupervised pretraining" data-startref="up11" id="idm140582998506080"></a>training data.</p>

<figure><div id="unsupervised_pretraining_diagram" class="figure">
<img src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/mlst_1105.png" alt="mlst 1105" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1105.png" width="2031" height="1342">
<h6><span class="label">Figure 11-5. </span>Unsupervised pretraining</h6>
</div></figure>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Pretraining on an Auxiliary Task"><div class="sect2" id="idm140582998502752">
<h2>Pretraining on an Auxiliary Task</h2>

<p>One <a data-type="indexterm" data-primary="pretrained layers reuse" data-secondary="auxiliary task" id="plr11at"></a>last
 option is to train a first neural network on an auxiliary task for 
which you can easily obtain or generate labeled training data, then 
reuse the lower layers of that network for your actual task. The first 
neural network’s lower layers will learn feature detectors that will 
likely be reusable by the second neural network.</p>

<p>For example, if you want to build a system to recognize faces, you 
may only have a few pictures of each individual—clearly not enough to 
train a good classifier. Gathering hundreds of pictures of each person 
would not be practical. However, you could gather a lot of pictures of 
random people on the internet and train a first neural network to detect
 whether or not two different pictures feature the same person. Such a 
network would learn good feature detectors for faces, so reusing its 
lower layers would allow you to train a good face classifier using 
little training data.</p>

<p>It is often rather cheap to gather unlabeled training examples, but 
quite expensive to label them. In this situation, a common technique is 
to label all your training examples as “good,” then generate many new 
training instances by corrupting the good ones, and label these 
corrupted instances as “bad.” Then you can train a first neural network 
to classify instances as good or bad. For example, you could download 
millions of sentences, label them as “good,” then randomly change a word
 in each sentence and label the resulting sentences as “bad.” If a 
neural network can tell that “The dog sleeps” is a good sentence but 
“The dog they” is bad, it probably knows quite a lot about language. 
Reusing its lower layers will likely help in many language processing 
tasks.</p>

<p>Another approach is to train a first network to output a score for each training instance, and use a <a data-type="indexterm" data-primary="cost function" data-secondary="in pretrained layers reuse" data-secondary-sortas="pretrained" id="idm140582998496448"></a>cost function that ensures that a good instance’s score is greater than a bad instance’s score by at least some margin. This is <a data-type="indexterm" data-primary="pretrained layers reuse" data-secondary="auxiliary task" data-startref="plr11at" id="idm140582998494912"></a><a data-type="indexterm" data-primary="deep neural networks (DNNs)" data-secondary="reusing pretrained layers" data-startref="dnn11rpl" id="idm140582998493696"></a><a data-type="indexterm" data-primary="pretrained layers reuse" data-startref="plr11" id="idm140582998492448"></a><a data-type="indexterm" data-primary="transfer learning" data-seealso="pretrained layers reuse" data-startref="tl11" id="idm140582998491504"></a><a data-type="indexterm" data-primary="max margin learning" id="idm140582998490288"></a>called <em>max margin learning</em>.</p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Faster Optimizers"><div class="sect1" id="idm140582999416208">
<h1>Faster Optimizers</h1>

<p>Training <a data-type="indexterm" data-primary="deep neural networks (DNNs)" data-secondary="faster optimizers for" id="dnn11fof"></a><a data-type="indexterm" data-primary="optimizers" id="o11"></a><a data-type="indexterm" data-primary="optimizers" data-secondary="Gradient Descent" data-see="Gradient Descent optimizer" id="idm140582998485600"></a>a
 very large deep neural network can be painfully slow. So far we have 
seen four ways to speed up training (and reach a better solution): 
applying a good initialization strategy for the connection weights, 
using a good activation function, using Batch Normalization, and reusing
 parts of a pretrained network. Another huge speed boost comes from 
using a faster optimizer than the regular Gradient Descent optimizer. In
 this section we will present the most popular ones: Momentum 
optimization, Nesterov Accelerated Gradient, AdaGrad, RMSProp, and 
finally Adam optimization.</p>








<section data-type="sect2" data-pdf-bookmark="Momentum Optimization"><div class="sect2" id="idm140582998483568">
<h2>Momentum Optimization</h2>

<p>Imagine <a data-type="indexterm" data-primary="optimizers" data-secondary="Momentum optimization" id="o11mo"></a><a data-type="indexterm" data-primary="Momentum optimization" id="mo11"></a>a
 bowling ball rolling down a gentle slope on a smooth surface: it will 
start out slowly, but it will quickly pick up momentum until it 
eventually reaches terminal velocity (if there is some friction or air 
resistance). This is the very simple idea behind <em>Momentum optimization</em>, <a href="https://goo.gl/FlSE8c">proposed by Boris Polyak in 1964</a>.<sup><a data-type="noteref" id="idm140582998478144-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140582998478144">10</a></sup>
 In contrast, regular Gradient Descent will simply take small regular 
steps down the slope, so it will take much more time to reach the 
bottom.</p>

<p>Recall that <a data-type="indexterm" data-primary="Gradient Descent (GD)" id="idm140582998476800"></a>Gradient Descent simply updates the weights <em>θ</em> by directly subtracting the gradient of the cost function <em>J</em>(<em>θ</em>) with regards to the weights (∇<sub><em>θ</em></sub><em>J</em>(<em>θ</em>)) multiplied by the learning rate  <em>η</em>. The equation is: <em>θ</em> ← <em>θ</em> – <em>η</em>∇<sub><em>θ</em></sub><em>J</em>(<em>θ</em>). It does not care about what the earlier gradients were. If the local gradient is tiny, it goes very slowly.</p>

<p>Momentum optimization cares a great deal about what previous 
gradients were: at each iteration, it subtracts the local gradient from 
the <em>momentum vector</em> <strong>m</strong> (multiplied by the learning rate <em>η</em>), and it updates the weights by simply adding this momentum vector (see <a data-type="xref" href="#momentum_equation">Equation 11-4</a>).
 In other words, the gradient is used as an acceleration, not as a 
speed. To simulate some sort of friction mechanism and prevent the 
momentum from growing too large, the algorithm introduces a new 
hyperparameter <em>β</em>, simply called the <em>momentum</em>, which must be set between 0 (high friction) and 1 (no friction). A typical momentum value is 0.9.</p>
<div class="fifty-percent" id="momentum_equation" data-type="equation"><h5><span class="label">Equation 11-4. </span>Momentum algorithm</h5>
<img src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_116.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_116.png" width="650" height="134"></div>

<p>You can easily verify that if the gradient remains constant, the 
terminal velocity (i.e., the maximum size of the weight updates) is 
equal to that gradient multiplied by the learning rate <em>η</em> multiplied by <img src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_117.png" alt="StartFraction 1 Over 1 minus beta EndFraction" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_117.png" width="36" height="30"> (ignoring the sign). For example, if <em>β</em>
 = 0.9, then the terminal velocity is equal to 10 times the gradient 
times the learning rate, so Momentum optimization ends up going 10 times
 faster than Gradient Descent! This allows Momentum optimization to 
escape from plateaus much faster than Gradient Descent. In particular, 
we saw in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch04.html#linear_models_chapter">Chapter&nbsp;4</a> that when the inputs have very different scales the <a data-type="indexterm" data-primary="cost function" data-secondary="in Momentum optimization" data-secondary-sortas="Momentum" id="cf11imo"></a>cost function will look like an elongated bowl (see <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch04.html#elongated_bowl_diagram">Figure&nbsp;4-7</a>).
 Gradient Descent goes down the steep slope quite fast, but then it 
takes a very long time to go down the valley. In contrast, Momentum 
optimization will roll down the bottom of the valley faster and faster 
until it reaches the bottom (the optimum). In deep neural networks that 
don’t use Batch Normalization, the upper layers will often end up having
 inputs with very different scales, so using Momentum optimization helps
 a lot. It can also help roll past local optima.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Due to the momentum, the optimizer may overshoot a bit, then come 
back, overshoot again, and oscillate like this many times before 
stabilizing at the minimum. This is one of the reasons why it is good to
 have a bit of friction in the system: it gets rid of these oscillations
 and thus speeds up convergence.</p>
</div>

<p>Implementing Momentum optimization in <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.train.MomentumOptimizer" id="tftrainmoch11"></a> <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.train.GradientDescentOptimizer" id="idm140582998378848"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="Momentum optimization in" id="idm140582998377856"></a>TensorFlow is a no-brainer: just replace the <code>GradientDescentOptimizer</code> with the <code>MomentumOptimizer</code>, then lie back and profit!</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">optimizer</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">train</code><code class="o">.</code><code class="n">MomentumOptimizer</code><code class="p">(</code><code class="n">learning_rate</code><code class="o">=</code><code class="n">learning_rate</code><code class="p">,</code>
                                       <code class="n">momentum</code><code class="o">=</code><code class="mf">0.9</code><code class="p">)</code></pre>

<p>The one drawback of Momentum optimization is that it adds yet another
 hyperparameter to tune. However, the momentum value of&nbsp;0.9 usually
 works well in practice and almost always goes faster <a data-type="indexterm" data-primary="optimizers" data-secondary="Momentum optimization" data-startref="o11mo" id="idm140582998357408"></a><a data-type="indexterm" data-primary="Momentum optimization" data-startref="mo11" id="idm140582998356320"></a>than Gradient Descent.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Nesterov Accelerated Gradient"><div class="sect2" id="idm140582998482976">
<h2>Nesterov Accelerated Gradient</h2>

<p>One <a data-type="indexterm" data-primary="optimizers" data-secondary="Nesterov Accelerated Gradient (NAG)" id="o11nag"></a><a data-type="indexterm" data-primary="Nesterov Accelerated Gradient (NAG)" id="nag11"></a>small variant to Momentum optimization, proposed by <a href="https://goo.gl/V011vD">Yurii Nesterov in 1983</a>,<sup><a data-type="noteref" id="idm140582998350592-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140582998350592">11</a></sup> is almost always faster than vanilla Momentum optimization. The <a data-type="indexterm" data-primary="Nesterov momentum optimization" id="nmo11"></a>idea of <em>Nesterov Momentum optimization</em>, or <em>Nesterov Accelerated Gradient</em>
 (NAG), is to measure the gradient of the cost function not at the local
 position but slightly ahead in the direction of the momentum (see <a data-type="xref" href="#nesterov_momentum_equation">Equation 11-5</a>). The only difference from vanilla Momentum optimization is that the gradient is measured at <em>θ</em> + <em>β</em><strong>m</strong> rather than at <em>θ</em>.</p>
<div class="fifty-percent" id="nesterov_momentum_equation" data-type="equation"><h5><span class="label">Equation 11-5. </span>Nesterov Accelerated Gradient algorithm</h5>
<img src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_118.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_118.png" width="803" height="134"></div>

<p>This small tweak works because in general the momentum vector will be
 pointing in the right direction (i.e., toward the optimum), so it will 
be slightly more accurate to use the gradient measured a bit farther in 
that direction rather than using the gradient at the original position, 
as you can see in <a data-type="xref" href="#nesterov_momentum_diagram">Figure&nbsp;11-6</a> (where ∇<sub>1</sub> represents the gradient of the cost function measured <a data-type="indexterm" data-primary="cost function" data-secondary="in Momentum optimization" data-secondary-sortas="Momentum" data-startref="cf11imo" id="idm140582998340880"></a>at the starting point <em>θ</em>, and ∇<sub>2</sub> represents the gradient at the point located at <em>θ</em> + <em>β</em><strong>m</strong>).
 As you can see, the Nesterov update ends up slightly closer to the 
optimum. After a while, these small improvements add up and NAG ends up 
being significantly faster than regular Momentum optimization. Moreover,
 note that when the momentum pushes the weights across a valley, ∇<sub>1</sub> continues to push further across the valley, while ∇<sub>2</sub> pushes back toward the bottom of the valley. This helps reduce oscillations and thus converges faster.</p>

<p>NAG will almost always speed up training compared to <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.train.MomentumOptimizer" data-startref="tftrainmoch11" id="idm140582998335312"></a>regular Momentum optimization. To use it, simply <a data-type="indexterm" data-primary="optimizers" data-secondary="Nesterov Accelerated Gradient (NAG)" data-startref="o11nag" id="idm140582998333904"></a><a data-type="indexterm" data-primary="Nesterov Accelerated Gradient (NAG)" data-startref="nag11" id="idm140582998332720"></a><a data-type="indexterm" data-primary="Nesterov momentum optimization" data-startref="nmo11" id="idm140582998331760"></a>set <code>use_nesterov=True</code> when creating the <code>MomentumOptimizer</code>:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">optimizer</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">train</code><code class="o">.</code><code class="n">MomentumOptimizer</code><code class="p">(</code><code class="n">learning_rate</code><code class="o">=</code><code class="n">learning_rate</code><code class="p">,</code>
                                       <code class="n">momentum</code><code class="o">=</code><code class="mf">0.9</code><code class="p">,</code> <code class="n">use_nesterov</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code></pre>

<figure class="smallerseventy"><div id="nesterov_momentum_diagram" class="figure">
<img src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/mlst_1106.png" alt="mlst 1106" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1106.png" width="994" height="988">
<h6><span class="label">Figure 11-6. </span>Regular versus Nesterov Momentum optimization</h6>
</div></figure>
</div></section>













<section data-type="sect2" data-pdf-bookmark="AdaGrad"><div class="sect2" id="idm140582998318640">
<h2>AdaGrad</h2>

<p>Consider <a data-type="indexterm" data-primary="optimizers" data-secondary="AdaGrad" id="o11a"></a><a data-type="indexterm" data-primary="Adagrad" id="a11"></a>the elongated bowl problem again: <a data-type="indexterm" data-primary="Gradient Descent (GD)" id="idm140582998306112"></a>Gradient
 Descent starts by quickly going down the steepest slope, then slowly 
goes down the bottom of the valley. It would be nice if the algorithm 
could detect this early on and correct its direction to point a bit more
 toward the global optimum.</p>

<p>The <a href="http://goo.gl/4Tyd4j"><em>AdaGrad</em> algorithm</a><sup><a data-type="noteref" id="idm140582998303792-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140582998303792">12</a></sup> achieves this by scaling down the gradient vector along the steepest dimensions (see <a data-type="xref" href="#adagrad_algorithm">Equation 11-6</a>):</p>
<div id="adagrad_algorithm" data-type="equation"><h5><span class="label">Equation 11-6. </span>AdaGrad algorithm</h5>
<img src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_119.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_119.png" width="844" height="161"></div>

<p>The first step accumulates the square of the gradients into the vector <strong>s</strong> (the ⊗ symbol represents the element-wise multiplication). This vectorized form is equivalent to computing <em>s</em><sub><em>i</em></sub> ← <em>s</em><sub><em>i</em></sub> + (∂ <em>J</em>(<em>θ</em>) / ∂ <em>θ</em><sub><em>i</em></sub>)<sup>2</sup> for each element <em>s</em><sub><em>i</em></sub> of the vector <strong>s</strong>; in other words, each <em>s</em><sub><em>i</em></sub> accumulates the squares of the partial derivative of the <a data-type="indexterm" data-primary="cost function" data-secondary="in adagrad" data-secondary-sortas="adagrad" id="idm140582998293040"></a>cost function with regards to parameter <em>θ</em><sub><em>i</em></sub>. If the cost function is steep along the i<sup>th</sup> dimension, then <em>s</em><sub><em>i</em></sub> will get larger and larger at each iteration.</p>

<p>The second step is almost identical to Gradient Descent, but with one
 big difference: the gradient vector is scaled down by a factor of <img src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_120.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_120.png" width="66" height="25"> (the ⊘ symbol represents the element-wise division, and ϵ is a <a data-type="indexterm" data-primary="smoothing terms" id="idm140582998288608"></a>smoothing term to avoid division by zero, typically set to 10<sup>–10</sup>). This vectorized form is equivalent to computing <img src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_121.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_121.png" width="274" height="26"> for all parameters <em>θ</em><sub><em>i</em></sub> (simultaneously).</p>

<p>In short, this algorithm decays the learning rate, but it does so 
faster for steep dimensions than for dimensions with gentler slopes. 
This is called an <em>adaptive learning rate</em>. <a data-type="indexterm" data-primary="adaptive learning rate" id="idm140582998285056"></a>It helps point the resulting updates more directly toward the global optimum (see <a data-type="xref" href="#adagrad_diagram">Figure&nbsp;11-7</a>). One additional benefit is that it requires much less tuning of the learning rate hyperparameter <em>η</em>.</p>

<figure class="smallerseventy"><div id="adagrad_diagram" class="figure">
<img src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/mlst_1107.png" alt="mlst 1107" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1107.png" width="1440" height="739">
<h6><span class="label">Figure 11-7. </span>AdaGrad versus Gradient Descent</h6>
</div></figure>

<p>AdaGrad often performs well for simple quadratic problems, but 
unfortunately it often stops too early when training neural networks. 
The learning rate gets scaled down so much that the algorithm ends up 
stopping entirely before reaching the global optimum. So even though 
TensorFlow has an <code>AdagradOptimizer</code>, you should not use it to train deep neural networks (it may be efficient for simpler tasks such as Linear Regression, <a data-type="indexterm" data-primary="optimizers" data-secondary="AdaGrad" data-startref="o11a" id="idm140582998180352"></a><a data-type="indexterm" data-primary="Adagrad" data-startref="a11" id="idm140582998179104"></a>though).</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="RMSProp"><div class="sect2" id="idm140582998177904">
<h2>RMSProp</h2>

<p>Although <a data-type="indexterm" data-primary="optimizers" data-secondary="RMSProp" id="idm140582998176336"></a><a data-type="indexterm" data-primary="RMSProp" id="idm140582998175328"></a>AdaGrad slows down a bit too fast and ends up never converging to the global optimum, the <em>RMSProp</em> algorithm<sup><a data-type="noteref" id="idm140582998174032-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140582998174032">13</a></sup>
 fixes this by accumulating only the gradients from the most recent 
iterations (as opposed to all the gradients since the beginning of 
training). It does so by using exponential decay in the first step (see <a data-type="xref" href="#rmsprop_algorithm">Equation 11-7</a>).</p>
<div id="rmsprop_algorithm" data-type="equation"><h5><span class="label">Equation 11-7. </span>RMSProp algorithm</h5><img src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_122.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_122.png" width="974" height="161"></div>

<p>The decay rate <em>β</em> is typically set to 0.9. Yes, it is once 
again a new hyperparameter, but this default value often works well, so 
you may not need to tune it at all.</p>

<p>As you might expect, TensorFlow has <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.train.RMSPropOptimizer" id="idm140582998166784"></a>an <code>RMSPropOptimizer</code> class:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">optimizer</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">train</code><code class="o">.</code><code class="n">RMSPropOptimizer</code><code class="p">(</code><code class="n">learning_rate</code><code class="o">=</code><code class="n">learning_rate</code><code class="p">,</code>
                                      <code class="n">momentum</code><code class="o">=</code><code class="mf">0.9</code><code class="p">,</code> <code class="n">decay</code><code class="o">=</code><code class="mf">0.9</code><code class="p">,</code> <code class="n">epsilon</code><code class="o">=</code><code class="mf">1e-10</code><code class="p">)</code></pre>

<p>Except on very simple problems, this optimizer almost always performs
 much better than AdaGrad. In fact, it was the preferred optimization 
algorithm of many researchers until Adam optimization came around.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Adam Optimization"><div class="sect2" id="idm140582998129936">
<h2>Adam Optimization</h2>

<p><a href="https://goo.gl/Un8Axa"><em>Adam</em></a>,<sup><a data-type="noteref" id="idm140582998127520-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140582998127520">14</a></sup> which <a data-type="indexterm" data-primary="optimizers" data-secondary="Adam optimization" id="o11ao"></a><a data-type="indexterm" data-primary="Adam optimization" id="ao11"></a>stands for <em>adaptive moment estimation</em>, <a data-type="indexterm" data-primary="moments" id="idm140582998155744"></a><a data-type="indexterm" data-primary="adaptive moment optimization" id="idm140582998155040"></a>combines
 the ideas of Momentum optimization and RMSProp: just like Momentum 
optimization it keeps track of an exponentially decaying average of past
 gradients, and just like RMSProp it keeps track of an exponentially 
decaying average of past squared gradients (see <a data-type="xref" href="#adam_algorithm">Equation 11-8</a>).<sup><a data-type="noteref" id="idm140582998153184-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140582998153184">15</a></sup></p>
<div class="pagebreak-before" id="adam_algorithm" data-type="equation"><h5><span class="label">Equation 11-8. </span>Adam algorithm</h5>

<img src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_123.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_123.png" width="1019" height="543"></div>

<ul>
<li>
<p><em>t</em> represents the iteration number (starting at 1).</p>
</li>
</ul>

<p>If you just look at steps 1, 2, and 5, you will notice Adam’s close 
similarity to both Momentum optimization and RMSProp. The only 
difference is that step 1 computes an exponentially decaying average 
rather than an exponentially decaying sum, but these are actually 
equivalent except for a constant factor (the decaying average is just 1 –
 <em>β</em><sub>1</sub> times the decaying sum). Steps 3 and 4 are somewhat of a technical detail: since <strong>m</strong> and <strong>s</strong> are initialized at 0, they will be biased toward 0 at the beginning of training, so these two steps will help boost <strong>m</strong> and <strong>s</strong> at the beginning of training.</p>

<p>The momentum decay hyperparameter <em>β</em><sub>1</sub> is typically initialized to 0.9, while the scaling decay hyperparameter <em>β</em><sub>2</sub> is often initialized to 0.999. As earlier, the <a data-type="indexterm" data-primary="smoothing terms" id="idm140582998109120"></a>smoothing term <em>ϵ</em> is usually initialized to a tiny number such as 10<sup>–8</sup>. These are the default values for TensorFlow’s <code>AdamOptimizer</code> class, <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.train.AdamOptimizer" id="idm140582998106912"></a>so you can simply use:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">optimizer</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">train</code><code class="o">.</code><code class="n">AdamOptimizer</code><code class="p">(</code><code class="n">learning_rate</code><code class="o">=</code><code class="n">learning_rate</code><code class="p">)</code></pre>

<p>In fact, since Adam is an adaptive learning rate algorithm (like 
AdaGrad and RMSProp), it requires less tuning of the learning rate 
hyperparameter <em>η</em>. You can often use the default value <em>η</em> = 0.001, making Adam even easier to use than Gradient Descent.</p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>This book initially recommended using <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.train.AdamOptimizer" id="idm140582998096208"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.train.GradientDescentOptimizer" id="idm140582998095232"></a><a data-type="indexterm" data-primary="Adam optimization" id="idm140582998094320"></a><a data-type="indexterm" data-primary="optimizers" data-secondary="Adam optimization" id="idm140582998012640"></a>Adam optimization, because it was generally considered faster and better than other methods. However, a <a href="https://goo.gl/NAkWIa">2017 paper</a><sup><a data-type="noteref" id="idm140582998010912-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140582998010912">16</a></sup>
 by Ashia C. Wilson et al. showed that adaptive optimization methods 
(i.e., AdaGrad, RMSProp and Adam optimization) can lead to solutions 
that generalize poorly on some datasets. So you may want to stick to 
Momentum optimization or Nesterov Accelerated Gradient for now, until 
researchers have a better understanding of this issue.</p>
</div>

<p>All the optimization techniques discussed so far only rely on the <em>first-order partial derivatives</em> (<em>Jacobians</em>). The <a data-type="indexterm" data-primary="first-order partial derivatives (Jacobians)" id="idm140582998008032"></a>optimization literature contains amazing algorithms based on the <em>second-order partial derivatives</em> (the <em>Hessians</em>). <a data-type="indexterm" data-primary="second-order partial derivatives (Hessians)" id="idm140582998006400"></a>Unfortunately, these algorithms are very hard to apply to deep neural networks because there are <em>n</em><sup>2</sup> Hessians per output (where <em>n</em> is the number of parameters), as opposed to just <em>n</em>
 Jacobians per output. Since DNNs typically have tens of thousands of 
parameters, the second-order optimization algorithms often don’t even 
fit in memory, and even when they do, computing the Hessians is <a data-type="indexterm" data-primary="optimizers" data-secondary="Adam optimization" data-startref="o11ao" id="idm140582998003664"></a><a data-type="indexterm" data-primary="Adam optimization" data-startref="ao11" id="idm140582998002416"></a>just too slow.</p>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm140582998008912">
<h5>Training Sparse Models</h5>
<p>All the <a data-type="indexterm" data-primary="sparse models" id="idm140582997999808"></a>optimization
 algorithms just presented produce dense models, meaning that most 
parameters will be nonzero. If you need a blazingly fast model at 
runtime, or if you need it to take up less memory, you may prefer to end
 up with a sparse model instead.</p>

<p>One trivial way to achieve this is to train the model as usual, then get rid of the tiny weights (set them to 0).</p>

<p>Another option is to apply strong ℓ<sub>1</sub> <a data-type="indexterm" data-primary="ℓ 1 norm" id="idm140582997997328"></a>regularization during training, as it pushes the optimizer to zero out as many weights as it can (as discussed in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch04.html#linear_models_chapter">Chapter&nbsp;4</a> about Lasso Regression).</p>

<p>However, in some cases these techniques may remain insufficient. One last option is to apply <em>Dual Averaging</em>, <a data-type="indexterm" data-primary="Dual Averaging" id="idm140582997994400"></a>often called <em>Follow The Regularized Leader</em> (FTRL), a <a data-type="indexterm" data-primary="Follow The Regularized Leader (FTRL)" id="idm140582997993120"></a><a href="https://goo.gl/xSQD4C">technique proposed by Yurii Nesterov</a>.<sup><a data-type="noteref" id="idm140582997991696-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140582997991696">17</a></sup> When used with ℓ<sub>1</sub> regularization, this technique often leads to very sparse models. TensorFlow implements a variant of FTRL called <a href="https://goo.gl/bxme2B"><em>FTRL-Proximal</em></a><sup><a data-type="noteref" id="idm140582997989744-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140582997989744">18</a></sup> in the <code>FTRLOptimizer</code> class.</p>
</div></aside>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Learning Rate Scheduling"><div class="sect2" id="idm140582998129344">
<h2>Learning Rate Scheduling</h2>

<p>Finding <a data-type="indexterm" data-primary="learning rate scheduling" id="lrs11"></a><a data-type="indexterm" data-primary="optimizers" data-secondary="learning rate scheduling" id="o11lrs"></a>a good learning rate can be tricky. If you set it way too high, training may actually diverge (as we discussed in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch04.html#linear_models_chapter">Chapter&nbsp;4</a>).
 If you set it too low, training will eventually converge to the 
optimum, but it will take a very long time. If you set it slightly too 
high, it will make progress very quickly at first, but it will end up 
dancing around the optimum, never settling down (unless you use an 
adaptive learning rate optimization algorithm such as AdaGrad, RMSProp, 
or Adam, but even then it may take time to settle). If you have a 
limited computing budget, you may have to interrupt training before it 
has converged properly, yielding a suboptimal solution (see <a data-type="xref" href="#learning_schedule_diagram">Figure&nbsp;11-8</a>).</p>

<figure class="smallerseventy"><div id="learning_schedule_diagram" class="figure">
<img src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/mlst_1108.png" alt="mlst 1108" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1108.png" width="1440" height="700">
<h6><span class="label">Figure 11-8. </span>Learning curves for various learning rates η</h6>
</div></figure>

<p>You may be able to find a fairly good learning rate by training your 
network several times during just a few epochs using various learning 
rates and comparing the learning curves. The ideal learning rate will 
learn quickly and converge to good solution.</p>

<p>However, you can do better than a constant learning rate: if you 
start with a high learning rate and then reduce it once it stops making 
fast progress, you can reach a good solution faster than with the 
optimal constant learning rate. There are many different strategies to 
reduce the learning rate during training. These strategies are called <em>learning schedules</em> (we briefly introduced this concept in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch04.html#linear_models_chapter">Chapter&nbsp;4</a>), the most common of which are:</p>
<dl>
<dt><em>Predetermined piecewise constant learning rate</em></dt>
<dd>
<p><a data-type="indexterm" data-primary="predetermined piecewise constant learning rate" id="idm140582997975744"></a>For example, set the learning rate to <em>η</em><sub>0</sub> = 0.1 at first, then to <em>η</em><sub>1</sub>
 = 0.001 after 50 epochs. Although this solution can work very well, it 
often requires fiddling around to figure out the right learning rates 
and when to use them.</p>
</dd>
<dt><em>Performance scheduling</em></dt>
<dd>
<p><a data-type="indexterm" data-primary="performance scheduling" id="idm140582998084736"></a>Measure the validation error every <em>N</em> steps (just like for early stopping) and reduce the learning rate by a factor of <em>λ</em> when the error stops dropping.</p>
</dd>
<dt><em>Exponential scheduling</em></dt>
<dd>
<p><a data-type="indexterm" data-primary="exponential scheduling" id="idm140582998081696"></a>Set the learning rate to a function of the iteration number <em>t</em>: <em>η</em>(<em>t</em>) = <em>η</em><sub>0</sub> 10<sup><em>–t/r</em></sup>. This works great, but it requires tuning <em>η</em><sub>0</sub> and <em>r</em>. The learning rate will drop by a factor of&nbsp;10 every <em>r</em> steps.</p>
</dd>
<dt><em>Power scheduling</em></dt>
<dd>
<p><a data-type="indexterm" data-primary="power scheduling" id="idm140582998075232"></a>Set the learning rate to <em>η</em>(<em>t</em>) = <em>η</em><sub>0</sub> (1 + <em>t</em>/<em>r</em>)<sup><em>–c</em></sup>. The hyperparameter <em>c</em> is typically set to&nbsp;1. This is similar to exponential scheduling, but the learning rate drops much more slowly.</p>
</dd>
</dl>

<p>A <a href="http://goo.gl/Hu6Zyq">2013 paper</a><sup><a data-type="noteref" id="idm140582998069552-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140582998069552">19</a></sup>
 by Andrew Senior et al. compared the performance of some of the most 
popular learning schedules when training deep neural networks for speech
 recognition using Momentum optimization. The authors concluded that, in
 this setting, both performance scheduling and exponential scheduling 
performed well, but they favored exponential scheduling because it is 
simpler to implement, is easy to tune, and converged slightly faster to 
the optimal solution.</p>

<p>Implementing a <a data-type="indexterm" data-primary="TensorFlow" data-secondary="learning schedules in" id="idm140582998067888"></a>learning schedule with TensorFlow is fairly straightforward:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">initial_learning_rate</code> <code class="o">=</code> <code class="mf">0.1</code>
<code class="n">decay_steps</code> <code class="o">=</code> <code class="mi">10000</code>
<code class="n">decay_rate</code> <code class="o">=</code> <code class="mi">1</code><code class="o">/</code><code class="mi">10</code>
<code class="n">global_step</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">Variable</code><code class="p">(</code><code class="mi">0</code><code class="p">,</code> <code class="n">trainable</code><code class="o">=</code><code class="bp">False</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"global_step"</code><code class="p">)</code>
<code class="n">learning_rate</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">train</code><code class="o">.</code><code class="n">exponential_decay</code><code class="p">(</code><code class="n">initial_learning_rate</code><code class="p">,</code> <code class="n">global_step</code><code class="p">,</code>
                                           <code class="n">decay_steps</code><code class="p">,</code> <code class="n">decay_rate</code><code class="p">)</code>
<code class="n">optimizer</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">train</code><code class="o">.</code><code class="n">MomentumOptimizer</code><code class="p">(</code><code class="n">learning_rate</code><code class="p">,</code> <code class="n">momentum</code><code class="o">=</code><code class="mf">0.9</code><code class="p">)</code>
<code class="n">training_op</code> <code class="o">=</code> <code class="n">optimizer</code><code class="o">.</code><code class="n">minimize</code><code class="p">(</code><code class="n">loss</code><code class="p">,</code> <code class="n">global_step</code><code class="o">=</code><code class="n">global_step</code><code class="p">)</code></pre>

<p>After setting the hyperparameter values, we create a nontrainable variable <code>global_step</code> (initialized to 0) to keep track of the current training <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.train.MomentumOptimizer" id="idm140582998063920"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.train.exponential_decay()" id="idm140582997898832"></a>iteration number. Then we define an exponentially decaying learning rate (with <em>η</em><sub>0</sub> = 0.1 and <em>r</em> = 10,000) using TensorFlow’s <code>exponential_decay()</code> function. Next, we create an optimizer (in this example, a <code>MomentumOptimizer</code>) using this decaying learning rate. Finally, we create the training operation by calling the optimizer’s <code>minimize()</code> method; since we pass it the <code>global_step</code> variable, it will kindly take care of <a data-type="indexterm" data-primary="learning rate scheduling" data-startref="lrs11" id="idm140582997894912"></a><a data-type="indexterm" data-primary="optimizers" data-secondary="learning rate scheduling" data-startref="o11lrs" id="idm140582997893872"></a>incrementing it. That’s it!</p>

<p>Since AdaGrad, RMSProp, and Adam optimization automatically reduce 
the learning rate during training, it is not necessary to add an extra 
learning schedule. For other optimization algorithms, using exponential 
decay or performance scheduling can considerably speed <a data-type="indexterm" data-primary="deep neural networks (DNNs)" data-secondary="faster optimizers for" data-startref="dnn11fof" id="idm140582997892224"></a><a data-type="indexterm" data-primary="optimizers" data-startref="o11" id="idm140582997890944"></a>up convergence.</p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Avoiding Overfitting Through Regularization"><div class="sect1" id="idm140582997988208">
<h1>Avoiding Overfitting Through Regularization</h1>
<blockquote>
<p>With four parameters I can fit an elephant and with five I can make him wiggle his trunk.</p>
<p data-type="attribution">John von Neumann, <cite>cited by Enrico Fermi in Nature 427</cite></p>
</blockquote>

<p>Deep neural networks <a data-type="indexterm" data-primary="deep neural networks (DNNs)" data-secondary="regularization" id="dnn11reg"></a><a data-type="indexterm" data-primary="overfitting" data-secondary="avoiding through regularization" id="o11atr"></a>typically
 have tens of thousands of parameters, sometimes even millions. With so 
many parameters, the network has an incredible amount of freedom and can
 fit a huge variety of complex datasets. But this great flexibility also
 means that it is prone to overfitting the training set.</p>

<p>With millions of parameters you can fit the whole zoo. In this 
section we will present some of the most popular regularization 
techniques for neural networks, and how to implement them with 
TensorFlow: early stopping, ℓ<sub>1</sub> and ℓ<sub>2</sub> <a data-type="indexterm" data-primary="ℓ 1 norm" id="idm140582997882016"></a><a data-type="indexterm" data-primary="ℓ 2 norm" id="idm140582997881280"></a>regularization, dropout, max-norm regularization, and data augmentation.</p>








<section data-type="sect2" data-pdf-bookmark="Early Stopping"><div class="sect2" id="idm140582997880352">
<h2>Early Stopping</h2>

<p>To <a data-type="indexterm" data-primary="regularization" data-secondary="early stopping" id="idm140582997879056"></a><a data-type="indexterm" data-primary="early stopping" id="idm140582997878048"></a>avoid overfitting the training set, a great solution is early stopping (introduced in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch04.html#linear_models_chapter">Chapter&nbsp;4</a>): just interrupt training when its performance on the validation set starts dropping.</p>

<p>One way to implement this with TensorFlow is to evaluate the model on
 a validation set at regular intervals (e.g., every 50 steps), and save a
 “winner” snapshot if it outperforms previous “winner” snapshots. Count 
the number of steps since the last “winner” snapshot was saved, and 
interrupt training when this number reaches some limit (e.g., 2,000 
steps). Then restore the last “winner” snapshot.</p>

<p>Although early stopping works very well in practice, you can usually 
get much higher performance out of your network by combining it with 
other regularization techniques.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="ℓ1 and ℓ2 Regularization"><div class="sect2" id="idm140582997874768">
<h2>ℓ<sub>1</sub> and ℓ<sub>2</sub> Regularization</h2>

<p>Just <a data-type="indexterm" data-primary="regularization" data-secondary="ℓ 1 and ℓ 2 regularization" id="r11l1l2r"></a><a data-type="indexterm" data-primary="ℓ 1 and ℓ 2 regularization" id="l1l2r11"></a>like you did in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch04.html#linear_models_chapter">Chapter&nbsp;4</a> for simple linear models, you can use ℓ<sub>1</sub> and ℓ<sub>2</sub> regularization to constrain a neural network’s connection weights (but typically not its biases).</p>

<p>One way to do this using TensorFlow <a data-type="indexterm" data-primary="TensorFlow" data-secondary="l1 and l2 regularization with" id="idm140582997867504"></a>is
 to simply add the appropriate regularization terms to your cost 
function. For example, assuming you have just one hidden layer with 
weights <code>W1</code> and one output layer with weights <code>W2</code>, then you can apply ℓ<sub>1</sub> regularization <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.reduce_mean()" id="idm140582997864960"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.abs()" id="idm140582997863952"></a> <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.reduce_sum()" id="idm140582997862880"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.add()" id="tfaddch11"></a>like this:</p>

<pre data-type="programlisting" data-code-language="python" class="pagebreak-before"><code class="p">[</code><code class="o">...</code><code class="p">]</code> <code class="c1"># construct the neural network</code>
<code class="n">W1</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">get_default_graph</code><code class="p">()</code><code class="o">.</code><code class="n">get_tensor_by_name</code><code class="p">(</code><code class="s2">"hidden1/kernel:0"</code><code class="p">)</code>
<code class="n">W2</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">get_default_graph</code><code class="p">()</code><code class="o">.</code><code class="n">get_tensor_by_name</code><code class="p">(</code><code class="s2">"outputs/kernel:0"</code><code class="p">)</code>

<code class="n">scale</code> <code class="o">=</code> <code class="mf">0.001</code> <code class="c1"># l1 regularization hyperparameter</code>

<code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">name_scope</code><code class="p">(</code><code class="s2">"loss"</code><code class="p">):</code>
    <code class="n">xentropy</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">sparse_softmax_cross_entropy_with_logits</code><code class="p">(</code><code class="n">labels</code><code class="o">=</code><code class="n">y</code><code class="p">,</code>
                                                              <code class="n">logits</code><code class="o">=</code><code class="n">logits</code><code class="p">)</code>
    <code class="n">base_loss</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">reduce_mean</code><code class="p">(</code><code class="n">xentropy</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"avg_xentropy"</code><code class="p">)</code>
    <code class="n">reg_losses</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">reduce_sum</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">abs</code><code class="p">(</code><code class="n">W1</code><code class="p">))</code> <code class="o">+</code> <code class="n">tf</code><code class="o">.</code><code class="n">reduce_sum</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">abs</code><code class="p">(</code><code class="n">W2</code><code class="p">))</code>
    <code class="n">loss</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">base_loss</code><code class="p">,</code> <code class="n">scale</code> <code class="o">*</code> <code class="n">reg_losses</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"loss"</code><code class="p">)</code></pre>

<p>However, if there are many layers, this approach is not very 
convenient. Fortunately, TensorFlow provides a better option. Many 
functions that create variables (such as <code>get_variable()</code> or <code>tf.layers.dense()</code>) accept a <code>*_regularizer</code> argument for each created variable (e.g., <code>kernel_regularizer</code>). You can pass any function that takes weights as an argument and returns the corresponding regularization loss. The <code>l1_regularizer()</code>, <code>l2_regularizer()</code>, and <code>l1_l2_regularizer()</code> functions return <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.contrib.layers.l2_regularizer()" id="idm140582997817328"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.contrib.layers.l1_regularizer()" id="idm140582997816464"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.get_variable()" id="tfgetvarch11"></a><a data-type="indexterm" data-primary="l1_l2_regularizer()" id="idm140582997814336"></a>such functions. The following code puts all this together:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">my_dense_layer</code> <code class="o">=</code> <code class="n">partial</code><code class="p">(</code>
    <code class="n">tf</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">dense</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">relu</code><code class="p">,</code>
    <code class="n">kernel_regularizer</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">contrib</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">l1_regularizer</code><code class="p">(</code><code class="n">scale</code><code class="p">))</code>

<code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">name_scope</code><code class="p">(</code><code class="s2">"dnn"</code><code class="p">):</code>
    <code class="n">hidden1</code> <code class="o">=</code> <code class="n">my_dense_layer</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">n_hidden1</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"hidden1"</code><code class="p">)</code>
    <code class="n">hidden2</code> <code class="o">=</code> <code class="n">my_dense_layer</code><code class="p">(</code><code class="n">hidden1</code><code class="p">,</code> <code class="n">n_hidden2</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"hidden2"</code><code class="p">)</code>
    <code class="n">logits</code> <code class="o">=</code> <code class="n">my_dense_layer</code><code class="p">(</code><code class="n">hidden2</code><code class="p">,</code> <code class="n">n_outputs</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="bp">None</code><code class="p">,</code>
                            <code class="n">name</code><code class="o">=</code><code class="s2">"outputs"</code><code class="p">)</code></pre>

<p>This code creates a neural network with two hidden layers and one 
output layer, and it also creates nodes in the graph to compute the ℓ<sub>1</sub>
 regularization loss corresponding to each layer’s weights. TensorFlow 
automatically adds these nodes to a special collection containing all 
the regularization <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.GraphKeys.REGULARIZATION_LOSSES" id="idm140582997740000"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.get_collection()" id="idm140582997495840"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.add_n()" data-startref="tfaddnch11" id="idm140582997494928"></a>losses. You just need to add these regularization losses to your overall loss, like this:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">reg_losses</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">get_collection</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">GraphKeys</code><code class="o">.</code><code class="n">REGULARIZATION_LOSSES</code><code class="p">)</code>
<code class="n">loss</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">add_n</code><code class="p">([</code><code class="n">base_loss</code><code class="p">]</code> <code class="o">+</code> <code class="n">reg_losses</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"loss"</code><code class="p">)</code></pre>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>Don’t forget to add the regularization losses to your overall loss, or else they will simply be <a data-type="indexterm" data-primary="regularization" data-secondary="ℓ 1 and ℓ 2 regularization" data-startref="r11l1l2r" id="idm140582997474288"></a><a data-type="indexterm" data-primary="ℓ 1 and ℓ 2 regularization" data-startref="l1l2r11" id="idm140582997703056"></a>ignored.</p>
</div>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Dropout"><div class="sect2" id="idm140582997701760">
<h2>Dropout</h2>

<p>The <a data-type="indexterm" data-primary="regularization" data-secondary="dropout" id="r11d"></a><a data-type="indexterm" data-primary="dropout" data-startref="d11" id="idm140582997698976"></a>most popular regularization technique for deep neural networks is arguably <em>dropout</em>. It was <a href="https://goo.gl/PMjVnG">proposed</a><sup><a data-type="noteref" id="idm140582997696928-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140582997696928">20</a></sup> by G. E. Hinton in 2012 and further detailed in a <a href="http://goo.gl/DNKZo1">paper</a><sup><a data-type="noteref" id="idm140582997695584-marker" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140582997695584">21</a></sup>
 by Nitish Srivastava et al., and it has proven to be highly successful:
 even the state-of-the-art neural networks got a 1–2% accuracy boost 
simply by adding dropout. This may not sound like a lot, but when a 
model already has 95% accuracy, getting a&nbsp;2% accuracy boost means 
dropping the error rate by almost 40% (going from 5% error to roughly 
3%).</p>

<p>It is a fairly simple algorithm: at every training step, every neuron
 (including the input neurons but excluding the output neurons) has a 
probability <em>p</em> of being temporarily “dropped out,” meaning it 
will be entirely ignored during this training step, but it may be active
 during the next step (see <a data-type="xref" href="#dropout_diagram">Figure&nbsp;11-9</a>). The hyperparameter <em>p</em> is called the <em>dropout rate</em>, <a data-type="indexterm" data-primary="dropout rate" id="idm140582997691504"></a>and
 it is typically set to 50%. After training, neurons don’t get dropped 
anymore. And that’s all (except for a technical detail we will discuss 
momentarily).</p>

<figure class="smallerfiftyfive"><div id="dropout_diagram" class="figure">
<img src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/mlst_1109.png" alt="mlst 1109" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1109.png" width="1279" height="914">
<h6><span class="label">Figure 11-9. </span>Dropout regularization</h6>
</div></figure>

<p>It is quite surprising at first that this rather brutal technique 
works at all. Would a company perform better if its employees were told 
to toss a coin every morning to decide whether or not to go to work? 
Well, who knows; perhaps it would! The company would obviously be forced
 to adapt its organization; it could not rely on any single person to 
fill in the coffee machine or perform any other critical tasks, so this 
expertise would have to be spread across several people. Employees would
 have to learn to cooperate with many of their coworkers, not just a 
handful of them. The company would become much more resilient. If one 
person quit, it wouldn’t make much of a difference. It’s unclear whether
 this idea would actually work for companies, but it certainly does for 
neural networks. Neurons trained with dropout cannot co-adapt with their
 neighboring neurons; they have to be as useful as possible on their 
own. They also cannot rely excessively on just a few input neurons; they
 must pay attention to each of their input neurons. They end up being 
less sensitive to slight changes in the inputs. In the end you get a 
more robust network that generalizes better.</p>

<p>Another way to understand the power of dropout is to realize that a 
unique neural network is generated at each training step. Since each 
neuron can be either present or absent, there is a total of 2<sup><em>N</em></sup> possible networks (where <em>N</em>
 is the total number of droppable neurons). This is such a huge number 
that it is virtually impossible for the same neural network to be 
sampled twice. Once you have run a 10,000 training steps, you have 
essentially trained 10,000 different neural networks (each with just one
 training instance). These neural networks are obviously not independent
 since they share many of their weights, but they are nevertheless all 
different. The resulting neural network can be seen as an averaging 
ensemble of all these smaller neural networks.</p>

<p>There is one small but important technical detail. Suppose <em>p</em>
 = 50%, in which case during testing a neuron will be connected to twice
 as many input neurons as it was (on average) during training. To 
compensate for this fact, we need to multiply each neuron’s input 
connection weights by&nbsp;0.5 after training. If we don’t, each neuron 
will get a total input signal roughly twice as large as what the network
 was trained on, and it is unlikely to perform well. More generally, we 
need to multiply each input connection weight by <a data-type="indexterm" data-primary="keep probability" id="idm140582997683296"></a>the <em>keep probability</em> (1 – <em>p</em>)
 after training. Alternatively, we can divide each neuron’s output by 
the keep probability during training (these alternatives are not 
perfectly equivalent, but they work equally well).</p>

<p>To implement dropout using <a data-type="indexterm" data-primary="TensorFlow" data-secondary="dropout with" id="idm140582997680976"></a>TensorFlow, you can simply apply the <code>tf.layers.dropout()</code> <a data-type="indexterm" data-primary="dropout()" id="idm140582997679488"></a>function
 to the input layer and/or to the output of any hidden layer you want. 
During training, this function randomly drops some items (setting them 
to 0) and divides the remaining items by the keep probability. After 
training, this function does nothing at all. The following code applies 
dropout regularization to our three-layer <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.bool" id="idm140582997678272"></a>neural network:</p>

<pre data-type="programlisting" data-code-language="python"><code class="p">[</code><code class="o">...</code><code class="p">]</code>
<code class="n">training</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">placeholder_with_default</code><code class="p">(</code><code class="bp">False</code><code class="p">,</code> <code class="n">shape</code><code class="o">=</code><code class="p">(),</code> <code class="n">name</code><code class="o">=</code><code class="s1">'training'</code><code class="p">)</code>

<code class="n">dropout_rate</code> <code class="o">=</code> <code class="mf">0.5</code>  <code class="c1"># == 1 - keep_prob</code>
<code class="n">X_drop</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">dropout</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">dropout_rate</code><code class="p">,</code> <code class="n">training</code><code class="o">=</code><code class="n">training</code><code class="p">)</code>

<code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">name_scope</code><code class="p">(</code><code class="s2">"dnn"</code><code class="p">):</code>
    <code class="n">hidden1</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">dense</code><code class="p">(</code><code class="n">X_drop</code><code class="p">,</code> <code class="n">n_hidden1</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">relu</code><code class="p">,</code>
                              <code class="n">name</code><code class="o">=</code><code class="s2">"hidden1"</code><code class="p">)</code>
    <code class="n">hidden1_drop</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">dropout</code><code class="p">(</code><code class="n">hidden1</code><code class="p">,</code> <code class="n">dropout_rate</code><code class="p">,</code> <code class="n">training</code><code class="o">=</code><code class="n">training</code><code class="p">)</code>
    <code class="n">hidden2</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">dense</code><code class="p">(</code><code class="n">hidden1_drop</code><code class="p">,</code> <code class="n">n_hidden2</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">relu</code><code class="p">,</code>
                              <code class="n">name</code><code class="o">=</code><code class="s2">"hidden2"</code><code class="p">)</code>
    <code class="n">hidden2_drop</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">dropout</code><code class="p">(</code><code class="n">hidden2</code><code class="p">,</code> <code class="n">dropout_rate</code><code class="p">,</code> <code class="n">training</code><code class="o">=</code><code class="n">training</code><code class="p">)</code>
    <code class="n">logits</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">dense</code><code class="p">(</code><code class="n">hidden2_drop</code><code class="p">,</code> <code class="n">n_outputs</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"outputs"</code><code class="p">)</code></pre>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>You want to use the <code>tf.layers.dropout()</code> function, not <code>tf.nn.dropout()</code>. The first one turns off (no-op) when not training, which is what you want, while the second one does not.</p>
</div>

<p>Of course, just like you did earlier for Batch Normalization, you need to set <code>training</code> to <code>True</code> when training, and leave the default <code>False</code> value when testing.</p>

<p>If you observe that the model is overfitting, you can increase the 
dropout rate. Conversely, you should try decreasing the dropout rate if 
the model underfits the training set. It can also help to increase the 
dropout rate for large layers, and reduce it for small ones.</p>

<p>Dropout does tend to significantly slow down convergence, but it 
usually results in a much better model when tuned properly. So, it is 
generally well worth the extra time and effort.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p><em>Dropconnect</em> <a data-type="indexterm" data-primary="dropconnect" id="idm140582997366624"></a>is
 a variant of dropout where individual connections are dropped randomly 
rather than whole neurons. In general dropout performs <a data-type="indexterm" data-primary="regularization" data-secondary="dropout" data-startref="r11d" id="idm140582997365616"></a><a data-type="indexterm" data-primary="dropout" data-startref="d11" id="idm140582997364400"></a>better.</p>
</div>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Max-Norm Regularization"><div class="sect2" id="idm140582997701136">
<h2>Max-Norm Regularization</h2>

<p>Another <a data-type="indexterm" data-primary="max-norm regularization" id="mnr11"></a><a data-type="indexterm" data-primary="regularization" data-secondary="max-norm" id="r11mn"></a>regularization technique that is quite popular for neural networks is called <em>max-norm regularization</em>: for each neuron, it constrains the weights <strong>w</strong> of the incoming connections such that ∥ <strong>w</strong> ∥<sub>2</sub> ≤ <em>r</em>, where <em>r</em> is the max-norm hyperparameter and <span class="keep-together">∥ · ∥<sub>2</sub></span> is the<a data-type="indexterm" data-primary="ℓ 2 norm" id="idm140582997355136"></a> ℓ<sub>2</sub> norm.</p>

<p>We typically implement this constraint by computing ∥<strong>w</strong>∥<sub>2</sub> after each training step and clipping <strong>w</strong> if needed (<img src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/eq_124.png" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/eq_124.png" width="115" height="28">).</p>

<p>Reducing <em>r</em> increases the amount of regularization and helps 
reduce overfitting. Max-norm regularization can also help alleviate the 
vanishing/exploding gradients problems (if you are not using Batch 
Normalization).</p>

<p>TensorFlow <a data-type="indexterm" data-primary="TensorFlow" data-secondary="max-norm regularization with" id="idm140582997350384"></a>does
 not provide an off-the-shelf max-norm regularizer, but it is not too 
hard to implement. The following code gets a handle on the weights of 
the first hidden layer, then it uses the <code>clip_by_norm()</code> function <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.clip_by_norm()" id="tfclipbynormch11"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.assign()" id="tfassignch11"></a>to
 create an operation that will clip the weights along the second axis so
 that each row vector ends up with a maximum norm of 1.0. The last line 
creates an assignment operation that will assign the clipped weights to 
the weights variable:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">threshold</code> <code class="o">=</code> <code class="mf">1.0</code>
<code class="n">weights</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">get_default_graph</code><code class="p">()</code><code class="o">.</code><code class="n">get_tensor_by_name</code><code class="p">(</code><code class="s2">"hidden1/kernel:0"</code><code class="p">)</code>
<code class="n">clipped_weights</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">clip_by_norm</code><code class="p">(</code><code class="n">weights</code><code class="p">,</code> <code class="n">clip_norm</code><code class="o">=</code><code class="n">threshold</code><code class="p">,</code> <code class="n">axes</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>
<code class="n">clip_weights</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">assign</code><code class="p">(</code><code class="n">weights</code><code class="p">,</code> <code class="n">clipped_weights</code><code class="p">)</code></pre>

<p>Then you just apply this operation after each training step, like so:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">sess</code><code class="o">.</code><code class="n">run</code><code class="p">(</code><code class="n">training_op</code><code class="p">,</code> <code class="n">feed_dict</code><code class="o">=</code><code class="p">{</code><code class="n">X</code><code class="p">:</code> <code class="n">X_batch</code><code class="p">,</code> <code class="n">y</code><code class="p">:</code> <code class="n">y_batch</code><code class="p">})</code>
<code class="n">clip_weights</code><code class="o">.</code><code class="n">eval</code><code class="p">()</code></pre>

<p>In general, you would do this for every hidden layer. Although this 
solution should work fine, it is a bit messy. A cleaner solution is to <a data-type="indexterm" data-primary="max_norm_regularizer()" id="idm140582997283728"></a>create a <code>max_norm_regularizer()</code> function <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.contrib.layers.l1_regularizer()" id="idm140582997282608"></a>and use it just like the earlier <code>l1_regularizer()</code> function:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">def</code> <code class="nf">max_norm_regularizer</code><code class="p">(</code><code class="n">threshold</code><code class="p">,</code> <code class="n">axes</code><code class="o">=</code><code class="mi">1</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"max_norm"</code><code class="p">,</code>
                         <code class="n">collection</code><code class="o">=</code><code class="s2">"max_norm"</code><code class="p">):</code>
    <code class="k">def</code> <code class="nf">max_norm</code><code class="p">(</code><code class="n">weights</code><code class="p">):</code>
        <code class="n">clipped</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">clip_by_norm</code><code class="p">(</code><code class="n">weights</code><code class="p">,</code> <code class="n">clip_norm</code><code class="o">=</code><code class="n">threshold</code><code class="p">,</code> <code class="n">axes</code><code class="o">=</code><code class="n">axes</code><code class="p">)</code>
        <code class="n">clip_weights</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">assign</code><code class="p">(</code><code class="n">weights</code><code class="p">,</code> <code class="n">clipped</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="n">name</code><code class="p">)</code>
        <code class="n">tf</code><code class="o">.</code><code class="n">add_to_collection</code><code class="p">(</code><code class="n">collection</code><code class="p">,</code> <code class="n">clip_weights</code><code class="p">)</code>
        <code class="k">return</code> <code class="bp">None</code>  <code class="c1"># there is no regularization loss term</code>
    <code class="k">return</code> <code class="n">max_norm</code></pre>

<p>This function returns a parametrized <code>max_norm()</code> <a data-type="indexterm" data-primary="max_norm()" id="idm140582997276288"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.clip_by_norm()" data-startref="tfclipbynormch11" id="idm140582997275904"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.assign()" data-startref="tfassignch11" id="idm140582997211312"></a><a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.add_to_collection()" id="idm140582997210096"></a>function that you can use like any other regularizer:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">max_norm_reg</code> <code class="o">=</code> <code class="n">max_norm_regularizer</code><code class="p">(</code><code class="n">threshold</code><code class="o">=</code><code class="mf">1.0</code><code class="p">)</code>

<code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">name_scope</code><code class="p">(</code><code class="s2">"dnn"</code><code class="p">):</code>
    <code class="n">hidden1</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">dense</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">n_hidden1</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">relu</code><code class="p">,</code>
                              <code class="n">kernel_regularizer</code><code class="o">=</code><code class="n">max_norm_reg</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"hidden1"</code><code class="p">)</code>
    <code class="n">hidden2</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">dense</code><code class="p">(</code><code class="n">hidden1</code><code class="p">,</code> <code class="n">n_hidden2</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">relu</code><code class="p">,</code>
                              <code class="n">kernel_regularizer</code><code class="o">=</code><code class="n">max_norm_reg</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"hidden2"</code><code class="p">)</code>
    <code class="n">logits</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">dense</code><code class="p">(</code><code class="n">hidden2</code><code class="p">,</code> <code class="n">n_outputs</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"outputs"</code><code class="p">)</code></pre>

<p>Note that max-norm regularization does not require adding a 
regularization loss term to your overall loss function, which is why the
 <code>max_norm()</code> function returns <code>None</code>. But you still need to be able to run the <code>clip_weights</code> operations after each training step, so you need to be able to get a handle on them. This is why the <code>max_norm()</code> function adds the <code>clip_weights</code> operation to a collection of max-norm clipping operations. You need to fetch these clipping operations and run them after <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.get_collection()" id="idm140582996964240"></a>each training step:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">clip_all_weights</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">get_collection</code><code class="p">(</code><code class="s2">"max_norm"</code><code class="p">)</code>

<code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">Session</code><code class="p">()</code> <code class="k">as</code> <code class="n">sess</code><code class="p">:</code>
    <code class="n">init</code><code class="o">.</code><code class="n">run</code><code class="p">()</code>
    <code class="k">for</code> <code class="n">epoch</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">n_epochs</code><code class="p">):</code>
        <code class="k">for</code> <code class="n">iteration</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">mnist</code><code class="o">.</code><code class="n">train</code><code class="o">.</code><code class="n">num_examples</code> <code class="o">//</code> <code class="n">batch_size</code><code class="p">):</code>
            <code class="n">X_batch</code><code class="p">,</code> <code class="n">y_batch</code> <code class="o">=</code> <code class="n">mnist</code><code class="o">.</code><code class="n">train</code><code class="o">.</code><code class="n">next_batch</code><code class="p">(</code><code class="n">batch_size</code><code class="p">)</code>
            <code class="n">sess</code><code class="o">.</code><code class="n">run</code><code class="p">(</code><code class="n">training_op</code><code class="p">,</code> <code class="n">feed_dict</code><code class="o">=</code><code class="p">{</code><code class="n">X</code><code class="p">:</code> <code class="n">X_batch</code><code class="p">,</code> <code class="n">y</code><code class="p">:</code> <code class="n">y_batch</code><code class="p">})</code>
            <code class="n">sess</code><code class="o">.</code><code class="n">run</code><code class="p">(</code><code class="n">clip_all_weights</code><code class="p">)</code></pre>

<p><em>Much</em> cleaner code, isn’t <a data-type="indexterm" data-primary="max-norm regularization" data-startref="mnr11" id="idm140582996961264"></a><a data-type="indexterm" data-primary="regularization" data-secondary="max-norm" data-startref="r11mn" id="idm140582996856272"></a>it?</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Data Augmentation"><div class="sect2" id="idm140582997362608">
<h2>Data Augmentation</h2>

<p>One <a data-type="indexterm" data-primary="data augmentation" id="da11"></a><a data-type="indexterm" data-primary="regularization" data-secondary="data augmentation" id="r11da"></a>last
 regularization technique, data augmentation, consists of generating new
 training instances from existing ones, artificially boosting the size 
of the training set. This will reduce overfitting, making this a 
regularization technique. The trick is to generate realistic training 
instances; ideally, a human should not be able to tell which instances 
were generated and which ones were not. Moreover, simply adding white 
noise will not help; the modifications you apply should be learnable 
(white noise is not).</p>

<p>For example, if your model is meant to classify pictures of 
mushrooms, you can slightly shift, rotate, and resize every picture in 
the training set by various amounts and add the resulting pictures to 
the training set (see <a data-type="xref" href="#data_augmentation_diagram">Figure&nbsp;11-10</a>).
 This forces the model to be more tolerant to the position, orientation,
 and size of the mushrooms in the picture. If you want the model to be 
more tolerant to lighting conditions, you can similarly generate many 
images with various contrasts. Assuming the mushrooms are symmetrical, 
you can also flip the pictures horizontally. By combining these 
transformations you can greatly increase the size of your training set.</p>

<figure><div id="data_augmentation_diagram" class="figure">
<img src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/mlst_1110.png" alt="mlst 1110" data-mfp-src="/library/view/hands-on-machine-learning/9781491962282/assets/mlst_1110.png" width="1440" height="888">
<h6><span class="label">Figure 11-10. </span>Generating new training instances from existing ones</h6>
</div></figure>

<p>It is often preferable to generate training instances on the fly 
during training rather than wasting storage space and network bandwidth.
 TensorFlow offers several image manipulation operations such as 
transposing (shifting), rotating, resizing, flipping, and cropping, as 
well as adjusting the brightness, contrast, saturation, and hue (see the
 API documentation for more details). This makes it easy to implement 
data augmentation for image datasets.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Another powerful technique to train very deep neural networks is to add<a data-type="indexterm" data-primary="skip connections" id="idm140582996844640"></a> <em>skip connections</em> (a skip connection is when you add the input of a layer to the output of a higher layer). We will explore this idea in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch13.html#cnn_chapter">Chapter&nbsp;13</a> when we talk about deep residual <a data-type="indexterm" data-primary="data augmentation" data-startref="da11" id="idm140582996842416"></a><a data-type="indexterm" data-primary="regularization" data-secondary="data augmentation" data-startref="r11da" id="idm140582996841472"></a><a data-type="indexterm" data-primary="deep neural networks (DNNs)" data-secondary="regularization" data-startref="dnn11reg" id="idm140582996840256"></a><a data-type="indexterm" data-primary="overfitting" data-secondary="avoiding through regularization" data-startref="o11atr" id="idm140582996839072"></a>networks.</p>
</div>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Practical Guidelines"><div class="sect1" id="idm140582996837632">
<h1>Practical Guidelines</h1>

<p>In <a data-type="indexterm" data-primary="deep neural networks (DNNs)" data-secondary="training guidelines overview" id="idm140582996836224"></a>this
 chapter, we have covered a wide range of techniques and you may be 
wondering which ones you should use. The configuration in <a data-type="xref" href="#default_deep_neural_network_config">Table&nbsp;11-2</a> will work fine in most cases.</p>
<table id="default_deep_neural_network_config" style="width: 70%">
<caption><span class="label">Table 11-2. </span>Default DNN configuration</caption>
<tbody>
<tr>
<td><p><strong>Initialization</strong></p></td>
<td><p>He initialization</p></td>
</tr>
<tr>
<td><p><strong>Activation function</strong></p></td>
<td><p>ELU</p></td>
</tr>
<tr>
<td><p><strong>Normalization</strong></p></td>
<td><p>Batch Normalization</p></td>
</tr>
<tr>
<td><p><strong>Regularization</strong></p></td>
<td><p>Dropout</p></td>
</tr>
<tr>
<td><p><strong>Optimizer</strong></p></td>
<td><p>Nesterov Accelerated Gradient</p></td>
</tr>
<tr>
<td><p><strong>Learning rate schedule</strong></p></td>
<td><p>None</p></td>
</tr>
</tbody>
</table>

<p>Of course, you should try to reuse parts of a pretrained neural network if you can find one that solves a similar problem.</p>

<p>This default configuration may need to be tweaked:</p>

<ul>
<li>
<p>If you can’t find a good learning rate (convergence was too slow, so 
you increased the training rate, and now convergence is fast but the 
network’s accuracy is suboptimal), then you can try adding a learning 
schedule such as exponential decay.</p>
</li>
<li>
<p>If your training set is a bit too small, you can implement data augmentation.</p>
</li>
<li>
<p>If you need a sparse model, you can add some ℓ<sub>1</sub> 
regularization to the mix (and optionally zero out the tiny weights 
after training). If you need an even sparser model, you can try using 
FTRL instead of Adam optimization, along with ℓ<sub>1</sub> regularization.</p>
</li>
<li>
<p>If you need a lightning-fast model at runtime, you may want to drop 
Batch Normalization, and possibly replace the ELU activation function 
with the leaky ReLU. Having a sparse model will also help.</p>
</li>
</ul>

<p>With these guidelines, you are now ready to train very deep 
nets—well, if you are very patient, that is! If you use a single 
machine, you may have to wait for days or even months for training to 
complete. In the next chapter we will discuss how to use distributed 
TensorFlow to train and run models across many servers and GPUs.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Exercises"><div class="sect1" id="idm140582996754144">
<h1>Exercises</h1>
<ol>
<li>
<p>Is it okay to initialize all the weights to the same value as long as that value is selected randomly using He initialization?</p>
</li>
<li>
<p>Is it okay to initialize the bias terms to 0?</p>
</li>
<li>
<p>Name three advantages of the ELU activation function over ReLU.</p>
</li>
<li>
<p>In which cases would you want to use each of the following activation
 functions: ELU, leaky ReLU (and its variants), ReLU, tanh, logistic, 
and softmax?</p>
</li>
<li>
<p>What may happen if you set the <code>momentum</code> hyperparameter too close to 1 (e.g., 0.99999) when <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.train.MomentumOptimizer" id="idm140582996747488"></a>using a <code>MomentumOptimizer</code>?</p>
</li>
<li>
<p>Name three ways you can produce a sparse model.</p>
</li>
<li>
<p>Does dropout slow down training? Does it slow down <a data-type="indexterm" data-primary="inference" id="idm140582996744112"></a>inference (i.e., making predictions on new instances)?</p>
</li>
<li>
<p>Deep Learning.</p>
<ol>
<li>
<p>Build a DNN with five hidden layers of 100 neurons each, He initialization, and the ELU activation function.</p>
</li>
<li>
<p>Using Adam optimization and early stopping, try training it on MNIST 
but only on digits 0 to 4, as we will use transfer learning for digits 5
 to 9 in the next exercise. You will need a softmax output layer with 
five neurons, and as always make sure to save checkpoints at regular 
intervals and save the final model so you can reuse it later.</p>
</li>
<li>
<p>Tune the hyperparameters using cross-validation and see what precision you can achieve.</p>
</li>
<li>
<p>Now try adding Batch Normalization and compare the learning curves: 
is it converging faster than before? Does it produce a better model?</p>
</li>
<li>
<p>Is the model overfitting the training set? Try adding dropout to every layer and try again. Does it help?</p>
</li>

</ol>
</li>
<li>
<p>Transfer learning.</p>
<ol>
<li>
<p>Create a new DNN that reuses all the pretrained hidden layers of the 
previous model, freezes them, and replaces the softmax output layer with
 a new one.</p>
</li>
<li>
<p>Train this new DNN on digits 5 to 9, using only 100 images per digit,
 and time how long it takes. Despite this small number of examples, can 
you achieve high precision?</p>
</li>
<li>
<p>Try caching the frozen layers, and train the model again: how much faster is it now?</p>
</li>
<li>
<p>Try again reusing just four hidden layers instead of five. Can you achieve a higher precision?</p>
</li>
<li>
<p>Now unfreeze the top two hidden layers and continue training: can you get the model to perform even better?</p>
</li>

</ol>
</li>
<li>
<p>Pretraining on an auxiliary task.</p>
<ol>
<li>
<p>In this exercise you will build a DNN that compares two MNIST digit 
images and predicts whether they represent the same digit or not. Then 
you will reuse the lower layers of this network to train an MNIST 
classifier using very little training data. Start by building two DNNs 
(let’s call them DNN A and B), both similar to the one you built earlier
 but without the output layer: each DNN should have five hidden layers 
of 100 neurons each, He initialization, and ELU activation. Next, add 
one more hidden layer with 10 units on top of both DNNs. To do this, you
 should use TensorFlow’s <code>concat()</code> <a data-type="indexterm" data-primary="TensorFlow" data-secondary="tf.concat()" id="idm140582996727408"></a>function with <code>axis=1</code>
 to concatenate the outputs of both DNNs for each instance, then feed 
the result to the hidden layer. Finally, add an output layer with a 
single neuron using the logistic activation function.</p>
</li>
<li>
<p>Split the MNIST training set in two sets: split #1 should containing 
55,000 images, and split #2 should contain contain 5,000 images. Create a
 function that generates a training batch where each instance is a pair 
of MNIST images picked from split #1. Half of the training instances 
should be pairs of images that belong to the same class, while the other
 half should be images from different classes. For each pair, the 
training label should be 0 if the images are from the same class, or 1 
if they are from different classes.</p>
</li>
<li>
<p>Train the DNN on this training set. For each image pair, you can 
simultaneously feed the first image to DNN A and the second image to DNN
 B. The whole network will gradually learn to tell whether two images 
belong to the same class or not.</p>
</li>
<li>
<p>Now create a new DNN by reusing and freezing the hidden layers of 
DNN&nbsp;A and adding a softmax output layer on top with 10 neurons. 
Train this network on split #2 and see if you can achieve high 
performance despite having only 500 images per class.</p>
</li>

</ol>
</li>

</ol>

<p>Solutions to these exercises are <a data-type="indexterm" data-primary="deep neural networks (DNNs)" data-startref="dnn11" id="idm140582996721360"></a>available in <a data-type="xref" href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/app01.html#solutions_appendix">Appendix&nbsp;A</a>.</p>
</div></section>







<div data-type="footnotes"><p data-type="footnote" id="idm140583000536464"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140583000536464-marker" class="totri-footnote">1</a></sup> “Understanding the Difficulty of Training Deep Feedforward Neural Networks,” X. Glorot, Y Bengio (2010).</p><p data-type="footnote" id="idm140583000528000"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140583000528000-marker" class="totri-footnote">2</a></sup>
 Here’s an analogy: if you set a microphone amplifier’s knob too close 
to zero, people won’t hear your voice, but if you set it too close to 
the max, your voice will be saturated and people won’t understand what 
you are saying. Now imagine a chain of such amplifiers: they all need to
 be set properly in order for your voice to come out loud and clear at 
the end of the chain. Your voice has to come out of each amplifier at 
the same amplitude as it came in.</p><p data-type="footnote" id="idm140583000517168"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140583000517168-marker" class="totri-footnote">3</a></sup> This simplified strategy was actually already proposed much earlier—for example, in the 1998 book <em>Neural Networks: Tricks of the Trade</em> by Genevieve Orr and Klaus-Robert Müller (Springer).</p><p data-type="footnote" id="idm140583000513424"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140583000513424-marker" class="totri-footnote">4</a></sup> Such as “Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification,” K. He et al. (2015).</p><p data-type="footnote" id="idm140583000442064"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140583000442064-marker" class="totri-footnote">5</a></sup> “Empirical Evaluation of Rectified Activations in Convolution Network,” B. Xu et al. (2015).</p><p data-type="footnote" id="idm140583000432272"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140583000432272-marker" class="totri-footnote">6</a></sup> “Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs),” D. Clevert, T. Unterthiner, S. Hochreiter (2015).</p><p data-type="footnote" id="idm140583000276592"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140583000276592-marker" class="totri-footnote">7</a></sup> “Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift,” S. Ioffe and C. Szegedy (2015).</p><p data-type="footnote" id="idm140583000060768"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140583000060768-marker" class="totri-footnote">8</a></sup>
 Many researchers argue that it is just as good, or even better, to 
place the batch normalization layers after (rather than before) the 
activations.</p><p data-type="footnote" id="idm140582999928672"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140582999928672-marker" class="totri-footnote">9</a></sup> “On the difficulty of training recurrent neural networks,” R. Pascanu et al. (2013).</p><p data-type="footnote" id="idm140582998478144"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140582998478144-marker">10</a></sup> “Some methods of speeding up the convergence of iteration methods,” B. Polyak (1964).</p><p data-type="footnote" id="idm140582998350592"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140582998350592-marker">11</a></sup> “A Method for Unconstrained Convex Minimization Problem with the Rate of Convergence O(1/k<sup>2</sup>),” Yurii Nesterov (1983).</p><p data-type="footnote" id="idm140582998303792"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140582998303792-marker">12</a></sup> “Adaptive Subgradient Methods for Online Learning and Stochastic Optimization,” J. Duchi et al. (2011).</p><p data-type="footnote" id="idm140582998174032"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140582998174032-marker">13</a></sup>
 This algorithm was created by Tijmen Tieleman and Geoffrey Hinton in 
2012, and presented by Geoffrey Hinton in his Coursera class on neural 
networks (slides: <a href="http://goo.gl/RsQeis"><em class="hyperlink">http://goo.gl/RsQeis</em></a>; video: <a href="https://goo.gl/XUbIyJ"><em class="hyperlink">https://goo.gl/XUbIyJ</em></a>).
 Amusingly, since the authors have not written a paper to describe it, 
researchers often cite “slide 29 in lecture 6” in their papers.</p><p data-type="footnote" id="idm140582998127520"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140582998127520-marker">14</a></sup> “Adam: A Method for Stochastic Optimization,” D. Kingma, J. Ba (2015).</p><p data-type="footnote" id="idm140582998153184"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140582998153184-marker">15</a></sup> These are estimations of the mean and (uncentered) variance of the gradients. The mean is often called the <em>first moment</em>, while the variance is often called the <em>second moment</em>, hence the name of the algorithm.</p><p data-type="footnote" id="idm140582998010912"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140582998010912-marker">16</a></sup> “The Marginal Value of Adaptive Gradient Methods in Machine Learning,” A. C. Wilson et al. (2017).</p><p data-type="footnote" id="idm140582997991696"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140582997991696-marker">17</a></sup> “Primal-Dual Subgradient Methods for Convex Problems,” Yurii Nesterov (2005).</p><p data-type="footnote" id="idm140582997989744"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140582997989744-marker">18</a></sup> “Ad Click Prediction: a View from the Trenches,” H. McMahan et al. (2013).</p><p data-type="footnote" id="idm140582998069552"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140582998069552-marker">19</a></sup> “An Empirical Study of Learning Rates in Deep Neural Networks for Speech Recognition,” A. Senior et al. (2013).</p><p data-type="footnote" id="idm140582997696928"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140582997696928-marker">20</a></sup> “Improving neural networks by preventing co-adaptation of feature detectors,” G. Hinton et al. (2012).</p><p data-type="footnote" id="idm140582997695584"><sup><a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch11.html#idm140582997695584-marker">21</a></sup> “Dropout: A Simple Way to Prevent Neural Networks from Overfitting,” N. Srivastava et al. (2014).</p></div></div></section><div class="annotator-outer annotator-viewer viewer annotator-hide">
  <ul class="annotator-widget annotator-listing"></ul>
</div><div class="annotator-modal-wrapper annotator-editor-modal annotator-editor annotator-hide">
	<div class="annotator-outer editor">
		<h2 class="title">Highlight</h2>
		<form class="annotator-widget">
			<ul class="annotator-listing">
			<li class="annotator-item"><textarea id="annotator-field-1" placeholder="Add a note using markdown (optional)" class="js-editor" maxlength="750"></textarea></li></ul>
			<div class="annotator-controls">
				<a class="link-to-markdown" href="https://daringfireball.net/projects/markdown/basics" target="_blank">?</a>
				<ul>
					<li class="delete annotator-hide"><a href="#delete" class="annotator-delete-note button positive">Delete Note</a></li>
					<li class="save"><a href="#save" class="annotator-save annotator-focus button positive">Save Note</a></li>
					<li class="cancel"><a href="#cancel" class="annotator-cancel button">Cancel</a></li>
				</ul>
			</div>
		</form>
	</div>
</div><div class="annotator-modal-wrapper annotator-delete-confirm-modal" style="display: none;">
  <div class="annotator-outer">
    <h2 class="title">Highlight</h2>
      <a class="js-close-delete-confirm annotator-cancel close" href="#close">Close</a>
      <div class="annotator-widget">
         <div class="delete-confirm">
            Are you sure you want to permanently delete this note?
         </div>
         <div class="annotator-controls">
            <a href="#cancel" class="annotator-cancel button js-cancel-delete-confirm">No, I changed my mind</a>
            <a href="#delete" class="annotator-delete button positive js-delete-confirm">Yes, delete it</a>
         </div>
       </div>
   </div>
</div><div class="annotator-adder" style="display: none;">
	<ul class="adders ">
		
		<li class="copy"><a href="#">Copy</a></li>
		
		<li class="add-highlight"><a href="#">Add Highlight</a></li>
		<li class="add-note"><a href="#">
			
				Add Note
			
		</a></li>
		
	</ul>
</div></div></div>



  <div class="t-sbo-prev sbo-prev sbo-nav-bottom">
  
    
      
        <a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch10.html" class="prev nav-link">
      
          <span aria-hidden="true" class="pagination-label t-prev-label">Prev</span>
          <span class="visuallyhidden">Previous Chapter</span>
          <div class="pagination-title t-prev-title">10. Introduction to Artificial Neural Networks</div>
        </a>
    
  
  </div>

  <div class="t-sbo-next sbo-next sbo-nav-bottom">
  
    
      
        <a href="https://www.safaribooksonline.com/library/view/hands-on-machine-learning/9781491962282/ch12.html" class="next nav-link">
      
          <span aria-hidden="true" class="pagination-label t-next-label">Next</span>
          <span class="visuallyhidden">Next Chapter</span>
          <div class="pagination-title t-next-title">12. Distributing TensorFlow Across Devices and Servers</div>
        </a>
    
  
  </div>

</section>
  </div>
<section class="sbo-saved-archives"></section>



          
          
  




    
    
      <div id="js-subscribe-nag" class="subscribe-nag clearfix trial-panel t-subscribe-nag collapsed slideUp">
        
        
          
          
            <p class="usage-data">Find answers on the fly, or master something new. Subscribe today. <a href="https://www.safaribooksonline.com/subscribe/" class="ga-active-trial-subscribe-nag">See pricing options.</a></p>
          

          
        
        

      </div>

    
    



        
      </div>
      




  <footer class="pagefoot t-pagefoot" style="padding-bottom: 69px;">
    <a href="#" class="icon-up" style="display: none;"><div class="visuallyhidden">Back to top</div></a>
    <ul class="js-footer-nav">
      
        <li><a class="t-recommendations-footer" href="https://www.safaribooksonline.com/r/">Recommended</a></li>
      
      <li>
      
      <a class="t-queue-footer" href="https://www.safaribooksonline.com/s/">Queue</a>
      
      </li>
      
        <li><a class="t-recent-footer" href="https://www.safaribooksonline.com/history/">History</a></li>
        <li><a class="t-topics-footer" href="https://www.safaribooksonline.com/topics?q=*&amp;limit=21">Topics</a></li>
      
      
        <li><a class="t-tutorials-footer" href="https://www.safaribooksonline.com/tutorials/">Tutorials</a></li>
      
      <li><a class="t-settings-footer js-settings" href="https://www.safaribooksonline.com/u/">Settings</a></li>
      <li class="full-support"><a href="https://www.safaribooksonline.com/public/support">Support</a></li>
      <li><a href="https://www.safaribooksonline.com/apps/">Get the App</a></li>
      <li><a href="https://www.safaribooksonline.com/accounts/logout/">Sign Out</a></li>
    </ul>
    <span class="copyright">© 2017 <a href="https://www.safaribooksonline.com/" target="_blank">Safari</a>.</span>
    <a href="https://www.safaribooksonline.com/terms/">Terms of Service</a> /
    <a href="https://www.safaribooksonline.com/privacy/">Privacy Policy</a>
  </footer>

<script type="text/javascript">window.NREUM||(NREUM={});NREUM.info={"beacon":"bam.nr-data.net","queueTime":0,"licenseKey":"510f1a6865","errorBeacon":"bam.nr-data.net","transactionName":"YgdaZ0NSW0cEB0RdWltNfkZfUEFdCgofXFBHDVYdR1pQQxZeRl1QQj1aWkU=","applicationTime":651,"applicationID":"3275661","agent":""}</script>


    

    <script src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/a_004.js" charset="utf-8"></script><script type="text/javascript" id="">!function(b,e,f,g,a,c,d){b.fbq||(a=b.fbq=function(){a.callMethod?a.callMethod.apply(a,arguments):a.queue.push(arguments)},b._fbq||(b._fbq=a),a.push=a,a.loaded=!0,a.version="2.0",a.queue=[],c=e.createElement(f),c.async=!0,c.src=g,d=e.getElementsByTagName(f)[0],d.parentNode.insertBefore(c,d))}(window,document,"script","https://connect.facebook.net/en_US/fbevents.js");fbq("init","1732687426968531");fbq("track","PageView");</script>
<noscript><img height="1" width="1" style="display:none" src="https://www.facebook.com/tr?id=1732687426968531&amp;ev=PageView&amp;noscript=1"></noscript><div style="width:0px; height:0px; display:none; visibility:hidden;" id="batBeacon0.3743867347277554"><img style="width:0px; height:0px; display:none; visibility:hidden;" id="batBeacon0.3342180628024528" alt="" src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/0.txt" width="0" height="0"></div>
    <script src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/a_005.js" charset="utf-8"></script>
  

<div class="annotator-notice"></div><div class="font-flyout" style="top: 200px; left: 1257px;"><div class="font-controls-panel">
	<div class="nightmodes">
		<ul>
			<li class="day"><a href="#" id="day-mode" title="Day Mode">
				<i class="fa fa-sun-o"></i>
				<span>Day Mode</span></a></li>
			<li class="cloudy"><a href="#" id="cloudy-mode" title="Cloudy Mode">
				<i class="fa fa-cloud"></i>
				<span>Cloud Mode</span>
			</a></li>
			<li class="night"><a href="#" id="night-mode" title="Night Mode">
				<i class="fa fa-moon-o"></i>
				<span>Night Mode</span>
			</a></li>
		</ul>
	</div>

	<div class="font-resizer resizer">
		<div class="draggable-containment-wrapper">
			<i class="fa fa-font left"></i>
			<span class="filler" style="width: 50%;"></span>
			<div id="js-font-size-draggable" class="draggable ui-widget-content ui-draggable ui-draggable-handle" style="position: relative; left: 80px;"></div>
			<i class="fa fa-font right"></i>
		</div>
	</div>

	<div class="column-resizer resizer">
		<div class="draggable-containment-wrapper">
			<i class="fa fa-compress left"></i>
			<span class="filler" style="width: 50%;"></span>
			<div id="js-column-size-draggable" class="draggable ui-widget-content ui-draggable ui-draggable-handle" style="position: relative; left: 80px;"></div>
			<i class="fa fa-expand right"></i>
		</div>
	</div>

	<a id="reset" class="button" href="#">Reset</a>
</div>
</div><iframe style="display: none;" src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/pixel.html"></iframe><script src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/a.js" type="text/javascript"></script><script src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/a" type="text/javascript"></script><img src="11.%20Training%20Deep%20Neural%20Nets%20-%20Hands-On%20Machine%20Learning%20with%20Scikit-Learn%20and%20TensorFlow_files/seg.gif" alt="" style="display: none;" width="1" height="1" border="0"></body></html>